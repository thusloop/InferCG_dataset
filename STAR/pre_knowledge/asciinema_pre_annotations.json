{
    "asciinema.api": {
        "API_name": "asciinema.api",
        "loc_name": "asciinema.api",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.api",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.api.APIError": {
        "API_name": "asciinema.api.APIError",
        "loc_name": "asciinema.api.APIError",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.api",
        "lineno": 11,
        "namespace": "APIError",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.api.Api": {
        "API_name": "asciinema.api.Api",
        "loc_name": "asciinema.api.Api",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.api",
        "lineno": 15,
        "namespace": "Api",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.api.Api.__init__": {
        "API_name": "asciinema.api.Api.__init__",
        "loc_name": "asciinema.api.Api.__init__",
        "args": "self;url;user;install_id;http_adapter",
        "args_default": 1,
        "filepath": "asciinema.api",
        "lineno": 17,
        "namespace": "Api",
        "body": "    def __init__(self, url, user, install_id, http_adapter=None):\n        self.url = url\n        self.user = user\n        self.install_id = install_id\n        self.http_adapter = http_adapter if http_adapter is not None else URLLibHttpAdapter()",
        "name_type": "local_name"
    },
    "asciinema.api.Api.hostname": {
        "API_name": "asciinema.api.Api.hostname",
        "loc_name": "asciinema.api.Api.hostname",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 23,
        "namespace": "Api",
        "body": "    def hostname(self):\n        return urlparse(self.url).hostname",
        "name_type": "local_name"
    },
    "asciinema.api.Api.auth_url": {
        "API_name": "asciinema.api.Api.auth_url",
        "loc_name": "asciinema.api.Api.auth_url",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 26,
        "namespace": "Api",
        "body": "    def auth_url(self):\n        return \"{}/connect/{}\".format(self.url, self.install_id)",
        "name_type": "local_name"
    },
    "asciinema.api.Api.upload_url": {
        "API_name": "asciinema.api.Api.upload_url",
        "loc_name": "asciinema.api.Api.upload_url",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 29,
        "namespace": "Api",
        "body": "    def upload_url(self):\n        return \"{}/api/asciicasts\".format(self.url)",
        "name_type": "local_name"
    },
    "asciinema.api.Api.upload_asciicast": {
        "API_name": "asciinema.api.Api.upload_asciicast",
        "loc_name": "asciinema.api.Api.upload_asciicast",
        "args": "self;path",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 32,
        "namespace": "Api",
        "body": "    def upload_asciicast(self, path):\n        with open(path, 'rb') as f:\n            try:\n                status, headers, body = self.http_adapter.post(\n                    self.upload_url(),\n                    files={\"asciicast\": (\"ascii.cast\", f)},\n                    headers=self._headers(),\n                    username=self.user,\n                    password=self.install_id\n                )\n            except HTTPConnectionError as e:\n                raise APIError(str(e))\n\n        if status != 200 and status != 201:\n            self._handle_error(status, body)\n\n        if (headers.get('content-type') or '')[0:16] == 'application/json':\n            result = json.loads(body)\n        else:\n            result = {'url': body}\n\n        return result, headers.get('Warning')",
        "name_type": "local_name"
    },
    "asciinema.api.Api._headers": {
        "API_name": "asciinema.api.Api._headers",
        "loc_name": "asciinema.api.Api._headers",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 55,
        "namespace": "Api",
        "body": "    def _headers(self):\n        return {'User-Agent': self._user_agent(), 'Accept': 'application/json'}",
        "name_type": "local_name"
    },
    "asciinema.api.Api._user_agent": {
        "API_name": "asciinema.api.Api._user_agent",
        "loc_name": "asciinema.api.Api._user_agent",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 58,
        "namespace": "Api",
        "body": "    def _user_agent(self):\n        os = re.sub('([^-]+)-(.*)', '\\\\1/\\\\2', platform.platform())\n\n        return 'asciinema/%s %s/%s %s' % (__version__,\n                                          platform.python_implementation(),\n                                          platform.python_version(),\n                                          os\n                                          )",
        "name_type": "local_name"
    },
    "asciinema.api.Api._handle_error": {
        "API_name": "asciinema.api.Api._handle_error",
        "loc_name": "asciinema.api.Api._handle_error",
        "args": "self;status;body",
        "args_default": 0,
        "filepath": "asciinema.api",
        "lineno": 67,
        "namespace": "Api",
        "body": "    def _handle_error(self, status, body):\n        errors = {\n            400: \"Invalid request: %s\" % body,\n            401: \"Invalid or revoked install ID\",\n            404: \"API endpoint not found. This asciinema version may no longer be supported. Please upgrade to the latest version.\",\n            413: \"Sorry, your asciicast is too big.\",\n            422: \"Invalid asciicast: %s\" % body,\n            503: \"The server is down for maintenance. Try again in a minute.\"\n        }\n\n        error = errors.get(status)\n\n        if not error:\n            if status >= 500:\n                error = \"The server is having temporary problems. Try again in a minute.\"\n            else:\n                error = \"HTTP status: %i\" % status\n\n        raise APIError(error)",
        "name_type": "local_name"
    },
    "asciinema.async_worker": {
        "API_name": "asciinema.async_worker",
        "loc_name": "asciinema.async_worker",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.async_worker",
        "lineno": "*",
        "namespace": "*",
        "body": "try:\n    # Importing synchronize is to detect platforms where\n    # multiprocessing does not work (python issue 3770)\n    # and cause an ImportError. Otherwise it will happen\n    # later when trying to use Queue().\n    from multiprocessing import synchronize, Process, Queue\nexcept ImportError:\n    from threading import Thread as Process\n    from queue import Queue",
        "name_type": "local_name"
    },
    "asciinema.async_worker.async_worker": {
        "API_name": "asciinema.async_worker.async_worker",
        "loc_name": "asciinema.async_worker.async_worker",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.async_worker",
        "lineno": 12,
        "namespace": "async_worker",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.async_worker.async_worker.__init__": {
        "API_name": "asciinema.async_worker.async_worker.__init__",
        "loc_name": "asciinema.async_worker.async_worker.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.async_worker",
        "lineno": 14,
        "namespace": "async_worker",
        "body": "    def __init__(self):\n        self.queue = Queue()",
        "name_type": "local_name"
    },
    "asciinema.async_worker.async_worker.__enter__": {
        "API_name": "asciinema.async_worker.async_worker.__enter__",
        "loc_name": "asciinema.async_worker.async_worker.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.async_worker",
        "lineno": 17,
        "namespace": "async_worker",
        "body": "    def __enter__(self):\n        self.process = Process(target=self.run)\n        self.process.start()\n        return self",
        "name_type": "local_name"
    },
    "asciinema.async_worker.async_worker.__exit__": {
        "API_name": "asciinema.async_worker.async_worker.__exit__",
        "loc_name": "asciinema.async_worker.async_worker.__exit__",
        "args": "self;exc_type;exc_value;exc_traceback",
        "args_default": 0,
        "filepath": "asciinema.async_worker",
        "lineno": 22,
        "namespace": "async_worker",
        "body": "    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.queue.put(None)\n        self.process.join()",
        "name_type": "local_name"
    },
    "asciinema.async_worker.async_worker.enqueue": {
        "API_name": "asciinema.async_worker.async_worker.enqueue",
        "loc_name": "asciinema.async_worker.async_worker.enqueue",
        "args": "self;payload",
        "args_default": 0,
        "filepath": "asciinema.async_worker",
        "lineno": 26,
        "namespace": "async_worker",
        "body": "    def enqueue(self, payload):\n        self.queue.put(payload)",
        "name_type": "local_name"
    },
    "asciinema.async_worker.async_worker.run": {
        "API_name": "asciinema.async_worker.async_worker.run",
        "loc_name": "asciinema.async_worker.async_worker.run",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.async_worker",
        "lineno": 29,
        "namespace": "async_worker",
        "body": "    def run(self):\n        for payload in iter(self.queue.get, None):\n            self.perform(payload)",
        "name_type": "local_name"
    },
    "asciinema.config": {
        "API_name": "asciinema.config",
        "loc_name": "asciinema.config",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.config",
        "lineno": "*",
        "namespace": "*",
        "body": "DEFAULT_API_URL = 'https://asciinema.org'\nDEFAULT_RECORD_ENV = 'SHELL,TERM'",
        "name_type": "local_name"
    },
    "asciinema.config.ConfigError": {
        "API_name": "asciinema.config.ConfigError",
        "loc_name": "asciinema.config.ConfigError",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.config",
        "lineno": 8,
        "namespace": "ConfigError",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.config.Config": {
        "API_name": "asciinema.config.Config",
        "loc_name": "asciinema.config.Config",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.config",
        "lineno": 16,
        "namespace": "Config",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__init__": {
        "API_name": "asciinema.config.Config.__init__",
        "loc_name": "asciinema.config.Config.__init__",
        "args": "self;config_home;env",
        "args_default": 1,
        "filepath": "asciinema.config",
        "lineno": 18,
        "namespace": "Config",
        "body": "    def __init__(self, config_home, env=None):\n        self.config_home = config_home\n        self.config_file_path = path.join(config_home, \"config\")\n        self.install_id_path = path.join(self.config_home, 'install-id')\n        self.config = configparser.ConfigParser()\n        self.config.read(self.config_file_path)\n        self.env = env if env is not None else os.environ",
        "name_type": "local_name"
    },
    "asciinema.config.Config.upgrade": {
        "API_name": "asciinema.config.Config.upgrade",
        "loc_name": "asciinema.config.Config.upgrade",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 26,
        "namespace": "Config",
        "body": "    def upgrade(self):\n        try:\n            self.install_id\n        except ConfigError:\n            id = self.__api_token() or self.__user_token() or self.__gen_install_id()\n            self.__save_install_id(id)\n\n            items = {name: dict(section) for (name, section) in self.config.items()}\n            if items == {'DEFAULT': {}, 'api': {'token': id}} or items == {'DEFAULT': {}, 'user': {'token': id}}:\n                os.remove(self.config_file_path)\n\n        if self.env.get('ASCIINEMA_API_TOKEN'):\n            raise ConfigError('ASCIINEMA_API_TOKEN variable is no longer supported, please use ASCIINEMA_INSTALL_ID instead')",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__read_install_id": {
        "API_name": "asciinema.config.Config.__read_install_id",
        "loc_name": "asciinema.config.Config.__read_install_id",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 40,
        "namespace": "Config",
        "body": "    def __read_install_id(self):\n        p = self.install_id_path\n        if path.isfile(p):\n            with open(p, 'r') as f:\n                return f.read().strip()",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__gen_install_id": {
        "API_name": "asciinema.config.Config.__gen_install_id",
        "loc_name": "asciinema.config.Config.__gen_install_id",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 46,
        "namespace": "Config",
        "body": "    def __gen_install_id(self):\n        return str(uuid.uuid4())",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__save_install_id": {
        "API_name": "asciinema.config.Config.__save_install_id",
        "loc_name": "asciinema.config.Config.__save_install_id",
        "args": "self;id",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 49,
        "namespace": "Config",
        "body": "    def __save_install_id(self, id):\n        self.__create_config_home()\n\n        with open(self.install_id_path, 'w') as f:\n            f.write(id)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__create_config_home": {
        "API_name": "asciinema.config.Config.__create_config_home",
        "loc_name": "asciinema.config.Config.__create_config_home",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 55,
        "namespace": "Config",
        "body": "    def __create_config_home(self):\n        if not path.exists(self.config_home):\n            os.makedirs(self.config_home)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__api_token": {
        "API_name": "asciinema.config.Config.__api_token",
        "loc_name": "asciinema.config.Config.__api_token",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 59,
        "namespace": "Config",
        "body": "    def __api_token(self):\n        try:\n            return self.config.get('api', 'token')\n        except (configparser.NoOptionError, configparser.NoSectionError):\n            pass",
        "name_type": "local_name"
    },
    "asciinema.config.Config.__user_token": {
        "API_name": "asciinema.config.Config.__user_token",
        "loc_name": "asciinema.config.Config.__user_token",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 65,
        "namespace": "Config",
        "body": "    def __user_token(self):\n        try:\n            return self.config.get('user', 'token')\n        except (configparser.NoOptionError, configparser.NoSectionError):\n            pass",
        "name_type": "local_name"
    },
    "asciinema.config.Config.install_id": {
        "API_name": "asciinema.config.Config.install_id",
        "loc_name": "asciinema.config.Config.install_id",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 72,
        "namespace": "Config",
        "body": "    def install_id(self):\n        id = self.env.get('ASCIINEMA_INSTALL_ID') or self.__read_install_id()\n\n        if id:\n            return id\n        else:\n            raise ConfigError('no install ID found')",
        "name_type": "local_name"
    },
    "asciinema.config.Config.api_url": {
        "API_name": "asciinema.config.Config.api_url",
        "loc_name": "asciinema.config.Config.api_url",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 81,
        "namespace": "Config",
        "body": "    def api_url(self):\n        return self.env.get(\n            'ASCIINEMA_API_URL',\n            self.config.get('api', 'url', fallback=DEFAULT_API_URL)\n        )",
        "name_type": "local_name"
    },
    "asciinema.config.Config.record_stdin": {
        "API_name": "asciinema.config.Config.record_stdin",
        "loc_name": "asciinema.config.Config.record_stdin",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 88,
        "namespace": "Config",
        "body": "    def record_stdin(self):\n        return self.config.getboolean('record', 'stdin', fallback=False)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.record_command": {
        "API_name": "asciinema.config.Config.record_command",
        "loc_name": "asciinema.config.Config.record_command",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 92,
        "namespace": "Config",
        "body": "    def record_command(self):\n        return self.config.get('record', 'command', fallback=None)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.record_env": {
        "API_name": "asciinema.config.Config.record_env",
        "loc_name": "asciinema.config.Config.record_env",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 96,
        "namespace": "Config",
        "body": "    def record_env(self):\n        return self.config.get('record', 'env', fallback=DEFAULT_RECORD_ENV)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.record_idle_time_limit": {
        "API_name": "asciinema.config.Config.record_idle_time_limit",
        "loc_name": "asciinema.config.Config.record_idle_time_limit",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 100,
        "namespace": "Config",
        "body": "    def record_idle_time_limit(self):\n        fallback = self.config.getfloat('record', 'maxwait', fallback=None)  # pre 2.0\n        return self.config.getfloat('record', 'idle_time_limit', fallback=fallback)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.record_yes": {
        "API_name": "asciinema.config.Config.record_yes",
        "loc_name": "asciinema.config.Config.record_yes",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 105,
        "namespace": "Config",
        "body": "    def record_yes(self):\n        return self.config.getboolean('record', 'yes', fallback=False)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.record_quiet": {
        "API_name": "asciinema.config.Config.record_quiet",
        "loc_name": "asciinema.config.Config.record_quiet",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 109,
        "namespace": "Config",
        "body": "    def record_quiet(self):\n        return self.config.getboolean('record', 'quiet', fallback=False)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.play_idle_time_limit": {
        "API_name": "asciinema.config.Config.play_idle_time_limit",
        "loc_name": "asciinema.config.Config.play_idle_time_limit",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 113,
        "namespace": "Config",
        "body": "    def play_idle_time_limit(self):\n        fallback = self.config.getfloat('play', 'maxwait', fallback=None)  # pre 2.0\n        return self.config.getfloat('play', 'idle_time_limit', fallback=fallback)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.play_speed": {
        "API_name": "asciinema.config.Config.play_speed",
        "loc_name": "asciinema.config.Config.play_speed",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 118,
        "namespace": "Config",
        "body": "    def play_speed(self):\n        return self.config.getfloat('play', 'speed', fallback=1.0)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.notifications_enabled": {
        "API_name": "asciinema.config.Config.notifications_enabled",
        "loc_name": "asciinema.config.Config.notifications_enabled",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 122,
        "namespace": "Config",
        "body": "    def notifications_enabled(self):\n        return self.config.getboolean('notifications', 'enabled', fallback=True)",
        "name_type": "local_name"
    },
    "asciinema.config.Config.notifications_command": {
        "API_name": "asciinema.config.Config.notifications_command",
        "loc_name": "asciinema.config.Config.notifications_command",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.config",
        "lineno": 126,
        "namespace": "Config",
        "body": "    def notifications_command(self):\n        return self.config.get('notifications', 'command', fallback=None)",
        "name_type": "local_name"
    },
    "asciinema.config.get_config_home": {
        "API_name": "asciinema.config.get_config_home",
        "loc_name": "asciinema.config.get_config_home",
        "args": "env",
        "args_default": 1,
        "filepath": "asciinema.config",
        "lineno": 130,
        "namespace": "*",
        "body": "def get_config_home(env=os.environ):\n    env_asciinema_config_home = env.get(\"ASCIINEMA_CONFIG_HOME\")\n    env_xdg_config_home = env.get(\"XDG_CONFIG_HOME\")\n    env_home = env.get(\"HOME\")\n\n    config_home = None\n\n    if env_asciinema_config_home:\n        config_home = env_asciinema_config_home\n    elif env_xdg_config_home:\n        config_home = path.join(env_xdg_config_home, \"asciinema\")\n    elif env_home:\n        if path.isfile(path.join(env_home, \".asciinema\", \"config\")):\n            # location for versions < 1.1\n            config_home = path.join(env_home, \".asciinema\")\n        else:\n            config_home = path.join(env_home, \".config\", \"asciinema\")\n    else:\n        raise Exception(\"need $HOME or $XDG_CONFIG_HOME or $ASCIINEMA_CONFIG_HOME\")\n\n    return config_home",
        "name_type": "local_name"
    },
    "asciinema.config.load": {
        "API_name": "asciinema.config.load",
        "loc_name": "asciinema.config.load",
        "args": "env",
        "args_default": 1,
        "filepath": "asciinema.config",
        "lineno": 153,
        "namespace": "*",
        "body": "def load(env=os.environ):\n    config = Config(get_config_home(env), env)\n    config.upgrade()\n    return config",
        "name_type": "local_name"
    },
    "asciinema.http_adapter": {
        "API_name": "asciinema.http_adapter",
        "loc_name": "asciinema.http_adapter",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.http_adapter",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.http_adapter.HTTPConnectionError": {
        "API_name": "asciinema.http_adapter.HTTPConnectionError",
        "loc_name": "asciinema.http_adapter.HTTPConnectionError",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.http_adapter",
        "lineno": 1,
        "namespace": "HTTPConnectionError",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier": {
        "API_name": "asciinema.notifier",
        "loc_name": "asciinema.notifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.Notifier.is_available": {
        "API_name": "asciinema.notifier.Notifier.is_available",
        "loc_name": "asciinema.notifier.Notifier.is_available",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 7,
        "namespace": "Notifier",
        "body": "    def is_available(self):\n        return shutil.which(self.cmd) is not None",
        "name_type": "local_name"
    },
    "asciinema.notifier.Notifier.notify": {
        "API_name": "asciinema.notifier.Notifier.notify",
        "loc_name": "asciinema.notifier.Notifier.notify",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 10,
        "namespace": "Notifier",
        "body": "    def notify(self, text):\n        subprocess.run(self.args(text), capture_output=True)",
        "name_type": "local_name"
    },
    "asciinema.notifier.Notifier.get_icon_path": {
        "API_name": "asciinema.notifier.Notifier.get_icon_path",
        "loc_name": "asciinema.notifier.Notifier.get_icon_path",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 15,
        "namespace": "Notifier",
        "body": "    def get_icon_path(self):\n        path = os.path.join(os.path.dirname(os.path.realpath(__file__)), \"data/icon-256x256.png\")\n\n        if os.path.exists(path):\n            return path",
        "name_type": "local_name"
    },
    "asciinema.notifier.Notifier": {
        "API_name": "asciinema.notifier.Notifier",
        "loc_name": "asciinema.notifier.Notifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": 6,
        "namespace": "Notifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.AppleScriptNotifier.args": {
        "API_name": "asciinema.notifier.AppleScriptNotifier.args",
        "loc_name": "asciinema.notifier.AppleScriptNotifier.args",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 25,
        "namespace": "AppleScriptNotifier",
        "body": "    def args(self, text):\n        text = text.replace('\"', '\\\\\"')\n        return ['osascript', '-e', 'display notification \"{}\" with title \"asciinema\"'.format(text)]",
        "name_type": "local_name"
    },
    "asciinema.notifier.AppleScriptNotifier": {
        "API_name": "asciinema.notifier.AppleScriptNotifier",
        "loc_name": "asciinema.notifier.AppleScriptNotifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": 22,
        "namespace": "AppleScriptNotifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.LibNotifyNotifier.args": {
        "API_name": "asciinema.notifier.LibNotifyNotifier.args",
        "loc_name": "asciinema.notifier.LibNotifyNotifier.args",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 33,
        "namespace": "LibNotifyNotifier",
        "body": "    def args(self, text):\n        icon_path = self.get_icon_path()\n\n        if icon_path is not None:\n            return ['notify-send', '-i', icon_path, 'asciinema', text]\n        else:\n            return ['notify-send', 'asciinema', text]",
        "name_type": "local_name"
    },
    "asciinema.notifier.LibNotifyNotifier": {
        "API_name": "asciinema.notifier.LibNotifyNotifier",
        "loc_name": "asciinema.notifier.LibNotifyNotifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": 30,
        "namespace": "LibNotifyNotifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.TerminalNotifier.args": {
        "API_name": "asciinema.notifier.TerminalNotifier.args",
        "loc_name": "asciinema.notifier.TerminalNotifier.args",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 45,
        "namespace": "TerminalNotifier",
        "body": "    def args(self, text):\n        icon_path = self.get_icon_path()\n\n        if icon_path is not None:\n            return ['terminal-notifier', '-title', 'asciinema', '-message', text, '-appIcon', icon_path]\n        else:\n            return ['terminal-notifier', '-title', 'asciinema', '-message', text]",
        "name_type": "local_name"
    },
    "asciinema.notifier.TerminalNotifier": {
        "API_name": "asciinema.notifier.TerminalNotifier",
        "loc_name": "asciinema.notifier.TerminalNotifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": 42,
        "namespace": "TerminalNotifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.CustomCommandNotifier": {
        "API_name": "asciinema.notifier.CustomCommandNotifier",
        "loc_name": "asciinema.notifier.CustomCommandNotifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": 54,
        "namespace": "CustomCommandNotifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.CustomCommandNotifier.__init__": {
        "API_name": "asciinema.notifier.CustomCommandNotifier.__init__",
        "loc_name": "asciinema.notifier.CustomCommandNotifier.__init__",
        "args": "self;command",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 55,
        "namespace": "CustomCommandNotifier",
        "body": "    def __init__(self, command):\n        Notifier.__init__(self)\n        self.command = command",
        "name_type": "local_name"
    },
    "asciinema.notifier.CustomCommandNotifier.notify": {
        "API_name": "asciinema.notifier.CustomCommandNotifier.notify",
        "loc_name": "asciinema.notifier.CustomCommandNotifier.notify",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 59,
        "namespace": "CustomCommandNotifier",
        "body": "    def notify(self, text):\n        args = ['/bin/sh', '-c', self.command]\n        env = os.environ.copy()\n        env['TEXT'] = text\n        env['ICON_PATH'] = self.get_icon_path()\n        subprocess.run(args, env=env, capture_output=True)",
        "name_type": "local_name"
    },
    "asciinema.notifier.NoopNotifier.notify": {
        "API_name": "asciinema.notifier.NoopNotifier.notify",
        "loc_name": "asciinema.notifier.NoopNotifier.notify",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.notifier",
        "lineno": 68,
        "namespace": "NoopNotifier",
        "body": "    def notify(self, text):\n        pass",
        "name_type": "local_name"
    },
    "asciinema.notifier.NoopNotifier": {
        "API_name": "asciinema.notifier.NoopNotifier",
        "loc_name": "asciinema.notifier.NoopNotifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.notifier",
        "lineno": 67,
        "namespace": "NoopNotifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.notifier.get_notifier": {
        "API_name": "asciinema.notifier.get_notifier",
        "loc_name": "asciinema.notifier.get_notifier",
        "args": "enabled;command",
        "args_default": 2,
        "filepath": "asciinema.notifier",
        "lineno": 72,
        "namespace": "*",
        "body": "def get_notifier(enabled=True, command=None):\n    if enabled:\n        if command:\n            return CustomCommandNotifier(command)\n        else:\n            for c in [TerminalNotifier, AppleScriptNotifier, LibNotifyNotifier]:\n                n = c()\n\n                if n.is_available():\n                    return n\n\n    return NoopNotifier()",
        "name_type": "local_name"
    },
    "asciinema.player": {
        "API_name": "asciinema.player",
        "loc_name": "asciinema.player",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.player",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.player.Player.play": {
        "API_name": "asciinema.player.Player.play",
        "loc_name": "asciinema.player.Player.play",
        "args": "self;asciicast;idle_time_limit;speed",
        "args_default": 2,
        "filepath": "asciinema.player",
        "lineno": 11,
        "namespace": "Player",
        "body": "    def play(self, asciicast, idle_time_limit=None, speed=1.0):\n        try:\n            stdin = open('/dev/tty')\n            with raw(stdin.fileno()):\n                self._play(asciicast, idle_time_limit, speed, stdin)\n        except Exception:\n            self._play(asciicast, idle_time_limit, speed, None)",
        "name_type": "local_name"
    },
    "asciinema.player.Player._play": {
        "API_name": "asciinema.player.Player._play",
        "loc_name": "asciinema.player.Player._play",
        "args": "self;asciicast;idle_time_limit;speed;stdin",
        "args_default": 0,
        "filepath": "asciinema.player",
        "lineno": 19,
        "namespace": "Player",
        "body": "    def _play(self, asciicast, idle_time_limit, speed, stdin):\n        idle_time_limit = idle_time_limit or asciicast.idle_time_limit\n\n        stdout = asciicast.stdout_events()\n        stdout = ev.to_relative_time(stdout)\n        stdout = ev.cap_relative_time(stdout, idle_time_limit)\n        stdout = ev.to_absolute_time(stdout)\n        stdout = ev.adjust_speed(stdout, speed)\n\n        base_time = time.time()\n        ctrl_c = False\n        paused = False\n        pause_time = None\n\n        for t, _type, text in stdout:\n            delay = t - (time.time() - base_time)\n\n            while stdin and not ctrl_c and delay > 0:\n                if paused:\n                    while True:\n                        data = read_blocking(stdin.fileno(), 1000)\n\n                        if 0x03 in data:  # ctrl-c\n                            ctrl_c = True\n                            break\n\n                        if 0x20 in data:  # space\n                            paused = False\n                            base_time = base_time + (time.time() - pause_time)\n                            break\n\n                        if 0x2e in data:  # period (dot)\n                            delay = 0\n                            pause_time = time.time()\n                            base_time = pause_time - t\n                            break\n                else:\n                    data = read_blocking(stdin.fileno(), delay)\n\n                    if not data:\n                        break\n\n                    if 0x03 in data:  # ctrl-c\n                        ctrl_c = True\n                        break\n\n                    if 0x20 in data:  # space\n                        paused = True\n                        pause_time = time.time()\n                        slept = t - (pause_time - base_time)\n                        delay = delay - slept\n\n            if ctrl_c:\n                break\n\n            sys.stdout.write(text)\n            sys.stdout.flush()",
        "name_type": "local_name"
    },
    "asciinema.player.Player": {
        "API_name": "asciinema.player.Player",
        "loc_name": "asciinema.player.Player",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.player",
        "lineno": 9,
        "namespace": "Player",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.pty": {
        "API_name": "asciinema.pty",
        "loc_name": "asciinema.pty",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.pty",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.pty.record": {
        "API_name": "asciinema.pty.record",
        "loc_name": "asciinema.pty.record",
        "args": "command;writer;env;rec_stdin;time_offset;notifier",
        "args_default": 4,
        "filepath": "asciinema.pty",
        "lineno": 18,
        "namespace": "*",
        "body": "def record(command, writer, env=os.environ, rec_stdin=False, time_offset=0, notifier=None):\n    master_fd = None\n    start_time = None\n    pause_time = None\n\n    def _notify(text):\n        if notifier:\n            notifier.notify(text)\n\n    def _set_pty_size():\n        '''\n        Sets the window size of the child pty based on the window size\n        of our own controlling terminal.\n        '''\n\n        # Get the terminal size of the real terminal, set it on the pseudoterminal.\n        if os.isatty(pty.STDOUT_FILENO):\n            buf = array.array('h', [0, 0, 0, 0])\n            fcntl.ioctl(pty.STDOUT_FILENO, termios.TIOCGWINSZ, buf, True)\n        else:\n            buf = array.array('h', [24, 80, 0, 0])\n\n        fcntl.ioctl(master_fd, termios.TIOCSWINSZ, buf)\n\n    def _write_stdout(data):\n        '''Writes to stdout as if the child process had written the data.'''\n\n        os.write(pty.STDOUT_FILENO, data)\n\n    def _handle_master_read(data):\n        '''Handles new data on child process stdout.'''\n\n        if not pause_time:\n            writer.write_stdout(time.time() - start_time, data)\n\n        _write_stdout(data)\n\n    def _write_master(data):\n        '''Writes to the child process from its controlling terminal.'''\n\n        while data:\n            n = os.write(master_fd, data)\n            data = data[n:]\n\n    def _handle_stdin_read(data):\n        '''Handles new data on child process stdin.'''\n\n        nonlocal pause_time\n        nonlocal start_time\n\n        if data == b'\\x10':  # ctrl+p\n            if pause_time:\n                start_time = start_time + (time.time() - pause_time)\n                pause_time = None\n                _notify('Resumed recording')\n            else:\n                pause_time = time.time()\n                _notify('Paused recording')\n        else:\n            _write_master(data)\n\n            if rec_stdin and not pause_time:\n                writer.write_stdin(time.time() - start_time, data)\n\n    def _signals(signal_list):\n        old_handlers = []\n        for sig, handler in signal_list:\n            old_handlers.append((sig, signal.signal(sig, handler)))\n        return old_handlers\n\n    def _copy(signal_fd):\n        '''Main select loop.\n\n        Passes control to _master_read() or _stdin_read()\n        when new data arrives.\n        '''\n\n        fds = [master_fd, pty.STDIN_FILENO, signal_fd]\n\n        while True:\n            try:\n                rfds, wfds, xfds = select.select(fds, [], [])\n            except OSError as e:  # Python >= 3.3\n                if e.errno == errno.EINTR:\n                    continue\n            except select.error as e:  # Python < 3.3\n                if e.args[0] == 4:\n                    continue\n\n            if master_fd in rfds:\n                data = os.read(master_fd, 1024)\n                if not data:  # Reached EOF.\n                    fds.remove(master_fd)\n                else:\n                    _handle_master_read(data)\n\n            if pty.STDIN_FILENO in rfds:\n                data = os.read(pty.STDIN_FILENO, 1024)\n                if not data:\n                    fds.remove(pty.STDIN_FILENO)\n                else:\n                    _handle_stdin_read(data)\n\n            if signal_fd in rfds:\n                data = os.read(signal_fd, 1024)\n                if data:\n                    signals = struct.unpack('%uB' % len(data), data)\n                    for sig in signals:\n                        if sig in [signal.SIGCHLD, signal.SIGHUP, signal.SIGTERM, signal.SIGQUIT]:\n                            os.close(master_fd)\n                            return\n                        elif sig == signal.SIGWINCH:\n                            _set_pty_size()\n\n    pid, master_fd = pty.fork()\n\n    if pid == pty.CHILD:\n        os.execvpe(command[0], command, env)\n\n    pipe_r, pipe_w = os.pipe()\n    flags = fcntl.fcntl(pipe_w, fcntl.F_GETFL, 0)\n    flags = flags | os.O_NONBLOCK\n    flags = fcntl.fcntl(pipe_w, fcntl.F_SETFL, flags)\n\n    signal.set_wakeup_fd(pipe_w)\n\n    old_handlers = _signals(map(lambda s: (s, lambda signal, frame: None),\n                                [signal.SIGWINCH,\n                                    signal.SIGCHLD,\n                                    signal.SIGHUP,\n                                    signal.SIGTERM,\n                                    signal.SIGQUIT]))\n\n    _set_pty_size()\n\n    start_time = time.time() - time_offset\n\n    with raw(pty.STDIN_FILENO):\n        try:\n            _copy(pipe_r)\n        except (IOError, OSError):\n            pass\n\n    _signals(old_handlers)\n\n    os.waitpid(pid, 0)",
        "name_type": "local_name"
    },
    "asciinema.pty.record._notify": {
        "API_name": "asciinema.pty.record._notify",
        "loc_name": "asciinema.pty.record._notify",
        "args": "text",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 23,
        "namespace": "*",
        "body": "    def _notify(text):\n        if notifier:\n            notifier.notify(text)",
        "name_type": "local_name"
    },
    "asciinema.pty.record._set_pty_size": {
        "API_name": "asciinema.pty.record._set_pty_size",
        "loc_name": "asciinema.pty.record._set_pty_size",
        "args": "",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 27,
        "namespace": "*",
        "body": "    def _set_pty_size():\n        '''\n        Sets the window size of the child pty based on the window size\n        of our own controlling terminal.\n        '''\n\n        # Get the terminal size of the real terminal, set it on the pseudoterminal.\n        if os.isatty(pty.STDOUT_FILENO):\n            buf = array.array('h', [0, 0, 0, 0])\n            fcntl.ioctl(pty.STDOUT_FILENO, termios.TIOCGWINSZ, buf, True)\n        else:\n            buf = array.array('h', [24, 80, 0, 0])\n\n        fcntl.ioctl(master_fd, termios.TIOCSWINSZ, buf)",
        "name_type": "local_name"
    },
    "asciinema.pty.record._write_stdout": {
        "API_name": "asciinema.pty.record._write_stdout",
        "loc_name": "asciinema.pty.record._write_stdout",
        "args": "data",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 42,
        "namespace": "*",
        "body": "    def _write_stdout(data):\n        '''Writes to stdout as if the child process had written the data.'''\n\n        os.write(pty.STDOUT_FILENO, data)",
        "name_type": "local_name"
    },
    "asciinema.pty.record._handle_master_read": {
        "API_name": "asciinema.pty.record._handle_master_read",
        "loc_name": "asciinema.pty.record._handle_master_read",
        "args": "data",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 47,
        "namespace": "*",
        "body": "    def _handle_master_read(data):\n        '''Handles new data on child process stdout.'''\n\n        if not pause_time:\n            writer.write_stdout(time.time() - start_time, data)\n\n        _write_stdout(data)",
        "name_type": "local_name"
    },
    "asciinema.pty.record._write_master": {
        "API_name": "asciinema.pty.record._write_master",
        "loc_name": "asciinema.pty.record._write_master",
        "args": "data",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 55,
        "namespace": "*",
        "body": "    def _write_master(data):\n        '''Writes to the child process from its controlling terminal.'''\n\n        while data:\n            n = os.write(master_fd, data)\n            data = data[n:]",
        "name_type": "local_name"
    },
    "asciinema.pty.record._handle_stdin_read": {
        "API_name": "asciinema.pty.record._handle_stdin_read",
        "loc_name": "asciinema.pty.record._handle_stdin_read",
        "args": "data",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 62,
        "namespace": "*",
        "body": "    def _handle_stdin_read(data):\n        '''Handles new data on child process stdin.'''\n\n        nonlocal pause_time\n        nonlocal start_time\n\n        if data == b'\\x10':  # ctrl+p\n            if pause_time:\n                start_time = start_time + (time.time() - pause_time)\n                pause_time = None\n                _notify('Resumed recording')\n            else:\n                pause_time = time.time()\n                _notify('Paused recording')\n        else:\n            _write_master(data)\n\n            if rec_stdin and not pause_time:\n                writer.write_stdin(time.time() - start_time, data)",
        "name_type": "local_name"
    },
    "asciinema.pty.record._signals": {
        "API_name": "asciinema.pty.record._signals",
        "loc_name": "asciinema.pty.record._signals",
        "args": "signal_list",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 82,
        "namespace": "*",
        "body": "    def _signals(signal_list):\n        old_handlers = []\n        for sig, handler in signal_list:\n            old_handlers.append((sig, signal.signal(sig, handler)))\n        return old_handlers",
        "name_type": "local_name"
    },
    "asciinema.pty.record._copy": {
        "API_name": "asciinema.pty.record._copy",
        "loc_name": "asciinema.pty.record._copy",
        "args": "signal_fd",
        "args_default": 0,
        "filepath": "asciinema.pty",
        "lineno": 88,
        "namespace": "*",
        "body": "    def _copy(signal_fd):\n        '''Main select loop.\n\n        Passes control to _master_read() or _stdin_read()\n        when new data arrives.\n        '''\n\n        fds = [master_fd, pty.STDIN_FILENO, signal_fd]\n\n        while True:\n            try:\n                rfds, wfds, xfds = select.select(fds, [], [])\n            except OSError as e:  # Python >= 3.3\n                if e.errno == errno.EINTR:\n                    continue\n            except select.error as e:  # Python < 3.3\n                if e.args[0] == 4:\n                    continue\n\n            if master_fd in rfds:\n                data = os.read(master_fd, 1024)\n                if not data:  # Reached EOF.\n                    fds.remove(master_fd)\n                else:\n                    _handle_master_read(data)\n\n            if pty.STDIN_FILENO in rfds:\n                data = os.read(pty.STDIN_FILENO, 1024)\n                if not data:\n                    fds.remove(pty.STDIN_FILENO)\n                else:\n                    _handle_stdin_read(data)\n\n            if signal_fd in rfds:\n                data = os.read(signal_fd, 1024)\n                if data:\n                    signals = struct.unpack('%uB' % len(data), data)\n                    for sig in signals:\n                        if sig in [signal.SIGCHLD, signal.SIGHUP, signal.SIGTERM, signal.SIGQUIT]:\n                            os.close(master_fd)\n                            return\n                        elif sig == signal.SIGWINCH:\n                            _set_pty_size()",
        "name_type": "local_name"
    },
    "asciinema.recorder": {
        "API_name": "asciinema.recorder",
        "loc_name": "asciinema.recorder",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.recorder",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.recorder.record": {
        "API_name": "asciinema.recorder.record",
        "loc_name": "asciinema.recorder.record",
        "args": "path;command;append;idle_time_limit;rec_stdin;title;metadata;command_env;capture_env;writer;record;notifier",
        "args_default": 11,
        "filepath": "asciinema.recorder",
        "lineno": 10,
        "namespace": "*",
        "body": "def record(path, command=None, append=False, idle_time_limit=None,\n           rec_stdin=False, title=None, metadata=None, command_env=None,\n           capture_env=None, writer=v2.writer, record=pty.record, notifier=None):\n    if command is None:\n        command = os.environ.get('SHELL') or 'sh'\n\n    if command_env is None:\n        command_env = os.environ.copy()\n        command_env['ASCIINEMA_REC'] = '1'\n\n    if capture_env is None:\n        capture_env = ['SHELL', 'TERM']\n\n    w, h = term.get_size()\n\n    full_metadata = {\n        'width': w,\n        'height': h,\n        'timestamp': int(time.time())\n    }\n\n    full_metadata.update(metadata or {})\n\n    if idle_time_limit is not None:\n        full_metadata['idle_time_limit'] = idle_time_limit\n\n    if capture_env:\n        full_metadata['env'] = {var: command_env.get(var) for var in capture_env}\n\n    if title:\n        full_metadata['title'] = title\n\n    time_offset = 0\n\n    if append and os.stat(path).st_size > 0:\n        time_offset = v2.get_duration(path)\n\n    with async_writer(writer, path, full_metadata, append) as w:\n        with async_notifier(notifier) as n:\n            record(\n                ['sh', '-c', command],\n                w,\n                command_env,\n                rec_stdin,\n                time_offset,\n                n\n            )",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_writer": {
        "API_name": "asciinema.recorder.async_writer",
        "loc_name": "asciinema.recorder.async_writer",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.recorder",
        "lineno": 59,
        "namespace": "async_writer",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_writer.__init__": {
        "API_name": "asciinema.recorder.async_writer.__init__",
        "loc_name": "asciinema.recorder.async_writer.__init__",
        "args": "self;writer;path;metadata;append",
        "args_default": 1,
        "filepath": "asciinema.recorder",
        "lineno": 60,
        "namespace": "async_writer",
        "body": "    def __init__(self, writer, path, metadata, append=False):\n        async_worker.__init__(self)\n        self.writer = writer\n        self.path = path\n        self.metadata = metadata\n        self.append = append",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_writer.write_stdin": {
        "API_name": "asciinema.recorder.async_writer.write_stdin",
        "loc_name": "asciinema.recorder.async_writer.write_stdin",
        "args": "self;ts;data",
        "args_default": 0,
        "filepath": "asciinema.recorder",
        "lineno": 67,
        "namespace": "async_writer",
        "body": "    def write_stdin(self, ts, data):\n        self.enqueue([ts, 'i', data])",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_writer.write_stdout": {
        "API_name": "asciinema.recorder.async_writer.write_stdout",
        "loc_name": "asciinema.recorder.async_writer.write_stdout",
        "args": "self;ts;data",
        "args_default": 0,
        "filepath": "asciinema.recorder",
        "lineno": 70,
        "namespace": "async_writer",
        "body": "    def write_stdout(self, ts, data):\n        self.enqueue([ts, 'o', data])",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_writer.run": {
        "API_name": "asciinema.recorder.async_writer.run",
        "loc_name": "asciinema.recorder.async_writer.run",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.recorder",
        "lineno": 73,
        "namespace": "async_writer",
        "body": "    def run(self):\n        with self.writer(self.path, metadata=self.metadata, append=self.append) as w:\n            for event in iter(self.queue.get, None):\n                ts, etype, data = event\n\n                if etype == 'o':\n                    w.write_stdout(ts, data)\n                elif etype == 'i':\n                    w.write_stdin(ts, data)",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_notifier": {
        "API_name": "asciinema.recorder.async_notifier",
        "loc_name": "asciinema.recorder.async_notifier",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.recorder",
        "lineno": 84,
        "namespace": "async_notifier",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_notifier.__init__": {
        "API_name": "asciinema.recorder.async_notifier.__init__",
        "loc_name": "asciinema.recorder.async_notifier.__init__",
        "args": "self;notifier",
        "args_default": 0,
        "filepath": "asciinema.recorder",
        "lineno": 85,
        "namespace": "async_notifier",
        "body": "    def __init__(self, notifier):\n        async_worker.__init__(self)\n        self.notifier = notifier",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_notifier.notify": {
        "API_name": "asciinema.recorder.async_notifier.notify",
        "loc_name": "asciinema.recorder.async_notifier.notify",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.recorder",
        "lineno": 89,
        "namespace": "async_notifier",
        "body": "    def notify(self, text):\n        self.enqueue(text)",
        "name_type": "local_name"
    },
    "asciinema.recorder.async_notifier.perform": {
        "API_name": "asciinema.recorder.async_notifier.perform",
        "loc_name": "asciinema.recorder.async_notifier.perform",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.recorder",
        "lineno": 92,
        "namespace": "async_notifier",
        "body": "    def perform(self, text):\n        try:\n            if self.notifier:\n                self.notifier.notify(text)\n        except:\n            # we catch *ALL* exceptions here because we don't want failed\n            # notification to crash the recording session\n            pass",
        "name_type": "local_name"
    },
    "asciinema.term": {
        "API_name": "asciinema.term",
        "loc_name": "asciinema.term",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.term",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.term.raw": {
        "API_name": "asciinema.term.raw",
        "loc_name": "asciinema.term.raw",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.term",
        "lineno": 7,
        "namespace": "raw",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.term.raw.__init__": {
        "API_name": "asciinema.term.raw.__init__",
        "loc_name": "asciinema.term.raw.__init__",
        "args": "self;fd",
        "args_default": 0,
        "filepath": "asciinema.term",
        "lineno": 8,
        "namespace": "raw",
        "body": "    def __init__(self, fd):\n        self.fd = fd\n        self.restore = False",
        "name_type": "local_name"
    },
    "asciinema.term.raw.__enter__": {
        "API_name": "asciinema.term.raw.__enter__",
        "loc_name": "asciinema.term.raw.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.term",
        "lineno": 12,
        "namespace": "raw",
        "body": "    def __enter__(self):\n        try:\n            self.mode = tty.tcgetattr(self.fd)\n            tty.setraw(self.fd)\n            self.restore = True\n        except tty.error:  # This is the same as termios.error\n            pass",
        "name_type": "local_name"
    },
    "asciinema.term.raw.__exit__": {
        "API_name": "asciinema.term.raw.__exit__",
        "loc_name": "asciinema.term.raw.__exit__",
        "args": "self;type;value;traceback",
        "args_default": 0,
        "filepath": "asciinema.term",
        "lineno": 20,
        "namespace": "raw",
        "body": "    def __exit__(self, type, value, traceback):\n        if self.restore:\n            tty.tcsetattr(self.fd, tty.TCSAFLUSH, self.mode)",
        "name_type": "local_name"
    },
    "asciinema.term.read_blocking": {
        "API_name": "asciinema.term.read_blocking",
        "loc_name": "asciinema.term.read_blocking",
        "args": "fd;timeout",
        "args_default": 0,
        "filepath": "asciinema.term",
        "lineno": 25,
        "namespace": "*",
        "body": "def read_blocking(fd, timeout):\n    if fd in select.select([fd], [], [], timeout)[0]:\n        return os.read(fd, 1024)\n\n    return b''",
        "name_type": "local_name"
    },
    "asciinema.term.get_size": {
        "API_name": "asciinema.term.get_size",
        "loc_name": "asciinema.term.get_size",
        "args": "",
        "args_default": 0,
        "filepath": "asciinema.term",
        "lineno": 32,
        "namespace": "*",
        "body": "def get_size():\n    # TODO maybe use os.get_terminal_size ?\n    return (\n        int(subprocess.check_output(['tput', 'cols'])),\n        int(subprocess.check_output(['tput', 'lines']))\n    )",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter": {
        "API_name": "asciinema.urllib_http_adapter",
        "loc_name": "asciinema.urllib_http_adapter",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.MultipartFormdataEncoder": {
        "API_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder",
        "loc_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 13,
        "namespace": "MultipartFormdataEncoder",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.MultipartFormdataEncoder.__init__": {
        "API_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.__init__",
        "loc_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 14,
        "namespace": "MultipartFormdataEncoder",
        "body": "    def __init__(self):\n        self.boundary = uuid.uuid4().hex\n        self.content_type = 'multipart/form-data; boundary={}'.format(self.boundary)",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.MultipartFormdataEncoder.u": {
        "API_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.u",
        "loc_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.u",
        "args": "cls;s",
        "args_default": 0,
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 19,
        "namespace": "MultipartFormdataEncoder",
        "body": "    def u(cls, s):\n        if sys.hexversion >= 0x03000000 and isinstance(s, bytes):\n            s = s.decode('utf-8')\n        return s",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.MultipartFormdataEncoder.iter": {
        "API_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.iter",
        "loc_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.iter",
        "args": "self;fields;files",
        "args_default": 0,
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 24,
        "namespace": "MultipartFormdataEncoder",
        "body": "    def iter(self, fields, files):\n        \"\"\"\n        fields is a dict of {name: value} for regular form fields.\n        files is a dict of {name: (filename, file-type)} for data to be uploaded as files\n        Yield body's chunk as bytes\n        \"\"\"\n        encoder = codecs.getencoder('utf-8')\n        for (key, value) in fields.items():\n            key = self.u(key)\n            yield encoder('--{}\\r\\n'.format(self.boundary))\n            yield encoder(self.u('Content-Disposition: form-data; name=\"{}\"\\r\\n').format(key))\n            yield encoder('\\r\\n')\n            if isinstance(value, int) or isinstance(value, float):\n                value = str(value)\n            yield encoder(self.u(value))\n            yield encoder('\\r\\n')\n        for (key, filename_and_f) in files.items():\n            filename, f = filename_and_f\n            key = self.u(key)\n            filename = self.u(filename)\n            yield encoder('--{}\\r\\n'.format(self.boundary))\n            yield encoder(self.u('Content-Disposition: form-data; name=\"{}\"; filename=\"{}\"\\r\\n').format(key, filename))\n            yield encoder('Content-Type: application/octet-stream\\r\\n')\n            yield encoder('\\r\\n')\n            data = f.read()\n            yield (data, len(data))\n            yield encoder('\\r\\n')\n        yield encoder('--{}--\\r\\n'.format(self.boundary))",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.MultipartFormdataEncoder.encode": {
        "API_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.encode",
        "loc_name": "asciinema.urllib_http_adapter.MultipartFormdataEncoder.encode",
        "args": "self;fields;files",
        "args_default": 0,
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 53,
        "namespace": "MultipartFormdataEncoder",
        "body": "    def encode(self, fields, files):\n        body = io.BytesIO()\n        for chunk, chunk_len in self.iter(fields, files):\n            body.write(chunk)\n        return self.content_type, body.getvalue()",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.URLLibHttpAdapter.post": {
        "API_name": "asciinema.urllib_http_adapter.URLLibHttpAdapter.post",
        "loc_name": "asciinema.urllib_http_adapter.URLLibHttpAdapter.post",
        "args": "self;url;fields;files;headers;username;password",
        "args_default": 5,
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 62,
        "namespace": "URLLibHttpAdapter",
        "body": "    def post(self, url, fields={}, files={}, headers={}, username=None, password=None):\n        content_type, body = MultipartFormdataEncoder().encode(fields, files)\n\n        headers = headers.copy()\n        headers[\"Content-Type\"] = content_type\n\n        if password:\n            auth = \"%s:%s\" % (username, password)\n            encoded_auth = base64.encodebytes(auth.encode('utf-8'))[:-1]\n            headers[\"Authorization\"] = b\"Basic \" + encoded_auth\n\n        request = Request(url, data=body, headers=headers, method=\"POST\")\n\n        try:\n            response = urlopen(request)\n            status = response.status\n            headers = self._parse_headers(response)\n            body = response.read().decode('utf-8')\n        except HTTPError as e:\n            status = e.code\n            headers = {}\n            body = e.read().decode('utf-8')\n        except (http.client.RemoteDisconnected, URLError) as e:\n            raise HTTPConnectionError(str(e))\n\n        return (status, headers, body)",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.URLLibHttpAdapter._parse_headers": {
        "API_name": "asciinema.urllib_http_adapter.URLLibHttpAdapter._parse_headers",
        "loc_name": "asciinema.urllib_http_adapter.URLLibHttpAdapter._parse_headers",
        "args": "self;response",
        "args_default": 0,
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 89,
        "namespace": "URLLibHttpAdapter",
        "body": "    def _parse_headers(self, response):\n        headers = {}\n        for k, v in response.getheaders():\n            headers[k.lower()] = v\n\n        return headers",
        "name_type": "local_name"
    },
    "asciinema.urllib_http_adapter.URLLibHttpAdapter": {
        "API_name": "asciinema.urllib_http_adapter.URLLibHttpAdapter",
        "loc_name": "asciinema.urllib_http_adapter.URLLibHttpAdapter",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.urllib_http_adapter",
        "lineno": 60,
        "namespace": "URLLibHttpAdapter",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema": {
        "API_name": "asciinema",
        "loc_name": "asciinema",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema",
        "lineno": "*",
        "namespace": "*",
        "body": "__author__ = 'Marcin Kulik'\n__version__ = '2.0.2'\nif sys.version_info[0] < 3:\n    raise ImportError('Python < 3 is unsupported.')",
        "name_type": "local_name"
    },
    "asciinema.record_asciicast": {
        "API_name": "asciinema.record_asciicast",
        "loc_name": "asciinema.record_asciicast",
        "args": "path;command;append;idle_time_limit;rec_stdin;title;metadata;command_env;capture_env",
        "args_default": 8,
        "filepath": "asciinema",
        "lineno": 12,
        "namespace": "*",
        "body": "def record_asciicast(path, command=None, append=False, idle_time_limit=None,\n                     rec_stdin=False, title=None, metadata=None,\n                     command_env=None, capture_env=None):\n    asciinema.recorder.record(\n        path,\n        command=command,\n        append=append,\n        idle_time_limit=idle_time_limit,\n        rec_stdin=rec_stdin,\n        title=title,\n        metadata=metadata,\n        command_env=command_env,\n        capture_env=capture_env\n    )",
        "name_type": "local_name"
    },
    "asciinema.__main__": {
        "API_name": "asciinema.__main__",
        "loc_name": "asciinema.__main__",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.__main__",
        "lineno": "*",
        "namespace": "*",
        "body": "if __name__ == '__main__':\n    main()",
        "name_type": "local_name"
    },
    "asciinema.__main__.positive_float": {
        "API_name": "asciinema.__main__.positive_float",
        "loc_name": "asciinema.__main__.positive_float",
        "args": "value",
        "args_default": 0,
        "filepath": "asciinema.__main__",
        "lineno": 15,
        "namespace": "*",
        "body": "def positive_float(value):\n    value = float(value)\n    if value <= 0.0:\n        raise argparse.ArgumentTypeError(\"must be positive\")\n\n    return value",
        "name_type": "local_name"
    },
    "asciinema.__main__.maybe_str": {
        "API_name": "asciinema.__main__.maybe_str",
        "loc_name": "asciinema.__main__.maybe_str",
        "args": "v",
        "args_default": 0,
        "filepath": "asciinema.__main__",
        "lineno": 23,
        "namespace": "*",
        "body": "def maybe_str(v):\n    if v is not None:\n        return str(v)",
        "name_type": "local_name"
    },
    "asciinema.__main__.main": {
        "API_name": "asciinema.__main__.main",
        "loc_name": "asciinema.__main__.main",
        "args": "",
        "args_default": 0,
        "filepath": "asciinema.__main__",
        "lineno": 28,
        "namespace": "*",
        "body": "def main():\n    if locale.nl_langinfo(locale.CODESET).upper() not in ['US-ASCII', 'UTF-8']:\n        print(\"asciinema needs an ASCII or UTF-8 character encoding to run. Check the output of `locale` command.\")\n        sys.exit(1)\n\n    try:\n        cfg = config.load()\n    except config.ConfigError as e:\n        sys.stderr.write(str(e) + '\\n')\n        sys.exit(1)\n\n    # create the top-level parser\n    parser = argparse.ArgumentParser(\n        description=\"Record and share your terminal sessions, the right way.\",\n        epilog=\"\"\"example usage:\n  Record terminal and upload it to asciinema.org:\n    \\x1b[1masciinema rec\\x1b[0m\n  Record terminal to local file:\n    \\x1b[1masciinema rec demo.cast\\x1b[0m\n  Record terminal and upload it to asciinema.org, specifying title:\n    \\x1b[1masciinema rec -t \"My git tutorial\"\\x1b[0m\n  Record terminal to local file, limiting idle time to max 2.5 sec:\n    \\x1b[1masciinema rec -i 2.5 demo.cast\\x1b[0m\n  Replay terminal recording from local file:\n    \\x1b[1masciinema play demo.cast\\x1b[0m\n  Replay terminal recording hosted on asciinema.org:\n    \\x1b[1masciinema play https://asciinema.org/a/difqlgx86ym6emrmd8u62yqu8\\x1b[0m\n  Print full output of recorded session:\n    \\x1b[1masciinema cat demo.cast\\x1b[0m\n\nFor help on a specific command run:\n  \\x1b[1masciinema <command> -h\\x1b[0m\"\"\",\n        formatter_class=argparse.RawDescriptionHelpFormatter\n    )\n    parser.add_argument('--version', action='version', version='asciinema %s' % __version__)\n\n    subparsers = parser.add_subparsers()\n\n    # create the parser for the \"rec\" command\n    parser_rec = subparsers.add_parser('rec', help='Record terminal session')\n    parser_rec.add_argument('--stdin', help='enable stdin recording, disabled by default', action='store_true', default=cfg.record_stdin)\n    parser_rec.add_argument('--append', help='append to existing recording', action='store_true', default=False)\n    parser_rec.add_argument('--raw', help='save only raw stdout output', action='store_true', default=False)\n    parser_rec.add_argument('--overwrite', help='overwrite the file if it already exists', action='store_true', default=False)\n    parser_rec.add_argument('-c', '--command', help='command to record, defaults to $SHELL', default=cfg.record_command)\n    parser_rec.add_argument('-e', '--env', help='list of environment variables to capture, defaults to ' + config.DEFAULT_RECORD_ENV, default=cfg.record_env)\n    parser_rec.add_argument('-t', '--title', help='title of the asciicast')\n    parser_rec.add_argument('-i', '--idle-time-limit', help='limit recorded idle time to given number of seconds', type=positive_float, default=maybe_str(cfg.record_idle_time_limit))\n    parser_rec.add_argument('-y', '--yes', help='answer \"yes\" to all prompts (e.g. upload confirmation)', action='store_true', default=cfg.record_yes)\n    parser_rec.add_argument('-q', '--quiet', help='be quiet, suppress all notices/warnings (implies -y)', action='store_true', default=cfg.record_quiet)\n    parser_rec.add_argument('filename', nargs='?', default='', help='filename/path to save the recording to')\n    parser_rec.set_defaults(cmd=RecordCommand)\n\n    # create the parser for the \"play\" command\n    parser_play = subparsers.add_parser('play', help='Replay terminal session')\n    parser_play.add_argument('-i', '--idle-time-limit', help='limit idle time during playback to given number of seconds', type=positive_float, default=maybe_str(cfg.play_idle_time_limit))\n    parser_play.add_argument('-s', '--speed', help='playback speedup (can be fractional)', type=positive_float, default=cfg.play_speed)\n    parser_play.add_argument('filename', help='local path, http/ipfs URL or \"-\" (read from stdin)')\n    parser_play.set_defaults(cmd=PlayCommand)\n\n    # create the parser for the \"cat\" command\n    parser_cat = subparsers.add_parser('cat', help='Print full output of terminal session')\n    parser_cat.add_argument('filename', help='local path, http/ipfs URL or \"-\" (read from stdin)')\n    parser_cat.set_defaults(cmd=CatCommand)\n\n    # create the parser for the \"upload\" command\n    parser_upload = subparsers.add_parser('upload', help='Upload locally saved terminal session to asciinema.org')\n    parser_upload.add_argument('filename', help='filename or path of local recording')\n    parser_upload.set_defaults(cmd=UploadCommand)\n\n    # create the parser for the \"auth\" command\n    parser_auth = subparsers.add_parser('auth', help='Manage recordings on asciinema.org account')\n    parser_auth.set_defaults(cmd=AuthCommand)\n\n    # parse the args and call whatever function was selected\n    args = parser.parse_args()\n\n    if hasattr(args, 'cmd'):\n        command = args.cmd(args, cfg, os.environ)\n        code = command.execute()\n        sys.exit(code)\n    else:\n        parser.print_help()\n        sys.exit(1)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.events": {
        "API_name": "asciinema.asciicast.events",
        "loc_name": "asciinema.asciicast.events",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.events",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.events.to_relative_time": {
        "API_name": "asciinema.asciicast.events.to_relative_time",
        "loc_name": "asciinema.asciicast.events.to_relative_time",
        "args": "events",
        "args_default": 0,
        "filepath": "asciinema.asciicast.events",
        "lineno": 1,
        "namespace": "*",
        "body": "def to_relative_time(events):\n    prev_time = 0\n\n    for frame in events:\n        time, type, data = frame\n        delay = time - prev_time\n        prev_time = time\n        yield [delay, type, data]",
        "name_type": "local_name"
    },
    "asciinema.asciicast.events.to_absolute_time": {
        "API_name": "asciinema.asciicast.events.to_absolute_time",
        "loc_name": "asciinema.asciicast.events.to_absolute_time",
        "args": "events",
        "args_default": 0,
        "filepath": "asciinema.asciicast.events",
        "lineno": 11,
        "namespace": "*",
        "body": "def to_absolute_time(events):\n    time = 0\n\n    for frame in events:\n        delay, type, data = frame\n        time = time + delay\n        yield [time, type, data]",
        "name_type": "local_name"
    },
    "asciinema.asciicast.events.cap_relative_time": {
        "API_name": "asciinema.asciicast.events.cap_relative_time",
        "loc_name": "asciinema.asciicast.events.cap_relative_time",
        "args": "events;time_limit",
        "args_default": 0,
        "filepath": "asciinema.asciicast.events",
        "lineno": 20,
        "namespace": "*",
        "body": "def cap_relative_time(events, time_limit):\n    if time_limit:\n        return ([min(delay, time_limit), type, data] for delay, type, data in events)\n    else:\n        return events",
        "name_type": "local_name"
    },
    "asciinema.asciicast.events.adjust_speed": {
        "API_name": "asciinema.asciicast.events.adjust_speed",
        "loc_name": "asciinema.asciicast.events.adjust_speed",
        "args": "events;speed",
        "args_default": 0,
        "filepath": "asciinema.asciicast.events",
        "lineno": 27,
        "namespace": "*",
        "body": "def adjust_speed(events, speed):\n    return ([delay / speed, type, data] for delay, type, data in events)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw": {
        "API_name": "asciinema.asciicast.raw",
        "loc_name": "asciinema.asciicast.raw",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.raw",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw.writer": {
        "API_name": "asciinema.asciicast.raw.writer",
        "loc_name": "asciinema.asciicast.raw.writer",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.raw",
        "lineno": 4,
        "namespace": "writer",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw.writer.__init__": {
        "API_name": "asciinema.asciicast.raw.writer.__init__",
        "loc_name": "asciinema.asciicast.raw.writer.__init__",
        "args": "self;path;metadata;append;buffering",
        "args_default": 3,
        "filepath": "asciinema.asciicast.raw",
        "lineno": 6,
        "namespace": "writer",
        "body": "    def __init__(self, path, metadata=None, append=False, buffering=0):\n        if append and os.path.exists(path) and os.stat(path).st_size == 0:  # true for pipes\n            append = False\n\n        self.path = path\n        self.buffering = buffering\n        self.mode = 'ab' if append else 'wb'",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw.writer.__enter__": {
        "API_name": "asciinema.asciicast.raw.writer.__enter__",
        "loc_name": "asciinema.asciicast.raw.writer.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.raw",
        "lineno": 14,
        "namespace": "writer",
        "body": "    def __enter__(self):\n        self.file = open(self.path, mode=self.mode, buffering=self.buffering)\n        return self",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw.writer.__exit__": {
        "API_name": "asciinema.asciicast.raw.writer.__exit__",
        "loc_name": "asciinema.asciicast.raw.writer.__exit__",
        "args": "self;exc_type;exc_value;exc_traceback",
        "args_default": 0,
        "filepath": "asciinema.asciicast.raw",
        "lineno": 18,
        "namespace": "writer",
        "body": "    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.file.close()",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw.writer.write_stdout": {
        "API_name": "asciinema.asciicast.raw.writer.write_stdout",
        "loc_name": "asciinema.asciicast.raw.writer.write_stdout",
        "args": "self;ts;data",
        "args_default": 0,
        "filepath": "asciinema.asciicast.raw",
        "lineno": 21,
        "namespace": "writer",
        "body": "    def write_stdout(self, ts, data):\n        self.file.write(data)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.raw.writer.write_stdin": {
        "API_name": "asciinema.asciicast.raw.writer.write_stdin",
        "loc_name": "asciinema.asciicast.raw.writer.write_stdin",
        "args": "self;ts;data",
        "args_default": 0,
        "filepath": "asciinema.asciicast.raw",
        "lineno": 24,
        "namespace": "writer",
        "body": "    def write_stdin(self, ts, data):\n        pass",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1": {
        "API_name": "asciinema.asciicast.v1",
        "loc_name": "asciinema.asciicast.v1",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v1",
        "lineno": "*",
        "namespace": "*",
        "body": "try:\n    JSONDecodeError = json.decoder.JSONDecodeError\nexcept AttributeError:\n    JSONDecodeError = ValueError",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.LoadError": {
        "API_name": "asciinema.asciicast.v1.LoadError",
        "loc_name": "asciinema.asciicast.v1.LoadError",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v1",
        "lineno": 13,
        "namespace": "LoadError",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.Asciicast": {
        "API_name": "asciinema.asciicast.v1.Asciicast",
        "loc_name": "asciinema.asciicast.v1.Asciicast",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v1",
        "lineno": 17,
        "namespace": "Asciicast",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.Asciicast.__init__": {
        "API_name": "asciinema.asciicast.v1.Asciicast.__init__",
        "loc_name": "asciinema.asciicast.v1.Asciicast.__init__",
        "args": "self;attrs",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 19,
        "namespace": "Asciicast",
        "body": "    def __init__(self, attrs):\n        self.version = 1\n        self.__attrs = attrs\n        self.idle_time_limit = None  # v1 doesn't store it",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.Asciicast.v2_header": {
        "API_name": "asciinema.asciicast.v1.Asciicast.v2_header",
        "loc_name": "asciinema.asciicast.v1.Asciicast.v2_header",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 25,
        "namespace": "Asciicast",
        "body": "    def v2_header(self):\n        keys = ['width', 'height', 'duration', 'command', 'title', 'env']\n        header = {k: v for k, v in self.__attrs.items() if k in keys and v is not None}\n        return header",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.Asciicast.__stdout_events": {
        "API_name": "asciinema.asciicast.v1.Asciicast.__stdout_events",
        "loc_name": "asciinema.asciicast.v1.Asciicast.__stdout_events",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 30,
        "namespace": "Asciicast",
        "body": "    def __stdout_events(self):\n        for time, data in self.__attrs['stdout']:\n            yield [time, 'o', data]",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.Asciicast.events": {
        "API_name": "asciinema.asciicast.v1.Asciicast.events",
        "loc_name": "asciinema.asciicast.v1.Asciicast.events",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 34,
        "namespace": "Asciicast",
        "body": "    def events(self):\n        return self.stdout_events()",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.Asciicast.stdout_events": {
        "API_name": "asciinema.asciicast.v1.Asciicast.stdout_events",
        "loc_name": "asciinema.asciicast.v1.Asciicast.stdout_events",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 37,
        "namespace": "Asciicast",
        "body": "    def stdout_events(self):\n        return to_absolute_time(self.__stdout_events())",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.open_from_file": {
        "API_name": "asciinema.asciicast.v1.open_from_file",
        "loc_name": "asciinema.asciicast.v1.open_from_file",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v1",
        "lineno": 41,
        "namespace": "open_from_file",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.open_from_file.__init__": {
        "API_name": "asciinema.asciicast.v1.open_from_file.__init__",
        "loc_name": "asciinema.asciicast.v1.open_from_file.__init__",
        "args": "self;first_line;file",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 44,
        "namespace": "open_from_file",
        "body": "    def __init__(self, first_line, file):\n        self.first_line = first_line\n        self.file = file",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.open_from_file.__enter__": {
        "API_name": "asciinema.asciicast.v1.open_from_file.__enter__",
        "loc_name": "asciinema.asciicast.v1.open_from_file.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 48,
        "namespace": "open_from_file",
        "body": "    def __enter__(self):\n        try:\n            attrs = json.loads(self.first_line + self.file.read())\n\n            if attrs.get('version') == 1:\n                return Asciicast(attrs)\n            else:\n                raise LoadError(self.FORMAT_ERROR)\n        except JSONDecodeError as e:\n            raise LoadError(self.FORMAT_ERROR)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v1.open_from_file.__exit__": {
        "API_name": "asciinema.asciicast.v1.open_from_file.__exit__",
        "loc_name": "asciinema.asciicast.v1.open_from_file.__exit__",
        "args": "self;exc_type;exc_value;exc_traceback",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v1",
        "lineno": 59,
        "namespace": "open_from_file",
        "body": "    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.file.close()",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2": {
        "API_name": "asciinema.asciicast.v2",
        "loc_name": "asciinema.asciicast.v2",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v2",
        "lineno": "*",
        "namespace": "*",
        "body": "try:\n    JSONDecodeError = json.decoder.JSONDecodeError\nexcept AttributeError:\n    JSONDecodeError = ValueError",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.LoadError": {
        "API_name": "asciinema.asciicast.v2.LoadError",
        "loc_name": "asciinema.asciicast.v2.LoadError",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v2",
        "lineno": 12,
        "namespace": "LoadError",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.Asciicast": {
        "API_name": "asciinema.asciicast.v2.Asciicast",
        "loc_name": "asciinema.asciicast.v2.Asciicast",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v2",
        "lineno": 16,
        "namespace": "Asciicast",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.Asciicast.__init__": {
        "API_name": "asciinema.asciicast.v2.Asciicast.__init__",
        "loc_name": "asciinema.asciicast.v2.Asciicast.__init__",
        "args": "self;f;header",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 18,
        "namespace": "Asciicast",
        "body": "    def __init__(self, f, header):\n        self.version = 2\n        self.__file = f\n        self.v2_header = header\n        self.idle_time_limit = header.get('idle_time_limit')",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.Asciicast.events": {
        "API_name": "asciinema.asciicast.v2.Asciicast.events",
        "loc_name": "asciinema.asciicast.v2.Asciicast.events",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 24,
        "namespace": "Asciicast",
        "body": "    def events(self):\n        for line in self.__file:\n            yield json.loads(line)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.Asciicast.stdout_events": {
        "API_name": "asciinema.asciicast.v2.Asciicast.stdout_events",
        "loc_name": "asciinema.asciicast.v2.Asciicast.stdout_events",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 28,
        "namespace": "Asciicast",
        "body": "    def stdout_events(self):\n        for time, type, data in self.events():\n            if type == 'o':\n                yield [time, type, data]",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.build_from_header_and_file": {
        "API_name": "asciinema.asciicast.v2.build_from_header_and_file",
        "loc_name": "asciinema.asciicast.v2.build_from_header_and_file",
        "args": "header;f",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 34,
        "namespace": "*",
        "body": "def build_from_header_and_file(header, f):\n    return Asciicast(f, header)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.open_from_file": {
        "API_name": "asciinema.asciicast.v2.open_from_file",
        "loc_name": "asciinema.asciicast.v2.open_from_file",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v2",
        "lineno": 38,
        "namespace": "open_from_file",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.open_from_file.__init__": {
        "API_name": "asciinema.asciicast.v2.open_from_file.__init__",
        "loc_name": "asciinema.asciicast.v2.open_from_file.__init__",
        "args": "self;first_line;file",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 41,
        "namespace": "open_from_file",
        "body": "    def __init__(self, first_line, file):\n        self.first_line = first_line\n        self.file = file",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.open_from_file.__enter__": {
        "API_name": "asciinema.asciicast.v2.open_from_file.__enter__",
        "loc_name": "asciinema.asciicast.v2.open_from_file.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 45,
        "namespace": "open_from_file",
        "body": "    def __enter__(self):\n        try:\n            v2_header = json.loads(self.first_line)\n            if v2_header.get('version') == 2:\n                return build_from_header_and_file(v2_header, self.file)\n            else:\n                raise LoadError(self.FORMAT_ERROR)\n        except JSONDecodeError as e:\n            raise LoadError(self.FORMAT_ERROR)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.open_from_file.__exit__": {
        "API_name": "asciinema.asciicast.v2.open_from_file.__exit__",
        "loc_name": "asciinema.asciicast.v2.open_from_file.__exit__",
        "args": "self;exc_type;exc_value;exc_traceback",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 55,
        "namespace": "open_from_file",
        "body": "    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.file.close()",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.get_duration": {
        "API_name": "asciinema.asciicast.v2.get_duration",
        "loc_name": "asciinema.asciicast.v2.get_duration",
        "args": "path",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 59,
        "namespace": "*",
        "body": "def get_duration(path):\n    with open(path, mode='rt', encoding='utf-8') as f:\n        first_line = f.readline()\n        with open_from_file(first_line, f) as a:\n            for last_frame in a.stdout_events():\n                pass\n            return last_frame[0]",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.build_header": {
        "API_name": "asciinema.asciicast.v2.build_header",
        "loc_name": "asciinema.asciicast.v2.build_header",
        "args": "width;height;metadata",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 68,
        "namespace": "*",
        "body": "def build_header(width, height, metadata):\n    header = {'version': 2, 'width': width, 'height': height}\n    header.update(metadata)\n\n    assert 'width' in header, 'width missing in metadata'\n    assert 'height' in header, 'height missing in metadata'\n    assert type(header['width']) == int\n    assert type(header['height']) == int\n\n    if 'timestamp' in header:\n        assert type(header['timestamp']) == int or type(header['timestamp']) == float\n\n    return header",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer": {
        "API_name": "asciinema.asciicast.v2.writer",
        "loc_name": "asciinema.asciicast.v2.writer",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast.v2",
        "lineno": 83,
        "namespace": "writer",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.__init__": {
        "API_name": "asciinema.asciicast.v2.writer.__init__",
        "loc_name": "asciinema.asciicast.v2.writer.__init__",
        "args": "self;path;metadata;append;buffering;width;height",
        "args_default": 5,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 85,
        "namespace": "writer",
        "body": "    def __init__(self, path, metadata=None, append=False, buffering=1, width=None, height=None):\n        self.path = path\n        self.buffering = buffering\n        self.stdin_decoder = codecs.getincrementaldecoder('UTF-8')('replace')\n        self.stdout_decoder = codecs.getincrementaldecoder('UTF-8')('replace')\n\n        if append:\n            self.mode = 'a'\n            self.header = None\n        else:\n            self.mode = 'w'\n            self.header = build_header(width, height, metadata or {})",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.__enter__": {
        "API_name": "asciinema.asciicast.v2.writer.__enter__",
        "loc_name": "asciinema.asciicast.v2.writer.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 98,
        "namespace": "writer",
        "body": "    def __enter__(self):\n        self.file = open(self.path, mode=self.mode, buffering=self.buffering)\n\n        if self.header:\n            self.__write_line(self.header)\n\n        return self",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.__exit__": {
        "API_name": "asciinema.asciicast.v2.writer.__exit__",
        "loc_name": "asciinema.asciicast.v2.writer.__exit__",
        "args": "self;exc_type;exc_value;exc_traceback",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 106,
        "namespace": "writer",
        "body": "    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.file.close()",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.write_stdout": {
        "API_name": "asciinema.asciicast.v2.writer.write_stdout",
        "loc_name": "asciinema.asciicast.v2.writer.write_stdout",
        "args": "self;ts;data",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 109,
        "namespace": "writer",
        "body": "    def write_stdout(self, ts, data):\n        if type(data) == str:\n            data = data.encode(encoding='utf-8', errors='strict')\n        data = self.stdout_decoder.decode(data)\n        self.__write_event(ts, 'o', data)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.write_stdin": {
        "API_name": "asciinema.asciicast.v2.writer.write_stdin",
        "loc_name": "asciinema.asciicast.v2.writer.write_stdin",
        "args": "self;ts;data",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 115,
        "namespace": "writer",
        "body": "    def write_stdin(self, ts, data):\n        if type(data) == str:\n            data = data.encode(encoding='utf-8', errors='strict')\n        data = self.stdin_decoder.decode(data)\n        self.__write_event(ts, 'i', data)",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.__write_event": {
        "API_name": "asciinema.asciicast.v2.writer.__write_event",
        "loc_name": "asciinema.asciicast.v2.writer.__write_event",
        "args": "self;ts;etype;data",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 121,
        "namespace": "writer",
        "body": "    def __write_event(self, ts, etype, data):\n        self.__write_line([round(ts, 6), etype, data])",
        "name_type": "local_name"
    },
    "asciinema.asciicast.v2.writer.__write_line": {
        "API_name": "asciinema.asciicast.v2.writer.__write_line",
        "loc_name": "asciinema.asciicast.v2.writer.__write_line",
        "args": "self;obj",
        "args_default": 0,
        "filepath": "asciinema.asciicast.v2",
        "lineno": 124,
        "namespace": "writer",
        "body": "    def __write_line(self, obj):\n        line = json.dumps(obj, ensure_ascii=False, indent=None, separators=(', ', ': '))\n        self.file.write(line + '\\n')",
        "name_type": "local_name"
    },
    "asciinema.asciicast": {
        "API_name": "asciinema.asciicast",
        "loc_name": "asciinema.asciicast",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.LoadError": {
        "API_name": "asciinema.asciicast.LoadError",
        "loc_name": "asciinema.asciicast.LoadError",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast",
        "lineno": 14,
        "namespace": "LoadError",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.Parser": {
        "API_name": "asciinema.asciicast.Parser",
        "loc_name": "asciinema.asciicast.Parser",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast",
        "lineno": 18,
        "namespace": "Parser",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.Parser.__init__": {
        "API_name": "asciinema.asciicast.Parser.__init__",
        "loc_name": "asciinema.asciicast.Parser.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast",
        "lineno": 19,
        "namespace": "Parser",
        "body": "    def __init__(self):\n        html.parser.HTMLParser.__init__(self)\n        self.url = None",
        "name_type": "local_name"
    },
    "asciinema.asciicast.Parser.handle_starttag": {
        "API_name": "asciinema.asciicast.Parser.handle_starttag",
        "loc_name": "asciinema.asciicast.Parser.handle_starttag",
        "args": "self;tag;attrs_list",
        "args_default": 0,
        "filepath": "asciinema.asciicast",
        "lineno": 23,
        "namespace": "Parser",
        "body": "    def handle_starttag(self, tag, attrs_list):\n        # look for <link rel=\"alternate\" type=\"application/x-asciicast\" href=\"https://...cast\">\n        if tag == 'link':\n            attrs = {}\n            for k, v in attrs_list:\n                attrs[k] = v\n\n            if attrs.get('rel') == 'alternate':\n                type = attrs.get('type')\n                if type == 'application/asciicast+json' or type == 'application/x-asciicast':\n                    self.url = attrs.get('href')",
        "name_type": "local_name"
    },
    "asciinema.asciicast.open_url": {
        "API_name": "asciinema.asciicast.open_url",
        "loc_name": "asciinema.asciicast.open_url",
        "args": "url",
        "args_default": 0,
        "filepath": "asciinema.asciicast",
        "lineno": 36,
        "namespace": "*",
        "body": "def open_url(url):\n    if url == \"-\":\n        return sys.stdin\n\n    if url.startswith(\"ipfs://\"):\n        url = \"https://ipfs.io/ipfs/%s\" % url[7:]\n    elif url.startswith(\"dweb:/ipfs/\"):\n        url = \"https://ipfs.io/%s\" % url[5:]\n\n    if url.startswith(\"http:\") or url.startswith(\"https:\"):\n        req = Request(url)\n        req.add_header('Accept-Encoding', 'gzip')\n        response = urlopen(req)\n        body = response\n        url = response.geturl()  # final URL after redirects\n\n        if response.headers['Content-Encoding'] == 'gzip':\n            body = gzip.open(body)\n\n        utf8_reader = codecs.getreader('utf-8')\n        content_type = response.headers['Content-Type']\n\n        if content_type and content_type.startswith('text/html'):\n            html = utf8_reader(body, errors='replace').read()\n            parser = Parser()\n            parser.feed(html)\n            new_url = parser.url\n\n            if not new_url:\n                raise LoadError(\"\"\"<link rel=\"alternate\" type=\"application/x-asciicast\" href=\"...\"> not found in fetched HTML document\"\"\")\n\n            if \"://\" not in new_url:\n                base_url = urlparse(url)\n\n                if new_url.startswith(\"/\"):\n                    new_url = urlunparse((base_url[0], base_url[1], new_url, '', '', ''))\n                else:\n                    path = os.path.dirname(base_url[2]) + '/' + new_url\n                    new_url = urlunparse((base_url[0], base_url[1], path, '', '', ''))\n\n            return open_url(new_url)\n\n        return utf8_reader(body, errors='strict')\n\n    return open(url, mode='rt', encoding='utf-8')",
        "name_type": "local_name"
    },
    "asciinema.asciicast.open_from_url": {
        "API_name": "asciinema.asciicast.open_from_url",
        "loc_name": "asciinema.asciicast.open_from_url",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.asciicast",
        "lineno": 83,
        "namespace": "open_from_url",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.asciicast.open_from_url.__init__": {
        "API_name": "asciinema.asciicast.open_from_url.__init__",
        "loc_name": "asciinema.asciicast.open_from_url.__init__",
        "args": "self;url",
        "args_default": 0,
        "filepath": "asciinema.asciicast",
        "lineno": 86,
        "namespace": "open_from_url",
        "body": "    def __init__(self, url):\n        self.url = url",
        "name_type": "local_name"
    },
    "asciinema.asciicast.open_from_url.__enter__": {
        "API_name": "asciinema.asciicast.open_from_url.__enter__",
        "loc_name": "asciinema.asciicast.open_from_url.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.asciicast",
        "lineno": 89,
        "namespace": "open_from_url",
        "body": "    def __enter__(self):\n        try:\n            self.file = open_url(self.url)\n            first_line = self.file.readline()\n\n            try:  # try v2 first\n                self.context = v2.open_from_file(first_line, self.file)\n                return self.context.__enter__()\n            except v2.LoadError:\n                try:  # try v1 next\n                    self.context = v1.open_from_file(first_line, self.file)\n                    return self.context.__enter__()\n                except v1.LoadError:\n                    raise LoadError(self.FORMAT_ERROR)\n\n        except (OSError, urllib.error.HTTPError) as e:\n            raise LoadError(str(e))",
        "name_type": "local_name"
    },
    "asciinema.asciicast.open_from_url.__exit__": {
        "API_name": "asciinema.asciicast.open_from_url.__exit__",
        "loc_name": "asciinema.asciicast.open_from_url.__exit__",
        "args": "self;exc_type;exc_value;exc_traceback",
        "args_default": 0,
        "filepath": "asciinema.asciicast",
        "lineno": 107,
        "namespace": "open_from_url",
        "body": "    def __exit__(self, exc_type, exc_value, exc_traceback):\n        self.context.__exit__(exc_type, exc_value, exc_traceback)",
        "name_type": "local_name"
    },
    "asciinema.commands.auth": {
        "API_name": "asciinema.commands.auth",
        "loc_name": "asciinema.commands.auth",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.auth",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.auth.AuthCommand": {
        "API_name": "asciinema.commands.auth.AuthCommand",
        "loc_name": "asciinema.commands.auth.AuthCommand",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.auth",
        "lineno": 4,
        "namespace": "AuthCommand",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.auth.AuthCommand.__init__": {
        "API_name": "asciinema.commands.auth.AuthCommand.__init__",
        "loc_name": "asciinema.commands.auth.AuthCommand.__init__",
        "args": "self;args;config;env",
        "args_default": 0,
        "filepath": "asciinema.commands.auth",
        "lineno": 6,
        "namespace": "AuthCommand",
        "body": "    def __init__(self, args, config, env):\n        Command.__init__(self, args, config, env)",
        "name_type": "local_name"
    },
    "asciinema.commands.auth.AuthCommand.execute": {
        "API_name": "asciinema.commands.auth.AuthCommand.execute",
        "loc_name": "asciinema.commands.auth.AuthCommand.execute",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.commands.auth",
        "lineno": 9,
        "namespace": "AuthCommand",
        "body": "    def execute(self):\n        self.print('Open the following URL in a web browser to link your '\n                   'install ID with your %s user account:\\n\\n'\n                   '%s\\n\\n'\n                   'This will associate all recordings uploaded from this machine '\n                   '(past and future ones) to your account, '\n                   'and allow you to manage them (change title/theme, delete) at %s.'\n                   % (self.api.hostname(), self.api.auth_url(), self.api.hostname()))",
        "name_type": "local_name"
    },
    "asciinema.commands.cat": {
        "API_name": "asciinema.commands.cat",
        "loc_name": "asciinema.commands.cat",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.cat",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.cat.CatCommand": {
        "API_name": "asciinema.commands.cat.CatCommand",
        "loc_name": "asciinema.commands.cat.CatCommand",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.cat",
        "lineno": 7,
        "namespace": "CatCommand",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.cat.CatCommand.__init__": {
        "API_name": "asciinema.commands.cat.CatCommand.__init__",
        "loc_name": "asciinema.commands.cat.CatCommand.__init__",
        "args": "self;args;config;env",
        "args_default": 0,
        "filepath": "asciinema.commands.cat",
        "lineno": 9,
        "namespace": "CatCommand",
        "body": "    def __init__(self, args, config, env):\n        Command.__init__(self, args, config, env)\n        self.filename = args.filename",
        "name_type": "local_name"
    },
    "asciinema.commands.cat.CatCommand.execute": {
        "API_name": "asciinema.commands.cat.CatCommand.execute",
        "loc_name": "asciinema.commands.cat.CatCommand.execute",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.commands.cat",
        "lineno": 13,
        "namespace": "CatCommand",
        "body": "    def execute(self):\n        try:\n            with asciicast.open_from_url(self.filename) as a:\n                for t, _type, text in a.stdout_events():\n                    sys.stdout.write(text)\n                    sys.stdout.flush()\n\n        except asciicast.LoadError as e:\n            self.print_error(\"printing failed: %s\" % str(e))\n            return 1\n\n        return 0",
        "name_type": "local_name"
    },
    "asciinema.commands.command": {
        "API_name": "asciinema.commands.command",
        "loc_name": "asciinema.commands.command",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.command",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.command.Command": {
        "API_name": "asciinema.commands.command.Command",
        "loc_name": "asciinema.commands.command.Command",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.command",
        "lineno": 6,
        "namespace": "Command",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.command.Command.__init__": {
        "API_name": "asciinema.commands.command.Command.__init__",
        "loc_name": "asciinema.commands.command.Command.__init__",
        "args": "self;args;config;env",
        "args_default": 0,
        "filepath": "asciinema.commands.command",
        "lineno": 8,
        "namespace": "Command",
        "body": "    def __init__(self, args, config, env):\n        self.quiet = False\n        self.api = Api(config.api_url, env.get(\"USER\"), config.install_id)",
        "name_type": "local_name"
    },
    "asciinema.commands.command.Command.print": {
        "API_name": "asciinema.commands.command.Command.print",
        "loc_name": "asciinema.commands.command.Command.print",
        "args": "self;text;file;end;force",
        "args_default": 3,
        "filepath": "asciinema.commands.command",
        "lineno": 12,
        "namespace": "Command",
        "body": "    def print(self, text, file=sys.stdout, end=\"\\n\", force=False):\n        if not self.quiet or force:\n            print(text, file=file, end=end)",
        "name_type": "local_name"
    },
    "asciinema.commands.command.Command.print_info": {
        "API_name": "asciinema.commands.command.Command.print_info",
        "loc_name": "asciinema.commands.command.Command.print_info",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.commands.command",
        "lineno": 16,
        "namespace": "Command",
        "body": "    def print_info(self, text):\n        self.print(\"\\x1b[0;32masciinema: %s\\x1b[0m\" % text)",
        "name_type": "local_name"
    },
    "asciinema.commands.command.Command.print_warning": {
        "API_name": "asciinema.commands.command.Command.print_warning",
        "loc_name": "asciinema.commands.command.Command.print_warning",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.commands.command",
        "lineno": 19,
        "namespace": "Command",
        "body": "    def print_warning(self, text):\n        self.print(\"\\x1b[0;33masciinema: %s\\x1b[0m\" % text)",
        "name_type": "local_name"
    },
    "asciinema.commands.command.Command.print_error": {
        "API_name": "asciinema.commands.command.Command.print_error",
        "loc_name": "asciinema.commands.command.Command.print_error",
        "args": "self;text",
        "args_default": 0,
        "filepath": "asciinema.commands.command",
        "lineno": 22,
        "namespace": "Command",
        "body": "    def print_error(self, text):\n        self.print(\"\\x1b[0;31masciinema: %s\\x1b[0m\" % text, file=sys.stderr, force=True)",
        "name_type": "local_name"
    },
    "asciinema.commands.play": {
        "API_name": "asciinema.commands.play",
        "loc_name": "asciinema.commands.play",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.play",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.play.PlayCommand": {
        "API_name": "asciinema.commands.play.PlayCommand",
        "loc_name": "asciinema.commands.play.PlayCommand",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.play",
        "lineno": 6,
        "namespace": "PlayCommand",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.play.PlayCommand.__init__": {
        "API_name": "asciinema.commands.play.PlayCommand.__init__",
        "loc_name": "asciinema.commands.play.PlayCommand.__init__",
        "args": "self;args;config;env;player",
        "args_default": 1,
        "filepath": "asciinema.commands.play",
        "lineno": 8,
        "namespace": "PlayCommand",
        "body": "    def __init__(self, args, config, env, player=None):\n        Command.__init__(self, args, config, env)\n        self.filename = args.filename\n        self.idle_time_limit = args.idle_time_limit\n        self.speed = args.speed\n        self.player = player if player is not None else Player()",
        "name_type": "local_name"
    },
    "asciinema.commands.play.PlayCommand.execute": {
        "API_name": "asciinema.commands.play.PlayCommand.execute",
        "loc_name": "asciinema.commands.play.PlayCommand.execute",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.commands.play",
        "lineno": 15,
        "namespace": "PlayCommand",
        "body": "    def execute(self):\n        try:\n            with asciicast.open_from_url(self.filename) as a:\n                self.player.play(a, self.idle_time_limit, self.speed)\n\n        except asciicast.LoadError as e:\n            self.print_error(\"playback failed: %s\" % str(e))\n            return 1\n        except KeyboardInterrupt:\n            return 1\n\n        return 0",
        "name_type": "local_name"
    },
    "asciinema.commands.record": {
        "API_name": "asciinema.commands.record",
        "loc_name": "asciinema.commands.record",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.record",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.record.RecordCommand": {
        "API_name": "asciinema.commands.record.RecordCommand",
        "loc_name": "asciinema.commands.record.RecordCommand",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.record",
        "lineno": 13,
        "namespace": "RecordCommand",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.record.RecordCommand.__init__": {
        "API_name": "asciinema.commands.record.RecordCommand.__init__",
        "loc_name": "asciinema.commands.record.RecordCommand.__init__",
        "args": "self;args;config;env",
        "args_default": 0,
        "filepath": "asciinema.commands.record",
        "lineno": 15,
        "namespace": "RecordCommand",
        "body": "    def __init__(self, args, config, env):\n        Command.__init__(self, args, config, env)\n        self.quiet = args.quiet\n        self.filename = args.filename\n        self.rec_stdin = args.stdin\n        self.command = args.command\n        self.env_whitelist = args.env\n        self.title = args.title\n        self.assume_yes = args.yes or args.quiet\n        self.idle_time_limit = args.idle_time_limit\n        self.append = args.append\n        self.overwrite = args.overwrite\n        self.raw = args.raw\n        self.writer = raw.writer if args.raw else v2.writer\n        self.notifier = notifier.get_notifier(config.notifications_enabled, config.notifications_command)\n        self.env = env",
        "name_type": "local_name"
    },
    "asciinema.commands.record.RecordCommand.execute": {
        "API_name": "asciinema.commands.record.RecordCommand.execute",
        "loc_name": "asciinema.commands.record.RecordCommand.execute",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.commands.record",
        "lineno": 32,
        "namespace": "RecordCommand",
        "body": "    def execute(self):\n        upload = False\n        append = self.append\n\n        if self.filename == \"\":\n            if self.raw:\n                self.print_error(\"filename required when recording in raw mode\")\n                return 1\n            else:\n                self.filename = _tmp_path()\n                upload = True\n\n        if os.path.exists(self.filename):\n            if not os.access(self.filename, os.W_OK):\n                self.print_error(\"can't write to %s\" % self.filename)\n                return 1\n\n            if os.stat(self.filename).st_size > 0 and self.overwrite:\n                os.remove(self.filename)\n                append = False\n\n            elif os.stat(self.filename).st_size > 0 and not append:\n                self.print_error(\"%s already exists, aborting\" % self.filename)\n                self.print_error(\"use --append option if you want to append to existing recording\")\n                return 1\n\n        if append:\n            self.print_info(\"appending to asciicast at %s\" % self.filename)\n        else:\n            self.print_info(\"recording asciicast to %s\" % self.filename)\n\n        if self.command:\n            self.print_info(\"\"\"exit opened program when you're done\"\"\")\n        else:\n            self.print_info(\"\"\"press <ctrl-d> or type \"exit\" when you're done\"\"\")\n\n        vars = filter(None, map((lambda var: var.strip()), self.env_whitelist.split(',')))\n\n        try:\n            recorder.record(\n                self.filename,\n                command=self.command,\n                append=append,\n                title=self.title,\n                idle_time_limit=self.idle_time_limit,\n                command_env=self.env,\n                capture_env=vars,\n                rec_stdin=self.rec_stdin,\n                writer=self.writer,\n                notifier=self.notifier\n            )\n        except v2.LoadError:\n            self.print_error(\"can only append to asciicast v2 format recordings\")\n            return 1\n\n        self.print_info(\"recording finished\")\n\n        if upload:\n            if not self.assume_yes:\n                self.print_info(\"press <enter> to upload to %s, <ctrl-c> to save locally\"\n                                % self.api.hostname())\n                try:\n                    sys.stdin.readline()\n                except KeyboardInterrupt:\n                    self.print(\"\\r\", end=\"\")\n                    self.print_info(\"asciicast saved to %s\" % self.filename)\n                    return 0\n\n            try:\n                result, warn = self.api.upload_asciicast(self.filename)\n\n                if warn:\n                    self.print_warning(warn)\n\n                os.remove(self.filename)\n                self.print(result.get('message') or result['url'])\n\n            except APIError as e:\n                self.print(\"\\r\\x1b[A\", end=\"\")\n                self.print_error(\"upload failed: %s\" % str(e))\n                self.print_error(\"retry later by running: asciinema upload %s\" % self.filename)\n                return 1\n        else:\n            self.print_info(\"asciicast saved to %s\" % self.filename)\n\n        return 0",
        "name_type": "local_name"
    },
    "asciinema.commands.record._tmp_path": {
        "API_name": "asciinema.commands.record._tmp_path",
        "loc_name": "asciinema.commands.record._tmp_path",
        "args": "",
        "args_default": 0,
        "filepath": "asciinema.commands.record",
        "lineno": 120,
        "namespace": "*",
        "body": "def _tmp_path():\n    fd, path = tempfile.mkstemp(suffix='-ascii.cast')\n    os.close(fd)\n    return path",
        "name_type": "local_name"
    },
    "asciinema.commands.upload": {
        "API_name": "asciinema.commands.upload",
        "loc_name": "asciinema.commands.upload",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.upload",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.upload.UploadCommand": {
        "API_name": "asciinema.commands.upload.UploadCommand",
        "loc_name": "asciinema.commands.upload.UploadCommand",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands.upload",
        "lineno": 5,
        "namespace": "UploadCommand",
        "body": "",
        "name_type": "local_name"
    },
    "asciinema.commands.upload.UploadCommand.__init__": {
        "API_name": "asciinema.commands.upload.UploadCommand.__init__",
        "loc_name": "asciinema.commands.upload.UploadCommand.__init__",
        "args": "self;args;config;env",
        "args_default": 0,
        "filepath": "asciinema.commands.upload",
        "lineno": 7,
        "namespace": "UploadCommand",
        "body": "    def __init__(self, args, config, env):\n        Command.__init__(self, args, config, env)\n        self.filename = args.filename",
        "name_type": "local_name"
    },
    "asciinema.commands.upload.UploadCommand.execute": {
        "API_name": "asciinema.commands.upload.UploadCommand.execute",
        "loc_name": "asciinema.commands.upload.UploadCommand.execute",
        "args": "self",
        "args_default": 0,
        "filepath": "asciinema.commands.upload",
        "lineno": 11,
        "namespace": "UploadCommand",
        "body": "    def execute(self):\n        try:\n            result, warn = self.api.upload_asciicast(self.filename)\n\n            if warn:\n                self.print_warning(warn)\n\n            self.print(result.get('message') or result['url'])\n\n        except OSError as e:\n            self.print_error(\"upload failed: %s\" % str(e))\n            return 1\n\n        except APIError as e:\n            self.print_error(\"upload failed: %s\" % str(e))\n            self.print_error(\"retry later by running: asciinema upload %s\" % self.filename)\n            return 1\n\n        return 0",
        "name_type": "local_name"
    },
    "asciinema.commands": {
        "API_name": "asciinema.commands",
        "loc_name": "asciinema.commands",
        "args": "*",
        "args_default": "*",
        "filepath": "asciinema.commands",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "local_name"
    },
    "argparse": {
        "API_name": "argparse",
        "loc_name": "argparse",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Command-line parsing library\n\nThis module is an optparse-inspired command-line parsing library that:\n\n    - handles both optional and positional arguments\n    - produces highly informative usage messages\n    - supports parsers that dispatch to sub-parsers\n\nThe following is a simple usage example that sums integers from the\ncommand-line and writes the result to a file::\n\n    parser = argparse.ArgumentParser(\n        description='sum the integers at the command line')\n    parser.add_argument(\n        'integers', metavar='int', nargs='+', type=int,\n        help='an integer to be summed')\n    parser.add_argument(\n        '--log', default=sys.stdout, type=argparse.FileType('w'),\n        help='the file where the sum should be written')\n    args = parser.parse_args()\n    args.log.write('%s' % sum(args.integers))\n    args.log.close()\n\nThe module contains the following public classes:\n\n    - ArgumentParser -- The main entry point for command-line parsing. As the\n        example above shows, the add_argument() method is used to populate\n        the parser with actions for optional and positional arguments. Then\n        the parse_args() method is invoked to convert the args at the\n        command-line into an object with attributes.\n\n    - ArgumentError -- The exception raised by ArgumentParser objects when\n        there are errors with the parser's actions. Errors raised while\n        parsing the command-line are caught by ArgumentParser and emitted\n        as command-line messages.\n\n    - FileType -- A factory for defining types of files to be created. As the\n        example above shows, instances of FileType are typically passed as\n        the type= argument of add_argument() calls.\n\n    - Action -- The base class for parser actions. Typically actions are\n        selected by passing strings like 'store_true' or 'append_const' to\n        the action= argument of add_argument(). However, for greater\n        customization of ArgumentParser actions, subclasses of Action may\n        be defined and passed as the action= argument.\n\n    - HelpFormatter, RawDescriptionHelpFormatter, RawTextHelpFormatter,\n        ArgumentDefaultsHelpFormatter -- Formatter classes which\n        may be passed as the formatter_class= argument to the\n        ArgumentParser constructor. HelpFormatter is the default,\n        RawDescriptionHelpFormatter and RawTextHelpFormatter tell the parser\n        not to change the formatting for help text, and\n        ArgumentDefaultsHelpFormatter adds information about argument defaults\n        to the help.\n\nAll other classes in this module are considered implementation details.\n(Also note that HelpFormatter and RawDescriptionHelpFormatter are only\nconsidered public as object names -- the API of the formatter objects is\nstill considered an implementation detail.)\n\"\"\"\n__version__ = '1.1'\n__all__ = [\n    'ArgumentParser',\n    'ArgumentError',\n    'ArgumentTypeError',\n    'BooleanOptionalAction',\n    'FileType',\n    'HelpFormatter',\n    'ArgumentDefaultsHelpFormatter',\n    'RawDescriptionHelpFormatter',\n    'RawTextHelpFormatter',\n    'MetavarTypeHelpFormatter',\n    'Namespace',\n    'Action',\n    'ONE_OR_MORE',\n    'OPTIONAL',\n    'PARSER',\n    'REMAINDER',\n    'SUPPRESS',\n    'ZERO_OR_MORE',\n]\nSUPPRESS = '==SUPPRESS=='\nOPTIONAL = '?'\nZERO_OR_MORE = '*'\nONE_OR_MORE = '+'\nPARSER = 'A...'\nREMAINDER = '...'\n_UNRECOGNIZED_ARGS_ATTR = '_unrecognized_args'",
        "name_type": "stdlib"
    },
    "argparse._AttributeHolder.__repr__": {
        "API_name": "argparse._AttributeHolder.__repr__",
        "loc_name": "argparse._AttributeHolder.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 116,
        "namespace": "_AttributeHolder",
        "body": "    def __repr__(self):\n        type_name = type(self).__name__\n        arg_strings = []\n        star_args = {}\n        for arg in self._get_args():\n            arg_strings.append(repr(arg))\n        for name, value in self._get_kwargs():\n            if name.isidentifier():\n                arg_strings.append('%s=%r' % (name, value))\n            else:\n                star_args[name] = value\n        if star_args:\n            arg_strings.append('**%s' % repr(star_args))\n        return '%s(%s)' % (type_name, ', '.join(arg_strings))",
        "name_type": "stdlib"
    },
    "argparse._AttributeHolder._get_kwargs": {
        "API_name": "argparse._AttributeHolder._get_kwargs",
        "loc_name": "argparse._AttributeHolder._get_kwargs",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 131,
        "namespace": "_AttributeHolder",
        "body": "    def _get_kwargs(self):\n        return list(self.__dict__.items())",
        "name_type": "stdlib"
    },
    "argparse._AttributeHolder._get_args": {
        "API_name": "argparse._AttributeHolder._get_args",
        "loc_name": "argparse._AttributeHolder._get_args",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 134,
        "namespace": "_AttributeHolder",
        "body": "    def _get_args(self):\n        return []",
        "name_type": "stdlib"
    },
    "argparse._AttributeHolder": {
        "API_name": "argparse._AttributeHolder",
        "loc_name": "argparse._AttributeHolder",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 107,
        "namespace": "_AttributeHolder",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._copy_items": {
        "API_name": "argparse._copy_items",
        "loc_name": "argparse._copy_items",
        "args": "items",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 138,
        "namespace": "*",
        "body": "def _copy_items(items):\n    if items is None:\n        return []\n    # The copy module is used only in the 'append' and 'append_const'\n    # actions, and it is needed only when the default value isn't a list.\n    # Delay its import for speeding up the common case.\n    if type(items) is list:\n        return items[:]\n    import copy\n    return copy.copy(items)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter": {
        "API_name": "argparse.HelpFormatter",
        "loc_name": "argparse.HelpFormatter",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 154,
        "namespace": "HelpFormatter",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.__init__": {
        "API_name": "argparse.HelpFormatter.__init__",
        "loc_name": "argparse.HelpFormatter.__init__",
        "args": "self;prog;indent_increment;max_help_position;width",
        "args_default": 3,
        "filepath": "argparse",
        "lineno": 161,
        "namespace": "HelpFormatter",
        "body": "    def __init__(self,\n                 prog,\n                 indent_increment=2,\n                 max_help_position=24,\n                 width=None):\n\n        # default setting for width\n        if width is None:\n            import shutil\n            width = shutil.get_terminal_size().columns\n            width -= 2\n\n        self._prog = prog\n        self._indent_increment = indent_increment\n        self._max_help_position = min(max_help_position,\n                                      max(width - 20, indent_increment * 2))\n        self._width = width\n\n        self._current_indent = 0\n        self._level = 0\n        self._action_max_length = 0\n\n        self._root_section = self._Section(self, None)\n        self._current_section = self._root_section\n\n        self._whitespace_matcher = _re.compile(r'\\s+', _re.ASCII)\n        self._long_break_matcher = _re.compile(r'\\n\\n\\n+')",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._indent": {
        "API_name": "argparse.HelpFormatter._indent",
        "loc_name": "argparse.HelpFormatter._indent",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 192,
        "namespace": "HelpFormatter",
        "body": "    def _indent(self):\n        self._current_indent += self._indent_increment\n        self._level += 1",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._dedent": {
        "API_name": "argparse.HelpFormatter._dedent",
        "loc_name": "argparse.HelpFormatter._dedent",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 196,
        "namespace": "HelpFormatter",
        "body": "    def _dedent(self):\n        self._current_indent -= self._indent_increment\n        assert self._current_indent >= 0, 'Indent decreased below 0.'\n        self._level -= 1",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._Section": {
        "API_name": "argparse.HelpFormatter._Section",
        "loc_name": "argparse.HelpFormatter._Section",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 201,
        "namespace": "HelpFormatter",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._Section.__init__": {
        "API_name": "argparse.HelpFormatter._Section.__init__",
        "loc_name": "argparse.HelpFormatter._Section.__init__",
        "args": "self;formatter;parent;heading",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 203,
        "namespace": "HelpFormatter",
        "body": "        def __init__(self, formatter, parent, heading=None):\n            self.formatter = formatter\n            self.parent = parent\n            self.heading = heading\n            self.items = []",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._Section.format_help": {
        "API_name": "argparse.HelpFormatter._Section.format_help",
        "loc_name": "argparse.HelpFormatter._Section.format_help",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 209,
        "namespace": "HelpFormatter",
        "body": "        def format_help(self):\n            # format the indented section\n            if self.parent is not None:\n                self.formatter._indent()\n            join = self.formatter._join_parts\n            item_help = join([func(*args) for func, args in self.items])\n            if self.parent is not None:\n                self.formatter._dedent()\n\n            # return nothing if the section was empty\n            if not item_help:\n                return ''\n\n            # add the heading if the section was non-empty\n            if self.heading is not SUPPRESS and self.heading is not None:\n                current_indent = self.formatter._current_indent\n                heading = '%*s%s:\\n' % (current_indent, '', self.heading)\n            else:\n                heading = ''\n\n            # join the section-initial newline, the heading and the help\n            return join(['\\n', heading, item_help, '\\n'])",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._add_item": {
        "API_name": "argparse.HelpFormatter._add_item",
        "loc_name": "argparse.HelpFormatter._add_item",
        "args": "self;func;args",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 232,
        "namespace": "HelpFormatter",
        "body": "    def _add_item(self, func, args):\n        self._current_section.items.append((func, args))",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.start_section": {
        "API_name": "argparse.HelpFormatter.start_section",
        "loc_name": "argparse.HelpFormatter.start_section",
        "args": "self;heading",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 238,
        "namespace": "HelpFormatter",
        "body": "    def start_section(self, heading):\n        self._indent()\n        section = self._Section(self, self._current_section, heading)\n        self._add_item(section.format_help, [])\n        self._current_section = section",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.end_section": {
        "API_name": "argparse.HelpFormatter.end_section",
        "loc_name": "argparse.HelpFormatter.end_section",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 244,
        "namespace": "HelpFormatter",
        "body": "    def end_section(self):\n        self._current_section = self._current_section.parent\n        self._dedent()",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.add_text": {
        "API_name": "argparse.HelpFormatter.add_text",
        "loc_name": "argparse.HelpFormatter.add_text",
        "args": "self;text",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 248,
        "namespace": "HelpFormatter",
        "body": "    def add_text(self, text):\n        if text is not SUPPRESS and text is not None:\n            self._add_item(self._format_text, [text])",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.add_usage": {
        "API_name": "argparse.HelpFormatter.add_usage",
        "loc_name": "argparse.HelpFormatter.add_usage",
        "args": "self;usage;actions;groups;prefix",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 252,
        "namespace": "HelpFormatter",
        "body": "    def add_usage(self, usage, actions, groups, prefix=None):\n        if usage is not SUPPRESS:\n            args = usage, actions, groups, prefix\n            self._add_item(self._format_usage, args)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.add_argument": {
        "API_name": "argparse.HelpFormatter.add_argument",
        "loc_name": "argparse.HelpFormatter.add_argument",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 257,
        "namespace": "HelpFormatter",
        "body": "    def add_argument(self, action):\n        if action.help is not SUPPRESS:\n\n            # find all invocations\n            get_invocation = self._format_action_invocation\n            invocations = [get_invocation(action)]\n            for subaction in self._iter_indented_subactions(action):\n                invocations.append(get_invocation(subaction))\n\n            # update the maximum item length\n            invocation_length = max(map(len, invocations))\n            action_length = invocation_length + self._current_indent\n            self._action_max_length = max(self._action_max_length,\n                                          action_length)\n\n            # add the item to the list\n            self._add_item(self._format_action, [action])",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.add_arguments": {
        "API_name": "argparse.HelpFormatter.add_arguments",
        "loc_name": "argparse.HelpFormatter.add_arguments",
        "args": "self;actions",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 275,
        "namespace": "HelpFormatter",
        "body": "    def add_arguments(self, actions):\n        for action in actions:\n            self.add_argument(action)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter.format_help": {
        "API_name": "argparse.HelpFormatter.format_help",
        "loc_name": "argparse.HelpFormatter.format_help",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 282,
        "namespace": "HelpFormatter",
        "body": "    def format_help(self):\n        help = self._root_section.format_help()\n        if help:\n            help = self._long_break_matcher.sub('\\n\\n', help)\n            help = help.strip('\\n') + '\\n'\n        return help",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._join_parts": {
        "API_name": "argparse.HelpFormatter._join_parts",
        "loc_name": "argparse.HelpFormatter._join_parts",
        "args": "self;part_strings",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 289,
        "namespace": "HelpFormatter",
        "body": "    def _join_parts(self, part_strings):\n        return ''.join([part\n                        for part in part_strings\n                        if part and part is not SUPPRESS])",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._format_usage": {
        "API_name": "argparse.HelpFormatter._format_usage",
        "loc_name": "argparse.HelpFormatter._format_usage",
        "args": "self;usage;actions;groups;prefix",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 294,
        "namespace": "HelpFormatter",
        "body": "    def _format_usage(self, usage, actions, groups, prefix):\n        if prefix is None:\n            prefix = _('usage: ')\n\n        # if usage is specified, use that\n        if usage is not None:\n            usage = usage % dict(prog=self._prog)\n\n        # if no optionals or positionals are available, usage is just prog\n        elif usage is None and not actions:\n            usage = '%(prog)s' % dict(prog=self._prog)\n\n        # if optionals and positionals are available, calculate usage\n        elif usage is None:\n            prog = '%(prog)s' % dict(prog=self._prog)\n\n            # split optionals from positionals\n            optionals = []\n            positionals = []\n            for action in actions:\n                if action.option_strings:\n                    optionals.append(action)\n                else:\n                    positionals.append(action)\n\n            # build full usage string\n            format = self._format_actions_usage\n            action_usage = format(optionals + positionals, groups)\n            usage = ' '.join([s for s in [prog, action_usage] if s])\n\n            # wrap the usage parts if it's too long\n            text_width = self._width - self._current_indent\n            if len(prefix) + len(usage) > text_width:\n\n                # break usage into wrappable parts\n                part_regexp = (\n                    r'\\(.*?\\)+(?=\\s|$)|'\n                    r'\\[.*?\\]+(?=\\s|$)|'\n                    r'\\S+'\n                )\n                opt_usage = format(optionals, groups)\n                pos_usage = format(positionals, groups)\n                opt_parts = _re.findall(part_regexp, opt_usage)\n                pos_parts = _re.findall(part_regexp, pos_usage)\n                assert ' '.join(opt_parts) == opt_usage\n                assert ' '.join(pos_parts) == pos_usage\n\n                # helper for wrapping lines\n                def get_lines(parts, indent, prefix=None):\n                    lines = []\n                    line = []\n                    if prefix is not None:\n                        line_len = len(prefix) - 1\n                    else:\n                        line_len = len(indent) - 1\n                    for part in parts:\n                        if line_len + 1 + len(part) > text_width and line:\n                            lines.append(indent + ' '.join(line))\n                            line = []\n                            line_len = len(indent) - 1\n                        line.append(part)\n                        line_len += len(part) + 1\n                    if line:\n                        lines.append(indent + ' '.join(line))\n                    if prefix is not None:\n                        lines[0] = lines[0][len(indent):]\n                    return lines\n\n                # if prog is short, follow it with optionals or positionals\n                if len(prefix) + len(prog) <= 0.75 * text_width:\n                    indent = ' ' * (len(prefix) + len(prog) + 1)\n                    if opt_parts:\n                        lines = get_lines([prog] + opt_parts, indent, prefix)\n                        lines.extend(get_lines(pos_parts, indent))\n                    elif pos_parts:\n                        lines = get_lines([prog] + pos_parts, indent, prefix)\n                    else:\n                        lines = [prog]\n\n                # if prog is long, put it on its own line\n                else:\n                    indent = ' ' * len(prefix)\n                    parts = opt_parts + pos_parts\n                    lines = get_lines(parts, indent)\n                    if len(lines) > 1:\n                        lines = []\n                        lines.extend(get_lines(opt_parts, indent))\n                        lines.extend(get_lines(pos_parts, indent))\n                    lines = [prog] + lines\n\n                # join lines into usage\n                usage = '\\n'.join(lines)\n\n        # prefix with 'usage:'\n        return '%s%s\\n\\n' % (prefix, usage)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._format_actions_usage": {
        "API_name": "argparse.HelpFormatter._format_actions_usage",
        "loc_name": "argparse.HelpFormatter._format_actions_usage",
        "args": "self;actions;groups",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 390,
        "namespace": "HelpFormatter",
        "body": "    def _format_actions_usage(self, actions, groups):\n        # find group indices and identify actions in groups\n        group_actions = set()\n        inserts = {}\n        for group in groups:\n            if not group._group_actions:\n                raise ValueError(f'empty group {group}')\n\n            try:\n                start = actions.index(group._group_actions[0])\n            except ValueError:\n                continue\n            else:\n                end = start + len(group._group_actions)\n                if actions[start:end] == group._group_actions:\n                    for action in group._group_actions:\n                        group_actions.add(action)\n                    if not group.required:\n                        if start in inserts:\n                            inserts[start] += ' ['\n                        else:\n                            inserts[start] = '['\n                        if end in inserts:\n                            inserts[end] += ']'\n                        else:\n                            inserts[end] = ']'\n                    else:\n                        if start in inserts:\n                            inserts[start] += ' ('\n                        else:\n                            inserts[start] = '('\n                        if end in inserts:\n                            inserts[end] += ')'\n                        else:\n                            inserts[end] = ')'\n                    for i in range(start + 1, end):\n                        inserts[i] = '|'\n\n        # collect all actions format strings\n        parts = []\n        for i, action in enumerate(actions):\n\n            # suppressed arguments are marked with None\n            # remove | separators for suppressed arguments\n            if action.help is SUPPRESS:\n                parts.append(None)\n                if inserts.get(i) == '|':\n                    inserts.pop(i)\n                elif inserts.get(i + 1) == '|':\n                    inserts.pop(i + 1)\n\n            # produce all arg strings\n            elif not action.option_strings:\n                default = self._get_default_metavar_for_positional(action)\n                part = self._format_args(action, default)\n\n                # if it's in a group, strip the outer []\n                if action in group_actions:\n                    if part[0] == '[' and part[-1] == ']':\n                        part = part[1:-1]\n\n                # add the action string to the list\n                parts.append(part)\n\n            # produce the first way to invoke the option in brackets\n            else:\n                option_string = action.option_strings[0]\n\n                # if the Optional doesn't take a value, format is:\n                #    -s or --long\n                if action.nargs == 0:\n                    part = action.format_usage()\n\n                # if the Optional takes a value, format is:\n                #    -s ARGS or --long ARGS\n                else:\n                    default = self._get_default_metavar_for_optional(action)\n                    args_string = self._format_args(action, default)\n                    part = '%s %s' % (option_string, args_string)\n\n                # make it look optional if it's not required or in a group\n                if not action.required and action not in group_actions:\n                    part = '[%s]' % part\n\n                # add the action string to the list\n                parts.append(part)\n\n        # insert things at the necessary indices\n        for i in sorted(inserts, reverse=True):\n            parts[i:i] = [inserts[i]]\n\n        # join all the action items with spaces\n        text = ' '.join([item for item in parts if item is not None])\n\n        # clean up separators for mutually exclusive groups\n        open = r'[\\[(]'\n        close = r'[\\])]'\n        text = _re.sub(r'(%s) ' % open, r'\\1', text)\n        text = _re.sub(r' (%s)' % close, r'\\1', text)\n        text = _re.sub(r'%s *%s' % (open, close), r'', text)\n        text = _re.sub(r'\\(([^|]*)\\)', r'\\1', text)\n        text = text.strip()\n\n        # return the text\n        return text",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._format_text": {
        "API_name": "argparse.HelpFormatter._format_text",
        "loc_name": "argparse.HelpFormatter._format_text",
        "args": "self;text",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 496,
        "namespace": "HelpFormatter",
        "body": "    def _format_text(self, text):\n        if '%(prog)' in text:\n            text = text % dict(prog=self._prog)\n        text_width = max(self._width - self._current_indent, 11)\n        indent = ' ' * self._current_indent\n        return self._fill_text(text, text_width, indent) + '\\n\\n'",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._format_action": {
        "API_name": "argparse.HelpFormatter._format_action",
        "loc_name": "argparse.HelpFormatter._format_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 503,
        "namespace": "HelpFormatter",
        "body": "    def _format_action(self, action):\n        # determine the required width and the entry label\n        help_position = min(self._action_max_length + 2,\n                            self._max_help_position)\n        help_width = max(self._width - help_position, 11)\n        action_width = help_position - self._current_indent - 2\n        action_header = self._format_action_invocation(action)\n\n        # no help; start on same line and add a final newline\n        if not action.help:\n            tup = self._current_indent, '', action_header\n            action_header = '%*s%s\\n' % tup\n\n        # short action name; start on the same line and pad two spaces\n        elif len(action_header) <= action_width:\n            tup = self._current_indent, '', action_width, action_header\n            action_header = '%*s%-*s  ' % tup\n            indent_first = 0\n\n        # long action name; start on the next line\n        else:\n            tup = self._current_indent, '', action_header\n            action_header = '%*s%s\\n' % tup\n            indent_first = help_position\n\n        # collect the pieces of the action help\n        parts = [action_header]\n\n        # if there was help for the action, add lines of help text\n        if action.help and action.help.strip():\n            help_text = self._expand_help(action)\n            if help_text:\n                help_lines = self._split_lines(help_text, help_width)\n                parts.append('%*s%s\\n' % (indent_first, '', help_lines[0]))\n                for line in help_lines[1:]:\n                    parts.append('%*s%s\\n' % (help_position, '', line))\n\n        # or add a newline if the description doesn't end with one\n        elif not action_header.endswith('\\n'):\n            parts.append('\\n')\n\n        # if there are any sub-actions, add their help as well\n        for subaction in self._iter_indented_subactions(action):\n            parts.append(self._format_action(subaction))\n\n        # return a single string\n        return self._join_parts(parts)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._format_action_invocation": {
        "API_name": "argparse.HelpFormatter._format_action_invocation",
        "loc_name": "argparse.HelpFormatter._format_action_invocation",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 551,
        "namespace": "HelpFormatter",
        "body": "    def _format_action_invocation(self, action):\n        if not action.option_strings:\n            default = self._get_default_metavar_for_positional(action)\n            metavar, = self._metavar_formatter(action, default)(1)\n            return metavar\n\n        else:\n            parts = []\n\n            # if the Optional doesn't take a value, format is:\n            #    -s, --long\n            if action.nargs == 0:\n                parts.extend(action.option_strings)\n\n            # if the Optional takes a value, format is:\n            #    -s ARGS, --long ARGS\n            else:\n                default = self._get_default_metavar_for_optional(action)\n                args_string = self._format_args(action, default)\n                for option_string in action.option_strings:\n                    parts.append('%s %s' % (option_string, args_string))\n\n            return ', '.join(parts)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._metavar_formatter": {
        "API_name": "argparse.HelpFormatter._metavar_formatter",
        "loc_name": "argparse.HelpFormatter._metavar_formatter",
        "args": "self;action;default_metavar",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 575,
        "namespace": "HelpFormatter",
        "body": "    def _metavar_formatter(self, action, default_metavar):\n        if action.metavar is not None:\n            result = action.metavar\n        elif action.choices is not None:\n            choice_strs = [str(choice) for choice in action.choices]\n            result = '{%s}' % ','.join(choice_strs)\n        else:\n            result = default_metavar\n\n        def format(tuple_size):\n            if isinstance(result, tuple):\n                return result\n            else:\n                return (result, ) * tuple_size\n        return format",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._metavar_formatter.format": {
        "API_name": "argparse.HelpFormatter._metavar_formatter.format",
        "loc_name": "argparse.HelpFormatter._metavar_formatter.format",
        "args": "tuple_size",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 584,
        "namespace": "HelpFormatter",
        "body": "        def format(tuple_size):\n            if isinstance(result, tuple):\n                return result\n            else:\n                return (result, ) * tuple_size",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._format_args": {
        "API_name": "argparse.HelpFormatter._format_args",
        "loc_name": "argparse.HelpFormatter._format_args",
        "args": "self;action;default_metavar",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 591,
        "namespace": "HelpFormatter",
        "body": "    def _format_args(self, action, default_metavar):\n        get_metavar = self._metavar_formatter(action, default_metavar)\n        if action.nargs is None:\n            result = '%s' % get_metavar(1)\n        elif action.nargs == OPTIONAL:\n            result = '[%s]' % get_metavar(1)\n        elif action.nargs == ZERO_OR_MORE:\n            metavar = get_metavar(1)\n            if len(metavar) == 2:\n                result = '[%s [%s ...]]' % metavar\n            else:\n                result = '[%s ...]' % metavar\n        elif action.nargs == ONE_OR_MORE:\n            result = '%s [%s ...]' % get_metavar(2)\n        elif action.nargs == REMAINDER:\n            result = '...'\n        elif action.nargs == PARSER:\n            result = '%s ...' % get_metavar(1)\n        elif action.nargs == SUPPRESS:\n            result = ''\n        else:\n            try:\n                formats = ['%s' for _ in range(action.nargs)]\n            except TypeError:\n                raise ValueError(\"invalid nargs value\") from None\n            result = ' '.join(formats) % get_metavar(action.nargs)\n        return result",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._expand_help": {
        "API_name": "argparse.HelpFormatter._expand_help",
        "loc_name": "argparse.HelpFormatter._expand_help",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 619,
        "namespace": "HelpFormatter",
        "body": "    def _expand_help(self, action):\n        params = dict(vars(action), prog=self._prog)\n        for name in list(params):\n            if params[name] is SUPPRESS:\n                del params[name]\n        for name in list(params):\n            if hasattr(params[name], '__name__'):\n                params[name] = params[name].__name__\n        if params.get('choices') is not None:\n            choices_str = ', '.join([str(c) for c in params['choices']])\n            params['choices'] = choices_str\n        return self._get_help_string(action) % params",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._iter_indented_subactions": {
        "API_name": "argparse.HelpFormatter._iter_indented_subactions",
        "loc_name": "argparse.HelpFormatter._iter_indented_subactions",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 632,
        "namespace": "HelpFormatter",
        "body": "    def _iter_indented_subactions(self, action):\n        try:\n            get_subactions = action._get_subactions\n        except AttributeError:\n            pass\n        else:\n            self._indent()\n            yield from get_subactions()\n            self._dedent()",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._split_lines": {
        "API_name": "argparse.HelpFormatter._split_lines",
        "loc_name": "argparse.HelpFormatter._split_lines",
        "args": "self;text;width",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 642,
        "namespace": "HelpFormatter",
        "body": "    def _split_lines(self, text, width):\n        text = self._whitespace_matcher.sub(' ', text).strip()\n        # The textwrap module is used only for formatting help.\n        # Delay its import for speeding up the common usage of argparse.\n        import textwrap\n        return textwrap.wrap(text, width)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._fill_text": {
        "API_name": "argparse.HelpFormatter._fill_text",
        "loc_name": "argparse.HelpFormatter._fill_text",
        "args": "self;text;width;indent",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 649,
        "namespace": "HelpFormatter",
        "body": "    def _fill_text(self, text, width, indent):\n        text = self._whitespace_matcher.sub(' ', text).strip()\n        import textwrap\n        return textwrap.fill(text, width,\n                             initial_indent=indent,\n                             subsequent_indent=indent)",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._get_help_string": {
        "API_name": "argparse.HelpFormatter._get_help_string",
        "loc_name": "argparse.HelpFormatter._get_help_string",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 656,
        "namespace": "HelpFormatter",
        "body": "    def _get_help_string(self, action):\n        return action.help",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._get_default_metavar_for_optional": {
        "API_name": "argparse.HelpFormatter._get_default_metavar_for_optional",
        "loc_name": "argparse.HelpFormatter._get_default_metavar_for_optional",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 659,
        "namespace": "HelpFormatter",
        "body": "    def _get_default_metavar_for_optional(self, action):\n        return action.dest.upper()",
        "name_type": "stdlib"
    },
    "argparse.HelpFormatter._get_default_metavar_for_positional": {
        "API_name": "argparse.HelpFormatter._get_default_metavar_for_positional",
        "loc_name": "argparse.HelpFormatter._get_default_metavar_for_positional",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 662,
        "namespace": "HelpFormatter",
        "body": "    def _get_default_metavar_for_positional(self, action):\n        return action.dest",
        "name_type": "stdlib"
    },
    "argparse.RawDescriptionHelpFormatter._fill_text": {
        "API_name": "argparse.RawDescriptionHelpFormatter._fill_text",
        "loc_name": "argparse.RawDescriptionHelpFormatter._fill_text",
        "args": "self;text;width;indent",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 673,
        "namespace": "RawDescriptionHelpFormatter",
        "body": "    def _fill_text(self, text, width, indent):\n        return ''.join(indent + line for line in text.splitlines(keepends=True))",
        "name_type": "stdlib"
    },
    "argparse.RawDescriptionHelpFormatter": {
        "API_name": "argparse.RawDescriptionHelpFormatter",
        "loc_name": "argparse.RawDescriptionHelpFormatter",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 666,
        "namespace": "RawDescriptionHelpFormatter",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.RawTextHelpFormatter._split_lines": {
        "API_name": "argparse.RawTextHelpFormatter._split_lines",
        "loc_name": "argparse.RawTextHelpFormatter._split_lines",
        "args": "self;text;width",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 684,
        "namespace": "RawTextHelpFormatter",
        "body": "    def _split_lines(self, text, width):\n        return text.splitlines()",
        "name_type": "stdlib"
    },
    "argparse.RawTextHelpFormatter": {
        "API_name": "argparse.RawTextHelpFormatter",
        "loc_name": "argparse.RawTextHelpFormatter",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 677,
        "namespace": "RawTextHelpFormatter",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.ArgumentDefaultsHelpFormatter._get_help_string": {
        "API_name": "argparse.ArgumentDefaultsHelpFormatter._get_help_string",
        "loc_name": "argparse.ArgumentDefaultsHelpFormatter._get_help_string",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 695,
        "namespace": "ArgumentDefaultsHelpFormatter",
        "body": "    def _get_help_string(self, action):\n        help = action.help\n        if '%(default)' not in action.help:\n            if action.default is not SUPPRESS:\n                defaulting_nargs = [OPTIONAL, ZERO_OR_MORE]\n                if action.option_strings or action.nargs in defaulting_nargs:\n                    help += ' (default: %(default)s)'\n        return help",
        "name_type": "stdlib"
    },
    "argparse.ArgumentDefaultsHelpFormatter": {
        "API_name": "argparse.ArgumentDefaultsHelpFormatter",
        "loc_name": "argparse.ArgumentDefaultsHelpFormatter",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 688,
        "namespace": "ArgumentDefaultsHelpFormatter",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.MetavarTypeHelpFormatter._get_default_metavar_for_optional": {
        "API_name": "argparse.MetavarTypeHelpFormatter._get_default_metavar_for_optional",
        "loc_name": "argparse.MetavarTypeHelpFormatter._get_default_metavar_for_optional",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 713,
        "namespace": "MetavarTypeHelpFormatter",
        "body": "    def _get_default_metavar_for_optional(self, action):\n        return action.type.__name__",
        "name_type": "stdlib"
    },
    "argparse.MetavarTypeHelpFormatter._get_default_metavar_for_positional": {
        "API_name": "argparse.MetavarTypeHelpFormatter._get_default_metavar_for_positional",
        "loc_name": "argparse.MetavarTypeHelpFormatter._get_default_metavar_for_positional",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 716,
        "namespace": "MetavarTypeHelpFormatter",
        "body": "    def _get_default_metavar_for_positional(self, action):\n        return action.type.__name__",
        "name_type": "stdlib"
    },
    "argparse.MetavarTypeHelpFormatter": {
        "API_name": "argparse.MetavarTypeHelpFormatter",
        "loc_name": "argparse.MetavarTypeHelpFormatter",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 705,
        "namespace": "MetavarTypeHelpFormatter",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._get_action_name": {
        "API_name": "argparse._get_action_name",
        "loc_name": "argparse._get_action_name",
        "args": "argument",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 725,
        "namespace": "*",
        "body": "def _get_action_name(argument):\n    if argument is None:\n        return None\n    elif argument.option_strings:\n        return '/'.join(argument.option_strings)\n    elif argument.metavar not in (None, SUPPRESS):\n        return argument.metavar\n    elif argument.dest not in (None, SUPPRESS):\n        return argument.dest\n    elif argument.choices:\n        return '{' + ','.join(argument.choices) + '}'\n    else:\n        return None",
        "name_type": "stdlib"
    },
    "argparse.ArgumentError": {
        "API_name": "argparse.ArgumentError",
        "loc_name": "argparse.ArgumentError",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 740,
        "namespace": "ArgumentError",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.ArgumentError.__init__": {
        "API_name": "argparse.ArgumentError.__init__",
        "loc_name": "argparse.ArgumentError.__init__",
        "args": "self;argument;message",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 747,
        "namespace": "ArgumentError",
        "body": "    def __init__(self, argument, message):\n        self.argument_name = _get_action_name(argument)\n        self.message = message",
        "name_type": "stdlib"
    },
    "argparse.ArgumentError.__str__": {
        "API_name": "argparse.ArgumentError.__str__",
        "loc_name": "argparse.ArgumentError.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 751,
        "namespace": "ArgumentError",
        "body": "    def __str__(self):\n        if self.argument_name is None:\n            format = '%(message)s'\n        else:\n            format = 'argument %(argument_name)s: %(message)s'\n        return format % dict(message=self.message,\n                             argument_name=self.argument_name)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentTypeError": {
        "API_name": "argparse.ArgumentTypeError",
        "loc_name": "argparse.ArgumentTypeError",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 760,
        "namespace": "ArgumentTypeError",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.Action": {
        "API_name": "argparse.Action",
        "loc_name": "argparse.Action",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 769,
        "namespace": "Action",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.Action.__init__": {
        "API_name": "argparse.Action.__init__",
        "loc_name": "argparse.Action.__init__",
        "args": "self;option_strings;dest;nargs;const;default;type;choices;required;help;metavar",
        "args_default": 8,
        "filepath": "argparse",
        "lineno": 820,
        "namespace": "Action",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 nargs=None,\n                 const=None,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        self.option_strings = option_strings\n        self.dest = dest\n        self.nargs = nargs\n        self.const = const\n        self.default = default\n        self.type = type\n        self.choices = choices\n        self.required = required\n        self.help = help\n        self.metavar = metavar",
        "name_type": "stdlib"
    },
    "argparse.Action._get_kwargs": {
        "API_name": "argparse.Action._get_kwargs",
        "loc_name": "argparse.Action._get_kwargs",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 842,
        "namespace": "Action",
        "body": "    def _get_kwargs(self):\n        names = [\n            'option_strings',\n            'dest',\n            'nargs',\n            'const',\n            'default',\n            'type',\n            'choices',\n            'required',\n            'help',\n            'metavar',\n        ]\n        return [(name, getattr(self, name)) for name in names]",
        "name_type": "stdlib"
    },
    "argparse.Action.format_usage": {
        "API_name": "argparse.Action.format_usage",
        "loc_name": "argparse.Action.format_usage",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 857,
        "namespace": "Action",
        "body": "    def format_usage(self):\n        return self.option_strings[0]",
        "name_type": "stdlib"
    },
    "argparse.Action.__call__": {
        "API_name": "argparse.Action.__call__",
        "loc_name": "argparse.Action.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 860,
        "namespace": "Action",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        raise NotImplementedError(_('.__call__() not defined'))",
        "name_type": "stdlib"
    },
    "argparse.BooleanOptionalAction": {
        "API_name": "argparse.BooleanOptionalAction",
        "loc_name": "argparse.BooleanOptionalAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 863,
        "namespace": "BooleanOptionalAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.BooleanOptionalAction.__init__": {
        "API_name": "argparse.BooleanOptionalAction.__init__",
        "loc_name": "argparse.BooleanOptionalAction.__init__",
        "args": "self;option_strings;dest;default;type;choices;required;help;metavar",
        "args_default": 6,
        "filepath": "argparse",
        "lineno": 864,
        "namespace": "BooleanOptionalAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n\n        _option_strings = []\n        for option_string in option_strings:\n            _option_strings.append(option_string)\n\n            if option_string.startswith('--'):\n                option_string = '--no-' + option_string[2:]\n                _option_strings.append(option_string)\n\n        if help is not None and default is not None and default is not SUPPRESS:\n            help += \" (default: %(default)s)\"\n\n        super().__init__(\n            option_strings=_option_strings,\n            dest=dest,\n            nargs=0,\n            default=default,\n            type=type,\n            choices=choices,\n            required=required,\n            help=help,\n            metavar=metavar)",
        "name_type": "stdlib"
    },
    "argparse.BooleanOptionalAction.__call__": {
        "API_name": "argparse.BooleanOptionalAction.__call__",
        "loc_name": "argparse.BooleanOptionalAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 896,
        "namespace": "BooleanOptionalAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        if option_string in self.option_strings:\n            setattr(namespace, self.dest, not option_string.startswith('--no-'))",
        "name_type": "stdlib"
    },
    "argparse.BooleanOptionalAction.format_usage": {
        "API_name": "argparse.BooleanOptionalAction.format_usage",
        "loc_name": "argparse.BooleanOptionalAction.format_usage",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 900,
        "namespace": "BooleanOptionalAction",
        "body": "    def format_usage(self):\n        return ' | '.join(self.option_strings)",
        "name_type": "stdlib"
    },
    "argparse._StoreAction": {
        "API_name": "argparse._StoreAction",
        "loc_name": "argparse._StoreAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 904,
        "namespace": "_StoreAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._StoreAction.__init__": {
        "API_name": "argparse._StoreAction.__init__",
        "loc_name": "argparse._StoreAction.__init__",
        "args": "self;option_strings;dest;nargs;const;default;type;choices;required;help;metavar",
        "args_default": 8,
        "filepath": "argparse",
        "lineno": 906,
        "namespace": "_StoreAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 nargs=None,\n                 const=None,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        if nargs == 0:\n            raise ValueError('nargs for store actions must be != 0; if you '\n                             'have nothing to store, actions such as store '\n                             'true or store const may be more appropriate')\n        if const is not None and nargs != OPTIONAL:\n            raise ValueError('nargs must be %r to supply const' % OPTIONAL)\n        super(_StoreAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=nargs,\n            const=const,\n            default=default,\n            type=type,\n            choices=choices,\n            required=required,\n            help=help,\n            metavar=metavar)",
        "name_type": "stdlib"
    },
    "argparse._StoreAction.__call__": {
        "API_name": "argparse._StoreAction.__call__",
        "loc_name": "argparse._StoreAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 935,
        "namespace": "_StoreAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, values)",
        "name_type": "stdlib"
    },
    "argparse._StoreConstAction": {
        "API_name": "argparse._StoreConstAction",
        "loc_name": "argparse._StoreConstAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 939,
        "namespace": "_StoreConstAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._StoreConstAction.__init__": {
        "API_name": "argparse._StoreConstAction.__init__",
        "loc_name": "argparse._StoreConstAction.__init__",
        "args": "self;option_strings;dest;const;default;required;help;metavar",
        "args_default": 4,
        "filepath": "argparse",
        "lineno": 941,
        "namespace": "_StoreConstAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 const,\n                 default=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        super(_StoreConstAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            const=const,\n            default=default,\n            required=required,\n            help=help)",
        "name_type": "stdlib"
    },
    "argparse._StoreConstAction.__call__": {
        "API_name": "argparse._StoreConstAction.__call__",
        "loc_name": "argparse._StoreConstAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 958,
        "namespace": "_StoreConstAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        setattr(namespace, self.dest, self.const)",
        "name_type": "stdlib"
    },
    "argparse._StoreTrueAction": {
        "API_name": "argparse._StoreTrueAction",
        "loc_name": "argparse._StoreTrueAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 962,
        "namespace": "_StoreTrueAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._StoreTrueAction.__init__": {
        "API_name": "argparse._StoreTrueAction.__init__",
        "loc_name": "argparse._StoreTrueAction.__init__",
        "args": "self;option_strings;dest;default;required;help",
        "args_default": 3,
        "filepath": "argparse",
        "lineno": 964,
        "namespace": "_StoreTrueAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=False,\n                 required=False,\n                 help=None):\n        super(_StoreTrueAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            const=True,\n            default=default,\n            required=required,\n            help=help)",
        "name_type": "stdlib"
    },
    "argparse._StoreFalseAction": {
        "API_name": "argparse._StoreFalseAction",
        "loc_name": "argparse._StoreFalseAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 979,
        "namespace": "_StoreFalseAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._StoreFalseAction.__init__": {
        "API_name": "argparse._StoreFalseAction.__init__",
        "loc_name": "argparse._StoreFalseAction.__init__",
        "args": "self;option_strings;dest;default;required;help",
        "args_default": 3,
        "filepath": "argparse",
        "lineno": 981,
        "namespace": "_StoreFalseAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=True,\n                 required=False,\n                 help=None):\n        super(_StoreFalseAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            const=False,\n            default=default,\n            required=required,\n            help=help)",
        "name_type": "stdlib"
    },
    "argparse._AppendAction": {
        "API_name": "argparse._AppendAction",
        "loc_name": "argparse._AppendAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 996,
        "namespace": "_AppendAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._AppendAction.__init__": {
        "API_name": "argparse._AppendAction.__init__",
        "loc_name": "argparse._AppendAction.__init__",
        "args": "self;option_strings;dest;nargs;const;default;type;choices;required;help;metavar",
        "args_default": 8,
        "filepath": "argparse",
        "lineno": 998,
        "namespace": "_AppendAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 nargs=None,\n                 const=None,\n                 default=None,\n                 type=None,\n                 choices=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        if nargs == 0:\n            raise ValueError('nargs for append actions must be != 0; if arg '\n                             'strings are not supplying the value to append, '\n                             'the append const action may be more appropriate')\n        if const is not None and nargs != OPTIONAL:\n            raise ValueError('nargs must be %r to supply const' % OPTIONAL)\n        super(_AppendAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=nargs,\n            const=const,\n            default=default,\n            type=type,\n            choices=choices,\n            required=required,\n            help=help,\n            metavar=metavar)",
        "name_type": "stdlib"
    },
    "argparse._AppendAction.__call__": {
        "API_name": "argparse._AppendAction.__call__",
        "loc_name": "argparse._AppendAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1027,
        "namespace": "_AppendAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        items = getattr(namespace, self.dest, None)\n        items = _copy_items(items)\n        items.append(values)\n        setattr(namespace, self.dest, items)",
        "name_type": "stdlib"
    },
    "argparse._AppendConstAction": {
        "API_name": "argparse._AppendConstAction",
        "loc_name": "argparse._AppendConstAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1034,
        "namespace": "_AppendConstAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._AppendConstAction.__init__": {
        "API_name": "argparse._AppendConstAction.__init__",
        "loc_name": "argparse._AppendConstAction.__init__",
        "args": "self;option_strings;dest;const;default;required;help;metavar",
        "args_default": 4,
        "filepath": "argparse",
        "lineno": 1036,
        "namespace": "_AppendConstAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 const,\n                 default=None,\n                 required=False,\n                 help=None,\n                 metavar=None):\n        super(_AppendConstAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            const=const,\n            default=default,\n            required=required,\n            help=help,\n            metavar=metavar)",
        "name_type": "stdlib"
    },
    "argparse._AppendConstAction.__call__": {
        "API_name": "argparse._AppendConstAction.__call__",
        "loc_name": "argparse._AppendConstAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1054,
        "namespace": "_AppendConstAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        items = getattr(namespace, self.dest, None)\n        items = _copy_items(items)\n        items.append(self.const)\n        setattr(namespace, self.dest, items)",
        "name_type": "stdlib"
    },
    "argparse._CountAction": {
        "API_name": "argparse._CountAction",
        "loc_name": "argparse._CountAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1061,
        "namespace": "_CountAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._CountAction.__init__": {
        "API_name": "argparse._CountAction.__init__",
        "loc_name": "argparse._CountAction.__init__",
        "args": "self;option_strings;dest;default;required;help",
        "args_default": 3,
        "filepath": "argparse",
        "lineno": 1063,
        "namespace": "_CountAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest,\n                 default=None,\n                 required=False,\n                 help=None):\n        super(_CountAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=0,\n            default=default,\n            required=required,\n            help=help)",
        "name_type": "stdlib"
    },
    "argparse._CountAction.__call__": {
        "API_name": "argparse._CountAction.__call__",
        "loc_name": "argparse._CountAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1077,
        "namespace": "_CountAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        count = getattr(namespace, self.dest, None)\n        if count is None:\n            count = 0\n        setattr(namespace, self.dest, count + 1)",
        "name_type": "stdlib"
    },
    "argparse._HelpAction": {
        "API_name": "argparse._HelpAction",
        "loc_name": "argparse._HelpAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1084,
        "namespace": "_HelpAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._HelpAction.__init__": {
        "API_name": "argparse._HelpAction.__init__",
        "loc_name": "argparse._HelpAction.__init__",
        "args": "self;option_strings;dest;default;help",
        "args_default": 3,
        "filepath": "argparse",
        "lineno": 1086,
        "namespace": "_HelpAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 dest=SUPPRESS,\n                 default=SUPPRESS,\n                 help=None):\n        super(_HelpAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            default=default,\n            nargs=0,\n            help=help)",
        "name_type": "stdlib"
    },
    "argparse._HelpAction.__call__": {
        "API_name": "argparse._HelpAction.__call__",
        "loc_name": "argparse._HelpAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1098,
        "namespace": "_HelpAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        parser.print_help()\n        parser.exit()",
        "name_type": "stdlib"
    },
    "argparse._VersionAction": {
        "API_name": "argparse._VersionAction",
        "loc_name": "argparse._VersionAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1103,
        "namespace": "_VersionAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._VersionAction.__init__": {
        "API_name": "argparse._VersionAction.__init__",
        "loc_name": "argparse._VersionAction.__init__",
        "args": "self;option_strings;version;dest;default;help",
        "args_default": 4,
        "filepath": "argparse",
        "lineno": 1105,
        "namespace": "_VersionAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 version=None,\n                 dest=SUPPRESS,\n                 default=SUPPRESS,\n                 help=\"show program's version number and exit\"):\n        super(_VersionAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            default=default,\n            nargs=0,\n            help=help)\n        self.version = version",
        "name_type": "stdlib"
    },
    "argparse._VersionAction.__call__": {
        "API_name": "argparse._VersionAction.__call__",
        "loc_name": "argparse._VersionAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1119,
        "namespace": "_VersionAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        version = self.version\n        if version is None:\n            version = parser.version\n        formatter = parser._get_formatter()\n        formatter.add_text(version)\n        parser._print_message(formatter.format_help(), _sys.stdout)\n        parser.exit()",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction": {
        "API_name": "argparse._SubParsersAction",
        "loc_name": "argparse._SubParsersAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1129,
        "namespace": "_SubParsersAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction._ChoicesPseudoAction": {
        "API_name": "argparse._SubParsersAction._ChoicesPseudoAction",
        "loc_name": "argparse._SubParsersAction._ChoicesPseudoAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1131,
        "namespace": "_SubParsersAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction._ChoicesPseudoAction.__init__": {
        "API_name": "argparse._SubParsersAction._ChoicesPseudoAction.__init__",
        "loc_name": "argparse._SubParsersAction._ChoicesPseudoAction.__init__",
        "args": "self;name;aliases;help",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1133,
        "namespace": "_SubParsersAction",
        "body": "        def __init__(self, name, aliases, help):\n            metavar = dest = name\n            if aliases:\n                metavar += ' (%s)' % ', '.join(aliases)\n            sup = super(_SubParsersAction._ChoicesPseudoAction, self)\n            sup.__init__(option_strings=[], dest=dest, help=help,\n                         metavar=metavar)",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction.__init__": {
        "API_name": "argparse._SubParsersAction.__init__",
        "loc_name": "argparse._SubParsersAction.__init__",
        "args": "self;option_strings;prog;parser_class;dest;required;help;metavar",
        "args_default": 4,
        "filepath": "argparse",
        "lineno": 1141,
        "namespace": "_SubParsersAction",
        "body": "    def __init__(self,\n                 option_strings,\n                 prog,\n                 parser_class,\n                 dest=SUPPRESS,\n                 required=False,\n                 help=None,\n                 metavar=None):\n\n        self._prog_prefix = prog\n        self._parser_class = parser_class\n        self._name_parser_map = {}\n        self._choices_actions = []\n\n        super(_SubParsersAction, self).__init__(\n            option_strings=option_strings,\n            dest=dest,\n            nargs=PARSER,\n            choices=self._name_parser_map,\n            required=required,\n            help=help,\n            metavar=metavar)",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction.add_parser": {
        "API_name": "argparse._SubParsersAction.add_parser",
        "loc_name": "argparse._SubParsersAction.add_parser",
        "args": "self;name",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1164,
        "namespace": "_SubParsersAction",
        "body": "    def add_parser(self, name, **kwargs):\n        # set prog from the existing prefix\n        if kwargs.get('prog') is None:\n            kwargs['prog'] = '%s %s' % (self._prog_prefix, name)\n\n        aliases = kwargs.pop('aliases', ())\n\n        # create a pseudo-action to hold the choice help\n        if 'help' in kwargs:\n            help = kwargs.pop('help')\n            choice_action = self._ChoicesPseudoAction(name, aliases, help)\n            self._choices_actions.append(choice_action)\n\n        # create the parser and add it to the map\n        parser = self._parser_class(**kwargs)\n        self._name_parser_map[name] = parser\n\n        # make parser available under aliases also\n        for alias in aliases:\n            self._name_parser_map[alias] = parser\n\n        return parser",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction._get_subactions": {
        "API_name": "argparse._SubParsersAction._get_subactions",
        "loc_name": "argparse._SubParsersAction._get_subactions",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1187,
        "namespace": "_SubParsersAction",
        "body": "    def _get_subactions(self):\n        return self._choices_actions",
        "name_type": "stdlib"
    },
    "argparse._SubParsersAction.__call__": {
        "API_name": "argparse._SubParsersAction.__call__",
        "loc_name": "argparse._SubParsersAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1190,
        "namespace": "_SubParsersAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        parser_name = values[0]\n        arg_strings = values[1:]\n\n        # set the parser name if requested\n        if self.dest is not SUPPRESS:\n            setattr(namespace, self.dest, parser_name)\n\n        # select the parser\n        try:\n            parser = self._name_parser_map[parser_name]\n        except KeyError:\n            args = {'parser_name': parser_name,\n                    'choices': ', '.join(self._name_parser_map)}\n            msg = _('unknown parser %(parser_name)r (choices: %(choices)s)') % args\n            raise ArgumentError(self, msg)\n\n        # parse all the remaining options into the namespace\n        # store any unrecognized options on the object, so that the top\n        # level parser can decide what to do with them\n\n        # In case this subparser defines new defaults, we parse them\n        # in a new namespace object and then update the original\n        # namespace for the relevant parts.\n        subnamespace, arg_strings = parser.parse_known_args(arg_strings, None)\n        for key, value in vars(subnamespace).items():\n            setattr(namespace, key, value)\n\n        if arg_strings:\n            vars(namespace).setdefault(_UNRECOGNIZED_ARGS_ATTR, [])\n            getattr(namespace, _UNRECOGNIZED_ARGS_ATTR).extend(arg_strings)",
        "name_type": "stdlib"
    },
    "argparse._ExtendAction.__call__": {
        "API_name": "argparse._ExtendAction.__call__",
        "loc_name": "argparse._ExtendAction.__call__",
        "args": "self;parser;namespace;values;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1223,
        "namespace": "_ExtendAction",
        "body": "    def __call__(self, parser, namespace, values, option_string=None):\n        items = getattr(namespace, self.dest, None)\n        items = _copy_items(items)\n        items.extend(values)\n        setattr(namespace, self.dest, items)",
        "name_type": "stdlib"
    },
    "argparse._ExtendAction": {
        "API_name": "argparse._ExtendAction",
        "loc_name": "argparse._ExtendAction",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1222,
        "namespace": "_ExtendAction",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.FileType": {
        "API_name": "argparse.FileType",
        "loc_name": "argparse.FileType",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1233,
        "namespace": "FileType",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.FileType.__init__": {
        "API_name": "argparse.FileType.__init__",
        "loc_name": "argparse.FileType.__init__",
        "args": "self;mode;bufsize;encoding;errors",
        "args_default": 4,
        "filepath": "argparse",
        "lineno": 1250,
        "namespace": "FileType",
        "body": "    def __init__(self, mode='r', bufsize=-1, encoding=None, errors=None):\n        self._mode = mode\n        self._bufsize = bufsize\n        self._encoding = encoding\n        self._errors = errors",
        "name_type": "stdlib"
    },
    "argparse.FileType.__call__": {
        "API_name": "argparse.FileType.__call__",
        "loc_name": "argparse.FileType.__call__",
        "args": "self;string",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1256,
        "namespace": "FileType",
        "body": "    def __call__(self, string):\n        # the special argument \"-\" means sys.std{in,out}\n        if string == '-':\n            if 'r' in self._mode:\n                return _sys.stdin.buffer if 'b' in self._mode else _sys.stdin\n            elif any(c in self._mode for c in 'wax'):\n                return _sys.stdout.buffer if 'b' in self._mode else _sys.stdout\n            else:\n                msg = _('argument \"-\" with mode %r') % self._mode\n                raise ValueError(msg)\n\n        # all other arguments are used as file names\n        try:\n            return open(string, self._mode, self._bufsize, self._encoding,\n                        self._errors)\n        except OSError as e:\n            args = {'filename': string, 'error': e}\n            message = _(\"can't open '%(filename)s': %(error)s\")\n            raise ArgumentTypeError(message % args)",
        "name_type": "stdlib"
    },
    "argparse.FileType.__repr__": {
        "API_name": "argparse.FileType.__repr__",
        "loc_name": "argparse.FileType.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1276,
        "namespace": "FileType",
        "body": "    def __repr__(self):\n        args = self._mode, self._bufsize\n        kwargs = [('encoding', self._encoding), ('errors', self._errors)]\n        args_str = ', '.join([repr(arg) for arg in args if arg != -1] +\n                             ['%s=%r' % (kw, arg) for kw, arg in kwargs\n                              if arg is not None])\n        return '%s(%s)' % (type(self).__name__, args_str)",
        "name_type": "stdlib"
    },
    "argparse.Namespace": {
        "API_name": "argparse.Namespace",
        "loc_name": "argparse.Namespace",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1288,
        "namespace": "Namespace",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.Namespace.__init__": {
        "API_name": "argparse.Namespace.__init__",
        "loc_name": "argparse.Namespace.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1295,
        "namespace": "Namespace",
        "body": "    def __init__(self, **kwargs):\n        for name in kwargs:\n            setattr(self, name, kwargs[name])",
        "name_type": "stdlib"
    },
    "argparse.Namespace.__eq__": {
        "API_name": "argparse.Namespace.__eq__",
        "loc_name": "argparse.Namespace.__eq__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1299,
        "namespace": "Namespace",
        "body": "    def __eq__(self, other):\n        if not isinstance(other, Namespace):\n            return NotImplemented\n        return vars(self) == vars(other)",
        "name_type": "stdlib"
    },
    "argparse.Namespace.__contains__": {
        "API_name": "argparse.Namespace.__contains__",
        "loc_name": "argparse.Namespace.__contains__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1304,
        "namespace": "Namespace",
        "body": "    def __contains__(self, key):\n        return key in self.__dict__",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer": {
        "API_name": "argparse._ActionsContainer",
        "loc_name": "argparse._ActionsContainer",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1308,
        "namespace": "_ActionsContainer",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.__init__": {
        "API_name": "argparse._ActionsContainer.__init__",
        "loc_name": "argparse._ActionsContainer.__init__",
        "args": "self;description;prefix_chars;argument_default;conflict_handler",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1310,
        "namespace": "_ActionsContainer",
        "body": "    def __init__(self,\n                 description,\n                 prefix_chars,\n                 argument_default,\n                 conflict_handler):\n        super(_ActionsContainer, self).__init__()\n\n        self.description = description\n        self.argument_default = argument_default\n        self.prefix_chars = prefix_chars\n        self.conflict_handler = conflict_handler\n\n        # set up registries\n        self._registries = {}\n\n        # register actions\n        self.register('action', None, _StoreAction)\n        self.register('action', 'store', _StoreAction)\n        self.register('action', 'store_const', _StoreConstAction)\n        self.register('action', 'store_true', _StoreTrueAction)\n        self.register('action', 'store_false', _StoreFalseAction)\n        self.register('action', 'append', _AppendAction)\n        self.register('action', 'append_const', _AppendConstAction)\n        self.register('action', 'count', _CountAction)\n        self.register('action', 'help', _HelpAction)\n        self.register('action', 'version', _VersionAction)\n        self.register('action', 'parsers', _SubParsersAction)\n        self.register('action', 'extend', _ExtendAction)\n\n        # raise an exception if the conflict handler is invalid\n        self._get_handler()\n\n        # action storage\n        self._actions = []\n        self._option_string_actions = {}\n\n        # groups\n        self._action_groups = []\n        self._mutually_exclusive_groups = []\n\n        # defaults storage\n        self._defaults = {}\n\n        # determines whether an \"option\" looks like a negative number\n        self._negative_number_matcher = _re.compile(r'^-\\d+$|^-\\d*\\.\\d+$')\n\n        # whether or not there are any optionals that look like negative\n        # numbers -- uses a list so it can be shared and edited\n        self._has_negative_number_optionals = []",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.register": {
        "API_name": "argparse._ActionsContainer.register",
        "loc_name": "argparse._ActionsContainer.register",
        "args": "self;registry_name;value;object",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1363,
        "namespace": "_ActionsContainer",
        "body": "    def register(self, registry_name, value, object):\n        registry = self._registries.setdefault(registry_name, {})\n        registry[value] = object",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._registry_get": {
        "API_name": "argparse._ActionsContainer._registry_get",
        "loc_name": "argparse._ActionsContainer._registry_get",
        "args": "self;registry_name;value;default",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1367,
        "namespace": "_ActionsContainer",
        "body": "    def _registry_get(self, registry_name, value, default=None):\n        return self._registries[registry_name].get(value, default)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.set_defaults": {
        "API_name": "argparse._ActionsContainer.set_defaults",
        "loc_name": "argparse._ActionsContainer.set_defaults",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1373,
        "namespace": "_ActionsContainer",
        "body": "    def set_defaults(self, **kwargs):\n        self._defaults.update(kwargs)\n\n        # if these defaults match any existing arguments, replace\n        # the previous default on the object with the new one\n        for action in self._actions:\n            if action.dest in kwargs:\n                action.default = kwargs[action.dest]",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.get_default": {
        "API_name": "argparse._ActionsContainer.get_default",
        "loc_name": "argparse._ActionsContainer.get_default",
        "args": "self;dest",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1382,
        "namespace": "_ActionsContainer",
        "body": "    def get_default(self, dest):\n        for action in self._actions:\n            if action.dest == dest and action.default is not None:\n                return action.default\n        return self._defaults.get(dest, None)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.add_argument": {
        "API_name": "argparse._ActionsContainer.add_argument",
        "loc_name": "argparse._ActionsContainer.add_argument",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1392,
        "namespace": "_ActionsContainer",
        "body": "    def add_argument(self, *args, **kwargs):\n        \"\"\"\n        add_argument(dest, ..., name=value, ...)\n        add_argument(option_string, option_string, ..., name=value, ...)\n        \"\"\"\n\n        # if no positional args are supplied or only one is supplied and\n        # it doesn't look like an option string, parse a positional\n        # argument\n        chars = self.prefix_chars\n        if not args or len(args) == 1 and args[0][0] not in chars:\n            if args and 'dest' in kwargs:\n                raise ValueError('dest supplied twice for positional argument')\n            kwargs = self._get_positional_kwargs(*args, **kwargs)\n\n        # otherwise, we're adding an optional argument\n        else:\n            kwargs = self._get_optional_kwargs(*args, **kwargs)\n\n        # if no default was supplied, use the parser-level default\n        if 'default' not in kwargs:\n            dest = kwargs['dest']\n            if dest in self._defaults:\n                kwargs['default'] = self._defaults[dest]\n            elif self.argument_default is not None:\n                kwargs['default'] = self.argument_default\n\n        # create the action object, and add it to the parser\n        action_class = self._pop_action_class(kwargs)\n        if not callable(action_class):\n            raise ValueError('unknown action \"%s\"' % (action_class,))\n        action = action_class(**kwargs)\n\n        # raise an error if the action type is not callable\n        type_func = self._registry_get('type', action.type, action.type)\n        if not callable(type_func):\n            raise ValueError('%r is not callable' % (type_func,))\n\n        if type_func is FileType:\n            raise ValueError('%r is a FileType class object, instance of it'\n                             ' must be passed' % (type_func,))\n\n        # raise an error if the metavar does not match the type\n        if hasattr(self, \"_get_formatter\"):\n            try:\n                self._get_formatter()._format_args(action, None)\n            except TypeError:\n                raise ValueError(\"length of metavar tuple does not match nargs\")\n\n        return self._add_action(action)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.add_argument_group": {
        "API_name": "argparse._ActionsContainer.add_argument_group",
        "loc_name": "argparse._ActionsContainer.add_argument_group",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1443,
        "namespace": "_ActionsContainer",
        "body": "    def add_argument_group(self, *args, **kwargs):\n        group = _ArgumentGroup(self, *args, **kwargs)\n        self._action_groups.append(group)\n        return group",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer.add_mutually_exclusive_group": {
        "API_name": "argparse._ActionsContainer.add_mutually_exclusive_group",
        "loc_name": "argparse._ActionsContainer.add_mutually_exclusive_group",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1448,
        "namespace": "_ActionsContainer",
        "body": "    def add_mutually_exclusive_group(self, **kwargs):\n        group = _MutuallyExclusiveGroup(self, **kwargs)\n        self._mutually_exclusive_groups.append(group)\n        return group",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._add_action": {
        "API_name": "argparse._ActionsContainer._add_action",
        "loc_name": "argparse._ActionsContainer._add_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1453,
        "namespace": "_ActionsContainer",
        "body": "    def _add_action(self, action):\n        # resolve any conflicts\n        self._check_conflict(action)\n\n        # add to actions list\n        self._actions.append(action)\n        action.container = self\n\n        # index the action by any option strings it has\n        for option_string in action.option_strings:\n            self._option_string_actions[option_string] = action\n\n        # set the flag if any option strings look like negative numbers\n        for option_string in action.option_strings:\n            if self._negative_number_matcher.match(option_string):\n                if not self._has_negative_number_optionals:\n                    self._has_negative_number_optionals.append(True)\n\n        # return the created action\n        return action",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._remove_action": {
        "API_name": "argparse._ActionsContainer._remove_action",
        "loc_name": "argparse._ActionsContainer._remove_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1474,
        "namespace": "_ActionsContainer",
        "body": "    def _remove_action(self, action):\n        self._actions.remove(action)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._add_container_actions": {
        "API_name": "argparse._ActionsContainer._add_container_actions",
        "loc_name": "argparse._ActionsContainer._add_container_actions",
        "args": "self;container",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1477,
        "namespace": "_ActionsContainer",
        "body": "    def _add_container_actions(self, container):\n        # collect groups by titles\n        title_group_map = {}\n        for group in self._action_groups:\n            if group.title in title_group_map:\n                msg = _('cannot merge actions - two groups are named %r')\n                raise ValueError(msg % (group.title))\n            title_group_map[group.title] = group\n\n        # map each action to its group\n        group_map = {}\n        for group in container._action_groups:\n\n            # if a group with the title exists, use that, otherwise\n            # create a new group matching the container's group\n            if group.title not in title_group_map:\n                title_group_map[group.title] = self.add_argument_group(\n                    title=group.title,\n                    description=group.description,\n                    conflict_handler=group.conflict_handler)\n\n            # map the actions to their new group\n            for action in group._group_actions:\n                group_map[action] = title_group_map[group.title]\n\n        # add container's mutually exclusive groups\n        # NOTE: if add_mutually_exclusive_group ever gains title= and\n        # description= then this code will need to be expanded as above\n        for group in container._mutually_exclusive_groups:\n            mutex_group = self.add_mutually_exclusive_group(\n                required=group.required)\n\n            # map the actions to their new mutex group\n            for action in group._group_actions:\n                group_map[action] = mutex_group\n\n        # add all actions to this container or their group\n        for action in container._actions:\n            group_map.get(action, self)._add_action(action)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._get_positional_kwargs": {
        "API_name": "argparse._ActionsContainer._get_positional_kwargs",
        "loc_name": "argparse._ActionsContainer._get_positional_kwargs",
        "args": "self;dest",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1517,
        "namespace": "_ActionsContainer",
        "body": "    def _get_positional_kwargs(self, dest, **kwargs):\n        # make sure required is not specified\n        if 'required' in kwargs:\n            msg = _(\"'required' is an invalid argument for positionals\")\n            raise TypeError(msg)\n\n        # mark positional arguments as required if at least one is\n        # always required\n        if kwargs.get('nargs') not in [OPTIONAL, ZERO_OR_MORE]:\n            kwargs['required'] = True\n        if kwargs.get('nargs') == ZERO_OR_MORE and 'default' not in kwargs:\n            kwargs['required'] = True\n\n        # return the keyword arguments with no option strings\n        return dict(kwargs, dest=dest, option_strings=[])",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._get_optional_kwargs": {
        "API_name": "argparse._ActionsContainer._get_optional_kwargs",
        "loc_name": "argparse._ActionsContainer._get_optional_kwargs",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1533,
        "namespace": "_ActionsContainer",
        "body": "    def _get_optional_kwargs(self, *args, **kwargs):\n        # determine short and long option strings\n        option_strings = []\n        long_option_strings = []\n        for option_string in args:\n            # error on strings that don't start with an appropriate prefix\n            if not option_string[0] in self.prefix_chars:\n                args = {'option': option_string,\n                        'prefix_chars': self.prefix_chars}\n                msg = _('invalid option string %(option)r: '\n                        'must start with a character %(prefix_chars)r')\n                raise ValueError(msg % args)\n\n            # strings starting with two prefix characters are long options\n            option_strings.append(option_string)\n            if len(option_string) > 1 and option_string[1] in self.prefix_chars:\n                long_option_strings.append(option_string)\n\n        # infer destination, '--foo-bar' -> 'foo_bar' and '-x' -> 'x'\n        dest = kwargs.pop('dest', None)\n        if dest is None:\n            if long_option_strings:\n                dest_option_string = long_option_strings[0]\n            else:\n                dest_option_string = option_strings[0]\n            dest = dest_option_string.lstrip(self.prefix_chars)\n            if not dest:\n                msg = _('dest= is required for options like %r')\n                raise ValueError(msg % option_string)\n            dest = dest.replace('-', '_')\n\n        # return the updated keyword arguments\n        return dict(kwargs, dest=dest, option_strings=option_strings)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._pop_action_class": {
        "API_name": "argparse._ActionsContainer._pop_action_class",
        "loc_name": "argparse._ActionsContainer._pop_action_class",
        "args": "self;kwargs;default",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1567,
        "namespace": "_ActionsContainer",
        "body": "    def _pop_action_class(self, kwargs, default=None):\n        action = kwargs.pop('action', default)\n        return self._registry_get('action', action, action)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._get_handler": {
        "API_name": "argparse._ActionsContainer._get_handler",
        "loc_name": "argparse._ActionsContainer._get_handler",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1571,
        "namespace": "_ActionsContainer",
        "body": "    def _get_handler(self):\n        # determine function from conflict handler string\n        handler_func_name = '_handle_conflict_%s' % self.conflict_handler\n        try:\n            return getattr(self, handler_func_name)\n        except AttributeError:\n            msg = _('invalid conflict_resolution value: %r')\n            raise ValueError(msg % self.conflict_handler)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._check_conflict": {
        "API_name": "argparse._ActionsContainer._check_conflict",
        "loc_name": "argparse._ActionsContainer._check_conflict",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1580,
        "namespace": "_ActionsContainer",
        "body": "    def _check_conflict(self, action):\n\n        # find all options that conflict with this option\n        confl_optionals = []\n        for option_string in action.option_strings:\n            if option_string in self._option_string_actions:\n                confl_optional = self._option_string_actions[option_string]\n                confl_optionals.append((option_string, confl_optional))\n\n        # resolve any conflicts\n        if confl_optionals:\n            conflict_handler = self._get_handler()\n            conflict_handler(action, confl_optionals)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._handle_conflict_error": {
        "API_name": "argparse._ActionsContainer._handle_conflict_error",
        "loc_name": "argparse._ActionsContainer._handle_conflict_error",
        "args": "self;action;conflicting_actions",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1594,
        "namespace": "_ActionsContainer",
        "body": "    def _handle_conflict_error(self, action, conflicting_actions):\n        message = ngettext('conflicting option string: %s',\n                           'conflicting option strings: %s',\n                           len(conflicting_actions))\n        conflict_string = ', '.join([option_string\n                                     for option_string, action\n                                     in conflicting_actions])\n        raise ArgumentError(action, message % conflict_string)",
        "name_type": "stdlib"
    },
    "argparse._ActionsContainer._handle_conflict_resolve": {
        "API_name": "argparse._ActionsContainer._handle_conflict_resolve",
        "loc_name": "argparse._ActionsContainer._handle_conflict_resolve",
        "args": "self;action;conflicting_actions",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1603,
        "namespace": "_ActionsContainer",
        "body": "    def _handle_conflict_resolve(self, action, conflicting_actions):\n\n        # remove all conflicting options\n        for option_string, action in conflicting_actions:\n\n            # remove the conflicting option\n            action.option_strings.remove(option_string)\n            self._option_string_actions.pop(option_string, None)\n\n            # if the option now has no option string, remove it from the\n            # container holding it\n            if not action.option_strings:\n                action.container._remove_action(action)",
        "name_type": "stdlib"
    },
    "argparse._ArgumentGroup": {
        "API_name": "argparse._ArgumentGroup",
        "loc_name": "argparse._ArgumentGroup",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1618,
        "namespace": "_ArgumentGroup",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._ArgumentGroup.__init__": {
        "API_name": "argparse._ArgumentGroup.__init__",
        "loc_name": "argparse._ArgumentGroup.__init__",
        "args": "self;container;title;description",
        "args_default": 2,
        "filepath": "argparse",
        "lineno": 1620,
        "namespace": "_ArgumentGroup",
        "body": "    def __init__(self, container, title=None, description=None, **kwargs):\n        # add any missing keyword arguments by checking the container\n        update = kwargs.setdefault\n        update('conflict_handler', container.conflict_handler)\n        update('prefix_chars', container.prefix_chars)\n        update('argument_default', container.argument_default)\n        super_init = super(_ArgumentGroup, self).__init__\n        super_init(description=description, **kwargs)\n\n        # group attributes\n        self.title = title\n        self._group_actions = []\n\n        # share most attributes with the container\n        self._registries = container._registries\n        self._actions = container._actions\n        self._option_string_actions = container._option_string_actions\n        self._defaults = container._defaults\n        self._has_negative_number_optionals = \\\n            container._has_negative_number_optionals\n        self._mutually_exclusive_groups = container._mutually_exclusive_groups",
        "name_type": "stdlib"
    },
    "argparse._ArgumentGroup._add_action": {
        "API_name": "argparse._ArgumentGroup._add_action",
        "loc_name": "argparse._ArgumentGroup._add_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1642,
        "namespace": "_ArgumentGroup",
        "body": "    def _add_action(self, action):\n        action = super(_ArgumentGroup, self)._add_action(action)\n        self._group_actions.append(action)\n        return action",
        "name_type": "stdlib"
    },
    "argparse._ArgumentGroup._remove_action": {
        "API_name": "argparse._ArgumentGroup._remove_action",
        "loc_name": "argparse._ArgumentGroup._remove_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1647,
        "namespace": "_ArgumentGroup",
        "body": "    def _remove_action(self, action):\n        super(_ArgumentGroup, self)._remove_action(action)\n        self._group_actions.remove(action)",
        "name_type": "stdlib"
    },
    "argparse._MutuallyExclusiveGroup": {
        "API_name": "argparse._MutuallyExclusiveGroup",
        "loc_name": "argparse._MutuallyExclusiveGroup",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1652,
        "namespace": "_MutuallyExclusiveGroup",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse._MutuallyExclusiveGroup.__init__": {
        "API_name": "argparse._MutuallyExclusiveGroup.__init__",
        "loc_name": "argparse._MutuallyExclusiveGroup.__init__",
        "args": "self;container;required",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1654,
        "namespace": "_MutuallyExclusiveGroup",
        "body": "    def __init__(self, container, required=False):\n        super(_MutuallyExclusiveGroup, self).__init__(container)\n        self.required = required\n        self._container = container",
        "name_type": "stdlib"
    },
    "argparse._MutuallyExclusiveGroup._add_action": {
        "API_name": "argparse._MutuallyExclusiveGroup._add_action",
        "loc_name": "argparse._MutuallyExclusiveGroup._add_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1659,
        "namespace": "_MutuallyExclusiveGroup",
        "body": "    def _add_action(self, action):\n        if action.required:\n            msg = _('mutually exclusive arguments must be optional')\n            raise ValueError(msg)\n        action = self._container._add_action(action)\n        self._group_actions.append(action)\n        return action",
        "name_type": "stdlib"
    },
    "argparse._MutuallyExclusiveGroup._remove_action": {
        "API_name": "argparse._MutuallyExclusiveGroup._remove_action",
        "loc_name": "argparse._MutuallyExclusiveGroup._remove_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1667,
        "namespace": "_MutuallyExclusiveGroup",
        "body": "    def _remove_action(self, action):\n        self._container._remove_action(action)\n        self._group_actions.remove(action)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser": {
        "API_name": "argparse.ArgumentParser",
        "loc_name": "argparse.ArgumentParser",
        "args": "*",
        "args_default": "*",
        "filepath": "argparse",
        "lineno": 1672,
        "namespace": "ArgumentParser",
        "body": "",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.__init__": {
        "API_name": "argparse.ArgumentParser.__init__",
        "loc_name": "argparse.ArgumentParser.__init__",
        "args": "self;prog;usage;description;epilog;parents;formatter_class;prefix_chars;fromfile_prefix_chars;argument_default;conflict_handler;add_help;allow_abbrev;exit_on_error",
        "args_default": 13,
        "filepath": "argparse",
        "lineno": 1693,
        "namespace": "ArgumentParser",
        "body": "    def __init__(self,\n                 prog=None,\n                 usage=None,\n                 description=None,\n                 epilog=None,\n                 parents=[],\n                 formatter_class=HelpFormatter,\n                 prefix_chars='-',\n                 fromfile_prefix_chars=None,\n                 argument_default=None,\n                 conflict_handler='error',\n                 add_help=True,\n                 allow_abbrev=True,\n                 exit_on_error=True):\n\n        superinit = super(ArgumentParser, self).__init__\n        superinit(description=description,\n                  prefix_chars=prefix_chars,\n                  argument_default=argument_default,\n                  conflict_handler=conflict_handler)\n\n        # default setting for prog\n        if prog is None:\n            prog = _os.path.basename(_sys.argv[0])\n\n        self.prog = prog\n        self.usage = usage\n        self.epilog = epilog\n        self.formatter_class = formatter_class\n        self.fromfile_prefix_chars = fromfile_prefix_chars\n        self.add_help = add_help\n        self.allow_abbrev = allow_abbrev\n        self.exit_on_error = exit_on_error\n\n        add_group = self.add_argument_group\n        self._positionals = add_group(_('positional arguments'))\n        self._optionals = add_group(_('optional arguments'))\n        self._subparsers = None\n\n        # register types\n        def identity(string):\n            return string\n        self.register('type', None, identity)\n\n        # add help argument if necessary\n        # (using explicit default to override global argument_default)\n        default_prefix = '-' if '-' in prefix_chars else prefix_chars[0]\n        if self.add_help:\n            self.add_argument(\n                default_prefix+'h', default_prefix*2+'help',\n                action='help', default=SUPPRESS,\n                help=_('show this help message and exit'))\n\n        # add parent arguments and defaults\n        for parent in parents:\n            self._add_container_actions(parent)\n            try:\n                defaults = parent._defaults\n            except AttributeError:\n                pass\n            else:\n                self._defaults.update(defaults)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.__init__.identity": {
        "API_name": "argparse.ArgumentParser.__init__.identity",
        "loc_name": "argparse.ArgumentParser.__init__.identity",
        "args": "string",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1733,
        "namespace": "ArgumentParser",
        "body": "        def identity(string):\n            return string",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_kwargs": {
        "API_name": "argparse.ArgumentParser._get_kwargs",
        "loc_name": "argparse.ArgumentParser._get_kwargs",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1759,
        "namespace": "ArgumentParser",
        "body": "    def _get_kwargs(self):\n        names = [\n            'prog',\n            'usage',\n            'description',\n            'formatter_class',\n            'conflict_handler',\n            'add_help',\n        ]\n        return [(name, getattr(self, name)) for name in names]",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.add_subparsers": {
        "API_name": "argparse.ArgumentParser.add_subparsers",
        "loc_name": "argparse.ArgumentParser.add_subparsers",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1773,
        "namespace": "ArgumentParser",
        "body": "    def add_subparsers(self, **kwargs):\n        if self._subparsers is not None:\n            self.error(_('cannot have multiple subparser arguments'))\n\n        # add the parser class to the arguments if it's not present\n        kwargs.setdefault('parser_class', type(self))\n\n        if 'title' in kwargs or 'description' in kwargs:\n            title = _(kwargs.pop('title', 'subcommands'))\n            description = _(kwargs.pop('description', None))\n            self._subparsers = self.add_argument_group(title, description)\n        else:\n            self._subparsers = self._positionals\n\n        # prog defaults to the usage message of this parser, skipping\n        # optional arguments and with no \"usage:\" prefix\n        if kwargs.get('prog') is None:\n            formatter = self._get_formatter()\n            positionals = self._get_positional_actions()\n            groups = self._mutually_exclusive_groups\n            formatter.add_usage(self.usage, positionals, groups, '')\n            kwargs['prog'] = formatter.format_help().strip()\n\n        # create the parsers action and add it to the positionals list\n        parsers_class = self._pop_action_class(kwargs, 'parsers')\n        action = parsers_class(option_strings=[], **kwargs)\n        self._subparsers._add_action(action)\n\n        # return the created parsers action\n        return action",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._add_action": {
        "API_name": "argparse.ArgumentParser._add_action",
        "loc_name": "argparse.ArgumentParser._add_action",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1804,
        "namespace": "ArgumentParser",
        "body": "    def _add_action(self, action):\n        if action.option_strings:\n            self._optionals._add_action(action)\n        else:\n            self._positionals._add_action(action)\n        return action",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_optional_actions": {
        "API_name": "argparse.ArgumentParser._get_optional_actions",
        "loc_name": "argparse.ArgumentParser._get_optional_actions",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1811,
        "namespace": "ArgumentParser",
        "body": "    def _get_optional_actions(self):\n        return [action\n                for action in self._actions\n                if action.option_strings]",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_positional_actions": {
        "API_name": "argparse.ArgumentParser._get_positional_actions",
        "loc_name": "argparse.ArgumentParser._get_positional_actions",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1816,
        "namespace": "ArgumentParser",
        "body": "    def _get_positional_actions(self):\n        return [action\n                for action in self._actions\n                if not action.option_strings]",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.parse_args": {
        "API_name": "argparse.ArgumentParser.parse_args",
        "loc_name": "argparse.ArgumentParser.parse_args",
        "args": "self;args;namespace",
        "args_default": 2,
        "filepath": "argparse",
        "lineno": 1824,
        "namespace": "ArgumentParser",
        "body": "    def parse_args(self, args=None, namespace=None):\n        args, argv = self.parse_known_args(args, namespace)\n        if argv:\n            msg = _('unrecognized arguments: %s')\n            self.error(msg % ' '.join(argv))\n        return args",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.parse_known_args": {
        "API_name": "argparse.ArgumentParser.parse_known_args",
        "loc_name": "argparse.ArgumentParser.parse_known_args",
        "args": "self;args;namespace",
        "args_default": 2,
        "filepath": "argparse",
        "lineno": 1831,
        "namespace": "ArgumentParser",
        "body": "    def parse_known_args(self, args=None, namespace=None):\n        if args is None:\n            # args default to the system args\n            args = _sys.argv[1:]\n        else:\n            # make sure that args are mutable\n            args = list(args)\n\n        # default Namespace built from parser defaults\n        if namespace is None:\n            namespace = Namespace()\n\n        # add any action defaults that aren't present\n        for action in self._actions:\n            if action.dest is not SUPPRESS:\n                if not hasattr(namespace, action.dest):\n                    if action.default is not SUPPRESS:\n                        setattr(namespace, action.dest, action.default)\n\n        # add any parser defaults that aren't present\n        for dest in self._defaults:\n            if not hasattr(namespace, dest):\n                setattr(namespace, dest, self._defaults[dest])\n\n        # parse the arguments and exit if there are any errors\n        if self.exit_on_error:\n            try:\n                namespace, args = self._parse_known_args(args, namespace)\n            except ArgumentError:\n                err = _sys.exc_info()[1]\n                self.error(str(err))\n        else:\n            namespace, args = self._parse_known_args(args, namespace)\n\n        if hasattr(namespace, _UNRECOGNIZED_ARGS_ATTR):\n            args.extend(getattr(namespace, _UNRECOGNIZED_ARGS_ATTR))\n            delattr(namespace, _UNRECOGNIZED_ARGS_ATTR)\n        return namespace, args",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._parse_known_args": {
        "API_name": "argparse.ArgumentParser._parse_known_args",
        "loc_name": "argparse.ArgumentParser._parse_known_args",
        "args": "self;arg_strings;namespace",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1870,
        "namespace": "ArgumentParser",
        "body": "    def _parse_known_args(self, arg_strings, namespace):\n        # replace arg strings that are file references\n        if self.fromfile_prefix_chars is not None:\n            arg_strings = self._read_args_from_files(arg_strings)\n\n        # map all mutually exclusive arguments to the other arguments\n        # they can't occur with\n        action_conflicts = {}\n        for mutex_group in self._mutually_exclusive_groups:\n            group_actions = mutex_group._group_actions\n            for i, mutex_action in enumerate(mutex_group._group_actions):\n                conflicts = action_conflicts.setdefault(mutex_action, [])\n                conflicts.extend(group_actions[:i])\n                conflicts.extend(group_actions[i + 1:])\n\n        # find all option indices, and determine the arg_string_pattern\n        # which has an 'O' if there is an option at an index,\n        # an 'A' if there is an argument, or a '-' if there is a '--'\n        option_string_indices = {}\n        arg_string_pattern_parts = []\n        arg_strings_iter = iter(arg_strings)\n        for i, arg_string in enumerate(arg_strings_iter):\n\n            # all args after -- are non-options\n            if arg_string == '--':\n                arg_string_pattern_parts.append('-')\n                for arg_string in arg_strings_iter:\n                    arg_string_pattern_parts.append('A')\n\n            # otherwise, add the arg to the arg strings\n            # and note the index if it was an option\n            else:\n                option_tuple = self._parse_optional(arg_string)\n                if option_tuple is None:\n                    pattern = 'A'\n                else:\n                    option_string_indices[i] = option_tuple\n                    pattern = 'O'\n                arg_string_pattern_parts.append(pattern)\n\n        # join the pieces together to form the pattern\n        arg_strings_pattern = ''.join(arg_string_pattern_parts)\n\n        # converts arg strings to the appropriate and then takes the action\n        seen_actions = set()\n        seen_non_default_actions = set()\n\n        def take_action(action, argument_strings, option_string=None):\n            seen_actions.add(action)\n            argument_values = self._get_values(action, argument_strings)\n\n            # error if this argument is not allowed with other previously\n            # seen arguments, assuming that actions that use the default\n            # value don't really count as \"present\"\n            if argument_values is not action.default:\n                seen_non_default_actions.add(action)\n                for conflict_action in action_conflicts.get(action, []):\n                    if conflict_action in seen_non_default_actions:\n                        msg = _('not allowed with argument %s')\n                        action_name = _get_action_name(conflict_action)\n                        raise ArgumentError(action, msg % action_name)\n\n            # take the action if we didn't receive a SUPPRESS value\n            # (e.g. from a default)\n            if argument_values is not SUPPRESS:\n                action(self, namespace, argument_values, option_string)\n\n        # function to convert arg_strings into an optional action\n        def consume_optional(start_index):\n\n            # get the optional identified at this index\n            option_tuple = option_string_indices[start_index]\n            action, option_string, explicit_arg = option_tuple\n\n            # identify additional optionals in the same arg string\n            # (e.g. -xyz is the same as -x -y -z if no args are required)\n            match_argument = self._match_argument\n            action_tuples = []\n            while True:\n\n                # if we found no optional action, skip it\n                if action is None:\n                    extras.append(arg_strings[start_index])\n                    return start_index + 1\n\n                # if there is an explicit argument, try to match the\n                # optional's string arguments to only this\n                if explicit_arg is not None:\n                    arg_count = match_argument(action, 'A')\n\n                    # if the action is a single-dash option and takes no\n                    # arguments, try to parse more single-dash options out\n                    # of the tail of the option string\n                    chars = self.prefix_chars\n                    if arg_count == 0 and option_string[1] not in chars:\n                        action_tuples.append((action, [], option_string))\n                        char = option_string[0]\n                        option_string = char + explicit_arg[0]\n                        new_explicit_arg = explicit_arg[1:] or None\n                        optionals_map = self._option_string_actions\n                        if option_string in optionals_map:\n                            action = optionals_map[option_string]\n                            explicit_arg = new_explicit_arg\n                        else:\n                            msg = _('ignored explicit argument %r')\n                            raise ArgumentError(action, msg % explicit_arg)\n\n                    # if the action expect exactly one argument, we've\n                    # successfully matched the option; exit the loop\n                    elif arg_count == 1:\n                        stop = start_index + 1\n                        args = [explicit_arg]\n                        action_tuples.append((action, args, option_string))\n                        break\n\n                    # error if a double-dash option did not use the\n                    # explicit argument\n                    else:\n                        msg = _('ignored explicit argument %r')\n                        raise ArgumentError(action, msg % explicit_arg)\n\n                # if there is no explicit argument, try to match the\n                # optional's string arguments with the following strings\n                # if successful, exit the loop\n                else:\n                    start = start_index + 1\n                    selected_patterns = arg_strings_pattern[start:]\n                    arg_count = match_argument(action, selected_patterns)\n                    stop = start + arg_count\n                    args = arg_strings[start:stop]\n                    action_tuples.append((action, args, option_string))\n                    break\n\n            # add the Optional to the list and return the index at which\n            # the Optional's string args stopped\n            assert action_tuples\n            for action, args, option_string in action_tuples:\n                take_action(action, args, option_string)\n            return stop\n\n        # the list of Positionals left to be parsed; this is modified\n        # by consume_positionals()\n        positionals = self._get_positional_actions()\n\n        # function to convert arg_strings into positional actions\n        def consume_positionals(start_index):\n            # match as many Positionals as possible\n            match_partial = self._match_arguments_partial\n            selected_pattern = arg_strings_pattern[start_index:]\n            arg_counts = match_partial(positionals, selected_pattern)\n\n            # slice off the appropriate arg strings for each Positional\n            # and add the Positional and its args to the list\n            for action, arg_count in zip(positionals, arg_counts):\n                args = arg_strings[start_index: start_index + arg_count]\n                start_index += arg_count\n                take_action(action, args)\n\n            # slice off the Positionals that we just parsed and return the\n            # index at which the Positionals' string args stopped\n            positionals[:] = positionals[len(arg_counts):]\n            return start_index\n\n        # consume Positionals and Optionals alternately, until we have\n        # passed the last option string\n        extras = []\n        start_index = 0\n        if option_string_indices:\n            max_option_string_index = max(option_string_indices)\n        else:\n            max_option_string_index = -1\n        while start_index <= max_option_string_index:\n\n            # consume any Positionals preceding the next option\n            next_option_string_index = min([\n                index\n                for index in option_string_indices\n                if index >= start_index])\n            if start_index != next_option_string_index:\n                positionals_end_index = consume_positionals(start_index)\n\n                # only try to parse the next optional if we didn't consume\n                # the option string during the positionals parsing\n                if positionals_end_index > start_index:\n                    start_index = positionals_end_index\n                    continue\n                else:\n                    start_index = positionals_end_index\n\n            # if we consumed all the positionals we could and we're not\n            # at the index of an option string, there were extra arguments\n            if start_index not in option_string_indices:\n                strings = arg_strings[start_index:next_option_string_index]\n                extras.extend(strings)\n                start_index = next_option_string_index\n\n            # consume the next optional and any arguments for it\n            start_index = consume_optional(start_index)\n\n        # consume any positionals following the last Optional\n        stop_index = consume_positionals(start_index)\n\n        # if we didn't consume all the argument strings, there were extras\n        extras.extend(arg_strings[stop_index:])\n\n        # make sure all required actions were present and also convert\n        # action defaults which were not given as arguments\n        required_actions = []\n        for action in self._actions:\n            if action not in seen_actions:\n                if action.required:\n                    required_actions.append(_get_action_name(action))\n                else:\n                    # Convert action default now instead of doing it before\n                    # parsing arguments to avoid calling convert functions\n                    # twice (which may fail) if the argument was given, but\n                    # only if it was defined already in the namespace\n                    if (action.default is not None and\n                        isinstance(action.default, str) and\n                        hasattr(namespace, action.dest) and\n                        action.default is getattr(namespace, action.dest)):\n                        setattr(namespace, action.dest,\n                                self._get_value(action, action.default))\n\n        if required_actions:\n            self.error(_('the following arguments are required: %s') %\n                       ', '.join(required_actions))\n\n        # make sure all required groups had one option present\n        for group in self._mutually_exclusive_groups:\n            if group.required:\n                for action in group._group_actions:\n                    if action in seen_non_default_actions:\n                        break\n\n                # if no actions were used, report the error\n                else:\n                    names = [_get_action_name(action)\n                             for action in group._group_actions\n                             if action.help is not SUPPRESS]\n                    msg = _('one of the arguments %s is required')\n                    self.error(msg % ' '.join(names))\n\n        # return the updated namespace and the extra arguments\n        return namespace, extras",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._parse_known_args.take_action": {
        "API_name": "argparse.ArgumentParser._parse_known_args.take_action",
        "loc_name": "argparse.ArgumentParser._parse_known_args.take_action",
        "args": "action;argument_strings;option_string",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 1917,
        "namespace": "ArgumentParser",
        "body": "        def take_action(action, argument_strings, option_string=None):\n            seen_actions.add(action)\n            argument_values = self._get_values(action, argument_strings)\n\n            # error if this argument is not allowed with other previously\n            # seen arguments, assuming that actions that use the default\n            # value don't really count as \"present\"\n            if argument_values is not action.default:\n                seen_non_default_actions.add(action)\n                for conflict_action in action_conflicts.get(action, []):\n                    if conflict_action in seen_non_default_actions:\n                        msg = _('not allowed with argument %s')\n                        action_name = _get_action_name(conflict_action)\n                        raise ArgumentError(action, msg % action_name)\n\n            # take the action if we didn't receive a SUPPRESS value\n            # (e.g. from a default)\n            if argument_values is not SUPPRESS:\n                action(self, namespace, argument_values, option_string)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._parse_known_args.consume_optional": {
        "API_name": "argparse.ArgumentParser._parse_known_args.consume_optional",
        "loc_name": "argparse.ArgumentParser._parse_known_args.consume_optional",
        "args": "start_index",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 1938,
        "namespace": "ArgumentParser",
        "body": "        def consume_optional(start_index):\n\n            # get the optional identified at this index\n            option_tuple = option_string_indices[start_index]\n            action, option_string, explicit_arg = option_tuple\n\n            # identify additional optionals in the same arg string\n            # (e.g. -xyz is the same as -x -y -z if no args are required)\n            match_argument = self._match_argument\n            action_tuples = []\n            while True:\n\n                # if we found no optional action, skip it\n                if action is None:\n                    extras.append(arg_strings[start_index])\n                    return start_index + 1\n\n                # if there is an explicit argument, try to match the\n                # optional's string arguments to only this\n                if explicit_arg is not None:\n                    arg_count = match_argument(action, 'A')\n\n                    # if the action is a single-dash option and takes no\n                    # arguments, try to parse more single-dash options out\n                    # of the tail of the option string\n                    chars = self.prefix_chars\n                    if arg_count == 0 and option_string[1] not in chars:\n                        action_tuples.append((action, [], option_string))\n                        char = option_string[0]\n                        option_string = char + explicit_arg[0]\n                        new_explicit_arg = explicit_arg[1:] or None\n                        optionals_map = self._option_string_actions\n                        if option_string in optionals_map:\n                            action = optionals_map[option_string]\n                            explicit_arg = new_explicit_arg\n                        else:\n                            msg = _('ignored explicit argument %r')\n                            raise ArgumentError(action, msg % explicit_arg)\n\n                    # if the action expect exactly one argument, we've\n                    # successfully matched the option; exit the loop\n                    elif arg_count == 1:\n                        stop = start_index + 1\n                        args = [explicit_arg]\n                        action_tuples.append((action, args, option_string))\n                        break\n\n                    # error if a double-dash option did not use the\n                    # explicit argument\n                    else:\n                        msg = _('ignored explicit argument %r')\n                        raise ArgumentError(action, msg % explicit_arg)\n\n                # if there is no explicit argument, try to match the\n                # optional's string arguments with the following strings\n                # if successful, exit the loop\n                else:\n                    start = start_index + 1\n                    selected_patterns = arg_strings_pattern[start:]\n                    arg_count = match_argument(action, selected_patterns)\n                    stop = start + arg_count\n                    args = arg_strings[start:stop]\n                    action_tuples.append((action, args, option_string))\n                    break\n\n            # add the Optional to the list and return the index at which\n            # the Optional's string args stopped\n            assert action_tuples\n            for action, args, option_string in action_tuples:\n                take_action(action, args, option_string)\n            return stop",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._parse_known_args.consume_positionals": {
        "API_name": "argparse.ArgumentParser._parse_known_args.consume_positionals",
        "loc_name": "argparse.ArgumentParser._parse_known_args.consume_positionals",
        "args": "start_index",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2015,
        "namespace": "ArgumentParser",
        "body": "        def consume_positionals(start_index):\n            # match as many Positionals as possible\n            match_partial = self._match_arguments_partial\n            selected_pattern = arg_strings_pattern[start_index:]\n            arg_counts = match_partial(positionals, selected_pattern)\n\n            # slice off the appropriate arg strings for each Positional\n            # and add the Positional and its args to the list\n            for action, arg_count in zip(positionals, arg_counts):\n                args = arg_strings[start_index: start_index + arg_count]\n                start_index += arg_count\n                take_action(action, args)\n\n            # slice off the Positionals that we just parsed and return the\n            # index at which the Positionals' string args stopped\n            positionals[:] = positionals[len(arg_counts):]\n            return start_index",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._read_args_from_files": {
        "API_name": "argparse.ArgumentParser._read_args_from_files",
        "loc_name": "argparse.ArgumentParser._read_args_from_files",
        "args": "self;arg_strings",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2116,
        "namespace": "ArgumentParser",
        "body": "    def _read_args_from_files(self, arg_strings):\n        # expand arguments referencing files\n        new_arg_strings = []\n        for arg_string in arg_strings:\n\n            # for regular arguments, just add them back into the list\n            if not arg_string or arg_string[0] not in self.fromfile_prefix_chars:\n                new_arg_strings.append(arg_string)\n\n            # replace arguments referencing files with the file content\n            else:\n                try:\n                    with open(arg_string[1:]) as args_file:\n                        arg_strings = []\n                        for arg_line in args_file.read().splitlines():\n                            for arg in self.convert_arg_line_to_args(arg_line):\n                                arg_strings.append(arg)\n                        arg_strings = self._read_args_from_files(arg_strings)\n                        new_arg_strings.extend(arg_strings)\n                except OSError:\n                    err = _sys.exc_info()[1]\n                    self.error(str(err))\n\n        # return the modified argument list\n        return new_arg_strings",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.convert_arg_line_to_args": {
        "API_name": "argparse.ArgumentParser.convert_arg_line_to_args",
        "loc_name": "argparse.ArgumentParser.convert_arg_line_to_args",
        "args": "self;arg_line",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2142,
        "namespace": "ArgumentParser",
        "body": "    def convert_arg_line_to_args(self, arg_line):\n        return [arg_line]",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._match_argument": {
        "API_name": "argparse.ArgumentParser._match_argument",
        "loc_name": "argparse.ArgumentParser._match_argument",
        "args": "self;action;arg_strings_pattern",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2145,
        "namespace": "ArgumentParser",
        "body": "    def _match_argument(self, action, arg_strings_pattern):\n        # match the pattern for this action to the arg strings\n        nargs_pattern = self._get_nargs_pattern(action)\n        match = _re.match(nargs_pattern, arg_strings_pattern)\n\n        # raise an exception if we weren't able to find a match\n        if match is None:\n            nargs_errors = {\n                None: _('expected one argument'),\n                OPTIONAL: _('expected at most one argument'),\n                ONE_OR_MORE: _('expected at least one argument'),\n            }\n            msg = nargs_errors.get(action.nargs)\n            if msg is None:\n                msg = ngettext('expected %s argument',\n                               'expected %s arguments',\n                               action.nargs) % action.nargs\n            raise ArgumentError(action, msg)\n\n        # return the number of arguments matched\n        return len(match.group(1))",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._match_arguments_partial": {
        "API_name": "argparse.ArgumentParser._match_arguments_partial",
        "loc_name": "argparse.ArgumentParser._match_arguments_partial",
        "args": "self;actions;arg_strings_pattern",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2167,
        "namespace": "ArgumentParser",
        "body": "    def _match_arguments_partial(self, actions, arg_strings_pattern):\n        # progressively shorten the actions list by slicing off the\n        # final actions until we find a match\n        result = []\n        for i in range(len(actions), 0, -1):\n            actions_slice = actions[:i]\n            pattern = ''.join([self._get_nargs_pattern(action)\n                               for action in actions_slice])\n            match = _re.match(pattern, arg_strings_pattern)\n            if match is not None:\n                result.extend([len(string) for string in match.groups()])\n                break\n\n        # return the list of arg string counts\n        return result",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._parse_optional": {
        "API_name": "argparse.ArgumentParser._parse_optional",
        "loc_name": "argparse.ArgumentParser._parse_optional",
        "args": "self;arg_string",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2183,
        "namespace": "ArgumentParser",
        "body": "    def _parse_optional(self, arg_string):\n        # if it's an empty string, it was meant to be a positional\n        if not arg_string:\n            return None\n\n        # if it doesn't start with a prefix, it was meant to be positional\n        if not arg_string[0] in self.prefix_chars:\n            return None\n\n        # if the option string is present in the parser, return the action\n        if arg_string in self._option_string_actions:\n            action = self._option_string_actions[arg_string]\n            return action, arg_string, None\n\n        # if it's just a single character, it was meant to be positional\n        if len(arg_string) == 1:\n            return None\n\n        # if the option string before the \"=\" is present, return the action\n        if '=' in arg_string:\n            option_string, explicit_arg = arg_string.split('=', 1)\n            if option_string in self._option_string_actions:\n                action = self._option_string_actions[option_string]\n                return action, option_string, explicit_arg\n\n        # search through all possible prefixes of the option string\n        # and all actions in the parser for possible interpretations\n        option_tuples = self._get_option_tuples(arg_string)\n\n        # if multiple actions match, the option string was ambiguous\n        if len(option_tuples) > 1:\n            options = ', '.join([option_string\n                for action, option_string, explicit_arg in option_tuples])\n            args = {'option': arg_string, 'matches': options}\n            msg = _('ambiguous option: %(option)s could match %(matches)s')\n            self.error(msg % args)\n\n        # if exactly one action matched, this segmentation is good,\n        # so return the parsed action\n        elif len(option_tuples) == 1:\n            option_tuple, = option_tuples\n            return option_tuple\n\n        # if it was not found as an option, but it looks like a negative\n        # number, it was meant to be positional\n        # unless there are negative-number-like options\n        if self._negative_number_matcher.match(arg_string):\n            if not self._has_negative_number_optionals:\n                return None\n\n        # if it contains a space, it was meant to be a positional\n        if ' ' in arg_string:\n            return None\n\n        # it was meant to be an optional but there is no such option\n        # in this parser (though it might be a valid option in a subparser)\n        return None, arg_string, None",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_option_tuples": {
        "API_name": "argparse.ArgumentParser._get_option_tuples",
        "loc_name": "argparse.ArgumentParser._get_option_tuples",
        "args": "self;option_string",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2241,
        "namespace": "ArgumentParser",
        "body": "    def _get_option_tuples(self, option_string):\n        result = []\n\n        # option strings starting with two prefix characters are only\n        # split at the '='\n        chars = self.prefix_chars\n        if option_string[0] in chars and option_string[1] in chars:\n            if self.allow_abbrev:\n                if '=' in option_string:\n                    option_prefix, explicit_arg = option_string.split('=', 1)\n                else:\n                    option_prefix = option_string\n                    explicit_arg = None\n                for option_string in self._option_string_actions:\n                    if option_string.startswith(option_prefix):\n                        action = self._option_string_actions[option_string]\n                        tup = action, option_string, explicit_arg\n                        result.append(tup)\n\n        # single character options can be concatenated with their arguments\n        # but multiple character options always have to have their argument\n        # separate\n        elif option_string[0] in chars and option_string[1] not in chars:\n            option_prefix = option_string\n            explicit_arg = None\n            short_option_prefix = option_string[:2]\n            short_explicit_arg = option_string[2:]\n\n            for option_string in self._option_string_actions:\n                if option_string == short_option_prefix:\n                    action = self._option_string_actions[option_string]\n                    tup = action, option_string, short_explicit_arg\n                    result.append(tup)\n                elif option_string.startswith(option_prefix):\n                    action = self._option_string_actions[option_string]\n                    tup = action, option_string, explicit_arg\n                    result.append(tup)\n\n        # shouldn't ever get here\n        else:\n            self.error(_('unexpected option string: %s') % option_string)\n\n        # return the collected option tuples\n        return result",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_nargs_pattern": {
        "API_name": "argparse.ArgumentParser._get_nargs_pattern",
        "loc_name": "argparse.ArgumentParser._get_nargs_pattern",
        "args": "self;action",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2286,
        "namespace": "ArgumentParser",
        "body": "    def _get_nargs_pattern(self, action):\n        # in all examples below, we have to allow for '--' args\n        # which are represented as '-' in the pattern\n        nargs = action.nargs\n\n        # the default (None) is assumed to be a single argument\n        if nargs is None:\n            nargs_pattern = '(-*A-*)'\n\n        # allow zero or one arguments\n        elif nargs == OPTIONAL:\n            nargs_pattern = '(-*A?-*)'\n\n        # allow zero or more arguments\n        elif nargs == ZERO_OR_MORE:\n            nargs_pattern = '(-*[A-]*)'\n\n        # allow one or more arguments\n        elif nargs == ONE_OR_MORE:\n            nargs_pattern = '(-*A[A-]*)'\n\n        # allow any number of options or arguments\n        elif nargs == REMAINDER:\n            nargs_pattern = '([-AO]*)'\n\n        # allow one argument followed by any number of options or arguments\n        elif nargs == PARSER:\n            nargs_pattern = '(-*A[-AO]*)'\n\n        # suppress action, like nargs=0\n        elif nargs == SUPPRESS:\n            nargs_pattern = '(-*-*)'\n\n        # all others should be integers\n        else:\n            nargs_pattern = '(-*%s-*)' % '-*'.join('A' * nargs)\n\n        # if this is an optional action, -- is not allowed\n        if action.option_strings:\n            nargs_pattern = nargs_pattern.replace('-*', '')\n            nargs_pattern = nargs_pattern.replace('-', '')\n\n        # return the pattern\n        return nargs_pattern",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.parse_intermixed_args": {
        "API_name": "argparse.ArgumentParser.parse_intermixed_args",
        "loc_name": "argparse.ArgumentParser.parse_intermixed_args",
        "args": "self;args;namespace",
        "args_default": 2,
        "filepath": "argparse",
        "lineno": 2335,
        "namespace": "ArgumentParser",
        "body": "    def parse_intermixed_args(self, args=None, namespace=None):\n        args, argv = self.parse_known_intermixed_args(args, namespace)\n        if argv:\n            msg = _('unrecognized arguments: %s')\n            self.error(msg % ' '.join(argv))\n        return args",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.parse_known_intermixed_args": {
        "API_name": "argparse.ArgumentParser.parse_known_intermixed_args",
        "loc_name": "argparse.ArgumentParser.parse_known_intermixed_args",
        "args": "self;args;namespace",
        "args_default": 2,
        "filepath": "argparse",
        "lineno": 2342,
        "namespace": "ArgumentParser",
        "body": "    def parse_known_intermixed_args(self, args=None, namespace=None):\n        # returns a namespace and list of extras\n        #\n        # positional can be freely intermixed with optionals.  optionals are\n        # first parsed with all positional arguments deactivated.  The 'extras'\n        # are then parsed.  If the parser definition is incompatible with the\n        # intermixed assumptions (e.g. use of REMAINDER, subparsers) a\n        # TypeError is raised.\n        #\n        # positionals are 'deactivated' by setting nargs and default to\n        # SUPPRESS.  This blocks the addition of that positional to the\n        # namespace\n\n        positionals = self._get_positional_actions()\n        a = [action for action in positionals\n             if action.nargs in [PARSER, REMAINDER]]\n        if a:\n            raise TypeError('parse_intermixed_args: positional arg'\n                            ' with nargs=%s'%a[0].nargs)\n\n        if [action.dest for group in self._mutually_exclusive_groups\n            for action in group._group_actions if action in positionals]:\n            raise TypeError('parse_intermixed_args: positional in'\n                            ' mutuallyExclusiveGroup')\n\n        try:\n            save_usage = self.usage\n            try:\n                if self.usage is None:\n                    # capture the full usage for use in error messages\n                    self.usage = self.format_usage()[7:]\n                for action in positionals:\n                    # deactivate positionals\n                    action.save_nargs = action.nargs\n                    # action.nargs = 0\n                    action.nargs = SUPPRESS\n                    action.save_default = action.default\n                    action.default = SUPPRESS\n                namespace, remaining_args = self.parse_known_args(args,\n                                                                  namespace)\n                for action in positionals:\n                    # remove the empty positional values from namespace\n                    if (hasattr(namespace, action.dest)\n                            and getattr(namespace, action.dest)==[]):\n                        from warnings import warn\n                        warn('Do not expect %s in %s' % (action.dest, namespace))\n                        delattr(namespace, action.dest)\n            finally:\n                # restore nargs and usage before exiting\n                for action in positionals:\n                    action.nargs = action.save_nargs\n                    action.default = action.save_default\n            optionals = self._get_optional_actions()\n            try:\n                # parse positionals.  optionals aren't normally required, but\n                # they could be, so make sure they aren't.\n                for action in optionals:\n                    action.save_required = action.required\n                    action.required = False\n                for group in self._mutually_exclusive_groups:\n                    group.save_required = group.required\n                    group.required = False\n                namespace, extras = self.parse_known_args(remaining_args,\n                                                          namespace)\n            finally:\n                # restore parser values before exiting\n                for action in optionals:\n                    action.required = action.save_required\n                for group in self._mutually_exclusive_groups:\n                    group.required = group.save_required\n        finally:\n            self.usage = save_usage\n        return namespace, extras",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_values": {
        "API_name": "argparse.ArgumentParser._get_values",
        "loc_name": "argparse.ArgumentParser._get_values",
        "args": "self;action;arg_strings",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2419,
        "namespace": "ArgumentParser",
        "body": "    def _get_values(self, action, arg_strings):\n        # for everything but PARSER, REMAINDER args, strip out first '--'\n        if action.nargs not in [PARSER, REMAINDER]:\n            try:\n                arg_strings.remove('--')\n            except ValueError:\n                pass\n\n        # optional argument produces a default when not present\n        if not arg_strings and action.nargs == OPTIONAL:\n            if action.option_strings:\n                value = action.const\n            else:\n                value = action.default\n            if isinstance(value, str):\n                value = self._get_value(action, value)\n                self._check_value(action, value)\n\n        # when nargs='*' on a positional, if there were no command-line\n        # args, use the default if it is anything other than None\n        elif (not arg_strings and action.nargs == ZERO_OR_MORE and\n              not action.option_strings):\n            if action.default is not None:\n                value = action.default\n            else:\n                value = arg_strings\n            self._check_value(action, value)\n\n        # single argument or optional argument produces a single value\n        elif len(arg_strings) == 1 and action.nargs in [None, OPTIONAL]:\n            arg_string, = arg_strings\n            value = self._get_value(action, arg_string)\n            self._check_value(action, value)\n\n        # REMAINDER arguments convert all values, checking none\n        elif action.nargs == REMAINDER:\n            value = [self._get_value(action, v) for v in arg_strings]\n\n        # PARSER arguments convert all values, but check only the first\n        elif action.nargs == PARSER:\n            value = [self._get_value(action, v) for v in arg_strings]\n            self._check_value(action, value[0])\n\n        # SUPPRESS argument does not put anything in the namespace\n        elif action.nargs == SUPPRESS:\n            value = SUPPRESS\n\n        # all other types of nargs produce a list\n        else:\n            value = [self._get_value(action, v) for v in arg_strings]\n            for v in value:\n                self._check_value(action, v)\n\n        # return the converted value\n        return value",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_value": {
        "API_name": "argparse.ArgumentParser._get_value",
        "loc_name": "argparse.ArgumentParser._get_value",
        "args": "self;action;arg_string",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2475,
        "namespace": "ArgumentParser",
        "body": "    def _get_value(self, action, arg_string):\n        type_func = self._registry_get('type', action.type, action.type)\n        if not callable(type_func):\n            msg = _('%r is not callable')\n            raise ArgumentError(action, msg % type_func)\n\n        # convert the value to the appropriate type\n        try:\n            result = type_func(arg_string)\n\n        # ArgumentTypeErrors indicate errors\n        except ArgumentTypeError:\n            name = getattr(action.type, '__name__', repr(action.type))\n            msg = str(_sys.exc_info()[1])\n            raise ArgumentError(action, msg)\n\n        # TypeErrors or ValueErrors also indicate errors\n        except (TypeError, ValueError):\n            name = getattr(action.type, '__name__', repr(action.type))\n            args = {'type': name, 'value': arg_string}\n            msg = _('invalid %(type)s value: %(value)r')\n            raise ArgumentError(action, msg % args)\n\n        # return the converted value\n        return result",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._check_value": {
        "API_name": "argparse.ArgumentParser._check_value",
        "loc_name": "argparse.ArgumentParser._check_value",
        "args": "self;action;value",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2501,
        "namespace": "ArgumentParser",
        "body": "    def _check_value(self, action, value):\n        # converted value must be one of the choices (if specified)\n        if action.choices is not None and value not in action.choices:\n            args = {'value': value,\n                    'choices': ', '.join(map(repr, action.choices))}\n            msg = _('invalid choice: %(value)r (choose from %(choices)s)')\n            raise ArgumentError(action, msg % args)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.format_usage": {
        "API_name": "argparse.ArgumentParser.format_usage",
        "loc_name": "argparse.ArgumentParser.format_usage",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2512,
        "namespace": "ArgumentParser",
        "body": "    def format_usage(self):\n        formatter = self._get_formatter()\n        formatter.add_usage(self.usage, self._actions,\n                            self._mutually_exclusive_groups)\n        return formatter.format_help()",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.format_help": {
        "API_name": "argparse.ArgumentParser.format_help",
        "loc_name": "argparse.ArgumentParser.format_help",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2518,
        "namespace": "ArgumentParser",
        "body": "    def format_help(self):\n        formatter = self._get_formatter()\n\n        # usage\n        formatter.add_usage(self.usage, self._actions,\n                            self._mutually_exclusive_groups)\n\n        # description\n        formatter.add_text(self.description)\n\n        # positionals, optionals and user-defined groups\n        for action_group in self._action_groups:\n            formatter.start_section(action_group.title)\n            formatter.add_text(action_group.description)\n            formatter.add_arguments(action_group._group_actions)\n            formatter.end_section()\n\n        # epilog\n        formatter.add_text(self.epilog)\n\n        # determine help from format above\n        return formatter.format_help()",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._get_formatter": {
        "API_name": "argparse.ArgumentParser._get_formatter",
        "loc_name": "argparse.ArgumentParser._get_formatter",
        "args": "self",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2541,
        "namespace": "ArgumentParser",
        "body": "    def _get_formatter(self):\n        return self.formatter_class(prog=self.prog)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.print_usage": {
        "API_name": "argparse.ArgumentParser.print_usage",
        "loc_name": "argparse.ArgumentParser.print_usage",
        "args": "self;file",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 2547,
        "namespace": "ArgumentParser",
        "body": "    def print_usage(self, file=None):\n        if file is None:\n            file = _sys.stdout\n        self._print_message(self.format_usage(), file)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.print_help": {
        "API_name": "argparse.ArgumentParser.print_help",
        "loc_name": "argparse.ArgumentParser.print_help",
        "args": "self;file",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 2552,
        "namespace": "ArgumentParser",
        "body": "    def print_help(self, file=None):\n        if file is None:\n            file = _sys.stdout\n        self._print_message(self.format_help(), file)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser._print_message": {
        "API_name": "argparse.ArgumentParser._print_message",
        "loc_name": "argparse.ArgumentParser._print_message",
        "args": "self;message;file",
        "args_default": 1,
        "filepath": "argparse",
        "lineno": 2557,
        "namespace": "ArgumentParser",
        "body": "    def _print_message(self, message, file=None):\n        if message:\n            if file is None:\n                file = _sys.stderr\n            file.write(message)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.exit": {
        "API_name": "argparse.ArgumentParser.exit",
        "loc_name": "argparse.ArgumentParser.exit",
        "args": "self;status;message",
        "args_default": 2,
        "filepath": "argparse",
        "lineno": 2566,
        "namespace": "ArgumentParser",
        "body": "    def exit(self, status=0, message=None):\n        if message:\n            self._print_message(message, _sys.stderr)\n        _sys.exit(status)",
        "name_type": "stdlib"
    },
    "argparse.ArgumentParser.error": {
        "API_name": "argparse.ArgumentParser.error",
        "loc_name": "argparse.ArgumentParser.error",
        "args": "self;message",
        "args_default": 0,
        "filepath": "argparse",
        "lineno": 2571,
        "namespace": "ArgumentParser",
        "body": "    def error(self, message):\n        \"\"\"error(message: string)\n\n        Prints a usage message incorporating the message to stderr and\n        exits.\n\n        If you override this in a subclass, it should not return -- it\n        should either exit or raise an exception.\n        \"\"\"\n        self.print_usage(_sys.stderr)\n        args = {'prog': self.prog, 'message': message}\n        self.exit(2, _('%(prog)s: error: %(message)s\\n') % args)",
        "name_type": "stdlib"
    },
    "base64": {
        "API_name": "base64",
        "loc_name": "base64",
        "args": "*",
        "args_default": "*",
        "filepath": "base64",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Base16, Base32, Base64 (RFC 3548), Base85 and Ascii85 data encodings\"\"\"\n__all__ = [\n    # Legacy interface exports traditional RFC 2045 Base64 encodings\n    'encode', 'decode', 'encodebytes', 'decodebytes',\n    # Generalized interface for other encodings\n    'b64encode', 'b64decode', 'b32encode', 'b32decode',\n    'b16encode', 'b16decode',\n    # Base85 and Ascii85 encodings\n    'b85encode', 'b85decode', 'a85encode', 'a85decode',\n    # Standard Base64 encoding\n    'standard_b64encode', 'standard_b64decode',\n    # Some common Base64 alternatives.  As referenced by RFC 3458, see thread\n    # starting at:\n    #\n    # http://zgp.org/pipermail/p2p-hackers/2001-September/000316.html\n    'urlsafe_b64encode', 'urlsafe_b64decode',\n    ]\nbytes_types = (bytes, bytearray)  # Types acceptable as binary data\n_urlsafe_encode_translation = bytes.maketrans(b'+/', b'-_')\n_urlsafe_decode_translation = bytes.maketrans(b'-_', b'+/')\n_b32alphabet = b'ABCDEFGHIJKLMNOPQRSTUVWXYZ234567'\n_b32tab2 = None\n_b32rev = None\n_a85chars = None\n_a85chars2 = None\n_A85START = b\"<~\"\n_A85END = b\"~>\"\n_b85alphabet = (b\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n                b\"abcdefghijklmnopqrstuvwxyz!#$%&()*+-;<=>?@^_`{|}~\")\n_b85chars = None\n_b85chars2 = None\n_b85dec = None\nMAXLINESIZE = 76 # Excluding the CRLF\nMAXBINSIZE = (MAXLINESIZE//4)*3\nif __name__ == '__main__':\n    main()",
        "name_type": "stdlib"
    },
    "base64._bytes_from_decode_data": {
        "API_name": "base64._bytes_from_decode_data",
        "loc_name": "base64._bytes_from_decode_data",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 34,
        "namespace": "*",
        "body": "def _bytes_from_decode_data(s):\n    if isinstance(s, str):\n        try:\n            return s.encode('ascii')\n        except UnicodeEncodeError:\n            raise ValueError('string argument should contain only ASCII characters')\n    if isinstance(s, bytes_types):\n        return s\n    try:\n        return memoryview(s).tobytes()\n    except TypeError:\n        raise TypeError(\"argument should be a bytes-like object or ASCII \"\n                        \"string, not %r\" % s.__class__.__name__) from None",
        "name_type": "stdlib"
    },
    "base64.b64encode": {
        "API_name": "base64.b64encode",
        "loc_name": "base64.b64encode",
        "args": "s;altchars",
        "args_default": 1,
        "filepath": "base64",
        "lineno": 51,
        "namespace": "*",
        "body": "def b64encode(s, altchars=None):\n    \"\"\"Encode the bytes-like object s using Base64 and return a bytes object.\n\n    Optional altchars should be a byte string of length 2 which specifies an\n    alternative alphabet for the '+' and '/' characters.  This allows an\n    application to e.g. generate url or filesystem safe Base64 strings.\n    \"\"\"\n    encoded = binascii.b2a_base64(s, newline=False)\n    if altchars is not None:\n        assert len(altchars) == 2, repr(altchars)\n        return encoded.translate(bytes.maketrans(b'+/', altchars))\n    return encoded",
        "name_type": "stdlib"
    },
    "base64.b64decode": {
        "API_name": "base64.b64decode",
        "loc_name": "base64.b64decode",
        "args": "s;altchars;validate",
        "args_default": 2,
        "filepath": "base64",
        "lineno": 65,
        "namespace": "*",
        "body": "def b64decode(s, altchars=None, validate=False):\n    \"\"\"Decode the Base64 encoded bytes-like object or ASCII string s.\n\n    Optional altchars must be a bytes-like object or ASCII string of length 2\n    which specifies the alternative alphabet used instead of the '+' and '/'\n    characters.\n\n    The result is returned as a bytes object.  A binascii.Error is raised if\n    s is incorrectly padded.\n\n    If validate is False (the default), characters that are neither in the\n    normal base-64 alphabet nor the alternative alphabet are discarded prior\n    to the padding check.  If validate is True, these non-alphabet characters\n    in the input result in a binascii.Error.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    if altchars is not None:\n        altchars = _bytes_from_decode_data(altchars)\n        assert len(altchars) == 2, repr(altchars)\n        s = s.translate(bytes.maketrans(altchars, b'+/'))\n    if validate and not re.fullmatch(b'[A-Za-z0-9+/]*={0,2}', s):\n        raise binascii.Error('Non-base64 digit found')\n    return binascii.a2b_base64(s)",
        "name_type": "stdlib"
    },
    "base64.standard_b64encode": {
        "API_name": "base64.standard_b64encode",
        "loc_name": "base64.standard_b64encode",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 90,
        "namespace": "*",
        "body": "def standard_b64encode(s):\n    \"\"\"Encode bytes-like object s using the standard Base64 alphabet.\n\n    The result is returned as a bytes object.\n    \"\"\"\n    return b64encode(s)",
        "name_type": "stdlib"
    },
    "base64.standard_b64decode": {
        "API_name": "base64.standard_b64decode",
        "loc_name": "base64.standard_b64decode",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 97,
        "namespace": "*",
        "body": "def standard_b64decode(s):\n    \"\"\"Decode bytes encoded with the standard Base64 alphabet.\n\n    Argument s is a bytes-like object or ASCII string to decode.  The result\n    is returned as a bytes object.  A binascii.Error is raised if the input\n    is incorrectly padded.  Characters that are not in the standard alphabet\n    are discarded prior to the padding check.\n    \"\"\"\n    return b64decode(s)",
        "name_type": "stdlib"
    },
    "base64.urlsafe_b64encode": {
        "API_name": "base64.urlsafe_b64encode",
        "loc_name": "base64.urlsafe_b64encode",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 111,
        "namespace": "*",
        "body": "def urlsafe_b64encode(s):\n    \"\"\"Encode bytes using the URL- and filesystem-safe Base64 alphabet.\n\n    Argument s is a bytes-like object to encode.  The result is returned as a\n    bytes object.  The alphabet uses '-' instead of '+' and '_' instead of\n    '/'.\n    \"\"\"\n    return b64encode(s).translate(_urlsafe_encode_translation)",
        "name_type": "stdlib"
    },
    "base64.urlsafe_b64decode": {
        "API_name": "base64.urlsafe_b64decode",
        "loc_name": "base64.urlsafe_b64decode",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 120,
        "namespace": "*",
        "body": "def urlsafe_b64decode(s):\n    \"\"\"Decode bytes using the URL- and filesystem-safe Base64 alphabet.\n\n    Argument s is a bytes-like object or ASCII string to decode.  The result\n    is returned as a bytes object.  A binascii.Error is raised if the input\n    is incorrectly padded.  Characters that are not in the URL-safe base-64\n    alphabet, and are not a plus '+' or slash '/', are discarded prior to the\n    padding check.\n\n    The alphabet uses '-' instead of '+' and '_' instead of '/'.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    s = s.translate(_urlsafe_decode_translation)\n    return b64decode(s)",
        "name_type": "stdlib"
    },
    "base64.b32encode": {
        "API_name": "base64.b32encode",
        "loc_name": "base64.b32encode",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 142,
        "namespace": "*",
        "body": "def b32encode(s):\n    \"\"\"Encode the bytes-like object s using Base32 and return a bytes object.\n    \"\"\"\n    global _b32tab2\n    # Delay the initialization of the table to not waste memory\n    # if the function is never called\n    if _b32tab2 is None:\n        b32tab = [bytes((i,)) for i in _b32alphabet]\n        _b32tab2 = [a + b for a in b32tab for b in b32tab]\n        b32tab = None\n\n    if not isinstance(s, bytes_types):\n        s = memoryview(s).tobytes()\n    leftover = len(s) % 5\n    # Pad the last quantum with zero bits if necessary\n    if leftover:\n        s = s + b'\\0' * (5 - leftover)  # Don't use += !\n    encoded = bytearray()\n    from_bytes = int.from_bytes\n    b32tab2 = _b32tab2\n    for i in range(0, len(s), 5):\n        c = from_bytes(s[i: i + 5], 'big')\n        encoded += (b32tab2[c >> 30] +           # bits 1 - 10\n                    b32tab2[(c >> 20) & 0x3ff] + # bits 11 - 20\n                    b32tab2[(c >> 10) & 0x3ff] + # bits 21 - 30\n                    b32tab2[c & 0x3ff]           # bits 31 - 40\n                   )\n    # Adjust for any leftover partial quanta\n    if leftover == 1:\n        encoded[-6:] = b'======'\n    elif leftover == 2:\n        encoded[-4:] = b'===='\n    elif leftover == 3:\n        encoded[-3:] = b'==='\n    elif leftover == 4:\n        encoded[-1:] = b'='\n    return bytes(encoded)",
        "name_type": "stdlib"
    },
    "base64.b32decode": {
        "API_name": "base64.b32decode",
        "loc_name": "base64.b32decode",
        "args": "s;casefold;map01",
        "args_default": 2,
        "filepath": "base64",
        "lineno": 180,
        "namespace": "*",
        "body": "def b32decode(s, casefold=False, map01=None):\n    \"\"\"Decode the Base32 encoded bytes-like object or ASCII string s.\n\n    Optional casefold is a flag specifying whether a lowercase alphabet is\n    acceptable as input.  For security purposes, the default is False.\n\n    RFC 3548 allows for optional mapping of the digit 0 (zero) to the\n    letter O (oh), and for optional mapping of the digit 1 (one) to\n    either the letter I (eye) or letter L (el).  The optional argument\n    map01 when not None, specifies which letter the digit 1 should be\n    mapped to (when map01 is not None, the digit 0 is always mapped to\n    the letter O).  For security purposes the default is None, so that\n    0 and 1 are not allowed in the input.\n\n    The result is returned as a bytes object.  A binascii.Error is raised if\n    the input is incorrectly padded or if there are non-alphabet\n    characters present in the input.\n    \"\"\"\n    global _b32rev\n    # Delay the initialization of the table to not waste memory\n    # if the function is never called\n    if _b32rev is None:\n        _b32rev = {v: k for k, v in enumerate(_b32alphabet)}\n    s = _bytes_from_decode_data(s)\n    if len(s) % 8:\n        raise binascii.Error('Incorrect padding')\n    # Handle section 2.4 zero and one mapping.  The flag map01 will be either\n    # False, or the character to map the digit 1 (one) to.  It should be\n    # either L (el) or I (eye).\n    if map01 is not None:\n        map01 = _bytes_from_decode_data(map01)\n        assert len(map01) == 1, repr(map01)\n        s = s.translate(bytes.maketrans(b'01', b'O' + map01))\n    if casefold:\n        s = s.upper()\n    # Strip off pad characters from the right.  We need to count the pad\n    # characters because this will tell us how many null bytes to remove from\n    # the end of the decoded string.\n    l = len(s)\n    s = s.rstrip(b'=')\n    padchars = l - len(s)\n    # Now decode the full quanta\n    decoded = bytearray()\n    b32rev = _b32rev\n    for i in range(0, len(s), 8):\n        quanta = s[i: i + 8]\n        acc = 0\n        try:\n            for c in quanta:\n                acc = (acc << 5) + b32rev[c]\n        except KeyError:\n            raise binascii.Error('Non-base32 digit found') from None\n        decoded += acc.to_bytes(5, 'big')\n    # Process the last, partial quanta\n    if l % 8 or padchars not in {0, 1, 3, 4, 6}:\n        raise binascii.Error('Incorrect padding')\n    if padchars and decoded:\n        acc <<= 5 * padchars\n        last = acc.to_bytes(5, 'big')\n        leftover = (43 - 5 * padchars) // 8  # 1: 4, 3: 3, 4: 2, 6: 1\n        decoded[-5:] = last[:leftover]\n    return bytes(decoded)",
        "name_type": "stdlib"
    },
    "base64.b16encode": {
        "API_name": "base64.b16encode",
        "loc_name": "base64.b16encode",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 247,
        "namespace": "*",
        "body": "def b16encode(s):\n    \"\"\"Encode the bytes-like object s using Base16 and return a bytes object.\n    \"\"\"\n    return binascii.hexlify(s).upper()",
        "name_type": "stdlib"
    },
    "base64.b16decode": {
        "API_name": "base64.b16decode",
        "loc_name": "base64.b16decode",
        "args": "s;casefold",
        "args_default": 1,
        "filepath": "base64",
        "lineno": 253,
        "namespace": "*",
        "body": "def b16decode(s, casefold=False):\n    \"\"\"Decode the Base16 encoded bytes-like object or ASCII string s.\n\n    Optional casefold is a flag specifying whether a lowercase alphabet is\n    acceptable as input.  For security purposes, the default is False.\n\n    The result is returned as a bytes object.  A binascii.Error is raised if\n    s is incorrectly padded or if there are non-alphabet characters present\n    in the input.\n    \"\"\"\n    s = _bytes_from_decode_data(s)\n    if casefold:\n        s = s.upper()\n    if re.search(b'[^0-9A-F]', s):\n        raise binascii.Error('Non-base16 digit found')\n    return binascii.unhexlify(s)",
        "name_type": "stdlib"
    },
    "base64._85encode": {
        "API_name": "base64._85encode",
        "loc_name": "base64._85encode",
        "args": "b;chars;chars2;pad;foldnuls;foldspaces",
        "args_default": 3,
        "filepath": "base64",
        "lineno": 279,
        "namespace": "*",
        "body": "def _85encode(b, chars, chars2, pad=False, foldnuls=False, foldspaces=False):\n    # Helper function for a85encode and b85encode\n    if not isinstance(b, bytes_types):\n        b = memoryview(b).tobytes()\n\n    padding = (-len(b)) % 4\n    if padding:\n        b = b + b'\\0' * padding\n    words = struct.Struct('!%dI' % (len(b) // 4)).unpack(b)\n\n    chunks = [b'z' if foldnuls and not word else\n              b'y' if foldspaces and word == 0x20202020 else\n              (chars2[word // 614125] +\n               chars2[word // 85 % 7225] +\n               chars[word % 85])\n              for word in words]\n\n    if padding and not pad:\n        if chunks[-1] == b'z':\n            chunks[-1] = chars[0] * 5\n        chunks[-1] = chunks[-1][:-padding]\n\n    return b''.join(chunks)",
        "name_type": "stdlib"
    },
    "base64.a85encode": {
        "API_name": "base64.a85encode",
        "loc_name": "base64.a85encode",
        "args": "b",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 303,
        "namespace": "*",
        "body": "def a85encode(b, *, foldspaces=False, wrapcol=0, pad=False, adobe=False):\n    \"\"\"Encode bytes-like object b using Ascii85 and return a bytes object.\n\n    foldspaces is an optional flag that uses the special short sequence 'y'\n    instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This\n    feature is not supported by the \"standard\" Adobe encoding.\n\n    wrapcol controls whether the output should have newline (b'\\\\n') characters\n    added to it. If this is non-zero, each output line will be at most this\n    many characters long.\n\n    pad controls whether the input is padded to a multiple of 4 before\n    encoding. Note that the btoa implementation always pads.\n\n    adobe controls whether the encoded byte sequence is framed with <~ and ~>,\n    which is used by the Adobe implementation.\n    \"\"\"\n    global _a85chars, _a85chars2\n    # Delay the initialization of tables to not waste memory\n    # if the function is never called\n    if _a85chars2 is None:\n        _a85chars = [bytes((i,)) for i in range(33, 118)]\n        _a85chars2 = [(a + b) for a in _a85chars for b in _a85chars]\n\n    result = _85encode(b, _a85chars, _a85chars2, pad, True, foldspaces)\n\n    if adobe:\n        result = _A85START + result\n    if wrapcol:\n        wrapcol = max(2 if adobe else 1, wrapcol)\n        chunks = [result[i: i + wrapcol]\n                  for i in range(0, len(result), wrapcol)]\n        if adobe:\n            if len(chunks[-1]) + 2 > wrapcol:\n                chunks.append(b'')\n        result = b'\\n'.join(chunks)\n    if adobe:\n        result += _A85END\n\n    return result",
        "name_type": "stdlib"
    },
    "base64.a85decode": {
        "API_name": "base64.a85decode",
        "loc_name": "base64.a85decode",
        "args": "b",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 344,
        "namespace": "*",
        "body": "def a85decode(b, *, foldspaces=False, adobe=False, ignorechars=b' \\t\\n\\r\\v'):\n    \"\"\"Decode the Ascii85 encoded bytes-like object or ASCII string b.\n\n    foldspaces is a flag that specifies whether the 'y' short sequence should be\n    accepted as shorthand for 4 consecutive spaces (ASCII 0x20). This feature is\n    not supported by the \"standard\" Adobe encoding.\n\n    adobe controls whether the input sequence is in Adobe Ascii85 format (i.e.\n    is framed with <~ and ~>).\n\n    ignorechars should be a byte string containing characters to ignore from the\n    input. This should only contain whitespace characters, and by default\n    contains all whitespace characters in ASCII.\n\n    The result is returned as a bytes object.\n    \"\"\"\n    b = _bytes_from_decode_data(b)\n    if adobe:\n        if not b.endswith(_A85END):\n            raise ValueError(\n                \"Ascii85 encoded byte sequences must end \"\n                \"with {!r}\".format(_A85END)\n                )\n        if b.startswith(_A85START):\n            b = b[2:-2]  # Strip off start/end markers\n        else:\n            b = b[:-2]\n    #\n    # We have to go through this stepwise, so as to ignore spaces and handle\n    # special short sequences\n    #\n    packI = struct.Struct('!I').pack\n    decoded = []\n    decoded_append = decoded.append\n    curr = []\n    curr_append = curr.append\n    curr_clear = curr.clear\n    for x in b + b'u' * 4:\n        if b'!'[0] <= x <= b'u'[0]:\n            curr_append(x)\n            if len(curr) == 5:\n                acc = 0\n                for x in curr:\n                    acc = 85 * acc + (x - 33)\n                try:\n                    decoded_append(packI(acc))\n                except struct.error:\n                    raise ValueError('Ascii85 overflow') from None\n                curr_clear()\n        elif x == b'z'[0]:\n            if curr:\n                raise ValueError('z inside Ascii85 5-tuple')\n            decoded_append(b'\\0\\0\\0\\0')\n        elif foldspaces and x == b'y'[0]:\n            if curr:\n                raise ValueError('y inside Ascii85 5-tuple')\n            decoded_append(b'\\x20\\x20\\x20\\x20')\n        elif x in ignorechars:\n            # Skip whitespace\n            continue\n        else:\n            raise ValueError('Non-Ascii85 digit found: %c' % x)\n\n    result = b''.join(decoded)\n    padding = 4 - len(curr)\n    if padding:\n        # Throw away the extra padding\n        result = result[:-padding]\n    return result",
        "name_type": "stdlib"
    },
    "base64.b85encode": {
        "API_name": "base64.b85encode",
        "loc_name": "base64.b85encode",
        "args": "b;pad",
        "args_default": 1,
        "filepath": "base64",
        "lineno": 422,
        "namespace": "*",
        "body": "def b85encode(b, pad=False):\n    \"\"\"Encode bytes-like object b in base85 format and return a bytes object.\n\n    If pad is true, the input is padded with b'\\\\0' so its length is a multiple of\n    4 bytes before encoding.\n    \"\"\"\n    global _b85chars, _b85chars2\n    # Delay the initialization of tables to not waste memory\n    # if the function is never called\n    if _b85chars2 is None:\n        _b85chars = [bytes((i,)) for i in _b85alphabet]\n        _b85chars2 = [(a + b) for a in _b85chars for b in _b85chars]\n    return _85encode(b, _b85chars, _b85chars2, pad)",
        "name_type": "stdlib"
    },
    "base64.b85decode": {
        "API_name": "base64.b85decode",
        "loc_name": "base64.b85decode",
        "args": "b",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 436,
        "namespace": "*",
        "body": "def b85decode(b):\n    \"\"\"Decode the base85-encoded bytes-like object or ASCII string b\n\n    The result is returned as a bytes object.\n    \"\"\"\n    global _b85dec\n    # Delay the initialization of tables to not waste memory\n    # if the function is never called\n    if _b85dec is None:\n        _b85dec = [None] * 256\n        for i, c in enumerate(_b85alphabet):\n            _b85dec[c] = i\n\n    b = _bytes_from_decode_data(b)\n    padding = (-len(b)) % 5\n    b = b + b'~' * padding\n    out = []\n    packI = struct.Struct('!I').pack\n    for i in range(0, len(b), 5):\n        chunk = b[i:i + 5]\n        acc = 0\n        try:\n            for c in chunk:\n                acc = acc * 85 + _b85dec[c]\n        except TypeError:\n            for j, c in enumerate(chunk):\n                if _b85dec[c] is None:\n                    raise ValueError('bad base85 character at position %d'\n                                    % (i + j)) from None\n            raise\n        try:\n            out.append(packI(acc))\n        except struct.error:\n            raise ValueError('base85 overflow in hunk starting at byte %d'\n                             % i) from None\n\n    result = b''.join(out)\n    if padding:\n        result = result[:-padding]\n    return result",
        "name_type": "stdlib"
    },
    "base64.encode": {
        "API_name": "base64.encode",
        "loc_name": "base64.encode",
        "args": "input;output",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 484,
        "namespace": "*",
        "body": "def encode(input, output):\n    \"\"\"Encode a file; input and output are binary files.\"\"\"\n    while True:\n        s = input.read(MAXBINSIZE)\n        if not s:\n            break\n        while len(s) < MAXBINSIZE:\n            ns = input.read(MAXBINSIZE-len(s))\n            if not ns:\n                break\n            s += ns\n        line = binascii.b2a_base64(s)\n        output.write(line)",
        "name_type": "stdlib"
    },
    "base64.decode": {
        "API_name": "base64.decode",
        "loc_name": "base64.decode",
        "args": "input;output",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 499,
        "namespace": "*",
        "body": "def decode(input, output):\n    \"\"\"Decode a file; input and output are binary files.\"\"\"\n    while True:\n        line = input.readline()\n        if not line:\n            break\n        s = binascii.a2b_base64(line)\n        output.write(s)",
        "name_type": "stdlib"
    },
    "base64._input_type_check": {
        "API_name": "base64._input_type_check",
        "loc_name": "base64._input_type_check",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 508,
        "namespace": "*",
        "body": "def _input_type_check(s):\n    try:\n        m = memoryview(s)\n    except TypeError as err:\n        msg = \"expected bytes-like object, not %s\" % s.__class__.__name__\n        raise TypeError(msg) from err\n    if m.format not in ('c', 'b', 'B'):\n        msg = (\"expected single byte elements, not %r from %s\" %\n                                          (m.format, s.__class__.__name__))\n        raise TypeError(msg)\n    if m.ndim != 1:\n        msg = (\"expected 1-D data, not %d-D data from %s\" %\n                                          (m.ndim, s.__class__.__name__))\n        raise TypeError(msg)",
        "name_type": "stdlib"
    },
    "base64.encodebytes": {
        "API_name": "base64.encodebytes",
        "loc_name": "base64.encodebytes",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 524,
        "namespace": "*",
        "body": "def encodebytes(s):\n    \"\"\"Encode a bytestring into a bytes object containing multiple lines\n    of base-64 data.\"\"\"\n    _input_type_check(s)\n    pieces = []\n    for i in range(0, len(s), MAXBINSIZE):\n        chunk = s[i : i + MAXBINSIZE]\n        pieces.append(binascii.b2a_base64(chunk))\n    return b\"\".join(pieces)",
        "name_type": "stdlib"
    },
    "base64.decodebytes": {
        "API_name": "base64.decodebytes",
        "loc_name": "base64.decodebytes",
        "args": "s",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 535,
        "namespace": "*",
        "body": "def decodebytes(s):\n    \"\"\"Decode a bytestring of base-64 data into a bytes object.\"\"\"\n    _input_type_check(s)\n    return binascii.a2b_base64(s)",
        "name_type": "stdlib"
    },
    "base64.main": {
        "API_name": "base64.main",
        "loc_name": "base64.main",
        "args": "",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 542,
        "namespace": "*",
        "body": "def main():\n    \"\"\"Small main program\"\"\"\n    import sys, getopt\n    try:\n        opts, args = getopt.getopt(sys.argv[1:], 'deut')\n    except getopt.error as msg:\n        sys.stdout = sys.stderr\n        print(msg)\n        print(\"\"\"usage: %s [-d|-e|-u|-t] [file|-]\n        -d, -u: decode\n        -e: encode (default)\n        -t: encode and decode string 'Aladdin:open sesame'\"\"\"%sys.argv[0])\n        sys.exit(2)\n    func = encode\n    for o, a in opts:\n        if o == '-e': func = encode\n        if o == '-d': func = decode\n        if o == '-u': func = decode\n        if o == '-t': test(); return\n    if args and args[0] != '-':\n        with open(args[0], 'rb') as f:\n            func(f, sys.stdout.buffer)\n    else:\n        func(sys.stdin.buffer, sys.stdout.buffer)",
        "name_type": "stdlib"
    },
    "base64.test": {
        "API_name": "base64.test",
        "loc_name": "base64.test",
        "args": "",
        "args_default": 0,
        "filepath": "base64",
        "lineno": 568,
        "namespace": "*",
        "body": "def test():\n    s0 = b\"Aladdin:open sesame\"\n    print(repr(s0))\n    s1 = encodebytes(s0)\n    print(repr(s1))\n    s2 = decodebytes(s1)\n    print(repr(s2))\n    assert s0 == s2",
        "name_type": "stdlib"
    },
    "codecs": {
        "API_name": "codecs",
        "loc_name": "codecs",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\" codecs -- Python Codec Registry, API and helpers.\n\n\nWritten by Marc-Andre Lemburg (mal@lemburg.com).\n\n(c) Copyright CNRI, All Rights Reserved. NO WARRANTY.\n\n\"\"\"\ntry:\n    from _codecs import *\nexcept ImportError as why:\n    raise SystemError('Failed to load the builtin codecs: %s' % why)\n__all__ = [\"register\", \"lookup\", \"open\", \"EncodedFile\", \"BOM\", \"BOM_BE\",\n           \"BOM_LE\", \"BOM32_BE\", \"BOM32_LE\", \"BOM64_BE\", \"BOM64_LE\",\n           \"BOM_UTF8\", \"BOM_UTF16\", \"BOM_UTF16_LE\", \"BOM_UTF16_BE\",\n           \"BOM_UTF32\", \"BOM_UTF32_LE\", \"BOM_UTF32_BE\",\n           \"CodecInfo\", \"Codec\", \"IncrementalEncoder\", \"IncrementalDecoder\",\n           \"StreamReader\", \"StreamWriter\",\n           \"StreamReaderWriter\", \"StreamRecoder\",\n           \"getencoder\", \"getdecoder\", \"getincrementalencoder\",\n           \"getincrementaldecoder\", \"getreader\", \"getwriter\",\n           \"encode\", \"decode\", \"iterencode\", \"iterdecode\",\n           \"strict_errors\", \"ignore_errors\", \"replace_errors\",\n           \"xmlcharrefreplace_errors\",\n           \"backslashreplace_errors\", \"namereplace_errors\",\n           \"register_error\", \"lookup_error\"]\nBOM_UTF8 = b'\\xef\\xbb\\xbf'\nBOM_LE = BOM_UTF16_LE = b'\\xff\\xfe'\nBOM_BE = BOM_UTF16_BE = b'\\xfe\\xff'\nBOM_UTF32_LE = b'\\xff\\xfe\\x00\\x00'\nBOM_UTF32_BE = b'\\x00\\x00\\xfe\\xff'\nif sys.byteorder == 'little':\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_LE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_LE\n\nelse:\n\n    # UTF-16, native endianness\n    BOM = BOM_UTF16 = BOM_UTF16_BE\n\n    # UTF-32, native endianness\n    BOM_UTF32 = BOM_UTF32_BE\nBOM32_LE = BOM_UTF16_LE\nBOM32_BE = BOM_UTF16_BE\nBOM64_LE = BOM_UTF32_LE\nBOM64_BE = BOM_UTF32_BE\ntry:\n    strict_errors = lookup_error(\"strict\")\n    ignore_errors = lookup_error(\"ignore\")\n    replace_errors = lookup_error(\"replace\")\n    xmlcharrefreplace_errors = lookup_error(\"xmlcharrefreplace\")\n    backslashreplace_errors = lookup_error(\"backslashreplace\")\n    namereplace_errors = lookup_error(\"namereplace\")\nexcept LookupError:\n    # In --disable-unicode builds, these error handler are missing\n    strict_errors = None\n    ignore_errors = None\n    replace_errors = None\n    xmlcharrefreplace_errors = None\n    backslashreplace_errors = None\n    namereplace_errors = None\n_false = 0\nif _false:\n    import encodings\nif __name__ == '__main__':\n\n    # Make stdout translate Latin-1 output into UTF-8 output\n    sys.stdout = EncodedFile(sys.stdout, 'latin-1', 'utf-8')\n\n    # Have stdin translate Latin-1 input into UTF-8 input\n    sys.stdin = EncodedFile(sys.stdin, 'utf-8', 'latin-1')",
        "name_type": "stdlib"
    },
    "codecs.CodecInfo.__new__": {
        "API_name": "codecs.CodecInfo.__new__",
        "loc_name": "codecs.CodecInfo.__new__",
        "args": "cls;encode;decode;streamreader;streamwriter;incrementalencoder;incrementaldecoder;name",
        "args_default": 5,
        "filepath": "codecs",
        "lineno": 94,
        "namespace": "CodecInfo",
        "body": "    def __new__(cls, encode, decode, streamreader=None, streamwriter=None,\n        incrementalencoder=None, incrementaldecoder=None, name=None,\n        *, _is_text_encoding=None):\n        self = tuple.__new__(cls, (encode, decode, streamreader, streamwriter))\n        self.name = name\n        self.encode = encode\n        self.decode = decode\n        self.incrementalencoder = incrementalencoder\n        self.incrementaldecoder = incrementaldecoder\n        self.streamwriter = streamwriter\n        self.streamreader = streamreader\n        if _is_text_encoding is not None:\n            self._is_text_encoding = _is_text_encoding\n        return self",
        "name_type": "stdlib"
    },
    "codecs.CodecInfo.__repr__": {
        "API_name": "codecs.CodecInfo.__repr__",
        "loc_name": "codecs.CodecInfo.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 109,
        "namespace": "CodecInfo",
        "body": "    def __repr__(self):\n        return \"<%s.%s object for encoding %s at %#x>\" % \\\n                (self.__class__.__module__, self.__class__.__qualname__,\n                 self.name, id(self))",
        "name_type": "stdlib"
    },
    "codecs.CodecInfo": {
        "API_name": "codecs.CodecInfo",
        "loc_name": "codecs.CodecInfo",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 83,
        "namespace": "CodecInfo",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.Codec.encode": {
        "API_name": "codecs.Codec.encode",
        "loc_name": "codecs.Codec.encode",
        "args": "self;input;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 138,
        "namespace": "Codec",
        "body": "    def encode(self, input, errors='strict'):\n\n        \"\"\" Encodes the object input and returns a tuple (output\n            object, length consumed).\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamWriter for codecs which have to keep state in order to\n            make encoding efficient.\n\n            The encoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.Codec.decode": {
        "API_name": "codecs.Codec.decode",
        "loc_name": "codecs.Codec.decode",
        "args": "self;input;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 157,
        "namespace": "Codec",
        "body": "    def decode(self, input, errors='strict'):\n\n        \"\"\" Decodes the object input and returns a tuple (output\n            object, length consumed).\n\n            input must be an object which provides the bf_getreadbuf\n            buffer slot. Python strings, buffer objects and memory\n            mapped files are examples of objects providing this slot.\n\n            errors defines the error handling to apply. It defaults to\n            'strict' handling.\n\n            The method may not store state in the Codec instance. Use\n            StreamReader for codecs which have to keep state in order to\n            make decoding efficient.\n\n            The decoder must be able to handle zero length input and\n            return an empty object of the output object type in this\n            situation.\n\n        \"\"\"\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.Codec": {
        "API_name": "codecs.Codec",
        "loc_name": "codecs.Codec",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 114,
        "namespace": "Codec",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.IncrementalEncoder": {
        "API_name": "codecs.IncrementalEncoder",
        "loc_name": "codecs.IncrementalEncoder",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 180,
        "namespace": "IncrementalEncoder",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.IncrementalEncoder.__init__": {
        "API_name": "codecs.IncrementalEncoder.__init__",
        "loc_name": "codecs.IncrementalEncoder.__init__",
        "args": "self;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 186,
        "namespace": "IncrementalEncoder",
        "body": "    def __init__(self, errors='strict'):\n        \"\"\"\n        Creates an IncrementalEncoder instance.\n\n        The IncrementalEncoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors\n        self.buffer = \"\"",
        "name_type": "stdlib"
    },
    "codecs.IncrementalEncoder.encode": {
        "API_name": "codecs.IncrementalEncoder.encode",
        "loc_name": "codecs.IncrementalEncoder.encode",
        "args": "self;input;final",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 197,
        "namespace": "IncrementalEncoder",
        "body": "    def encode(self, input, final=False):\n        \"\"\"\n        Encodes input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.IncrementalEncoder.reset": {
        "API_name": "codecs.IncrementalEncoder.reset",
        "loc_name": "codecs.IncrementalEncoder.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 203,
        "namespace": "IncrementalEncoder",
        "body": "    def reset(self):\n        \"\"\"\n        Resets the encoder to the initial state.\n        \"\"\"",
        "name_type": "stdlib"
    },
    "codecs.IncrementalEncoder.getstate": {
        "API_name": "codecs.IncrementalEncoder.getstate",
        "loc_name": "codecs.IncrementalEncoder.getstate",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 208,
        "namespace": "IncrementalEncoder",
        "body": "    def getstate(self):\n        \"\"\"\n        Return the current state of the encoder.\n        \"\"\"\n        return 0",
        "name_type": "stdlib"
    },
    "codecs.IncrementalEncoder.setstate": {
        "API_name": "codecs.IncrementalEncoder.setstate",
        "loc_name": "codecs.IncrementalEncoder.setstate",
        "args": "self;state",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 214,
        "namespace": "IncrementalEncoder",
        "body": "    def setstate(self, state):\n        \"\"\"\n        Set the current state of the encoder. state must have been\n        returned by getstate().\n        \"\"\"",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder": {
        "API_name": "codecs.BufferedIncrementalEncoder",
        "loc_name": "codecs.BufferedIncrementalEncoder",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 220,
        "namespace": "BufferedIncrementalEncoder",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder.__init__": {
        "API_name": "codecs.BufferedIncrementalEncoder.__init__",
        "loc_name": "codecs.BufferedIncrementalEncoder.__init__",
        "args": "self;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 226,
        "namespace": "BufferedIncrementalEncoder",
        "body": "    def __init__(self, errors='strict'):\n        IncrementalEncoder.__init__(self, errors)\n        # unencoded input that is kept between calls to encode()\n        self.buffer = \"\"",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder._buffer_encode": {
        "API_name": "codecs.BufferedIncrementalEncoder._buffer_encode",
        "loc_name": "codecs.BufferedIncrementalEncoder._buffer_encode",
        "args": "self;input;errors;final",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 231,
        "namespace": "BufferedIncrementalEncoder",
        "body": "    def _buffer_encode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must encode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder.encode": {
        "API_name": "codecs.BufferedIncrementalEncoder.encode",
        "loc_name": "codecs.BufferedIncrementalEncoder.encode",
        "args": "self;input;final",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 236,
        "namespace": "BufferedIncrementalEncoder",
        "body": "    def encode(self, input, final=False):\n        # encode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_encode(data, self.errors, final)\n        # keep unencoded input until the next call\n        self.buffer = data[consumed:]\n        return result",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder.reset": {
        "API_name": "codecs.BufferedIncrementalEncoder.reset",
        "loc_name": "codecs.BufferedIncrementalEncoder.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 244,
        "namespace": "BufferedIncrementalEncoder",
        "body": "    def reset(self):\n        IncrementalEncoder.reset(self)\n        self.buffer = \"\"",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder.getstate": {
        "API_name": "codecs.BufferedIncrementalEncoder.getstate",
        "loc_name": "codecs.BufferedIncrementalEncoder.getstate",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 248,
        "namespace": "BufferedIncrementalEncoder",
        "body": "    def getstate(self):\n        return self.buffer or 0",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalEncoder.setstate": {
        "API_name": "codecs.BufferedIncrementalEncoder.setstate",
        "loc_name": "codecs.BufferedIncrementalEncoder.setstate",
        "args": "self;state",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 251,
        "namespace": "BufferedIncrementalEncoder",
        "body": "    def setstate(self, state):\n        self.buffer = state or \"\"",
        "name_type": "stdlib"
    },
    "codecs.IncrementalDecoder": {
        "API_name": "codecs.IncrementalDecoder",
        "loc_name": "codecs.IncrementalDecoder",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 254,
        "namespace": "IncrementalDecoder",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.IncrementalDecoder.__init__": {
        "API_name": "codecs.IncrementalDecoder.__init__",
        "loc_name": "codecs.IncrementalDecoder.__init__",
        "args": "self;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 260,
        "namespace": "IncrementalDecoder",
        "body": "    def __init__(self, errors='strict'):\n        \"\"\"\n        Create an IncrementalDecoder instance.\n\n        The IncrementalDecoder may use different error handling schemes by\n        providing the errors keyword argument. See the module docstring\n        for a list of possible values.\n        \"\"\"\n        self.errors = errors",
        "name_type": "stdlib"
    },
    "codecs.IncrementalDecoder.decode": {
        "API_name": "codecs.IncrementalDecoder.decode",
        "loc_name": "codecs.IncrementalDecoder.decode",
        "args": "self;input;final",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 270,
        "namespace": "IncrementalDecoder",
        "body": "    def decode(self, input, final=False):\n        \"\"\"\n        Decode input and returns the resulting object.\n        \"\"\"\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.IncrementalDecoder.reset": {
        "API_name": "codecs.IncrementalDecoder.reset",
        "loc_name": "codecs.IncrementalDecoder.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 276,
        "namespace": "IncrementalDecoder",
        "body": "    def reset(self):\n        \"\"\"\n        Reset the decoder to the initial state.\n        \"\"\"",
        "name_type": "stdlib"
    },
    "codecs.IncrementalDecoder.getstate": {
        "API_name": "codecs.IncrementalDecoder.getstate",
        "loc_name": "codecs.IncrementalDecoder.getstate",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 281,
        "namespace": "IncrementalDecoder",
        "body": "    def getstate(self):\n        \"\"\"\n        Return the current state of the decoder.\n\n        This must be a (buffered_input, additional_state_info) tuple.\n        buffered_input must be a bytes object containing bytes that\n        were passed to decode() that have not yet been converted.\n        additional_state_info must be a non-negative integer\n        representing the state of the decoder WITHOUT yet having\n        processed the contents of buffered_input.  In the initial state\n        and after reset(), getstate() must return (b\"\", 0).\n        \"\"\"\n        return (b\"\", 0)",
        "name_type": "stdlib"
    },
    "codecs.IncrementalDecoder.setstate": {
        "API_name": "codecs.IncrementalDecoder.setstate",
        "loc_name": "codecs.IncrementalDecoder.setstate",
        "args": "self;state",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 295,
        "namespace": "IncrementalDecoder",
        "body": "    def setstate(self, state):\n        \"\"\"\n        Set the current state of the decoder.\n\n        state must have been returned by getstate().  The effect of\n        setstate((b\"\", 0)) must be equivalent to reset().\n        \"\"\"",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder": {
        "API_name": "codecs.BufferedIncrementalDecoder",
        "loc_name": "codecs.BufferedIncrementalDecoder",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 303,
        "namespace": "BufferedIncrementalDecoder",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder.__init__": {
        "API_name": "codecs.BufferedIncrementalDecoder.__init__",
        "loc_name": "codecs.BufferedIncrementalDecoder.__init__",
        "args": "self;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 309,
        "namespace": "BufferedIncrementalDecoder",
        "body": "    def __init__(self, errors='strict'):\n        IncrementalDecoder.__init__(self, errors)\n        # undecoded input that is kept between calls to decode()\n        self.buffer = b\"\"",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder._buffer_decode": {
        "API_name": "codecs.BufferedIncrementalDecoder._buffer_decode",
        "loc_name": "codecs.BufferedIncrementalDecoder._buffer_decode",
        "args": "self;input;errors;final",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 314,
        "namespace": "BufferedIncrementalDecoder",
        "body": "    def _buffer_decode(self, input, errors, final):\n        # Overwrite this method in subclasses: It must decode input\n        # and return an (output, length consumed) tuple\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder.decode": {
        "API_name": "codecs.BufferedIncrementalDecoder.decode",
        "loc_name": "codecs.BufferedIncrementalDecoder.decode",
        "args": "self;input;final",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 319,
        "namespace": "BufferedIncrementalDecoder",
        "body": "    def decode(self, input, final=False):\n        # decode input (taking the buffer into account)\n        data = self.buffer + input\n        (result, consumed) = self._buffer_decode(data, self.errors, final)\n        # keep undecoded input until the next call\n        self.buffer = data[consumed:]\n        return result",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder.reset": {
        "API_name": "codecs.BufferedIncrementalDecoder.reset",
        "loc_name": "codecs.BufferedIncrementalDecoder.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 327,
        "namespace": "BufferedIncrementalDecoder",
        "body": "    def reset(self):\n        IncrementalDecoder.reset(self)\n        self.buffer = b\"\"",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder.getstate": {
        "API_name": "codecs.BufferedIncrementalDecoder.getstate",
        "loc_name": "codecs.BufferedIncrementalDecoder.getstate",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 331,
        "namespace": "BufferedIncrementalDecoder",
        "body": "    def getstate(self):\n        # additional state info is always 0\n        return (self.buffer, 0)",
        "name_type": "stdlib"
    },
    "codecs.BufferedIncrementalDecoder.setstate": {
        "API_name": "codecs.BufferedIncrementalDecoder.setstate",
        "loc_name": "codecs.BufferedIncrementalDecoder.setstate",
        "args": "self;state",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 335,
        "namespace": "BufferedIncrementalDecoder",
        "body": "    def setstate(self, state):\n        # ignore additional state info\n        self.buffer = state[0]",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter": {
        "API_name": "codecs.StreamWriter",
        "loc_name": "codecs.StreamWriter",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 346,
        "namespace": "StreamWriter",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.__init__": {
        "API_name": "codecs.StreamWriter.__init__",
        "loc_name": "codecs.StreamWriter.__init__",
        "args": "self;stream;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 348,
        "namespace": "StreamWriter",
        "body": "    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamWriter instance.\n\n            stream must be a file-like object open for writing.\n\n            The StreamWriter may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'xmlcharrefreplace' - Replace with the appropriate XML\n                                   character reference.\n             'backslashreplace'  - Replace with backslashed escape\n                                   sequences.\n             'namereplace'       - Replace with \\\\N{...} escape sequences.\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.write": {
        "API_name": "codecs.StreamWriter.write",
        "loc_name": "codecs.StreamWriter.write",
        "args": "self;object",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 373,
        "namespace": "StreamWriter",
        "body": "    def write(self, object):\n\n        \"\"\" Writes the object's contents encoded to self.stream.\n        \"\"\"\n        data, consumed = self.encode(object, self.errors)\n        self.stream.write(data)",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.writelines": {
        "API_name": "codecs.StreamWriter.writelines",
        "loc_name": "codecs.StreamWriter.writelines",
        "args": "self;list",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 380,
        "namespace": "StreamWriter",
        "body": "    def writelines(self, list):\n\n        \"\"\" Writes the concatenated list of strings to the stream\n            using .write().\n        \"\"\"\n        self.write(''.join(list))",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.reset": {
        "API_name": "codecs.StreamWriter.reset",
        "loc_name": "codecs.StreamWriter.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 387,
        "namespace": "StreamWriter",
        "body": "    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping internal state.\n\n            Calling this method should ensure that the data on the\n            output is put into a clean state, that allows appending\n            of new fresh data without having to rescan the whole\n            stream to recover state.\n\n        \"\"\"\n        pass",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.seek": {
        "API_name": "codecs.StreamWriter.seek",
        "loc_name": "codecs.StreamWriter.seek",
        "args": "self;offset;whence",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 399,
        "namespace": "StreamWriter",
        "body": "    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        if whence == 0 and offset == 0:\n            self.reset()",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.__getattr__": {
        "API_name": "codecs.StreamWriter.__getattr__",
        "loc_name": "codecs.StreamWriter.__getattr__",
        "args": "self;name;getattr",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 404,
        "namespace": "StreamWriter",
        "body": "    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.__enter__": {
        "API_name": "codecs.StreamWriter.__enter__",
        "loc_name": "codecs.StreamWriter.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 411,
        "namespace": "StreamWriter",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamWriter.__exit__": {
        "API_name": "codecs.StreamWriter.__exit__",
        "loc_name": "codecs.StreamWriter.__exit__",
        "args": "self;type;value;tb",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 414,
        "namespace": "StreamWriter",
        "body": "    def __exit__(self, type, value, tb):\n        self.stream.close()",
        "name_type": "stdlib"
    },
    "codecs.StreamReader": {
        "API_name": "codecs.StreamReader",
        "loc_name": "codecs.StreamReader",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 419,
        "namespace": "StreamReader",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.__init__": {
        "API_name": "codecs.StreamReader.__init__",
        "loc_name": "codecs.StreamReader.__init__",
        "args": "self;stream;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 423,
        "namespace": "StreamReader",
        "body": "    def __init__(self, stream, errors='strict'):\n\n        \"\"\" Creates a StreamReader instance.\n\n            stream must be a file-like object open for reading.\n\n            The StreamReader may use different error handling\n            schemes by providing the errors keyword argument. These\n            parameters are predefined:\n\n             'strict' - raise a ValueError (or a subclass)\n             'ignore' - ignore the character and continue with the next\n             'replace'- replace with a suitable replacement character\n             'backslashreplace' - Replace with backslashed escape sequences;\n\n            The set of allowed parameter values can be extended via\n            register_error.\n        \"\"\"\n        self.stream = stream\n        self.errors = errors\n        self.bytebuffer = b\"\"\n        self._empty_charbuffer = self.charbuffertype()\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.decode": {
        "API_name": "codecs.StreamReader.decode",
        "loc_name": "codecs.StreamReader.decode",
        "args": "self;input;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 448,
        "namespace": "StreamReader",
        "body": "    def decode(self, input, errors='strict'):\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.read": {
        "API_name": "codecs.StreamReader.read",
        "loc_name": "codecs.StreamReader.read",
        "args": "self;size;chars;firstline",
        "args_default": 3,
        "filepath": "codecs",
        "lineno": 451,
        "namespace": "StreamReader",
        "body": "    def read(self, size=-1, chars=-1, firstline=False):\n\n        \"\"\" Decodes data from the stream self.stream and returns the\n            resulting object.\n\n            chars indicates the number of decoded code points or bytes to\n            return. read() will never return more data than requested,\n            but it might return less, if there is not enough available.\n\n            size indicates the approximate maximum number of decoded\n            bytes or code points to read for decoding. The decoder\n            can modify this setting as appropriate. The default value\n            -1 indicates to read and decode as much as possible.  size\n            is intended to prevent having to decode huge files in one\n            step.\n\n            If firstline is true, and a UnicodeDecodeError happens\n            after the first line terminator in the input only the first line\n            will be returned, the rest of the input will be kept until the\n            next call to read().\n\n            The method should use a greedy read strategy, meaning that\n            it should read as much data as is allowed within the\n            definition of the encoding and the given size, e.g.  if\n            optional encoding endings or state markers are available\n            on the stream, these should be read too.\n        \"\"\"\n        # If we have lines cached, first merge them back into characters\n        if self.linebuffer:\n            self.charbuffer = self._empty_charbuffer.join(self.linebuffer)\n            self.linebuffer = None\n\n        if chars < 0:\n            # For compatibility with other read() methods that take a\n            # single argument\n            chars = size\n\n        # read until we get the required number of characters (if available)\n        while True:\n            # can the request be satisfied from the character buffer?\n            if chars >= 0:\n                if len(self.charbuffer) >= chars:\n                    break\n            # we need more data\n            if size < 0:\n                newdata = self.stream.read()\n            else:\n                newdata = self.stream.read(size)\n            # decode bytes (those remaining from the last call included)\n            data = self.bytebuffer + newdata\n            if not data:\n                break\n            try:\n                newchars, decodedbytes = self.decode(data, self.errors)\n            except UnicodeDecodeError as exc:\n                if firstline:\n                    newchars, decodedbytes = \\\n                        self.decode(data[:exc.start], self.errors)\n                    lines = newchars.splitlines(keepends=True)\n                    if len(lines)<=1:\n                        raise\n                else:\n                    raise\n            # keep undecoded bytes until the next call\n            self.bytebuffer = data[decodedbytes:]\n            # put new characters in the character buffer\n            self.charbuffer += newchars\n            # there was no data available\n            if not newdata:\n                break\n        if chars < 0:\n            # Return everything we've got\n            result = self.charbuffer\n            self.charbuffer = self._empty_charbuffer\n        else:\n            # Return the first chars characters\n            result = self.charbuffer[:chars]\n            self.charbuffer = self.charbuffer[chars:]\n        return result",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.readline": {
        "API_name": "codecs.StreamReader.readline",
        "loc_name": "codecs.StreamReader.readline",
        "args": "self;size;keepends",
        "args_default": 2,
        "filepath": "codecs",
        "lineno": 531,
        "namespace": "StreamReader",
        "body": "    def readline(self, size=None, keepends=True):\n\n        \"\"\" Read one line from the input stream and return the\n            decoded data.\n\n            size, if given, is passed as size argument to the\n            read() method.\n\n        \"\"\"\n        # If we have lines cached from an earlier read, return\n        # them unconditionally\n        if self.linebuffer:\n            line = self.linebuffer[0]\n            del self.linebuffer[0]\n            if len(self.linebuffer) == 1:\n                # revert to charbuffer mode; we might need more data\n                # next time\n                self.charbuffer = self.linebuffer[0]\n                self.linebuffer = None\n            if not keepends:\n                line = line.splitlines(keepends=False)[0]\n            return line\n\n        readsize = size or 72\n        line = self._empty_charbuffer\n        # If size is given, we call read() only once\n        while True:\n            data = self.read(readsize, firstline=True)\n            if data:\n                # If we're at a \"\\r\" read one extra character (which might\n                # be a \"\\n\") to get a proper line ending. If the stream is\n                # temporarily exhausted we return the wrong line ending.\n                if (isinstance(data, str) and data.endswith(\"\\r\")) or \\\n                   (isinstance(data, bytes) and data.endswith(b\"\\r\")):\n                    data += self.read(size=1, chars=1)\n\n            line += data\n            lines = line.splitlines(keepends=True)\n            if lines:\n                if len(lines) > 1:\n                    # More than one line result; the first line is a full line\n                    # to return\n                    line = lines[0]\n                    del lines[0]\n                    if len(lines) > 1:\n                        # cache the remaining lines\n                        lines[-1] += self.charbuffer\n                        self.linebuffer = lines\n                        self.charbuffer = None\n                    else:\n                        # only one remaining line, put it back into charbuffer\n                        self.charbuffer = lines[0] + self.charbuffer\n                    if not keepends:\n                        line = line.splitlines(keepends=False)[0]\n                    break\n                line0withend = lines[0]\n                line0withoutend = lines[0].splitlines(keepends=False)[0]\n                if line0withend != line0withoutend: # We really have a line end\n                    # Put the rest back together and keep it until the next call\n                    self.charbuffer = self._empty_charbuffer.join(lines[1:]) + \\\n                                      self.charbuffer\n                    if keepends:\n                        line = line0withend\n                    else:\n                        line = line0withoutend\n                    break\n            # we didn't get anything or this was our only try\n            if not data or size is not None:\n                if line and not keepends:\n                    line = line.splitlines(keepends=False)[0]\n                break\n            if readsize < 8000:\n                readsize *= 2\n        return line",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.readlines": {
        "API_name": "codecs.StreamReader.readlines",
        "loc_name": "codecs.StreamReader.readlines",
        "args": "self;sizehint;keepends",
        "args_default": 2,
        "filepath": "codecs",
        "lineno": 606,
        "namespace": "StreamReader",
        "body": "    def readlines(self, sizehint=None, keepends=True):\n\n        \"\"\" Read all lines available on the input stream\n            and return them as a list.\n\n            Line breaks are implemented using the codec's decoder\n            method and are included in the list entries.\n\n            sizehint, if given, is ignored since there is no efficient\n            way to finding the true end-of-line.\n\n        \"\"\"\n        data = self.read()\n        return data.splitlines(keepends)",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.reset": {
        "API_name": "codecs.StreamReader.reset",
        "loc_name": "codecs.StreamReader.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 621,
        "namespace": "StreamReader",
        "body": "    def reset(self):\n\n        \"\"\" Resets the codec buffers used for keeping internal state.\n\n            Note that no stream repositioning should take place.\n            This method is primarily intended to be able to recover\n            from decoding errors.\n\n        \"\"\"\n        self.bytebuffer = b\"\"\n        self.charbuffer = self._empty_charbuffer\n        self.linebuffer = None",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.seek": {
        "API_name": "codecs.StreamReader.seek",
        "loc_name": "codecs.StreamReader.seek",
        "args": "self;offset;whence",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 634,
        "namespace": "StreamReader",
        "body": "    def seek(self, offset, whence=0):\n        \"\"\" Set the input stream's current position.\n\n            Resets the codec buffers used for keeping state.\n        \"\"\"\n        self.stream.seek(offset, whence)\n        self.reset()",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.__next__": {
        "API_name": "codecs.StreamReader.__next__",
        "loc_name": "codecs.StreamReader.__next__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 642,
        "namespace": "StreamReader",
        "body": "    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        line = self.readline()\n        if line:\n            return line\n        raise StopIteration",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.__iter__": {
        "API_name": "codecs.StreamReader.__iter__",
        "loc_name": "codecs.StreamReader.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 650,
        "namespace": "StreamReader",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.__getattr__": {
        "API_name": "codecs.StreamReader.__getattr__",
        "loc_name": "codecs.StreamReader.__getattr__",
        "args": "self;name;getattr",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 653,
        "namespace": "StreamReader",
        "body": "    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.__enter__": {
        "API_name": "codecs.StreamReader.__enter__",
        "loc_name": "codecs.StreamReader.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 660,
        "namespace": "StreamReader",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamReader.__exit__": {
        "API_name": "codecs.StreamReader.__exit__",
        "loc_name": "codecs.StreamReader.__exit__",
        "args": "self;type;value;tb",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 663,
        "namespace": "StreamReader",
        "body": "    def __exit__(self, type, value, tb):\n        self.stream.close()",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter": {
        "API_name": "codecs.StreamReaderWriter",
        "loc_name": "codecs.StreamReaderWriter",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 668,
        "namespace": "StreamReaderWriter",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.__init__": {
        "API_name": "codecs.StreamReaderWriter.__init__",
        "loc_name": "codecs.StreamReaderWriter.__init__",
        "args": "self;stream;Reader;Writer;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 681,
        "namespace": "StreamReaderWriter",
        "body": "    def __init__(self, stream, Reader, Writer, errors='strict'):\n\n        \"\"\" Creates a StreamReaderWriter instance.\n\n            stream must be a Stream-like object.\n\n            Reader, Writer must be factory functions or classes\n            providing the StreamReader, StreamWriter interface resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.read": {
        "API_name": "codecs.StreamReaderWriter.read",
        "loc_name": "codecs.StreamReaderWriter.read",
        "args": "self;size",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 699,
        "namespace": "StreamReaderWriter",
        "body": "    def read(self, size=-1):\n\n        return self.reader.read(size)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.readline": {
        "API_name": "codecs.StreamReaderWriter.readline",
        "loc_name": "codecs.StreamReaderWriter.readline",
        "args": "self;size",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 703,
        "namespace": "StreamReaderWriter",
        "body": "    def readline(self, size=None):\n\n        return self.reader.readline(size)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.readlines": {
        "API_name": "codecs.StreamReaderWriter.readlines",
        "loc_name": "codecs.StreamReaderWriter.readlines",
        "args": "self;sizehint",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 707,
        "namespace": "StreamReaderWriter",
        "body": "    def readlines(self, sizehint=None):\n\n        return self.reader.readlines(sizehint)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.__next__": {
        "API_name": "codecs.StreamReaderWriter.__next__",
        "loc_name": "codecs.StreamReaderWriter.__next__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 711,
        "namespace": "StreamReaderWriter",
        "body": "    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        return next(self.reader)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.__iter__": {
        "API_name": "codecs.StreamReaderWriter.__iter__",
        "loc_name": "codecs.StreamReaderWriter.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 716,
        "namespace": "StreamReaderWriter",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.write": {
        "API_name": "codecs.StreamReaderWriter.write",
        "loc_name": "codecs.StreamReaderWriter.write",
        "args": "self;data",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 719,
        "namespace": "StreamReaderWriter",
        "body": "    def write(self, data):\n\n        return self.writer.write(data)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.writelines": {
        "API_name": "codecs.StreamReaderWriter.writelines",
        "loc_name": "codecs.StreamReaderWriter.writelines",
        "args": "self;list",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 723,
        "namespace": "StreamReaderWriter",
        "body": "    def writelines(self, list):\n\n        return self.writer.writelines(list)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.reset": {
        "API_name": "codecs.StreamReaderWriter.reset",
        "loc_name": "codecs.StreamReaderWriter.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 727,
        "namespace": "StreamReaderWriter",
        "body": "    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.seek": {
        "API_name": "codecs.StreamReaderWriter.seek",
        "loc_name": "codecs.StreamReaderWriter.seek",
        "args": "self;offset;whence",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 732,
        "namespace": "StreamReaderWriter",
        "body": "    def seek(self, offset, whence=0):\n        self.stream.seek(offset, whence)\n        self.reader.reset()\n        if whence == 0 and offset == 0:\n            self.writer.reset()",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.__getattr__": {
        "API_name": "codecs.StreamReaderWriter.__getattr__",
        "loc_name": "codecs.StreamReaderWriter.__getattr__",
        "args": "self;name;getattr",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 738,
        "namespace": "StreamReaderWriter",
        "body": "    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.__enter__": {
        "API_name": "codecs.StreamReaderWriter.__enter__",
        "loc_name": "codecs.StreamReaderWriter.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 747,
        "namespace": "StreamReaderWriter",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamReaderWriter.__exit__": {
        "API_name": "codecs.StreamReaderWriter.__exit__",
        "loc_name": "codecs.StreamReaderWriter.__exit__",
        "args": "self;type;value;tb",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 750,
        "namespace": "StreamReaderWriter",
        "body": "    def __exit__(self, type, value, tb):\n        self.stream.close()",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder": {
        "API_name": "codecs.StreamRecoder",
        "loc_name": "codecs.StreamRecoder",
        "args": "*",
        "args_default": "*",
        "filepath": "codecs",
        "lineno": 755,
        "namespace": "StreamRecoder",
        "body": "",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.__init__": {
        "API_name": "codecs.StreamRecoder.__init__",
        "loc_name": "codecs.StreamRecoder.__init__",
        "args": "self;stream;encode;decode;Reader;Writer;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 775,
        "namespace": "StreamRecoder",
        "body": "    def __init__(self, stream, encode, decode, Reader, Writer,\n                 errors='strict'):\n\n        \"\"\" Creates a StreamRecoder instance which implements a two-way\n            conversion: encode and decode work on the frontend (the\n            data visible to .read() and .write()) while Reader and Writer\n            work on the backend (the data in stream).\n\n            You can use these objects to do transparent\n            transcodings from e.g. latin-1 to utf-8 and back.\n\n            stream must be a file-like object.\n\n            encode and decode must adhere to the Codec interface; Reader and\n            Writer must be factory functions or classes providing the\n            StreamReader and StreamWriter interfaces resp.\n\n            Error handling is done in the same way as defined for the\n            StreamWriter/Readers.\n\n        \"\"\"\n        self.stream = stream\n        self.encode = encode\n        self.decode = decode\n        self.reader = Reader(stream, errors)\n        self.writer = Writer(stream, errors)\n        self.errors = errors",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.read": {
        "API_name": "codecs.StreamRecoder.read",
        "loc_name": "codecs.StreamRecoder.read",
        "args": "self;size",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 803,
        "namespace": "StreamRecoder",
        "body": "    def read(self, size=-1):\n\n        data = self.reader.read(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.readline": {
        "API_name": "codecs.StreamRecoder.readline",
        "loc_name": "codecs.StreamRecoder.readline",
        "args": "self;size",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 809,
        "namespace": "StreamRecoder",
        "body": "    def readline(self, size=None):\n\n        if size is None:\n            data = self.reader.readline()\n        else:\n            data = self.reader.readline(size)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.readlines": {
        "API_name": "codecs.StreamRecoder.readlines",
        "loc_name": "codecs.StreamRecoder.readlines",
        "args": "self;sizehint",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 818,
        "namespace": "StreamRecoder",
        "body": "    def readlines(self, sizehint=None):\n\n        data = self.reader.read()\n        data, bytesencoded = self.encode(data, self.errors)\n        return data.splitlines(keepends=True)",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.__next__": {
        "API_name": "codecs.StreamRecoder.__next__",
        "loc_name": "codecs.StreamRecoder.__next__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 824,
        "namespace": "StreamRecoder",
        "body": "    def __next__(self):\n\n        \"\"\" Return the next decoded line from the input stream.\"\"\"\n        data = next(self.reader)\n        data, bytesencoded = self.encode(data, self.errors)\n        return data",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.__iter__": {
        "API_name": "codecs.StreamRecoder.__iter__",
        "loc_name": "codecs.StreamRecoder.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 831,
        "namespace": "StreamRecoder",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.write": {
        "API_name": "codecs.StreamRecoder.write",
        "loc_name": "codecs.StreamRecoder.write",
        "args": "self;data",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 834,
        "namespace": "StreamRecoder",
        "body": "    def write(self, data):\n\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.writelines": {
        "API_name": "codecs.StreamRecoder.writelines",
        "loc_name": "codecs.StreamRecoder.writelines",
        "args": "self;list",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 839,
        "namespace": "StreamRecoder",
        "body": "    def writelines(self, list):\n\n        data = b''.join(list)\n        data, bytesdecoded = self.decode(data, self.errors)\n        return self.writer.write(data)",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.reset": {
        "API_name": "codecs.StreamRecoder.reset",
        "loc_name": "codecs.StreamRecoder.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 845,
        "namespace": "StreamRecoder",
        "body": "    def reset(self):\n\n        self.reader.reset()\n        self.writer.reset()",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.seek": {
        "API_name": "codecs.StreamRecoder.seek",
        "loc_name": "codecs.StreamRecoder.seek",
        "args": "self;offset;whence",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 850,
        "namespace": "StreamRecoder",
        "body": "    def seek(self, offset, whence=0):\n        # Seeks must be propagated to both the readers and writers\n        # as they might need to reset their internal buffers.\n        self.reader.seek(offset, whence)\n        self.writer.seek(offset, whence)",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.__getattr__": {
        "API_name": "codecs.StreamRecoder.__getattr__",
        "loc_name": "codecs.StreamRecoder.__getattr__",
        "args": "self;name;getattr",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 856,
        "namespace": "StreamRecoder",
        "body": "    def __getattr__(self, name,\n                    getattr=getattr):\n\n        \"\"\" Inherit all other methods from the underlying stream.\n        \"\"\"\n        return getattr(self.stream, name)",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.__enter__": {
        "API_name": "codecs.StreamRecoder.__enter__",
        "loc_name": "codecs.StreamRecoder.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 863,
        "namespace": "StreamRecoder",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "codecs.StreamRecoder.__exit__": {
        "API_name": "codecs.StreamRecoder.__exit__",
        "loc_name": "codecs.StreamRecoder.__exit__",
        "args": "self;type;value;tb",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 866,
        "namespace": "StreamRecoder",
        "body": "    def __exit__(self, type, value, tb):\n        self.stream.close()",
        "name_type": "stdlib"
    },
    "codecs.open": {
        "API_name": "codecs.open",
        "loc_name": "codecs.open",
        "args": "filename;mode;encoding;errors;buffering",
        "args_default": 4,
        "filepath": "codecs",
        "lineno": 871,
        "namespace": "*",
        "body": "def open(filename, mode='r', encoding=None, errors='strict', buffering=-1):\n\n    \"\"\" Open an encoded file using the given mode and return\n        a wrapped version providing transparent encoding/decoding.\n\n        Note: The wrapped version will only accept the object format\n        defined by the codecs, i.e. Unicode objects for most builtin\n        codecs. Output is also codec dependent and will usually be\n        Unicode as well.\n\n        Underlying encoded files are always opened in binary mode.\n        The default file mode is 'r', meaning to open the file in read mode.\n\n        encoding specifies the encoding which is to be used for the\n        file.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        buffering has the same meaning as for the builtin open() API.\n        It defaults to -1 which means that the default buffer size will\n        be used.\n\n        The returned wrapped file object provides an extra attribute\n        .encoding which allows querying the used encoding. This\n        attribute is only available if an encoding was specified as\n        parameter.\n\n    \"\"\"\n    if encoding is not None and \\\n       'b' not in mode:\n        # Force opening of the file in binary mode\n        mode = mode + 'b'\n    file = builtins.open(filename, mode, buffering)\n    if encoding is None:\n        return file\n\n    try:\n        info = lookup(encoding)\n        srw = StreamReaderWriter(file, info.streamreader, info.streamwriter, errors)\n        # Add attributes to simplify introspection\n        srw.encoding = encoding\n        return srw\n    except:\n        file.close()\n        raise",
        "name_type": "stdlib"
    },
    "codecs.EncodedFile": {
        "API_name": "codecs.EncodedFile",
        "loc_name": "codecs.EncodedFile",
        "args": "file;data_encoding;file_encoding;errors",
        "args_default": 2,
        "filepath": "codecs",
        "lineno": 919,
        "namespace": "*",
        "body": "def EncodedFile(file, data_encoding, file_encoding=None, errors='strict'):\n\n    \"\"\" Return a wrapped version of file which provides transparent\n        encoding translation.\n\n        Data written to the wrapped file is decoded according\n        to the given data_encoding and then encoded to the underlying\n        file using file_encoding. The intermediate data type\n        will usually be Unicode but depends on the specified codecs.\n\n        Bytes read from the file are decoded using file_encoding and then\n        passed back to the caller encoded using data_encoding.\n\n        If file_encoding is not given, it defaults to data_encoding.\n\n        errors may be given to define the error handling. It defaults\n        to 'strict' which causes ValueErrors to be raised in case an\n        encoding error occurs.\n\n        The returned wrapped file object provides two extra attributes\n        .data_encoding and .file_encoding which reflect the given\n        parameters of the same name. The attributes can be used for\n        introspection by Python programs.\n\n    \"\"\"\n    if file_encoding is None:\n        file_encoding = data_encoding\n    data_info = lookup(data_encoding)\n    file_info = lookup(file_encoding)\n    sr = StreamRecoder(file, data_info.encode, data_info.decode,\n                       file_info.streamreader, file_info.streamwriter, errors)\n    # Add attributes to simplify introspection\n    sr.data_encoding = data_encoding\n    sr.file_encoding = file_encoding\n    return sr",
        "name_type": "stdlib"
    },
    "codecs.getencoder": {
        "API_name": "codecs.getencoder",
        "loc_name": "codecs.getencoder",
        "args": "encoding",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 957,
        "namespace": "*",
        "body": "def getencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its encoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).encode",
        "name_type": "stdlib"
    },
    "codecs.getdecoder": {
        "API_name": "codecs.getdecoder",
        "loc_name": "codecs.getdecoder",
        "args": "encoding",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 967,
        "namespace": "*",
        "body": "def getdecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its decoder function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).decode",
        "name_type": "stdlib"
    },
    "codecs.getincrementalencoder": {
        "API_name": "codecs.getincrementalencoder",
        "loc_name": "codecs.getincrementalencoder",
        "args": "encoding",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 977,
        "namespace": "*",
        "body": "def getincrementalencoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalEncoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental encoder.\n\n    \"\"\"\n    encoder = lookup(encoding).incrementalencoder\n    if encoder is None:\n        raise LookupError(encoding)\n    return encoder",
        "name_type": "stdlib"
    },
    "codecs.getincrementaldecoder": {
        "API_name": "codecs.getincrementaldecoder",
        "loc_name": "codecs.getincrementaldecoder",
        "args": "encoding",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 991,
        "namespace": "*",
        "body": "def getincrementaldecoder(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its IncrementalDecoder class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found\n        or the codecs doesn't provide an incremental decoder.\n\n    \"\"\"\n    decoder = lookup(encoding).incrementaldecoder\n    if decoder is None:\n        raise LookupError(encoding)\n    return decoder",
        "name_type": "stdlib"
    },
    "codecs.getreader": {
        "API_name": "codecs.getreader",
        "loc_name": "codecs.getreader",
        "args": "encoding",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 1005,
        "namespace": "*",
        "body": "def getreader(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamReader class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamreader",
        "name_type": "stdlib"
    },
    "codecs.getwriter": {
        "API_name": "codecs.getwriter",
        "loc_name": "codecs.getwriter",
        "args": "encoding",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 1015,
        "namespace": "*",
        "body": "def getwriter(encoding):\n\n    \"\"\" Lookup up the codec for the given encoding and return\n        its StreamWriter class or factory function.\n\n        Raises a LookupError in case the encoding cannot be found.\n\n    \"\"\"\n    return lookup(encoding).streamwriter",
        "name_type": "stdlib"
    },
    "codecs.iterencode": {
        "API_name": "codecs.iterencode",
        "loc_name": "codecs.iterencode",
        "args": "iterator;encoding;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 1025,
        "namespace": "*",
        "body": "def iterencode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Encoding iterator.\n\n    Encodes the input strings from the iterator using an IncrementalEncoder.\n\n    errors and kwargs are passed through to the IncrementalEncoder\n    constructor.\n    \"\"\"\n    encoder = getincrementalencoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = encoder.encode(input)\n        if output:\n            yield output\n    output = encoder.encode(\"\", True)\n    if output:\n        yield output",
        "name_type": "stdlib"
    },
    "codecs.iterdecode": {
        "API_name": "codecs.iterdecode",
        "loc_name": "codecs.iterdecode",
        "args": "iterator;encoding;errors",
        "args_default": 1,
        "filepath": "codecs",
        "lineno": 1043,
        "namespace": "*",
        "body": "def iterdecode(iterator, encoding, errors='strict', **kwargs):\n    \"\"\"\n    Decoding iterator.\n\n    Decodes the input strings from the iterator using an IncrementalDecoder.\n\n    errors and kwargs are passed through to the IncrementalDecoder\n    constructor.\n    \"\"\"\n    decoder = getincrementaldecoder(encoding)(errors, **kwargs)\n    for input in iterator:\n        output = decoder.decode(input)\n        if output:\n            yield output\n    output = decoder.decode(b\"\", True)\n    if output:\n        yield output",
        "name_type": "stdlib"
    },
    "codecs.make_identity_dict": {
        "API_name": "codecs.make_identity_dict",
        "loc_name": "codecs.make_identity_dict",
        "args": "rng",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 1063,
        "namespace": "*",
        "body": "def make_identity_dict(rng):\n\n    \"\"\" make_identity_dict(rng) -> dict\n\n        Return a dictionary where elements of the rng sequence are\n        mapped to themselves.\n\n    \"\"\"\n    return {i:i for i in rng}",
        "name_type": "stdlib"
    },
    "codecs.make_encoding_map": {
        "API_name": "codecs.make_encoding_map",
        "loc_name": "codecs.make_encoding_map",
        "args": "decoding_map",
        "args_default": 0,
        "filepath": "codecs",
        "lineno": 1073,
        "namespace": "*",
        "body": "def make_encoding_map(decoding_map):\n\n    \"\"\" Creates an encoding map from a decoding map.\n\n        If a target mapping in the decoding map occurs multiple\n        times, then that target is mapped to None (undefined mapping),\n        causing an exception when encountered by the charmap codec\n        during translation.\n\n        One example where this happens is cp875.py which decodes\n        multiple character to \\\\u001a.\n\n    \"\"\"\n    m = {}\n    for k,v in decoding_map.items():\n        if not v in m:\n            m[v] = k\n        else:\n            m[v] = None\n    return m",
        "name_type": "stdlib"
    },
    "configparser": {
        "API_name": "configparser",
        "loc_name": "configparser",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Configuration file parser.\n\nA configuration file consists of sections, lead by a \"[section]\" header,\nand followed by \"name: value\" entries, with continuations and such in\nthe style of RFC 822.\n\nIntrinsic defaults can be specified by passing them into the\nConfigParser constructor as a dictionary.\n\nclass:\n\nConfigParser -- responsible for parsing a list of\n                    configuration files, and managing the parsed database.\n\n    methods:\n\n    __init__(defaults=None, dict_type=_default_dict, allow_no_value=False,\n             delimiters=('=', ':'), comment_prefixes=('#', ';'),\n             inline_comment_prefixes=None, strict=True,\n             empty_lines_in_values=True, default_section='DEFAULT',\n             interpolation=<unset>, converters=<unset>):\n        Create the parser. When `defaults' is given, it is initialized into the\n        dictionary or intrinsic defaults. The keys must be strings, the values\n        must be appropriate for %()s string interpolation.\n\n        When `dict_type' is given, it will be used to create the dictionary\n        objects for the list of sections, for the options within a section, and\n        for the default values.\n\n        When `delimiters' is given, it will be used as the set of substrings\n        that divide keys from values.\n\n        When `comment_prefixes' is given, it will be used as the set of\n        substrings that prefix comments in empty lines. Comments can be\n        indented.\n\n        When `inline_comment_prefixes' is given, it will be used as the set of\n        substrings that prefix comments in non-empty lines.\n\n        When `strict` is True, the parser won't allow for any section or option\n        duplicates while reading from a single source (file, string or\n        dictionary). Default is True.\n\n        When `empty_lines_in_values' is False (default: True), each empty line\n        marks the end of an option. Otherwise, internal empty lines of\n        a multiline option are kept as part of the value.\n\n        When `allow_no_value' is True (default: False), options without\n        values are accepted; the value presented for these is None.\n\n        When `default_section' is given, the name of the special section is\n        named accordingly. By default it is called ``\"DEFAULT\"`` but this can\n        be customized to point to any other valid section name. Its current\n        value can be retrieved using the ``parser_instance.default_section``\n        attribute and may be modified at runtime.\n\n        When `interpolation` is given, it should be an Interpolation subclass\n        instance. It will be used as the handler for option value\n        pre-processing when using getters. RawConfigParser objects don't do\n        any sort of interpolation, whereas ConfigParser uses an instance of\n        BasicInterpolation. The library also provides a ``zc.buildbot``\n        inspired ExtendedInterpolation implementation.\n\n        When `converters` is given, it should be a dictionary where each key\n        represents the name of a type converter and each value is a callable\n        implementing the conversion from string to the desired datatype. Every\n        converter gets its corresponding get*() method on the parser object and\n        section proxies.\n\n    sections()\n        Return all the configuration section names, sans DEFAULT.\n\n    has_section(section)\n        Return whether the given section exists.\n\n    has_option(section, option)\n        Return whether the given option exists in the given section.\n\n    options(section)\n        Return list of configuration options for the named section.\n\n    read(filenames, encoding=None)\n        Read and parse the iterable of named configuration files, given by\n        name.  A single filename is also allowed.  Non-existing files\n        are ignored.  Return list of successfully read files.\n\n    read_file(f, filename=None)\n        Read and parse one configuration file, given as a file object.\n        The filename defaults to f.name; it is only used in error\n        messages (if f has no `name' attribute, the string `<???>' is used).\n\n    read_string(string)\n        Read configuration from a given string.\n\n    read_dict(dictionary)\n        Read configuration from a dictionary. Keys are section names,\n        values are dictionaries with keys and values that should be present\n        in the section. If the used dictionary type preserves order, sections\n        and their keys will be added in order. Values are automatically\n        converted to strings.\n\n    get(section, option, raw=False, vars=None, fallback=_UNSET)\n        Return a string value for the named option.  All % interpolations are\n        expanded in the return values, based on the defaults passed into the\n        constructor and the DEFAULT section.  Additional substitutions may be\n        provided using the `vars' argument, which must be a dictionary whose\n        contents override any pre-existing defaults. If `option' is a key in\n        `vars', the value from `vars' is used.\n\n    getint(section, options, raw=False, vars=None, fallback=_UNSET)\n        Like get(), but convert value to an integer.\n\n    getfloat(section, options, raw=False, vars=None, fallback=_UNSET)\n        Like get(), but convert value to a float.\n\n    getboolean(section, options, raw=False, vars=None, fallback=_UNSET)\n        Like get(), but convert value to a boolean (currently case\n        insensitively defined as 0, false, no, off for False, and 1, true,\n        yes, on for True).  Returns False or True.\n\n    items(section=_UNSET, raw=False, vars=None)\n        If section is given, return a list of tuples with (name, value) for\n        each option in the section. Otherwise, return a list of tuples with\n        (section_name, section_proxy) for each section, including DEFAULTSECT.\n\n    remove_section(section)\n        Remove the given file section and all its options.\n\n    remove_option(section, option)\n        Remove the given option from the given section.\n\n    set(section, option, value)\n        Set the given option.\n\n    write(fp, space_around_delimiters=True)\n        Write the configuration state in .ini format. If\n        `space_around_delimiters' is True (the default), delimiters\n        between keys and values are surrounded by spaces.\n\"\"\"\n__all__ = [\"NoSectionError\", \"DuplicateOptionError\", \"DuplicateSectionError\",\n           \"NoOptionError\", \"InterpolationError\", \"InterpolationDepthError\",\n           \"InterpolationMissingOptionError\", \"InterpolationSyntaxError\",\n           \"ParsingError\", \"MissingSectionHeaderError\",\n           \"ConfigParser\", \"SafeConfigParser\", \"RawConfigParser\",\n           \"Interpolation\", \"BasicInterpolation\",  \"ExtendedInterpolation\",\n           \"LegacyInterpolation\", \"SectionProxy\", \"ConverterMapping\",\n           \"DEFAULTSECT\", \"MAX_INTERPOLATION_DEPTH\"]\n_default_dict = dict\nDEFAULTSECT = \"DEFAULT\"\nMAX_INTERPOLATION_DEPTH = 10\n_UNSET = object()",
        "name_type": "stdlib"
    },
    "configparser.Error": {
        "API_name": "configparser.Error",
        "loc_name": "configparser.Error",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 168,
        "namespace": "Error",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.Error.__init__": {
        "API_name": "configparser.Error.__init__",
        "loc_name": "configparser.Error.__init__",
        "args": "self;msg",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 171,
        "namespace": "Error",
        "body": "    def __init__(self, msg=''):\n        self.message = msg\n        Exception.__init__(self, msg)",
        "name_type": "stdlib"
    },
    "configparser.Error.__repr__": {
        "API_name": "configparser.Error.__repr__",
        "loc_name": "configparser.Error.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 175,
        "namespace": "Error",
        "body": "    def __repr__(self):\n        return self.message",
        "name_type": "stdlib"
    },
    "configparser.NoSectionError": {
        "API_name": "configparser.NoSectionError",
        "loc_name": "configparser.NoSectionError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 181,
        "namespace": "NoSectionError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.NoSectionError.__init__": {
        "API_name": "configparser.NoSectionError.__init__",
        "loc_name": "configparser.NoSectionError.__init__",
        "args": "self;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 184,
        "namespace": "NoSectionError",
        "body": "    def __init__(self, section):\n        Error.__init__(self, 'No section: %r' % (section,))\n        self.section = section\n        self.args = (section, )",
        "name_type": "stdlib"
    },
    "configparser.DuplicateSectionError": {
        "API_name": "configparser.DuplicateSectionError",
        "loc_name": "configparser.DuplicateSectionError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 190,
        "namespace": "DuplicateSectionError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.DuplicateSectionError.__init__": {
        "API_name": "configparser.DuplicateSectionError.__init__",
        "loc_name": "configparser.DuplicateSectionError.__init__",
        "args": "self;section;source;lineno",
        "args_default": 2,
        "filepath": "configparser",
        "lineno": 198,
        "namespace": "DuplicateSectionError",
        "body": "    def __init__(self, section, source=None, lineno=None):\n        msg = [repr(section), \" already exists\"]\n        if source is not None:\n            message = [\"While reading from \", repr(source)]\n            if lineno is not None:\n                message.append(\" [line {0:2d}]\".format(lineno))\n            message.append(\": section \")\n            message.extend(msg)\n            msg = message\n        else:\n            msg.insert(0, \"Section \")\n        Error.__init__(self, \"\".join(msg))\n        self.section = section\n        self.source = source\n        self.lineno = lineno\n        self.args = (section, source, lineno)",
        "name_type": "stdlib"
    },
    "configparser.DuplicateOptionError": {
        "API_name": "configparser.DuplicateOptionError",
        "loc_name": "configparser.DuplicateOptionError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 216,
        "namespace": "DuplicateOptionError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.DuplicateOptionError.__init__": {
        "API_name": "configparser.DuplicateOptionError.__init__",
        "loc_name": "configparser.DuplicateOptionError.__init__",
        "args": "self;section;option;source;lineno",
        "args_default": 2,
        "filepath": "configparser",
        "lineno": 223,
        "namespace": "DuplicateOptionError",
        "body": "    def __init__(self, section, option, source=None, lineno=None):\n        msg = [repr(option), \" in section \", repr(section),\n               \" already exists\"]\n        if source is not None:\n            message = [\"While reading from \", repr(source)]\n            if lineno is not None:\n                message.append(\" [line {0:2d}]\".format(lineno))\n            message.append(\": option \")\n            message.extend(msg)\n            msg = message\n        else:\n            msg.insert(0, \"Option \")\n        Error.__init__(self, \"\".join(msg))\n        self.section = section\n        self.option = option\n        self.source = source\n        self.lineno = lineno\n        self.args = (section, option, source, lineno)",
        "name_type": "stdlib"
    },
    "configparser.NoOptionError": {
        "API_name": "configparser.NoOptionError",
        "loc_name": "configparser.NoOptionError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 243,
        "namespace": "NoOptionError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.NoOptionError.__init__": {
        "API_name": "configparser.NoOptionError.__init__",
        "loc_name": "configparser.NoOptionError.__init__",
        "args": "self;option;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 246,
        "namespace": "NoOptionError",
        "body": "    def __init__(self, option, section):\n        Error.__init__(self, \"No option %r in section: %r\" %\n                       (option, section))\n        self.option = option\n        self.section = section\n        self.args = (option, section)",
        "name_type": "stdlib"
    },
    "configparser.InterpolationError": {
        "API_name": "configparser.InterpolationError",
        "loc_name": "configparser.InterpolationError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 254,
        "namespace": "InterpolationError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.InterpolationError.__init__": {
        "API_name": "configparser.InterpolationError.__init__",
        "loc_name": "configparser.InterpolationError.__init__",
        "args": "self;option;section;msg",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 257,
        "namespace": "InterpolationError",
        "body": "    def __init__(self, option, section, msg):\n        Error.__init__(self, msg)\n        self.option = option\n        self.section = section\n        self.args = (option, section, msg)",
        "name_type": "stdlib"
    },
    "configparser.InterpolationMissingOptionError": {
        "API_name": "configparser.InterpolationMissingOptionError",
        "loc_name": "configparser.InterpolationMissingOptionError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 264,
        "namespace": "InterpolationMissingOptionError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.InterpolationMissingOptionError.__init__": {
        "API_name": "configparser.InterpolationMissingOptionError.__init__",
        "loc_name": "configparser.InterpolationMissingOptionError.__init__",
        "args": "self;option;section;rawval;reference",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 267,
        "namespace": "InterpolationMissingOptionError",
        "body": "    def __init__(self, option, section, rawval, reference):\n        msg = (\"Bad value substitution: option {!r} in section {!r} contains \"\n               \"an interpolation key {!r} which is not a valid option name. \"\n               \"Raw value: {!r}\".format(option, section, reference, rawval))\n        InterpolationError.__init__(self, option, section, msg)\n        self.reference = reference\n        self.args = (option, section, rawval, reference)",
        "name_type": "stdlib"
    },
    "configparser.InterpolationSyntaxError": {
        "API_name": "configparser.InterpolationSyntaxError",
        "loc_name": "configparser.InterpolationSyntaxError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 276,
        "namespace": "InterpolationSyntaxError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.InterpolationDepthError": {
        "API_name": "configparser.InterpolationDepthError",
        "loc_name": "configparser.InterpolationDepthError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 284,
        "namespace": "InterpolationDepthError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.InterpolationDepthError.__init__": {
        "API_name": "configparser.InterpolationDepthError.__init__",
        "loc_name": "configparser.InterpolationDepthError.__init__",
        "args": "self;option;section;rawval",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 287,
        "namespace": "InterpolationDepthError",
        "body": "    def __init__(self, option, section, rawval):\n        msg = (\"Recursion limit exceeded in value substitution: option {!r} \"\n               \"in section {!r} contains an interpolation key which \"\n               \"cannot be substituted in {} steps. Raw value: {!r}\"\n               \"\".format(option, section, MAX_INTERPOLATION_DEPTH,\n                         rawval))\n        InterpolationError.__init__(self, option, section, msg)\n        self.args = (option, section, rawval)",
        "name_type": "stdlib"
    },
    "configparser.ParsingError": {
        "API_name": "configparser.ParsingError",
        "loc_name": "configparser.ParsingError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 297,
        "namespace": "ParsingError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.ParsingError.__init__": {
        "API_name": "configparser.ParsingError.__init__",
        "loc_name": "configparser.ParsingError.__init__",
        "args": "self;source;filename",
        "args_default": 2,
        "filepath": "configparser",
        "lineno": 300,
        "namespace": "ParsingError",
        "body": "    def __init__(self, source=None, filename=None):\n        # Exactly one of `source'/`filename' arguments has to be given.\n        # `filename' kept for compatibility.\n        if filename and source:\n            raise ValueError(\"Cannot specify both `filename' and `source'. \"\n                             \"Use `source'.\")\n        elif not filename and not source:\n            raise ValueError(\"Required argument `source' not given.\")\n        elif filename:\n            source = filename\n        Error.__init__(self, 'Source contains parsing errors: %r' % source)\n        self.source = source\n        self.errors = []\n        self.args = (source, )",
        "name_type": "stdlib"
    },
    "configparser.ParsingError.filename": {
        "API_name": "configparser.ParsingError.filename",
        "loc_name": "configparser.ParsingError.filename",
        "args": "self;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 326,
        "namespace": "ParsingError",
        "body": "    def filename(self, value):\n        \"\"\"Deprecated, user `source'.\"\"\"\n        warnings.warn(\n            \"The 'filename' attribute will be removed in future versions.  \"\n            \"Use 'source' instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n        self.source = value",
        "name_type": "stdlib"
    },
    "configparser.ParsingError.append": {
        "API_name": "configparser.ParsingError.append",
        "loc_name": "configparser.ParsingError.append",
        "args": "self;lineno;line",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 335,
        "namespace": "ParsingError",
        "body": "    def append(self, lineno, line):\n        self.errors.append((lineno, line))\n        self.message += '\\n\\t[line %2d]: %s' % (lineno, line)",
        "name_type": "stdlib"
    },
    "configparser.MissingSectionHeaderError": {
        "API_name": "configparser.MissingSectionHeaderError",
        "loc_name": "configparser.MissingSectionHeaderError",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 340,
        "namespace": "MissingSectionHeaderError",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.MissingSectionHeaderError.__init__": {
        "API_name": "configparser.MissingSectionHeaderError.__init__",
        "loc_name": "configparser.MissingSectionHeaderError.__init__",
        "args": "self;filename;lineno;line",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 343,
        "namespace": "MissingSectionHeaderError",
        "body": "    def __init__(self, filename, lineno, line):\n        Error.__init__(\n            self,\n            'File contains no section headers.\\nfile: %r, line: %d\\n%r' %\n            (filename, lineno, line))\n        self.source = filename\n        self.lineno = lineno\n        self.line = line\n        self.args = (filename, lineno, line)",
        "name_type": "stdlib"
    },
    "configparser.Interpolation.before_get": {
        "API_name": "configparser.Interpolation.before_get",
        "loc_name": "configparser.Interpolation.before_get",
        "args": "self;parser;section;option;value;defaults",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 363,
        "namespace": "Interpolation",
        "body": "    def before_get(self, parser, section, option, value, defaults):\n        return value",
        "name_type": "stdlib"
    },
    "configparser.Interpolation.before_set": {
        "API_name": "configparser.Interpolation.before_set",
        "loc_name": "configparser.Interpolation.before_set",
        "args": "self;parser;section;option;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 366,
        "namespace": "Interpolation",
        "body": "    def before_set(self, parser, section, option, value):\n        return value",
        "name_type": "stdlib"
    },
    "configparser.Interpolation.before_read": {
        "API_name": "configparser.Interpolation.before_read",
        "loc_name": "configparser.Interpolation.before_read",
        "args": "self;parser;section;option;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 369,
        "namespace": "Interpolation",
        "body": "    def before_read(self, parser, section, option, value):\n        return value",
        "name_type": "stdlib"
    },
    "configparser.Interpolation.before_write": {
        "API_name": "configparser.Interpolation.before_write",
        "loc_name": "configparser.Interpolation.before_write",
        "args": "self;parser;section;option;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 372,
        "namespace": "Interpolation",
        "body": "    def before_write(self, parser, section, option, value):\n        return value",
        "name_type": "stdlib"
    },
    "configparser.Interpolation": {
        "API_name": "configparser.Interpolation",
        "loc_name": "configparser.Interpolation",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 360,
        "namespace": "Interpolation",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.BasicInterpolation.before_get": {
        "API_name": "configparser.BasicInterpolation.before_get",
        "loc_name": "configparser.BasicInterpolation.before_get",
        "args": "self;parser;section;option;value;defaults",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 393,
        "namespace": "BasicInterpolation",
        "body": "    def before_get(self, parser, section, option, value, defaults):\n        L = []\n        self._interpolate_some(parser, option, L, value, section, defaults, 1)\n        return ''.join(L)",
        "name_type": "stdlib"
    },
    "configparser.BasicInterpolation.before_set": {
        "API_name": "configparser.BasicInterpolation.before_set",
        "loc_name": "configparser.BasicInterpolation.before_set",
        "args": "self;parser;section;option;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 398,
        "namespace": "BasicInterpolation",
        "body": "    def before_set(self, parser, section, option, value):\n        tmp_value = value.replace('%%', '') # escaped percent signs\n        tmp_value = self._KEYCRE.sub('', tmp_value) # valid syntax\n        if '%' in tmp_value:\n            raise ValueError(\"invalid interpolation syntax in %r at \"\n                             \"position %d\" % (value, tmp_value.find('%')))\n        return value",
        "name_type": "stdlib"
    },
    "configparser.BasicInterpolation._interpolate_some": {
        "API_name": "configparser.BasicInterpolation._interpolate_some",
        "loc_name": "configparser.BasicInterpolation._interpolate_some",
        "args": "self;parser;option;accum;rest;section;map;depth",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 406,
        "namespace": "BasicInterpolation",
        "body": "    def _interpolate_some(self, parser, option, accum, rest, section, map,\n                          depth):\n        rawval = parser.get(section, option, raw=True, fallback=rest)\n        if depth > MAX_INTERPOLATION_DEPTH:\n            raise InterpolationDepthError(option, section, rawval)\n        while rest:\n            p = rest.find(\"%\")\n            if p < 0:\n                accum.append(rest)\n                return\n            if p > 0:\n                accum.append(rest[:p])\n                rest = rest[p:]\n            # p is no longer used\n            c = rest[1:2]\n            if c == \"%\":\n                accum.append(\"%\")\n                rest = rest[2:]\n            elif c == \"(\":\n                m = self._KEYCRE.match(rest)\n                if m is None:\n                    raise InterpolationSyntaxError(option, section,\n                        \"bad interpolation variable reference %r\" % rest)\n                var = parser.optionxform(m.group(1))\n                rest = rest[m.end():]\n                try:\n                    v = map[var]\n                except KeyError:\n                    raise InterpolationMissingOptionError(\n                        option, section, rawval, var) from None\n                if \"%\" in v:\n                    self._interpolate_some(parser, option, accum, v,\n                                           section, map, depth + 1)\n                else:\n                    accum.append(v)\n            else:\n                raise InterpolationSyntaxError(\n                    option, section,\n                    \"'%%' must be followed by '%%' or '(', \"\n                    \"found: %r\" % (rest,))",
        "name_type": "stdlib"
    },
    "configparser.BasicInterpolation": {
        "API_name": "configparser.BasicInterpolation",
        "loc_name": "configparser.BasicInterpolation",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 376,
        "namespace": "BasicInterpolation",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.ExtendedInterpolation.before_get": {
        "API_name": "configparser.ExtendedInterpolation.before_get",
        "loc_name": "configparser.ExtendedInterpolation.before_get",
        "args": "self;parser;section;option;value;defaults",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 454,
        "namespace": "ExtendedInterpolation",
        "body": "    def before_get(self, parser, section, option, value, defaults):\n        L = []\n        self._interpolate_some(parser, option, L, value, section, defaults, 1)\n        return ''.join(L)",
        "name_type": "stdlib"
    },
    "configparser.ExtendedInterpolation.before_set": {
        "API_name": "configparser.ExtendedInterpolation.before_set",
        "loc_name": "configparser.ExtendedInterpolation.before_set",
        "args": "self;parser;section;option;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 459,
        "namespace": "ExtendedInterpolation",
        "body": "    def before_set(self, parser, section, option, value):\n        tmp_value = value.replace('$$', '') # escaped dollar signs\n        tmp_value = self._KEYCRE.sub('', tmp_value) # valid syntax\n        if '$' in tmp_value:\n            raise ValueError(\"invalid interpolation syntax in %r at \"\n                             \"position %d\" % (value, tmp_value.find('$')))\n        return value",
        "name_type": "stdlib"
    },
    "configparser.ExtendedInterpolation._interpolate_some": {
        "API_name": "configparser.ExtendedInterpolation._interpolate_some",
        "loc_name": "configparser.ExtendedInterpolation._interpolate_some",
        "args": "self;parser;option;accum;rest;section;map;depth",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 467,
        "namespace": "ExtendedInterpolation",
        "body": "    def _interpolate_some(self, parser, option, accum, rest, section, map,\n                          depth):\n        rawval = parser.get(section, option, raw=True, fallback=rest)\n        if depth > MAX_INTERPOLATION_DEPTH:\n            raise InterpolationDepthError(option, section, rawval)\n        while rest:\n            p = rest.find(\"$\")\n            if p < 0:\n                accum.append(rest)\n                return\n            if p > 0:\n                accum.append(rest[:p])\n                rest = rest[p:]\n            # p is no longer used\n            c = rest[1:2]\n            if c == \"$\":\n                accum.append(\"$\")\n                rest = rest[2:]\n            elif c == \"{\":\n                m = self._KEYCRE.match(rest)\n                if m is None:\n                    raise InterpolationSyntaxError(option, section,\n                        \"bad interpolation variable reference %r\" % rest)\n                path = m.group(1).split(':')\n                rest = rest[m.end():]\n                sect = section\n                opt = option\n                try:\n                    if len(path) == 1:\n                        opt = parser.optionxform(path[0])\n                        v = map[opt]\n                    elif len(path) == 2:\n                        sect = path[0]\n                        opt = parser.optionxform(path[1])\n                        v = parser.get(sect, opt, raw=True)\n                    else:\n                        raise InterpolationSyntaxError(\n                            option, section,\n                            \"More than one ':' found: %r\" % (rest,))\n                except (KeyError, NoSectionError, NoOptionError):\n                    raise InterpolationMissingOptionError(\n                        option, section, rawval, \":\".join(path)) from None\n                if \"$\" in v:\n                    self._interpolate_some(parser, opt, accum, v, sect,\n                                           dict(parser.items(sect, raw=True)),\n                                           depth + 1)\n                else:\n                    accum.append(v)\n            else:\n                raise InterpolationSyntaxError(\n                    option, section,\n                    \"'$' must be followed by '$' or '{', \"\n                    \"found: %r\" % (rest,))",
        "name_type": "stdlib"
    },
    "configparser.ExtendedInterpolation": {
        "API_name": "configparser.ExtendedInterpolation",
        "loc_name": "configparser.ExtendedInterpolation",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 448,
        "namespace": "ExtendedInterpolation",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.LegacyInterpolation.before_get": {
        "API_name": "configparser.LegacyInterpolation.before_get",
        "loc_name": "configparser.LegacyInterpolation.before_get",
        "args": "self;parser;section;option;value;vars",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 528,
        "namespace": "LegacyInterpolation",
        "body": "    def before_get(self, parser, section, option, value, vars):\n        rawval = value\n        depth = MAX_INTERPOLATION_DEPTH\n        while depth:                    # Loop through this until it's done\n            depth -= 1\n            if value and \"%(\" in value:\n                replace = functools.partial(self._interpolation_replace,\n                                            parser=parser)\n                value = self._KEYCRE.sub(replace, value)\n                try:\n                    value = value % vars\n                except KeyError as e:\n                    raise InterpolationMissingOptionError(\n                        option, section, rawval, e.args[0]) from None\n            else:\n                break\n        if value and \"%(\" in value:\n            raise InterpolationDepthError(option, section, rawval)\n        return value",
        "name_type": "stdlib"
    },
    "configparser.LegacyInterpolation.before_set": {
        "API_name": "configparser.LegacyInterpolation.before_set",
        "loc_name": "configparser.LegacyInterpolation.before_set",
        "args": "self;parser;section;option;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 548,
        "namespace": "LegacyInterpolation",
        "body": "    def before_set(self, parser, section, option, value):\n        return value",
        "name_type": "stdlib"
    },
    "configparser.LegacyInterpolation._interpolation_replace": {
        "API_name": "configparser.LegacyInterpolation._interpolation_replace",
        "loc_name": "configparser.LegacyInterpolation._interpolation_replace",
        "args": "match;parser",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 552,
        "namespace": "LegacyInterpolation",
        "body": "    def _interpolation_replace(match, parser):\n        s = match.group(1)\n        if s is None:\n            return match.group()\n        else:\n            return \"%%(%s)s\" % parser.optionxform(s)",
        "name_type": "stdlib"
    },
    "configparser.LegacyInterpolation": {
        "API_name": "configparser.LegacyInterpolation",
        "loc_name": "configparser.LegacyInterpolation",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 522,
        "namespace": "LegacyInterpolation",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser": {
        "API_name": "configparser.RawConfigParser",
        "loc_name": "configparser.RawConfigParser",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 560,
        "namespace": "RawConfigParser",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__init__": {
        "API_name": "configparser.RawConfigParser.__init__",
        "loc_name": "configparser.RawConfigParser.__init__",
        "args": "self;defaults;dict_type;allow_no_value",
        "args_default": 3,
        "filepath": "configparser",
        "lineno": 601,
        "namespace": "RawConfigParser",
        "body": "    def __init__(self, defaults=None, dict_type=_default_dict,\n                 allow_no_value=False, *, delimiters=('=', ':'),\n                 comment_prefixes=('#', ';'), inline_comment_prefixes=None,\n                 strict=True, empty_lines_in_values=True,\n                 default_section=DEFAULTSECT,\n                 interpolation=_UNSET, converters=_UNSET):\n\n        self._dict = dict_type\n        self._sections = self._dict()\n        self._defaults = self._dict()\n        self._converters = ConverterMapping(self)\n        self._proxies = self._dict()\n        self._proxies[default_section] = SectionProxy(self, default_section)\n        self._delimiters = tuple(delimiters)\n        if delimiters == ('=', ':'):\n            self._optcre = self.OPTCRE_NV if allow_no_value else self.OPTCRE\n        else:\n            d = \"|\".join(re.escape(d) for d in delimiters)\n            if allow_no_value:\n                self._optcre = re.compile(self._OPT_NV_TMPL.format(delim=d),\n                                          re.VERBOSE)\n            else:\n                self._optcre = re.compile(self._OPT_TMPL.format(delim=d),\n                                          re.VERBOSE)\n        self._comment_prefixes = tuple(comment_prefixes or ())\n        self._inline_comment_prefixes = tuple(inline_comment_prefixes or ())\n        self._strict = strict\n        self._allow_no_value = allow_no_value\n        self._empty_lines_in_values = empty_lines_in_values\n        self.default_section=default_section\n        self._interpolation = interpolation\n        if self._interpolation is _UNSET:\n            self._interpolation = self._DEFAULT_INTERPOLATION\n        if self._interpolation is None:\n            self._interpolation = Interpolation()\n        if converters is not _UNSET:\n            self._converters.update(converters)\n        if defaults:\n            self._read_defaults(defaults)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.defaults": {
        "API_name": "configparser.RawConfigParser.defaults",
        "loc_name": "configparser.RawConfigParser.defaults",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 641,
        "namespace": "RawConfigParser",
        "body": "    def defaults(self):\n        return self._defaults",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.sections": {
        "API_name": "configparser.RawConfigParser.sections",
        "loc_name": "configparser.RawConfigParser.sections",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 644,
        "namespace": "RawConfigParser",
        "body": "    def sections(self):\n        \"\"\"Return a list of section names, excluding [DEFAULT]\"\"\"\n        # self._sections will never have [DEFAULT] in it\n        return list(self._sections.keys())",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.add_section": {
        "API_name": "configparser.RawConfigParser.add_section",
        "loc_name": "configparser.RawConfigParser.add_section",
        "args": "self;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 649,
        "namespace": "RawConfigParser",
        "body": "    def add_section(self, section):\n        \"\"\"Create a new section in the configuration.\n\n        Raise DuplicateSectionError if a section by the specified name\n        already exists. Raise ValueError if name is DEFAULT.\n        \"\"\"\n        if section == self.default_section:\n            raise ValueError('Invalid section name: %r' % section)\n\n        if section in self._sections:\n            raise DuplicateSectionError(section)\n        self._sections[section] = self._dict()\n        self._proxies[section] = SectionProxy(self, section)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.has_section": {
        "API_name": "configparser.RawConfigParser.has_section",
        "loc_name": "configparser.RawConfigParser.has_section",
        "args": "self;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 663,
        "namespace": "RawConfigParser",
        "body": "    def has_section(self, section):\n        \"\"\"Indicate whether the named section is present in the configuration.\n\n        The DEFAULT section is not acknowledged.\n        \"\"\"\n        return section in self._sections",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.options": {
        "API_name": "configparser.RawConfigParser.options",
        "loc_name": "configparser.RawConfigParser.options",
        "args": "self;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 670,
        "namespace": "RawConfigParser",
        "body": "    def options(self, section):\n        \"\"\"Return a list of option names for the given section name.\"\"\"\n        try:\n            opts = self._sections[section].copy()\n        except KeyError:\n            raise NoSectionError(section) from None\n        opts.update(self._defaults)\n        return list(opts.keys())",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.read": {
        "API_name": "configparser.RawConfigParser.read",
        "loc_name": "configparser.RawConfigParser.read",
        "args": "self;filenames;encoding",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 679,
        "namespace": "RawConfigParser",
        "body": "    def read(self, filenames, encoding=None):\n        \"\"\"Read and parse a filename or an iterable of filenames.\n\n        Files that cannot be opened are silently ignored; this is\n        designed so that you can specify an iterable of potential\n        configuration file locations (e.g. current directory, user's\n        home directory, systemwide directory), and all existing\n        configuration files in the iterable will be read.  A single\n        filename may also be given.\n\n        Return list of successfully read files.\n        \"\"\"\n        if isinstance(filenames, (str, bytes, os.PathLike)):\n            filenames = [filenames]\n        read_ok = []\n        for filename in filenames:\n            try:\n                with open(filename, encoding=encoding) as fp:\n                    self._read(fp, filename)\n            except OSError:\n                continue\n            if isinstance(filename, os.PathLike):\n                filename = os.fspath(filename)\n            read_ok.append(filename)\n        return read_ok",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.read_file": {
        "API_name": "configparser.RawConfigParser.read_file",
        "loc_name": "configparser.RawConfigParser.read_file",
        "args": "self;f;source",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 705,
        "namespace": "RawConfigParser",
        "body": "    def read_file(self, f, source=None):\n        \"\"\"Like read() but the argument must be a file-like object.\n\n        The `f' argument must be iterable, returning one line at a time.\n        Optional second argument is the `source' specifying the name of the\n        file being read. If not given, it is taken from f.name. If `f' has no\n        `name' attribute, `<???>' is used.\n        \"\"\"\n        if source is None:\n            try:\n                source = f.name\n            except AttributeError:\n                source = '<???>'\n        self._read(f, source)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.read_string": {
        "API_name": "configparser.RawConfigParser.read_string",
        "loc_name": "configparser.RawConfigParser.read_string",
        "args": "self;string;source",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 720,
        "namespace": "RawConfigParser",
        "body": "    def read_string(self, string, source='<string>'):\n        \"\"\"Read configuration from a given string.\"\"\"\n        sfile = io.StringIO(string)\n        self.read_file(sfile, source)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.read_dict": {
        "API_name": "configparser.RawConfigParser.read_dict",
        "loc_name": "configparser.RawConfigParser.read_dict",
        "args": "self;dictionary;source",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 725,
        "namespace": "RawConfigParser",
        "body": "    def read_dict(self, dictionary, source='<dict>'):\n        \"\"\"Read configuration from a dictionary.\n\n        Keys are section names, values are dictionaries with keys and values\n        that should be present in the section. If the used dictionary type\n        preserves order, sections and their keys will be added in order.\n\n        All types held in the dictionary are converted to strings during\n        reading, including section names, option names and keys.\n\n        Optional second argument is the `source' specifying the name of the\n        dictionary being read.\n        \"\"\"\n        elements_added = set()\n        for section, keys in dictionary.items():\n            section = str(section)\n            try:\n                self.add_section(section)\n            except (DuplicateSectionError, ValueError):\n                if self._strict and section in elements_added:\n                    raise\n            elements_added.add(section)\n            for key, value in keys.items():\n                key = self.optionxform(str(key))\n                if value is not None:\n                    value = str(value)\n                if self._strict and (section, key) in elements_added:\n                    raise DuplicateOptionError(section, key, source)\n                elements_added.add((section, key))\n                self.set(section, key, value)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.readfp": {
        "API_name": "configparser.RawConfigParser.readfp",
        "loc_name": "configparser.RawConfigParser.readfp",
        "args": "self;fp;filename",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 756,
        "namespace": "RawConfigParser",
        "body": "    def readfp(self, fp, filename=None):\n        \"\"\"Deprecated, use read_file instead.\"\"\"\n        warnings.warn(\n            \"This method will be removed in future versions.  \"\n            \"Use 'parser.read_file()' instead.\",\n            DeprecationWarning, stacklevel=2\n        )\n        self.read_file(fp, source=filename)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.get": {
        "API_name": "configparser.RawConfigParser.get",
        "loc_name": "configparser.RawConfigParser.get",
        "args": "self;section;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 765,
        "namespace": "RawConfigParser",
        "body": "    def get(self, section, option, *, raw=False, vars=None, fallback=_UNSET):\n        \"\"\"Get an option value for a given section.\n\n        If `vars' is provided, it must be a dictionary. The option is looked up\n        in `vars' (if provided), `section', and in `DEFAULTSECT' in that order.\n        If the key is not found and `fallback' is provided, it is used as\n        a fallback value. `None' can be provided as a `fallback' value.\n\n        If interpolation is enabled and the optional argument `raw' is False,\n        all interpolations are expanded in the return values.\n\n        Arguments `raw', `vars', and `fallback' are keyword only.\n\n        The section DEFAULT is special.\n        \"\"\"\n        try:\n            d = self._unify_values(section, vars)\n        except NoSectionError:\n            if fallback is _UNSET:\n                raise\n            else:\n                return fallback\n        option = self.optionxform(option)\n        try:\n            value = d[option]\n        except KeyError:\n            if fallback is _UNSET:\n                raise NoOptionError(option, section)\n            else:\n                return fallback\n\n        if raw or value is None:\n            return value\n        else:\n            return self._interpolation.before_get(self, section, option, value,\n                                                  d)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._get": {
        "API_name": "configparser.RawConfigParser._get",
        "loc_name": "configparser.RawConfigParser._get",
        "args": "self;section;conv;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 802,
        "namespace": "RawConfigParser",
        "body": "    def _get(self, section, conv, option, **kwargs):\n        return conv(self.get(section, option, **kwargs))",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._get_conv": {
        "API_name": "configparser.RawConfigParser._get_conv",
        "loc_name": "configparser.RawConfigParser._get_conv",
        "args": "self;section;option;conv",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 805,
        "namespace": "RawConfigParser",
        "body": "    def _get_conv(self, section, option, conv, *, raw=False, vars=None,\n                  fallback=_UNSET, **kwargs):\n        try:\n            return self._get(section, conv, option, raw=raw, vars=vars,\n                             **kwargs)\n        except (NoSectionError, NoOptionError):\n            if fallback is _UNSET:\n                raise\n            return fallback",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.getint": {
        "API_name": "configparser.RawConfigParser.getint",
        "loc_name": "configparser.RawConfigParser.getint",
        "args": "self;section;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 816,
        "namespace": "RawConfigParser",
        "body": "    def getint(self, section, option, *, raw=False, vars=None,\n               fallback=_UNSET, **kwargs):\n        return self._get_conv(section, option, int, raw=raw, vars=vars,\n                              fallback=fallback, **kwargs)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.getfloat": {
        "API_name": "configparser.RawConfigParser.getfloat",
        "loc_name": "configparser.RawConfigParser.getfloat",
        "args": "self;section;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 821,
        "namespace": "RawConfigParser",
        "body": "    def getfloat(self, section, option, *, raw=False, vars=None,\n                 fallback=_UNSET, **kwargs):\n        return self._get_conv(section, option, float, raw=raw, vars=vars,\n                              fallback=fallback, **kwargs)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.getboolean": {
        "API_name": "configparser.RawConfigParser.getboolean",
        "loc_name": "configparser.RawConfigParser.getboolean",
        "args": "self;section;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 826,
        "namespace": "RawConfigParser",
        "body": "    def getboolean(self, section, option, *, raw=False, vars=None,\n                   fallback=_UNSET, **kwargs):\n        return self._get_conv(section, option, self._convert_to_boolean,\n                              raw=raw, vars=vars, fallback=fallback, **kwargs)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.items": {
        "API_name": "configparser.RawConfigParser.items",
        "loc_name": "configparser.RawConfigParser.items",
        "args": "self;section;raw;vars",
        "args_default": 3,
        "filepath": "configparser",
        "lineno": 831,
        "namespace": "RawConfigParser",
        "body": "    def items(self, section=_UNSET, raw=False, vars=None):\n        \"\"\"Return a list of (name, value) tuples for each option in a section.\n\n        All % interpolations are expanded in the return values, based on the\n        defaults passed into the constructor, unless the optional argument\n        `raw' is true.  Additional substitutions may be provided using the\n        `vars' argument, which must be a dictionary whose contents overrides\n        any pre-existing defaults.\n\n        The section DEFAULT is special.\n        \"\"\"\n        if section is _UNSET:\n            return super().items()\n        d = self._defaults.copy()\n        try:\n            d.update(self._sections[section])\n        except KeyError:\n            if section != self.default_section:\n                raise NoSectionError(section)\n        orig_keys = list(d.keys())\n        # Update with the entry specific variables\n        if vars:\n            for key, value in vars.items():\n                d[self.optionxform(key)] = value\n        value_getter = lambda option: self._interpolation.before_get(self,\n            section, option, d[option], d)\n        if raw:\n            value_getter = lambda option: d[option]\n        return [(option, value_getter(option)) for option in orig_keys]",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.popitem": {
        "API_name": "configparser.RawConfigParser.popitem",
        "loc_name": "configparser.RawConfigParser.popitem",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 861,
        "namespace": "RawConfigParser",
        "body": "    def popitem(self):\n        \"\"\"Remove a section from the parser and return it as\n        a (section_name, section_proxy) tuple. If no section is present, raise\n        KeyError.\n\n        The section DEFAULT is never returned because it cannot be removed.\n        \"\"\"\n        for key in self.sections():\n            value = self[key]\n            del self[key]\n            return key, value\n        raise KeyError",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.optionxform": {
        "API_name": "configparser.RawConfigParser.optionxform",
        "loc_name": "configparser.RawConfigParser.optionxform",
        "args": "self;optionstr",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 874,
        "namespace": "RawConfigParser",
        "body": "    def optionxform(self, optionstr):\n        return optionstr.lower()",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.has_option": {
        "API_name": "configparser.RawConfigParser.has_option",
        "loc_name": "configparser.RawConfigParser.has_option",
        "args": "self;section;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 877,
        "namespace": "RawConfigParser",
        "body": "    def has_option(self, section, option):\n        \"\"\"Check for the existence of a given option in a given section.\n        If the specified `section' is None or an empty string, DEFAULT is\n        assumed. If the specified `section' does not exist, returns False.\"\"\"\n        if not section or section == self.default_section:\n            option = self.optionxform(option)\n            return option in self._defaults\n        elif section not in self._sections:\n            return False\n        else:\n            option = self.optionxform(option)\n            return (option in self._sections[section]\n                    or option in self._defaults)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.set": {
        "API_name": "configparser.RawConfigParser.set",
        "loc_name": "configparser.RawConfigParser.set",
        "args": "self;section;option;value",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 891,
        "namespace": "RawConfigParser",
        "body": "    def set(self, section, option, value=None):\n        \"\"\"Set an option.\"\"\"\n        if value:\n            value = self._interpolation.before_set(self, section, option,\n                                                   value)\n        if not section or section == self.default_section:\n            sectdict = self._defaults\n        else:\n            try:\n                sectdict = self._sections[section]\n            except KeyError:\n                raise NoSectionError(section) from None\n        sectdict[self.optionxform(option)] = value",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.write": {
        "API_name": "configparser.RawConfigParser.write",
        "loc_name": "configparser.RawConfigParser.write",
        "args": "self;fp;space_around_delimiters",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 905,
        "namespace": "RawConfigParser",
        "body": "    def write(self, fp, space_around_delimiters=True):\n        \"\"\"Write an .ini-format representation of the configuration state.\n\n        If `space_around_delimiters' is True (the default), delimiters\n        between keys and values are surrounded by spaces.\n\n        Please note that comments in the original configuration file are not\n        preserved when writing the configuration back.\n        \"\"\"\n        if space_around_delimiters:\n            d = \" {} \".format(self._delimiters[0])\n        else:\n            d = self._delimiters[0]\n        if self._defaults:\n            self._write_section(fp, self.default_section,\n                                    self._defaults.items(), d)\n        for section in self._sections:\n            self._write_section(fp, section,\n                                self._sections[section].items(), d)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._write_section": {
        "API_name": "configparser.RawConfigParser._write_section",
        "loc_name": "configparser.RawConfigParser._write_section",
        "args": "self;fp;section_name;section_items;delimiter",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 925,
        "namespace": "RawConfigParser",
        "body": "    def _write_section(self, fp, section_name, section_items, delimiter):\n        \"\"\"Write a single section to the specified `fp'.\"\"\"\n        fp.write(\"[{}]\\n\".format(section_name))\n        for key, value in section_items:\n            value = self._interpolation.before_write(self, section_name, key,\n                                                     value)\n            if value is not None or not self._allow_no_value:\n                value = delimiter + str(value).replace('\\n', '\\n\\t')\n            else:\n                value = \"\"\n            fp.write(\"{}{}\\n\".format(key, value))\n        fp.write(\"\\n\")",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.remove_option": {
        "API_name": "configparser.RawConfigParser.remove_option",
        "loc_name": "configparser.RawConfigParser.remove_option",
        "args": "self;section;option",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 938,
        "namespace": "RawConfigParser",
        "body": "    def remove_option(self, section, option):\n        \"\"\"Remove an option.\"\"\"\n        if not section or section == self.default_section:\n            sectdict = self._defaults\n        else:\n            try:\n                sectdict = self._sections[section]\n            except KeyError:\n                raise NoSectionError(section) from None\n        option = self.optionxform(option)\n        existed = option in sectdict\n        if existed:\n            del sectdict[option]\n        return existed",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.remove_section": {
        "API_name": "configparser.RawConfigParser.remove_section",
        "loc_name": "configparser.RawConfigParser.remove_section",
        "args": "self;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 953,
        "namespace": "RawConfigParser",
        "body": "    def remove_section(self, section):\n        \"\"\"Remove a file section.\"\"\"\n        existed = section in self._sections\n        if existed:\n            del self._sections[section]\n            del self._proxies[section]\n        return existed",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__getitem__": {
        "API_name": "configparser.RawConfigParser.__getitem__",
        "loc_name": "configparser.RawConfigParser.__getitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 961,
        "namespace": "RawConfigParser",
        "body": "    def __getitem__(self, key):\n        if key != self.default_section and not self.has_section(key):\n            raise KeyError(key)\n        return self._proxies[key]",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__setitem__": {
        "API_name": "configparser.RawConfigParser.__setitem__",
        "loc_name": "configparser.RawConfigParser.__setitem__",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 966,
        "namespace": "RawConfigParser",
        "body": "    def __setitem__(self, key, value):\n        # To conform with the mapping protocol, overwrites existing values in\n        # the section.\n        if key in self and self[key] is value:\n            return\n        # XXX this is not atomic if read_dict fails at any point. Then again,\n        # no update method in configparser is atomic in this implementation.\n        if key == self.default_section:\n            self._defaults.clear()\n        elif key in self._sections:\n            self._sections[key].clear()\n        self.read_dict({key: value})",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__delitem__": {
        "API_name": "configparser.RawConfigParser.__delitem__",
        "loc_name": "configparser.RawConfigParser.__delitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 979,
        "namespace": "RawConfigParser",
        "body": "    def __delitem__(self, key):\n        if key == self.default_section:\n            raise ValueError(\"Cannot remove the default section.\")\n        if not self.has_section(key):\n            raise KeyError(key)\n        self.remove_section(key)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__contains__": {
        "API_name": "configparser.RawConfigParser.__contains__",
        "loc_name": "configparser.RawConfigParser.__contains__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 986,
        "namespace": "RawConfigParser",
        "body": "    def __contains__(self, key):\n        return key == self.default_section or self.has_section(key)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__len__": {
        "API_name": "configparser.RawConfigParser.__len__",
        "loc_name": "configparser.RawConfigParser.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 989,
        "namespace": "RawConfigParser",
        "body": "    def __len__(self):\n        return len(self._sections) + 1 # the default section",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.__iter__": {
        "API_name": "configparser.RawConfigParser.__iter__",
        "loc_name": "configparser.RawConfigParser.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 992,
        "namespace": "RawConfigParser",
        "body": "    def __iter__(self):\n        # XXX does it break when underlying container state changed?\n        return itertools.chain((self.default_section,), self._sections.keys())",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._read": {
        "API_name": "configparser.RawConfigParser._read",
        "loc_name": "configparser.RawConfigParser._read",
        "args": "self;fp;fpname",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 996,
        "namespace": "RawConfigParser",
        "body": "    def _read(self, fp, fpname):\n        \"\"\"Parse a sectioned configuration file.\n\n        Each section in a configuration file contains a header, indicated by\n        a name in square brackets (`[]'), plus key/value options, indicated by\n        `name' and `value' delimited with a specific substring (`=' or `:' by\n        default).\n\n        Values can span multiple lines, as long as they are indented deeper\n        than the first line of the value. Depending on the parser's mode, blank\n        lines may be treated as parts of multiline values or ignored.\n\n        Configuration files may include comments, prefixed by specific\n        characters (`#' and `;' by default). Comments may appear on their own\n        in an otherwise empty line or may be entered in lines holding values or\n        section names. Please note that comments get stripped off when reading configuration files.\n        \"\"\"\n        elements_added = set()\n        cursect = None                        # None, or a dictionary\n        sectname = None\n        optname = None\n        lineno = 0\n        indent_level = 0\n        e = None                              # None, or an exception\n        for lineno, line in enumerate(fp, start=1):\n            comment_start = sys.maxsize\n            # strip inline comments\n            inline_prefixes = {p: -1 for p in self._inline_comment_prefixes}\n            while comment_start == sys.maxsize and inline_prefixes:\n                next_prefixes = {}\n                for prefix, index in inline_prefixes.items():\n                    index = line.find(prefix, index+1)\n                    if index == -1:\n                        continue\n                    next_prefixes[prefix] = index\n                    if index == 0 or (index > 0 and line[index-1].isspace()):\n                        comment_start = min(comment_start, index)\n                inline_prefixes = next_prefixes\n            # strip full line comments\n            for prefix in self._comment_prefixes:\n                if line.strip().startswith(prefix):\n                    comment_start = 0\n                    break\n            if comment_start == sys.maxsize:\n                comment_start = None\n            value = line[:comment_start].strip()\n            if not value:\n                if self._empty_lines_in_values:\n                    # add empty line to the value, but only if there was no\n                    # comment on the line\n                    if (comment_start is None and\n                        cursect is not None and\n                        optname and\n                        cursect[optname] is not None):\n                        cursect[optname].append('') # newlines added at join\n                else:\n                    # empty line marks end of value\n                    indent_level = sys.maxsize\n                continue\n            # continuation line?\n            first_nonspace = self.NONSPACECRE.search(line)\n            cur_indent_level = first_nonspace.start() if first_nonspace else 0\n            if (cursect is not None and optname and\n                cur_indent_level > indent_level):\n                cursect[optname].append(value)\n            # a section header or option header?\n            else:\n                indent_level = cur_indent_level\n                # is it a section header?\n                mo = self.SECTCRE.match(value)\n                if mo:\n                    sectname = mo.group('header')\n                    if sectname in self._sections:\n                        if self._strict and sectname in elements_added:\n                            raise DuplicateSectionError(sectname, fpname,\n                                                        lineno)\n                        cursect = self._sections[sectname]\n                        elements_added.add(sectname)\n                    elif sectname == self.default_section:\n                        cursect = self._defaults\n                    else:\n                        cursect = self._dict()\n                        self._sections[sectname] = cursect\n                        self._proxies[sectname] = SectionProxy(self, sectname)\n                        elements_added.add(sectname)\n                    # So sections can't start with a continuation line\n                    optname = None\n                # no section header in the file?\n                elif cursect is None:\n                    raise MissingSectionHeaderError(fpname, lineno, line)\n                # an option line?\n                else:\n                    mo = self._optcre.match(value)\n                    if mo:\n                        optname, vi, optval = mo.group('option', 'vi', 'value')\n                        if not optname:\n                            e = self._handle_error(e, fpname, lineno, line)\n                        optname = self.optionxform(optname.rstrip())\n                        if (self._strict and\n                            (sectname, optname) in elements_added):\n                            raise DuplicateOptionError(sectname, optname,\n                                                       fpname, lineno)\n                        elements_added.add((sectname, optname))\n                        # This check is fine because the OPTCRE cannot\n                        # match if it would set optval to None\n                        if optval is not None:\n                            optval = optval.strip()\n                            cursect[optname] = [optval]\n                        else:\n                            # valueless option handling\n                            cursect[optname] = None\n                    else:\n                        # a non-fatal parsing error occurred. set up the\n                        # exception but keep going. the exception will be\n                        # raised at the end of the file and will contain a\n                        # list of all bogus lines\n                        e = self._handle_error(e, fpname, lineno, line)\n        self._join_multiline_values()\n        # if any parsing errors occurred, raise an exception\n        if e:\n            raise e",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._join_multiline_values": {
        "API_name": "configparser.RawConfigParser._join_multiline_values",
        "loc_name": "configparser.RawConfigParser._join_multiline_values",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1118,
        "namespace": "RawConfigParser",
        "body": "    def _join_multiline_values(self):\n        defaults = self.default_section, self._defaults\n        all_sections = itertools.chain((defaults,),\n                                       self._sections.items())\n        for section, options in all_sections:\n            for name, val in options.items():\n                if isinstance(val, list):\n                    val = '\\n'.join(val).rstrip()\n                options[name] = self._interpolation.before_read(self,\n                                                                section,\n                                                                name, val)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._read_defaults": {
        "API_name": "configparser.RawConfigParser._read_defaults",
        "loc_name": "configparser.RawConfigParser._read_defaults",
        "args": "self;defaults",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1130,
        "namespace": "RawConfigParser",
        "body": "    def _read_defaults(self, defaults):\n        \"\"\"Read the defaults passed in the initializer.\n        Note: values can be non-string.\"\"\"\n        for key, value in defaults.items():\n            self._defaults[self.optionxform(key)] = value",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._handle_error": {
        "API_name": "configparser.RawConfigParser._handle_error",
        "loc_name": "configparser.RawConfigParser._handle_error",
        "args": "self;exc;fpname;lineno;line",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1136,
        "namespace": "RawConfigParser",
        "body": "    def _handle_error(self, exc, fpname, lineno, line):\n        if not exc:\n            exc = ParsingError(fpname)\n        exc.append(lineno, repr(line))\n        return exc",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._unify_values": {
        "API_name": "configparser.RawConfigParser._unify_values",
        "loc_name": "configparser.RawConfigParser._unify_values",
        "args": "self;section;vars",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1142,
        "namespace": "RawConfigParser",
        "body": "    def _unify_values(self, section, vars):\n        \"\"\"Create a sequence of lookups with 'vars' taking priority over\n        the 'section' which takes priority over the DEFAULTSECT.\n\n        \"\"\"\n        sectiondict = {}\n        try:\n            sectiondict = self._sections[section]\n        except KeyError:\n            if section != self.default_section:\n                raise NoSectionError(section) from None\n        # Update with the entry specific variables\n        vardict = {}\n        if vars:\n            for key, value in vars.items():\n                if value is not None:\n                    value = str(value)\n                vardict[self.optionxform(key)] = value\n        return _ChainMap(vardict, sectiondict, self._defaults)",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._convert_to_boolean": {
        "API_name": "configparser.RawConfigParser._convert_to_boolean",
        "loc_name": "configparser.RawConfigParser._convert_to_boolean",
        "args": "self;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1162,
        "namespace": "RawConfigParser",
        "body": "    def _convert_to_boolean(self, value):\n        \"\"\"Return a boolean value translating from other types if necessary.\n        \"\"\"\n        if value.lower() not in self.BOOLEAN_STATES:\n            raise ValueError('Not a boolean: %s' % value)\n        return self.BOOLEAN_STATES[value.lower()]",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser._validate_value_types": {
        "API_name": "configparser.RawConfigParser._validate_value_types",
        "loc_name": "configparser.RawConfigParser._validate_value_types",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1169,
        "namespace": "RawConfigParser",
        "body": "    def _validate_value_types(self, *, section=\"\", option=\"\", value=\"\"):\n        \"\"\"Raises a TypeError for non-string values.\n\n        The only legal non-string value if we allow valueless\n        options is None, so we need to check if the value is a\n        string if:\n        - we do not allow valueless options, or\n        - we allow valueless options but the value is not None\n\n        For compatibility reasons this method is not used in classic set()\n        for RawConfigParsers. It is invoked in every case for mapping protocol\n        access and in ConfigParser.set().\n        \"\"\"\n        if not isinstance(section, str):\n            raise TypeError(\"section names must be strings\")\n        if not isinstance(option, str):\n            raise TypeError(\"option keys must be strings\")\n        if not self._allow_no_value or value:\n            if not isinstance(value, str):\n                raise TypeError(\"option values must be strings\")",
        "name_type": "stdlib"
    },
    "configparser.RawConfigParser.converters": {
        "API_name": "configparser.RawConfigParser.converters",
        "loc_name": "configparser.RawConfigParser.converters",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1191,
        "namespace": "RawConfigParser",
        "body": "    def converters(self):\n        return self._converters",
        "name_type": "stdlib"
    },
    "configparser.ConfigParser.set": {
        "API_name": "configparser.ConfigParser.set",
        "loc_name": "configparser.ConfigParser.set",
        "args": "self;section;option;value",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 1200,
        "namespace": "ConfigParser",
        "body": "    def set(self, section, option, value=None):\n        \"\"\"Set an option.  Extends RawConfigParser.set by validating type and\n        interpolation syntax on the value.\"\"\"\n        self._validate_value_types(option=option, value=value)\n        super().set(section, option, value)",
        "name_type": "stdlib"
    },
    "configparser.ConfigParser.add_section": {
        "API_name": "configparser.ConfigParser.add_section",
        "loc_name": "configparser.ConfigParser.add_section",
        "args": "self;section",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1206,
        "namespace": "ConfigParser",
        "body": "    def add_section(self, section):\n        \"\"\"Create a new section in the configuration.  Extends\n        RawConfigParser.add_section by validating if the section name is\n        a string.\"\"\"\n        self._validate_value_types(section=section)\n        super().add_section(section)",
        "name_type": "stdlib"
    },
    "configparser.ConfigParser._read_defaults": {
        "API_name": "configparser.ConfigParser._read_defaults",
        "loc_name": "configparser.ConfigParser._read_defaults",
        "args": "self;defaults",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1213,
        "namespace": "ConfigParser",
        "body": "    def _read_defaults(self, defaults):\n        \"\"\"Reads the defaults passed in the initializer, implicitly converting\n        values to strings like the rest of the API.\n\n        Does not perform interpolation for backwards compatibility.\n        \"\"\"\n        try:\n            hold_interpolation = self._interpolation\n            self._interpolation = Interpolation()\n            self.read_dict({self.default_section: defaults})\n        finally:\n            self._interpolation = hold_interpolation",
        "name_type": "stdlib"
    },
    "configparser.ConfigParser": {
        "API_name": "configparser.ConfigParser",
        "loc_name": "configparser.ConfigParser",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 1195,
        "namespace": "ConfigParser",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.SafeConfigParser": {
        "API_name": "configparser.SafeConfigParser",
        "loc_name": "configparser.SafeConfigParser",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 1227,
        "namespace": "SafeConfigParser",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.SafeConfigParser.__init__": {
        "API_name": "configparser.SafeConfigParser.__init__",
        "loc_name": "configparser.SafeConfigParser.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1230,
        "namespace": "SafeConfigParser",
        "body": "    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)\n        warnings.warn(\n            \"The SafeConfigParser class has been renamed to ConfigParser \"\n            \"in Python 3.2. This alias will be removed in future versions.\"\n            \" Use ConfigParser directly instead.\",\n            DeprecationWarning, stacklevel=2\n        )",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy": {
        "API_name": "configparser.SectionProxy",
        "loc_name": "configparser.SectionProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 1240,
        "namespace": "SectionProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__init__": {
        "API_name": "configparser.SectionProxy.__init__",
        "loc_name": "configparser.SectionProxy.__init__",
        "args": "self;parser;name",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1243,
        "namespace": "SectionProxy",
        "body": "    def __init__(self, parser, name):\n        \"\"\"Creates a view on a section of the specified `name` in `parser`.\"\"\"\n        self._parser = parser\n        self._name = name\n        for conv in parser.converters:\n            key = 'get' + conv\n            getter = functools.partial(self.get, _impl=getattr(parser, key))\n            setattr(self, key, getter)",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__repr__": {
        "API_name": "configparser.SectionProxy.__repr__",
        "loc_name": "configparser.SectionProxy.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1252,
        "namespace": "SectionProxy",
        "body": "    def __repr__(self):\n        return '<Section: {}>'.format(self._name)",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__getitem__": {
        "API_name": "configparser.SectionProxy.__getitem__",
        "loc_name": "configparser.SectionProxy.__getitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1255,
        "namespace": "SectionProxy",
        "body": "    def __getitem__(self, key):\n        if not self._parser.has_option(self._name, key):\n            raise KeyError(key)\n        return self._parser.get(self._name, key)",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__setitem__": {
        "API_name": "configparser.SectionProxy.__setitem__",
        "loc_name": "configparser.SectionProxy.__setitem__",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1260,
        "namespace": "SectionProxy",
        "body": "    def __setitem__(self, key, value):\n        self._parser._validate_value_types(option=key, value=value)\n        return self._parser.set(self._name, key, value)",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__delitem__": {
        "API_name": "configparser.SectionProxy.__delitem__",
        "loc_name": "configparser.SectionProxy.__delitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1264,
        "namespace": "SectionProxy",
        "body": "    def __delitem__(self, key):\n        if not (self._parser.has_option(self._name, key) and\n                self._parser.remove_option(self._name, key)):\n            raise KeyError(key)",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__contains__": {
        "API_name": "configparser.SectionProxy.__contains__",
        "loc_name": "configparser.SectionProxy.__contains__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1269,
        "namespace": "SectionProxy",
        "body": "    def __contains__(self, key):\n        return self._parser.has_option(self._name, key)",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__len__": {
        "API_name": "configparser.SectionProxy.__len__",
        "loc_name": "configparser.SectionProxy.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1272,
        "namespace": "SectionProxy",
        "body": "    def __len__(self):\n        return len(self._options())",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.__iter__": {
        "API_name": "configparser.SectionProxy.__iter__",
        "loc_name": "configparser.SectionProxy.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1275,
        "namespace": "SectionProxy",
        "body": "    def __iter__(self):\n        return self._options().__iter__()",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy._options": {
        "API_name": "configparser.SectionProxy._options",
        "loc_name": "configparser.SectionProxy._options",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1278,
        "namespace": "SectionProxy",
        "body": "    def _options(self):\n        if self._name != self._parser.default_section:\n            return self._parser.options(self._name)\n        else:\n            return self._parser.defaults()",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.parser": {
        "API_name": "configparser.SectionProxy.parser",
        "loc_name": "configparser.SectionProxy.parser",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1285,
        "namespace": "SectionProxy",
        "body": "    def parser(self):\n        # The parser object of the proxy is read-only.\n        return self._parser",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.name": {
        "API_name": "configparser.SectionProxy.name",
        "loc_name": "configparser.SectionProxy.name",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1290,
        "namespace": "SectionProxy",
        "body": "    def name(self):\n        # The name of the section on a proxy is read-only.\n        return self._name",
        "name_type": "stdlib"
    },
    "configparser.SectionProxy.get": {
        "API_name": "configparser.SectionProxy.get",
        "loc_name": "configparser.SectionProxy.get",
        "args": "self;option;fallback",
        "args_default": 1,
        "filepath": "configparser",
        "lineno": 1294,
        "namespace": "SectionProxy",
        "body": "    def get(self, option, fallback=None, *, raw=False, vars=None,\n            _impl=None, **kwargs):\n        \"\"\"Get an option value.\n\n        Unless `fallback` is provided, `None` will be returned if the option\n        is not found.\n\n        \"\"\"\n        # If `_impl` is provided, it should be a getter method on the parser\n        # object that provides the desired type conversion.\n        if not _impl:\n            _impl = self._parser.get\n        return _impl(self._name, option, raw=raw, vars=vars,\n                     fallback=fallback, **kwargs)",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping": {
        "API_name": "configparser.ConverterMapping",
        "loc_name": "configparser.ConverterMapping",
        "args": "*",
        "args_default": "*",
        "filepath": "configparser",
        "lineno": 1310,
        "namespace": "ConverterMapping",
        "body": "",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping.__init__": {
        "API_name": "configparser.ConverterMapping.__init__",
        "loc_name": "configparser.ConverterMapping.__init__",
        "args": "self;parser",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1320,
        "namespace": "ConverterMapping",
        "body": "    def __init__(self, parser):\n        self._parser = parser\n        self._data = {}\n        for getter in dir(self._parser):\n            m = self.GETTERCRE.match(getter)\n            if not m or not callable(getattr(self._parser, getter)):\n                continue\n            self._data[m.group('name')] = None   # See class docstring.",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping.__getitem__": {
        "API_name": "configparser.ConverterMapping.__getitem__",
        "loc_name": "configparser.ConverterMapping.__getitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1329,
        "namespace": "ConverterMapping",
        "body": "    def __getitem__(self, key):\n        return self._data[key]",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping.__setitem__": {
        "API_name": "configparser.ConverterMapping.__setitem__",
        "loc_name": "configparser.ConverterMapping.__setitem__",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1332,
        "namespace": "ConverterMapping",
        "body": "    def __setitem__(self, key, value):\n        try:\n            k = 'get' + key\n        except TypeError:\n            raise ValueError('Incompatible key: {} (type: {})'\n                             ''.format(key, type(key)))\n        if k == 'get':\n            raise ValueError('Incompatible key: cannot use \"\" as a name')\n        self._data[key] = value\n        func = functools.partial(self._parser._get_conv, conv=value)\n        func.converter = value\n        setattr(self._parser, k, func)\n        for proxy in self._parser.values():\n            getter = functools.partial(proxy.get, _impl=func)\n            setattr(proxy, k, getter)",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping.__delitem__": {
        "API_name": "configparser.ConverterMapping.__delitem__",
        "loc_name": "configparser.ConverterMapping.__delitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1348,
        "namespace": "ConverterMapping",
        "body": "    def __delitem__(self, key):\n        try:\n            k = 'get' + (key or None)\n        except TypeError:\n            raise KeyError(key)\n        del self._data[key]\n        for inst in itertools.chain((self._parser,), self._parser.values()):\n            try:\n                delattr(inst, k)\n            except AttributeError:\n                # don't raise since the entry was present in _data, silently\n                # clean up\n                continue",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping.__iter__": {
        "API_name": "configparser.ConverterMapping.__iter__",
        "loc_name": "configparser.ConverterMapping.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1362,
        "namespace": "ConverterMapping",
        "body": "    def __iter__(self):\n        return iter(self._data)",
        "name_type": "stdlib"
    },
    "configparser.ConverterMapping.__len__": {
        "API_name": "configparser.ConverterMapping.__len__",
        "loc_name": "configparser.ConverterMapping.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "configparser",
        "lineno": 1365,
        "namespace": "ConverterMapping",
        "body": "    def __len__(self):\n        return len(self._data)",
        "name_type": "stdlib"
    },
    "gzip": {
        "API_name": "gzip",
        "loc_name": "gzip",
        "args": "*",
        "args_default": "*",
        "filepath": "gzip",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Functions that read and write gzipped files.\n\nThe user of the file doesn't have to worry about the compression,\nbut random access is not allowed.\"\"\"\n__all__ = [\"BadGzipFile\", \"GzipFile\", \"open\", \"compress\", \"decompress\"]\nFTEXT, FHCRC, FEXTRA, FNAME, FCOMMENT = 1, 2, 4, 8, 16\nREAD, WRITE = 1, 2\n_COMPRESS_LEVEL_FAST = 1\n_COMPRESS_LEVEL_TRADEOFF = 6\n_COMPRESS_LEVEL_BEST = 9\nif __name__ == '__main__':\n    main()",
        "name_type": "stdlib"
    },
    "gzip.open": {
        "API_name": "gzip.open",
        "loc_name": "gzip.open",
        "args": "filename;mode;compresslevel;encoding;errors;newline",
        "args_default": 5,
        "filepath": "gzip",
        "lineno": 25,
        "namespace": "*",
        "body": "def open(filename, mode=\"rb\", compresslevel=_COMPRESS_LEVEL_BEST,\n         encoding=None, errors=None, newline=None):\n    \"\"\"Open a gzip-compressed file in binary or text mode.\n\n    The filename argument can be an actual filename (a str or bytes object), or\n    an existing file object to read from or write to.\n\n    The mode argument can be \"r\", \"rb\", \"w\", \"wb\", \"x\", \"xb\", \"a\" or \"ab\" for\n    binary mode, or \"rt\", \"wt\", \"xt\" or \"at\" for text mode. The default mode is\n    \"rb\", and the default compresslevel is 9.\n\n    For binary mode, this function is equivalent to the GzipFile constructor:\n    GzipFile(filename, mode, compresslevel). In this case, the encoding, errors\n    and newline arguments must not be provided.\n\n    For text mode, a GzipFile object is created, and wrapped in an\n    io.TextIOWrapper instance with the specified encoding, error handling\n    behavior, and line ending(s).\n\n    \"\"\"\n    if \"t\" in mode:\n        if \"b\" in mode:\n            raise ValueError(\"Invalid mode: %r\" % (mode,))\n    else:\n        if encoding is not None:\n            raise ValueError(\"Argument 'encoding' not supported in binary mode\")\n        if errors is not None:\n            raise ValueError(\"Argument 'errors' not supported in binary mode\")\n        if newline is not None:\n            raise ValueError(\"Argument 'newline' not supported in binary mode\")\n\n    gz_mode = mode.replace(\"t\", \"\")\n    if isinstance(filename, (str, bytes, os.PathLike)):\n        binary_file = GzipFile(filename, gz_mode, compresslevel)\n    elif hasattr(filename, \"read\") or hasattr(filename, \"write\"):\n        binary_file = GzipFile(None, gz_mode, compresslevel, filename)\n    else:\n        raise TypeError(\"filename must be a str or bytes object, or a file\")\n\n    if \"t\" in mode:\n        return io.TextIOWrapper(binary_file, encoding, errors, newline)\n    else:\n        return binary_file",
        "name_type": "stdlib"
    },
    "gzip.write32u": {
        "API_name": "gzip.write32u",
        "loc_name": "gzip.write32u",
        "args": "output;value",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 69,
        "namespace": "*",
        "body": "def write32u(output, value):\n    # The L format writes the bit pattern correctly whether signed\n    # or unsigned.\n    output.write(struct.pack(\"<L\", value))",
        "name_type": "stdlib"
    },
    "gzip._PaddedFile": {
        "API_name": "gzip._PaddedFile",
        "loc_name": "gzip._PaddedFile",
        "args": "*",
        "args_default": "*",
        "filepath": "gzip",
        "lineno": 74,
        "namespace": "_PaddedFile",
        "body": "",
        "name_type": "stdlib"
    },
    "gzip._PaddedFile.__init__": {
        "API_name": "gzip._PaddedFile.__init__",
        "loc_name": "gzip._PaddedFile.__init__",
        "args": "self;f;prepend",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 79,
        "namespace": "_PaddedFile",
        "body": "    def __init__(self, f, prepend=b''):\n        self._buffer = prepend\n        self._length = len(prepend)\n        self.file = f\n        self._read = 0",
        "name_type": "stdlib"
    },
    "gzip._PaddedFile.read": {
        "API_name": "gzip._PaddedFile.read",
        "loc_name": "gzip._PaddedFile.read",
        "args": "self;size",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 85,
        "namespace": "_PaddedFile",
        "body": "    def read(self, size):\n        if self._read is None:\n            return self.file.read(size)\n        if self._read + size <= self._length:\n            read = self._read\n            self._read += size\n            return self._buffer[read:self._read]\n        else:\n            read = self._read\n            self._read = None\n            return self._buffer[read:] + \\\n                   self.file.read(size-self._length+read)",
        "name_type": "stdlib"
    },
    "gzip._PaddedFile.prepend": {
        "API_name": "gzip._PaddedFile.prepend",
        "loc_name": "gzip._PaddedFile.prepend",
        "args": "self;prepend",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 98,
        "namespace": "_PaddedFile",
        "body": "    def prepend(self, prepend=b''):\n        if self._read is None:\n            self._buffer = prepend\n        else:  # Assume data was read since the last prepend() call\n            self._read -= len(prepend)\n            return\n        self._length = len(self._buffer)\n        self._read = 0",
        "name_type": "stdlib"
    },
    "gzip._PaddedFile.seek": {
        "API_name": "gzip._PaddedFile.seek",
        "loc_name": "gzip._PaddedFile.seek",
        "args": "self;off",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 107,
        "namespace": "_PaddedFile",
        "body": "    def seek(self, off):\n        self._read = None\n        self._buffer = None\n        return self.file.seek(off)",
        "name_type": "stdlib"
    },
    "gzip._PaddedFile.seekable": {
        "API_name": "gzip._PaddedFile.seekable",
        "loc_name": "gzip._PaddedFile.seekable",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 112,
        "namespace": "_PaddedFile",
        "body": "    def seekable(self):\n        return True  # Allows fast-forwarding even in unseekable streams",
        "name_type": "stdlib"
    },
    "gzip.BadGzipFile": {
        "API_name": "gzip.BadGzipFile",
        "loc_name": "gzip.BadGzipFile",
        "args": "*",
        "args_default": "*",
        "filepath": "gzip",
        "lineno": 116,
        "namespace": "BadGzipFile",
        "body": "",
        "name_type": "stdlib"
    },
    "gzip.GzipFile": {
        "API_name": "gzip.GzipFile",
        "loc_name": "gzip.GzipFile",
        "args": "*",
        "args_default": "*",
        "filepath": "gzip",
        "lineno": 120,
        "namespace": "GzipFile",
        "body": "",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.__init__": {
        "API_name": "gzip.GzipFile.__init__",
        "loc_name": "gzip.GzipFile.__init__",
        "args": "self;filename;mode;compresslevel;fileobj;mtime",
        "args_default": 5,
        "filepath": "gzip",
        "lineno": 133,
        "namespace": "GzipFile",
        "body": "    def __init__(self, filename=None, mode=None,\n                 compresslevel=_COMPRESS_LEVEL_BEST, fileobj=None, mtime=None):\n        \"\"\"Constructor for the GzipFile class.\n\n        At least one of fileobj and filename must be given a\n        non-trivial value.\n\n        The new class instance is based on fileobj, which can be a regular\n        file, an io.BytesIO object, or any other object which simulates a file.\n        It defaults to None, in which case filename is opened to provide\n        a file object.\n\n        When fileobj is not None, the filename argument is only used to be\n        included in the gzip file header, which may include the original\n        filename of the uncompressed file.  It defaults to the filename of\n        fileobj, if discernible; otherwise, it defaults to the empty string,\n        and in this case the original filename is not included in the header.\n\n        The mode argument can be any of 'r', 'rb', 'a', 'ab', 'w', 'wb', 'x', or\n        'xb' depending on whether the file will be read or written.  The default\n        is the mode of fileobj if discernible; otherwise, the default is 'rb'.\n        A mode of 'r' is equivalent to one of 'rb', and similarly for 'w' and\n        'wb', 'a' and 'ab', and 'x' and 'xb'.\n\n        The compresslevel argument is an integer from 0 to 9 controlling the\n        level of compression; 1 is fastest and produces the least compression,\n        and 9 is slowest and produces the most compression. 0 is no compression\n        at all. The default is 9.\n\n        The mtime argument is an optional numeric timestamp to be written\n        to the last modification time field in the stream when compressing.\n        If omitted or None, the current time is used.\n\n        \"\"\"\n\n        if mode and ('t' in mode or 'U' in mode):\n            raise ValueError(\"Invalid mode: {!r}\".format(mode))\n        if mode and 'b' not in mode:\n            mode += 'b'\n        if fileobj is None:\n            fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\n        if filename is None:\n            filename = getattr(fileobj, 'name', '')\n            if not isinstance(filename, (str, bytes)):\n                filename = ''\n        else:\n            filename = os.fspath(filename)\n        origmode = mode\n        if mode is None:\n            mode = getattr(fileobj, 'mode', 'rb')\n\n        if mode.startswith('r'):\n            self.mode = READ\n            raw = _GzipReader(fileobj)\n            self._buffer = io.BufferedReader(raw)\n            self.name = filename\n\n        elif mode.startswith(('w', 'a', 'x')):\n            if origmode is None:\n                import warnings\n                warnings.warn(\n                    \"GzipFile was opened for writing, but this will \"\n                    \"change in future Python releases.  \"\n                    \"Specify the mode argument for opening it for writing.\",\n                    FutureWarning, 2)\n            self.mode = WRITE\n            self._init_write(filename)\n            self.compress = zlib.compressobj(compresslevel,\n                                             zlib.DEFLATED,\n                                             -zlib.MAX_WBITS,\n                                             zlib.DEF_MEM_LEVEL,\n                                             0)\n            self._write_mtime = mtime\n        else:\n            raise ValueError(\"Invalid mode: {!r}\".format(mode))\n\n        self.fileobj = fileobj\n\n        if self.mode == WRITE:\n            self._write_gzip_header(compresslevel)",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.filename": {
        "API_name": "gzip.GzipFile.filename",
        "loc_name": "gzip.GzipFile.filename",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 215,
        "namespace": "GzipFile",
        "body": "    def filename(self):\n        import warnings\n        warnings.warn(\"use the name attribute\", DeprecationWarning, 2)\n        if self.mode == WRITE and self.name[-3:] != \".gz\":\n            return self.name + \".gz\"\n        return self.name",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.mtime": {
        "API_name": "gzip.GzipFile.mtime",
        "loc_name": "gzip.GzipFile.mtime",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 223,
        "namespace": "GzipFile",
        "body": "    def mtime(self):\n        \"\"\"Last modification time read from stream, or None\"\"\"\n        return self._buffer.raw._last_mtime",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.__repr__": {
        "API_name": "gzip.GzipFile.__repr__",
        "loc_name": "gzip.GzipFile.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 227,
        "namespace": "GzipFile",
        "body": "    def __repr__(self):\n        s = repr(self.fileobj)\n        return '<gzip ' + s[1:-1] + ' ' + hex(id(self)) + '>'",
        "name_type": "stdlib"
    },
    "gzip.GzipFile._init_write": {
        "API_name": "gzip.GzipFile._init_write",
        "loc_name": "gzip.GzipFile._init_write",
        "args": "self;filename",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 231,
        "namespace": "GzipFile",
        "body": "    def _init_write(self, filename):\n        self.name = filename\n        self.crc = zlib.crc32(b\"\")\n        self.size = 0\n        self.writebuf = []\n        self.bufsize = 0\n        self.offset = 0  # Current file offset for seek(), tell(), etc",
        "name_type": "stdlib"
    },
    "gzip.GzipFile._write_gzip_header": {
        "API_name": "gzip.GzipFile._write_gzip_header",
        "loc_name": "gzip.GzipFile._write_gzip_header",
        "args": "self;compresslevel",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 239,
        "namespace": "GzipFile",
        "body": "    def _write_gzip_header(self, compresslevel):\n        self.fileobj.write(b'\\037\\213')             # magic header\n        self.fileobj.write(b'\\010')                 # compression method\n        try:\n            # RFC 1952 requires the FNAME field to be Latin-1. Do not\n            # include filenames that cannot be represented that way.\n            fname = os.path.basename(self.name)\n            if not isinstance(fname, bytes):\n                fname = fname.encode('latin-1')\n            if fname.endswith(b'.gz'):\n                fname = fname[:-3]\n        except UnicodeEncodeError:\n            fname = b''\n        flags = 0\n        if fname:\n            flags = FNAME\n        self.fileobj.write(chr(flags).encode('latin-1'))\n        mtime = self._write_mtime\n        if mtime is None:\n            mtime = time.time()\n        write32u(self.fileobj, int(mtime))\n        if compresslevel == _COMPRESS_LEVEL_BEST:\n            xfl = b'\\002'\n        elif compresslevel == _COMPRESS_LEVEL_FAST:\n            xfl = b'\\004'\n        else:\n            xfl = b'\\000'\n        self.fileobj.write(xfl)\n        self.fileobj.write(b'\\377')\n        if fname:\n            self.fileobj.write(fname + b'\\000')",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.write": {
        "API_name": "gzip.GzipFile.write",
        "loc_name": "gzip.GzipFile.write",
        "args": "self;data",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 271,
        "namespace": "GzipFile",
        "body": "    def write(self,data):\n        self._check_not_closed()\n        if self.mode != WRITE:\n            import errno\n            raise OSError(errno.EBADF, \"write() on read-only GzipFile object\")\n\n        if self.fileobj is None:\n            raise ValueError(\"write() on closed GzipFile object\")\n\n        if isinstance(data, bytes):\n            length = len(data)\n        else:\n            # accept any data that supports the buffer protocol\n            data = memoryview(data)\n            length = data.nbytes\n\n        if length > 0:\n            self.fileobj.write(self.compress.compress(data))\n            self.size += length\n            self.crc = zlib.crc32(data, self.crc)\n            self.offset += length\n\n        return length",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.read": {
        "API_name": "gzip.GzipFile.read",
        "loc_name": "gzip.GzipFile.read",
        "args": "self;size",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 295,
        "namespace": "GzipFile",
        "body": "    def read(self, size=-1):\n        self._check_not_closed()\n        if self.mode != READ:\n            import errno\n            raise OSError(errno.EBADF, \"read() on write-only GzipFile object\")\n        return self._buffer.read(size)",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.read1": {
        "API_name": "gzip.GzipFile.read1",
        "loc_name": "gzip.GzipFile.read1",
        "args": "self;size",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 302,
        "namespace": "GzipFile",
        "body": "    def read1(self, size=-1):\n        \"\"\"Implements BufferedIOBase.read1()\n\n        Reads up to a buffer's worth of data if size is negative.\"\"\"\n        self._check_not_closed()\n        if self.mode != READ:\n            import errno\n            raise OSError(errno.EBADF, \"read1() on write-only GzipFile object\")\n\n        if size < 0:\n            size = io.DEFAULT_BUFFER_SIZE\n        return self._buffer.read1(size)",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.peek": {
        "API_name": "gzip.GzipFile.peek",
        "loc_name": "gzip.GzipFile.peek",
        "args": "self;n",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 315,
        "namespace": "GzipFile",
        "body": "    def peek(self, n):\n        self._check_not_closed()\n        if self.mode != READ:\n            import errno\n            raise OSError(errno.EBADF, \"peek() on write-only GzipFile object\")\n        return self._buffer.peek(n)",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.closed": {
        "API_name": "gzip.GzipFile.closed",
        "loc_name": "gzip.GzipFile.closed",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 323,
        "namespace": "GzipFile",
        "body": "    def closed(self):\n        return self.fileobj is None",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.close": {
        "API_name": "gzip.GzipFile.close",
        "loc_name": "gzip.GzipFile.close",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 326,
        "namespace": "GzipFile",
        "body": "    def close(self):\n        fileobj = self.fileobj\n        if fileobj is None:\n            return\n        self.fileobj = None\n        try:\n            if self.mode == WRITE:\n                fileobj.write(self.compress.flush())\n                write32u(fileobj, self.crc)\n                # self.size may exceed 2 GiB, or even 4 GiB\n                write32u(fileobj, self.size & 0xffffffff)\n            elif self.mode == READ:\n                self._buffer.close()\n        finally:\n            myfileobj = self.myfileobj\n            if myfileobj:\n                self.myfileobj = None\n                myfileobj.close()",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.flush": {
        "API_name": "gzip.GzipFile.flush",
        "loc_name": "gzip.GzipFile.flush",
        "args": "self;zlib_mode",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 345,
        "namespace": "GzipFile",
        "body": "    def flush(self,zlib_mode=zlib.Z_SYNC_FLUSH):\n        self._check_not_closed()\n        if self.mode == WRITE:\n            # Ensure the compressor's buffer is flushed\n            self.fileobj.write(self.compress.flush(zlib_mode))\n            self.fileobj.flush()",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.fileno": {
        "API_name": "gzip.GzipFile.fileno",
        "loc_name": "gzip.GzipFile.fileno",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 352,
        "namespace": "GzipFile",
        "body": "    def fileno(self):\n        \"\"\"Invoke the underlying file object's fileno() method.\n\n        This will raise AttributeError if the underlying file object\n        doesn't support fileno().\n        \"\"\"\n        return self.fileobj.fileno()",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.rewind": {
        "API_name": "gzip.GzipFile.rewind",
        "loc_name": "gzip.GzipFile.rewind",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 360,
        "namespace": "GzipFile",
        "body": "    def rewind(self):\n        '''Return the uncompressed stream file position indicator to the\n        beginning of the file'''\n        if self.mode != READ:\n            raise OSError(\"Can't rewind in write mode\")\n        self._buffer.seek(0)",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.readable": {
        "API_name": "gzip.GzipFile.readable",
        "loc_name": "gzip.GzipFile.readable",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 367,
        "namespace": "GzipFile",
        "body": "    def readable(self):\n        return self.mode == READ",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.writable": {
        "API_name": "gzip.GzipFile.writable",
        "loc_name": "gzip.GzipFile.writable",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 370,
        "namespace": "GzipFile",
        "body": "    def writable(self):\n        return self.mode == WRITE",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.seekable": {
        "API_name": "gzip.GzipFile.seekable",
        "loc_name": "gzip.GzipFile.seekable",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 373,
        "namespace": "GzipFile",
        "body": "    def seekable(self):\n        return True",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.seek": {
        "API_name": "gzip.GzipFile.seek",
        "loc_name": "gzip.GzipFile.seek",
        "args": "self;offset;whence",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 376,
        "namespace": "GzipFile",
        "body": "    def seek(self, offset, whence=io.SEEK_SET):\n        if self.mode == WRITE:\n            if whence != io.SEEK_SET:\n                if whence == io.SEEK_CUR:\n                    offset = self.offset + offset\n                else:\n                    raise ValueError('Seek from end not supported')\n            if offset < self.offset:\n                raise OSError('Negative seek in write mode')\n            count = offset - self.offset\n            chunk = b'\\0' * 1024\n            for i in range(count // 1024):\n                self.write(chunk)\n            self.write(b'\\0' * (count % 1024))\n        elif self.mode == READ:\n            self._check_not_closed()\n            return self._buffer.seek(offset, whence)\n\n        return self.offset",
        "name_type": "stdlib"
    },
    "gzip.GzipFile.readline": {
        "API_name": "gzip.GzipFile.readline",
        "loc_name": "gzip.GzipFile.readline",
        "args": "self;size",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 396,
        "namespace": "GzipFile",
        "body": "    def readline(self, size=-1):\n        self._check_not_closed()\n        return self._buffer.readline(size)",
        "name_type": "stdlib"
    },
    "gzip._GzipReader": {
        "API_name": "gzip._GzipReader",
        "loc_name": "gzip._GzipReader",
        "args": "*",
        "args_default": "*",
        "filepath": "gzip",
        "lineno": 401,
        "namespace": "_GzipReader",
        "body": "",
        "name_type": "stdlib"
    },
    "gzip._GzipReader.__init__": {
        "API_name": "gzip._GzipReader.__init__",
        "loc_name": "gzip._GzipReader.__init__",
        "args": "self;fp",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 402,
        "namespace": "_GzipReader",
        "body": "    def __init__(self, fp):\n        super().__init__(_PaddedFile(fp), zlib.decompressobj,\n                         wbits=-zlib.MAX_WBITS)\n        # Set flag indicating start of a new member\n        self._new_member = True\n        self._last_mtime = None",
        "name_type": "stdlib"
    },
    "gzip._GzipReader._init_read": {
        "API_name": "gzip._GzipReader._init_read",
        "loc_name": "gzip._GzipReader._init_read",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 409,
        "namespace": "_GzipReader",
        "body": "    def _init_read(self):\n        self._crc = zlib.crc32(b\"\")\n        self._stream_size = 0  # Decompressed size of unconcatenated stream",
        "name_type": "stdlib"
    },
    "gzip._GzipReader._read_exact": {
        "API_name": "gzip._GzipReader._read_exact",
        "loc_name": "gzip._GzipReader._read_exact",
        "args": "self;n",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 413,
        "namespace": "_GzipReader",
        "body": "    def _read_exact(self, n):\n        '''Read exactly *n* bytes from `self._fp`\n\n        This method is required because self._fp may be unbuffered,\n        i.e. return short reads.\n        '''\n\n        data = self._fp.read(n)\n        while len(data) < n:\n            b = self._fp.read(n - len(data))\n            if not b:\n                raise EOFError(\"Compressed file ended before the \"\n                               \"end-of-stream marker was reached\")\n            data += b\n        return data",
        "name_type": "stdlib"
    },
    "gzip._GzipReader._read_gzip_header": {
        "API_name": "gzip._GzipReader._read_gzip_header",
        "loc_name": "gzip._GzipReader._read_gzip_header",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 429,
        "namespace": "_GzipReader",
        "body": "    def _read_gzip_header(self):\n        magic = self._fp.read(2)\n        if magic == b'':\n            return False\n\n        if magic != b'\\037\\213':\n            raise BadGzipFile('Not a gzipped file (%r)' % magic)\n\n        (method, flag,\n         self._last_mtime) = struct.unpack(\"<BBIxx\", self._read_exact(8))\n        if method != 8:\n            raise BadGzipFile('Unknown compression method')\n\n        if flag & FEXTRA:\n            # Read & discard the extra field, if present\n            extra_len, = struct.unpack(\"<H\", self._read_exact(2))\n            self._read_exact(extra_len)\n        if flag & FNAME:\n            # Read and discard a null-terminated string containing the filename\n            while True:\n                s = self._fp.read(1)\n                if not s or s==b'\\000':\n                    break\n        if flag & FCOMMENT:\n            # Read and discard a null-terminated string containing a comment\n            while True:\n                s = self._fp.read(1)\n                if not s or s==b'\\000':\n                    break\n        if flag & FHCRC:\n            self._read_exact(2)     # Read & discard the 16-bit header CRC\n        return True",
        "name_type": "stdlib"
    },
    "gzip._GzipReader.read": {
        "API_name": "gzip._GzipReader.read",
        "loc_name": "gzip._GzipReader.read",
        "args": "self;size",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 462,
        "namespace": "_GzipReader",
        "body": "    def read(self, size=-1):\n        if size < 0:\n            return self.readall()\n        # size=0 is special because decompress(max_length=0) is not supported\n        if not size:\n            return b\"\"\n\n        # For certain input data, a single\n        # call to decompress() may not return\n        # any data. In this case, retry until we get some data or reach EOF.\n        while True:\n            if self._decompressor.eof:\n                # Ending case: we've come to the end of a member in the file,\n                # so finish up this member, and read a new gzip header.\n                # Check the CRC and file size, and set the flag so we read\n                # a new member\n                self._read_eof()\n                self._new_member = True\n                self._decompressor = self._decomp_factory(\n                    **self._decomp_args)\n\n            if self._new_member:\n                # If the _new_member flag is set, we have to\n                # jump to the next member, if there is one.\n                self._init_read()\n                if not self._read_gzip_header():\n                    self._size = self._pos\n                    return b\"\"\n                self._new_member = False\n\n            # Read a chunk of data from the file\n            buf = self._fp.read(io.DEFAULT_BUFFER_SIZE)\n\n            uncompress = self._decompressor.decompress(buf, size)\n            if self._decompressor.unconsumed_tail != b\"\":\n                self._fp.prepend(self._decompressor.unconsumed_tail)\n            elif self._decompressor.unused_data != b\"\":\n                # Prepend the already read bytes to the fileobj so they can\n                # be seen by _read_eof() and _read_gzip_header()\n                self._fp.prepend(self._decompressor.unused_data)\n\n            if uncompress != b\"\":\n                break\n            if buf == b\"\":\n                raise EOFError(\"Compressed file ended before the \"\n                               \"end-of-stream marker was reached\")\n\n        self._add_read_data( uncompress )\n        self._pos += len(uncompress)\n        return uncompress",
        "name_type": "stdlib"
    },
    "gzip._GzipReader._add_read_data": {
        "API_name": "gzip._GzipReader._add_read_data",
        "loc_name": "gzip._GzipReader._add_read_data",
        "args": "self;data",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 513,
        "namespace": "_GzipReader",
        "body": "    def _add_read_data(self, data):\n        self._crc = zlib.crc32(data, self._crc)\n        self._stream_size = self._stream_size + len(data)",
        "name_type": "stdlib"
    },
    "gzip._GzipReader._read_eof": {
        "API_name": "gzip._GzipReader._read_eof",
        "loc_name": "gzip._GzipReader._read_eof",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 517,
        "namespace": "_GzipReader",
        "body": "    def _read_eof(self):\n        # We've read to the end of the file\n        # We check that the computed CRC and size of the\n        # uncompressed data matches the stored values.  Note that the size\n        # stored is the true file size mod 2**32.\n        crc32, isize = struct.unpack(\"<II\", self._read_exact(8))\n        if crc32 != self._crc:\n            raise BadGzipFile(\"CRC check failed %s != %s\" % (hex(crc32),\n                                                             hex(self._crc)))\n        elif isize != (self._stream_size & 0xffffffff):\n            raise BadGzipFile(\"Incorrect length of data produced\")\n\n        # Gzip files can be padded with zeroes and still have archives.\n        # Consume all zero bytes and set the file position to the first\n        # non-zero byte. See http://www.gzip.org/#faq8\n        c = b\"\\x00\"\n        while c == b\"\\x00\":\n            c = self._fp.read(1)\n        if c:\n            self._fp.prepend(c)",
        "name_type": "stdlib"
    },
    "gzip._GzipReader._rewind": {
        "API_name": "gzip._GzipReader._rewind",
        "loc_name": "gzip._GzipReader._rewind",
        "args": "self",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 538,
        "namespace": "_GzipReader",
        "body": "    def _rewind(self):\n        super()._rewind()\n        self._new_member = True",
        "name_type": "stdlib"
    },
    "gzip.compress": {
        "API_name": "gzip.compress",
        "loc_name": "gzip.compress",
        "args": "data;compresslevel",
        "args_default": 1,
        "filepath": "gzip",
        "lineno": 542,
        "namespace": "*",
        "body": "def compress(data, compresslevel=_COMPRESS_LEVEL_BEST, *, mtime=None):\n    \"\"\"Compress data in one shot and return the compressed string.\n    Optional argument is the compression level, in range of 0-9.\n    \"\"\"\n    buf = io.BytesIO()\n    with GzipFile(fileobj=buf, mode='wb', compresslevel=compresslevel, mtime=mtime) as f:\n        f.write(data)\n    return buf.getvalue()",
        "name_type": "stdlib"
    },
    "gzip.decompress": {
        "API_name": "gzip.decompress",
        "loc_name": "gzip.decompress",
        "args": "data",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 551,
        "namespace": "*",
        "body": "def decompress(data):\n    \"\"\"Decompress a gzip compressed string in one shot.\n    Return the decompressed string.\n    \"\"\"\n    with GzipFile(fileobj=io.BytesIO(data)) as f:\n        return f.read()",
        "name_type": "stdlib"
    },
    "gzip.main": {
        "API_name": "gzip.main",
        "loc_name": "gzip.main",
        "args": "",
        "args_default": 0,
        "filepath": "gzip",
        "lineno": 559,
        "namespace": "*",
        "body": "def main():\n    from argparse import ArgumentParser\n    parser = ArgumentParser(description=\n        \"A simple command line interface for the gzip module: act like gzip, \"\n        \"but do not delete the input file.\")\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--fast', action='store_true', help='compress faster')\n    group.add_argument('--best', action='store_true', help='compress better')\n    group.add_argument(\"-d\", \"--decompress\", action=\"store_true\",\n                        help=\"act like gunzip instead of gzip\")\n\n    parser.add_argument(\"args\", nargs=\"*\", default=[\"-\"], metavar='file')\n    args = parser.parse_args()\n\n    compresslevel = _COMPRESS_LEVEL_TRADEOFF\n    if args.fast:\n        compresslevel = _COMPRESS_LEVEL_FAST\n    elif args.best:\n        compresslevel = _COMPRESS_LEVEL_BEST\n\n    for arg in args.args:\n        if args.decompress:\n            if arg == \"-\":\n                f = GzipFile(filename=\"\", mode=\"rb\", fileobj=sys.stdin.buffer)\n                g = sys.stdout.buffer\n            else:\n                if arg[-3:] != \".gz\":\n                    sys.exit(f\"filename doesn't end in .gz: {arg!r}\")\n                f = open(arg, \"rb\")\n                g = builtins.open(arg[:-3], \"wb\")\n        else:\n            if arg == \"-\":\n                f = sys.stdin.buffer\n                g = GzipFile(filename=\"\", mode=\"wb\", fileobj=sys.stdout.buffer,\n                             compresslevel=compresslevel)\n            else:\n                f = builtins.open(arg, \"rb\")\n                g = open(arg + \".gz\", \"wb\")\n        while True:\n            chunk = f.read(1024)\n            if not chunk:\n                break\n            g.write(chunk)\n        if g is not sys.stdout.buffer:\n            g.close()\n        if f is not sys.stdin.buffer:\n            f.close()",
        "name_type": "stdlib"
    },
    "io": {
        "API_name": "io",
        "loc_name": "io",
        "args": "*",
        "args_default": "*",
        "filepath": "io",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"The io module provides the Python interfaces to stream handling. The\nbuiltin open function is defined in this module.\n\nAt the top of the I/O hierarchy is the abstract base class IOBase. It\ndefines the basic interface to a stream. Note, however, that there is no\nseparation between reading and writing to streams; implementations are\nallowed to raise an OSError if they do not support a given operation.\n\nExtending IOBase is RawIOBase which deals simply with the reading and\nwriting of raw bytes to a stream. FileIO subclasses RawIOBase to provide\nan interface to OS files.\n\nBufferedIOBase deals with buffering on a raw byte stream (RawIOBase). Its\nsubclasses, BufferedWriter, BufferedReader, and BufferedRWPair buffer\nstreams that are readable, writable, and both respectively.\nBufferedRandom provides a buffered interface to random access\nstreams. BytesIO is a simple stream of in-memory bytes.\n\nAnother IOBase subclass, TextIOBase, deals with the encoding and decoding\nof streams into text. TextIOWrapper, which extends it, is a buffered text\ninterface to a buffered raw stream (`BufferedIOBase`). Finally, StringIO\nis an in-memory stream for text.\n\nArgument names are not part of the specification, and only the arguments\nof open() are intended to be used as keyword arguments.\n\ndata:\n\nDEFAULT_BUFFER_SIZE\n\n   An int containing the default buffer size used by the module's buffered\n   I/O classes. open() uses the file's blksize (as obtained by os.stat) if\n   possible.\n\"\"\"\n__author__ = (\"Guido van Rossum <guido@python.org>, \"\n              \"Mike Verdone <mike.verdone@gmail.com>, \"\n              \"Mark Russell <mark.russell@zen.co.uk>, \"\n              \"Antoine Pitrou <solipsis@pitrou.net>, \"\n              \"Amaury Forgeot d'Arc <amauryfa@gmail.com>, \"\n              \"Benjamin Peterson <benjamin@python.org>\")\n__all__ = [\"BlockingIOError\", \"open\", \"open_code\", \"IOBase\", \"RawIOBase\",\n           \"FileIO\", \"BytesIO\", \"StringIO\", \"BufferedIOBase\",\n           \"BufferedReader\", \"BufferedWriter\", \"BufferedRWPair\",\n           \"BufferedRandom\", \"TextIOBase\", \"TextIOWrapper\",\n           \"UnsupportedOperation\", \"SEEK_SET\", \"SEEK_CUR\", \"SEEK_END\"]\nOpenWrapper = _io.open # for compatibility with _pyio\nUnsupportedOperation.__module__ = \"io\"\nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\nRawIOBase.register(FileIO)\nfor klass in (BytesIO, BufferedReader, BufferedWriter, BufferedRandom,\n              BufferedRWPair):\n    BufferedIOBase.register(klass)\nfor klass in (StringIO, TextIOWrapper):\n    TextIOBase.register(klass)\ndel klass\ntry:\n    from _io import _WindowsConsoleIO\nexcept ImportError:\n    pass\nelse:\n    RawIOBase.register(_WindowsConsoleIO)",
        "name_type": "stdlib"
    },
    "io.IOBase": {
        "API_name": "io.IOBase",
        "loc_name": "io.IOBase",
        "args": "*",
        "args_default": "*",
        "filepath": "io",
        "lineno": 72,
        "namespace": "IOBase",
        "body": "",
        "name_type": "stdlib"
    },
    "io.RawIOBase": {
        "API_name": "io.RawIOBase",
        "loc_name": "io.RawIOBase",
        "args": "*",
        "args_default": "*",
        "filepath": "io",
        "lineno": 75,
        "namespace": "RawIOBase",
        "body": "",
        "name_type": "stdlib"
    },
    "io.BufferedIOBase": {
        "API_name": "io.BufferedIOBase",
        "loc_name": "io.BufferedIOBase",
        "args": "*",
        "args_default": "*",
        "filepath": "io",
        "lineno": 78,
        "namespace": "BufferedIOBase",
        "body": "",
        "name_type": "stdlib"
    },
    "io.TextIOBase": {
        "API_name": "io.TextIOBase",
        "loc_name": "io.TextIOBase",
        "args": "*",
        "args_default": "*",
        "filepath": "io",
        "lineno": 81,
        "namespace": "TextIOBase",
        "body": "",
        "name_type": "stdlib"
    },
    "locale": {
        "API_name": "locale",
        "loc_name": "locale",
        "args": "*",
        "args_default": "*",
        "filepath": "locale",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Locale support module.\n\nThe module provides low-level access to the C lib's locale APIs and adds high\nlevel number formatting APIs as well as a locale aliasing engine to complement\nthese.\n\nThe aliasing engine includes support for many commonly used locale names and\nmaps them to values suitable for passing to the C lib's setlocale() function. It\nalso includes default encodings for all supported locale names.\n\n\"\"\"\n__all__ = [\"getlocale\", \"getdefaultlocale\", \"getpreferredencoding\", \"Error\",\n           \"setlocale\", \"resetlocale\", \"localeconv\", \"strcoll\", \"strxfrm\",\n           \"str\", \"atof\", \"atoi\", \"format\", \"format_string\", \"currency\",\n           \"normalize\", \"LC_CTYPE\", \"LC_COLLATE\", \"LC_TIME\", \"LC_MONETARY\",\n           \"LC_NUMERIC\", \"LC_ALL\", \"CHAR_MAX\"]\ntry:\n\n    from _locale import *\n\nexcept ImportError:\n\n    # Locale emulation\n\n    CHAR_MAX = 127\n    LC_ALL = 6\n    LC_COLLATE = 3\n    LC_CTYPE = 0\n    LC_MESSAGES = 5\n    LC_MONETARY = 4\n    LC_NUMERIC = 1\n    LC_TIME = 2\n    Error = ValueError\n\n    def localeconv():\n        \"\"\" localeconv() -> dict.\n            Returns numeric and monetary locale-specific parameters.\n        \"\"\"\n        # 'C' locale default values\n        return {'grouping': [127],\n                'currency_symbol': '',\n                'n_sign_posn': 127,\n                'p_cs_precedes': 127,\n                'n_cs_precedes': 127,\n                'mon_grouping': [],\n                'n_sep_by_space': 127,\n                'decimal_point': '.',\n                'negative_sign': '',\n                'positive_sign': '',\n                'p_sep_by_space': 127,\n                'int_curr_symbol': '',\n                'p_sign_posn': 127,\n                'thousands_sep': '',\n                'mon_thousands_sep': '',\n                'frac_digits': 127,\n                'mon_decimal_point': '',\n                'int_frac_digits': 127}\n\n    def setlocale(category, value=None):\n        \"\"\" setlocale(integer,string=None) -> string.\n            Activates/queries locale processing.\n        \"\"\"\n        if value not in (None, '', 'C'):\n            raise Error('_locale emulation only supports \"C\" locale')\n        return 'C'\nif 'strxfrm' not in globals():\n    strxfrm = _strxfrm\nif 'strcoll' not in globals():\n    strcoll = _strcoll\n_localeconv = localeconv\n_override_localeconv = {}\n_percent_re = re.compile(r'%(?:\\((?P<key>.*?)\\))?'\n                         r'(?P<modifiers>[-#0-9 +*.hlL]*?)[eEfFgGdiouxXcrs%]')\n_setlocale = setlocale\nif sys.platform.startswith(\"win\"):\n    # On Win32, this will return the ANSI code page\n    def getpreferredencoding(do_setlocale = True):\n        \"\"\"Return the charset that the user is likely using.\"\"\"\n        if sys.flags.utf8_mode:\n            return 'UTF-8'\n        import _bootlocale\n        return _bootlocale.getpreferredencoding(False)\nelse:\n    # On Unix, if CODESET is available, use that.\n    try:\n        CODESET\n    except NameError:\n        if hasattr(sys, 'getandroidapilevel'):\n            # On Android langinfo.h and CODESET are missing, and UTF-8 is\n            # always used in mbstowcs() and wcstombs().\n            def getpreferredencoding(do_setlocale = True):\n                return 'UTF-8'\n        else:\n            # Fall back to parsing environment variables :-(\n            def getpreferredencoding(do_setlocale = True):\n                \"\"\"Return the charset that the user is likely using,\n                by looking at environment variables.\"\"\"\n                if sys.flags.utf8_mode:\n                    return 'UTF-8'\n                res = getdefaultlocale()[1]\n                if res is None:\n                    # LANG not set, default conservatively to ASCII\n                    res = 'ascii'\n                return res\n    else:\n        def getpreferredencoding(do_setlocale = True):\n            \"\"\"Return the charset that the user is likely using,\n            according to the system configuration.\"\"\"\n            if sys.flags.utf8_mode:\n                return 'UTF-8'\n            import _bootlocale\n            if do_setlocale:\n                oldloc = setlocale(LC_CTYPE)\n                try:\n                    setlocale(LC_CTYPE, \"\")\n                except Error:\n                    pass\n            result = _bootlocale.getpreferredencoding(False)\n            if do_setlocale:\n                setlocale(LC_CTYPE, oldloc)\n            return result\nlocale_encoding_alias = {\n\n    # Mappings for non-standard encoding names used in locale names\n    '437':                          'C',\n    'c':                            'C',\n    'en':                           'ISO8859-1',\n    'jis':                          'JIS7',\n    'jis7':                         'JIS7',\n    'ajec':                         'eucJP',\n    'koi8c':                        'KOI8-C',\n    'microsoftcp1251':              'CP1251',\n    'microsoftcp1255':              'CP1255',\n    'microsoftcp1256':              'CP1256',\n    '88591':                        'ISO8859-1',\n    '88592':                        'ISO8859-2',\n    '88595':                        'ISO8859-5',\n    '885915':                       'ISO8859-15',\n\n    # Mappings from Python codec names to C lib encoding names\n    'ascii':                        'ISO8859-1',\n    'latin_1':                      'ISO8859-1',\n    'iso8859_1':                    'ISO8859-1',\n    'iso8859_10':                   'ISO8859-10',\n    'iso8859_11':                   'ISO8859-11',\n    'iso8859_13':                   'ISO8859-13',\n    'iso8859_14':                   'ISO8859-14',\n    'iso8859_15':                   'ISO8859-15',\n    'iso8859_16':                   'ISO8859-16',\n    'iso8859_2':                    'ISO8859-2',\n    'iso8859_3':                    'ISO8859-3',\n    'iso8859_4':                    'ISO8859-4',\n    'iso8859_5':                    'ISO8859-5',\n    'iso8859_6':                    'ISO8859-6',\n    'iso8859_7':                    'ISO8859-7',\n    'iso8859_8':                    'ISO8859-8',\n    'iso8859_9':                    'ISO8859-9',\n    'iso2022_jp':                   'JIS7',\n    'shift_jis':                    'SJIS',\n    'tactis':                       'TACTIS',\n    'euc_jp':                       'eucJP',\n    'euc_kr':                       'eucKR',\n    'utf_8':                        'UTF-8',\n    'koi8_r':                       'KOI8-R',\n    'koi8_t':                       'KOI8-T',\n    'koi8_u':                       'KOI8-U',\n    'kz1048':                       'RK1048',\n    'cp1251':                       'CP1251',\n    'cp1255':                       'CP1255',\n    'cp1256':                       'CP1256',\n\n    # XXX This list is still incomplete. If you know more\n    # mappings, please file a bug report. Thanks.\n}\nfor k, v in sorted(locale_encoding_alias.items()):\n    k = k.replace('_', '')\n    locale_encoding_alias.setdefault(k, v)\nlocale_alias = {\n    'a3':                                   'az_AZ.KOI8-C',\n    'a3_az':                                'az_AZ.KOI8-C',\n    'a3_az.koic':                           'az_AZ.KOI8-C',\n    'aa_dj':                                'aa_DJ.ISO8859-1',\n    'aa_er':                                'aa_ER.UTF-8',\n    'aa_et':                                'aa_ET.UTF-8',\n    'af':                                   'af_ZA.ISO8859-1',\n    'af_za':                                'af_ZA.ISO8859-1',\n    'agr_pe':                               'agr_PE.UTF-8',\n    'ak_gh':                                'ak_GH.UTF-8',\n    'am':                                   'am_ET.UTF-8',\n    'am_et':                                'am_ET.UTF-8',\n    'american':                             'en_US.ISO8859-1',\n    'an_es':                                'an_ES.ISO8859-15',\n    'anp_in':                               'anp_IN.UTF-8',\n    'ar':                                   'ar_AA.ISO8859-6',\n    'ar_aa':                                'ar_AA.ISO8859-6',\n    'ar_ae':                                'ar_AE.ISO8859-6',\n    'ar_bh':                                'ar_BH.ISO8859-6',\n    'ar_dz':                                'ar_DZ.ISO8859-6',\n    'ar_eg':                                'ar_EG.ISO8859-6',\n    'ar_in':                                'ar_IN.UTF-8',\n    'ar_iq':                                'ar_IQ.ISO8859-6',\n    'ar_jo':                                'ar_JO.ISO8859-6',\n    'ar_kw':                                'ar_KW.ISO8859-6',\n    'ar_lb':                                'ar_LB.ISO8859-6',\n    'ar_ly':                                'ar_LY.ISO8859-6',\n    'ar_ma':                                'ar_MA.ISO8859-6',\n    'ar_om':                                'ar_OM.ISO8859-6',\n    'ar_qa':                                'ar_QA.ISO8859-6',\n    'ar_sa':                                'ar_SA.ISO8859-6',\n    'ar_sd':                                'ar_SD.ISO8859-6',\n    'ar_ss':                                'ar_SS.UTF-8',\n    'ar_sy':                                'ar_SY.ISO8859-6',\n    'ar_tn':                                'ar_TN.ISO8859-6',\n    'ar_ye':                                'ar_YE.ISO8859-6',\n    'arabic':                               'ar_AA.ISO8859-6',\n    'as':                                   'as_IN.UTF-8',\n    'as_in':                                'as_IN.UTF-8',\n    'ast_es':                               'ast_ES.ISO8859-15',\n    'ayc_pe':                               'ayc_PE.UTF-8',\n    'az':                                   'az_AZ.ISO8859-9E',\n    'az_az':                                'az_AZ.ISO8859-9E',\n    'az_az.iso88599e':                      'az_AZ.ISO8859-9E',\n    'az_ir':                                'az_IR.UTF-8',\n    'be':                                   'be_BY.CP1251',\n    'be@latin':                             'be_BY.UTF-8@latin',\n    'be_bg.utf8':                           'bg_BG.UTF-8',\n    'be_by':                                'be_BY.CP1251',\n    'be_by@latin':                          'be_BY.UTF-8@latin',\n    'bem_zm':                               'bem_ZM.UTF-8',\n    'ber_dz':                               'ber_DZ.UTF-8',\n    'ber_ma':                               'ber_MA.UTF-8',\n    'bg':                                   'bg_BG.CP1251',\n    'bg_bg':                                'bg_BG.CP1251',\n    'bhb_in.utf8':                          'bhb_IN.UTF-8',\n    'bho_in':                               'bho_IN.UTF-8',\n    'bho_np':                               'bho_NP.UTF-8',\n    'bi_vu':                                'bi_VU.UTF-8',\n    'bn_bd':                                'bn_BD.UTF-8',\n    'bn_in':                                'bn_IN.UTF-8',\n    'bo_cn':                                'bo_CN.UTF-8',\n    'bo_in':                                'bo_IN.UTF-8',\n    'bokmal':                               'nb_NO.ISO8859-1',\n    'bokm\\xe5l':                            'nb_NO.ISO8859-1',\n    'br':                                   'br_FR.ISO8859-1',\n    'br_fr':                                'br_FR.ISO8859-1',\n    'brx_in':                               'brx_IN.UTF-8',\n    'bs':                                   'bs_BA.ISO8859-2',\n    'bs_ba':                                'bs_BA.ISO8859-2',\n    'bulgarian':                            'bg_BG.CP1251',\n    'byn_er':                               'byn_ER.UTF-8',\n    'c':                                    'C',\n    'c-french':                             'fr_CA.ISO8859-1',\n    'c.ascii':                              'C',\n    'c.en':                                 'C',\n    'c.iso88591':                           'en_US.ISO8859-1',\n    'c.utf8':                               'en_US.UTF-8',\n    'c_c':                                  'C',\n    'c_c.c':                                'C',\n    'ca':                                   'ca_ES.ISO8859-1',\n    'ca_ad':                                'ca_AD.ISO8859-1',\n    'ca_es':                                'ca_ES.ISO8859-1',\n    'ca_es@valencia':                       'ca_ES.UTF-8@valencia',\n    'ca_fr':                                'ca_FR.ISO8859-1',\n    'ca_it':                                'ca_IT.ISO8859-1',\n    'catalan':                              'ca_ES.ISO8859-1',\n    'ce_ru':                                'ce_RU.UTF-8',\n    'cextend':                              'en_US.ISO8859-1',\n    'chinese-s':                            'zh_CN.eucCN',\n    'chinese-t':                            'zh_TW.eucTW',\n    'chr_us':                               'chr_US.UTF-8',\n    'ckb_iq':                               'ckb_IQ.UTF-8',\n    'cmn_tw':                               'cmn_TW.UTF-8',\n    'crh_ua':                               'crh_UA.UTF-8',\n    'croatian':                             'hr_HR.ISO8859-2',\n    'cs':                                   'cs_CZ.ISO8859-2',\n    'cs_cs':                                'cs_CZ.ISO8859-2',\n    'cs_cz':                                'cs_CZ.ISO8859-2',\n    'csb_pl':                               'csb_PL.UTF-8',\n    'cv_ru':                                'cv_RU.UTF-8',\n    'cy':                                   'cy_GB.ISO8859-1',\n    'cy_gb':                                'cy_GB.ISO8859-1',\n    'cz':                                   'cs_CZ.ISO8859-2',\n    'cz_cz':                                'cs_CZ.ISO8859-2',\n    'czech':                                'cs_CZ.ISO8859-2',\n    'da':                                   'da_DK.ISO8859-1',\n    'da_dk':                                'da_DK.ISO8859-1',\n    'danish':                               'da_DK.ISO8859-1',\n    'dansk':                                'da_DK.ISO8859-1',\n    'de':                                   'de_DE.ISO8859-1',\n    'de_at':                                'de_AT.ISO8859-1',\n    'de_be':                                'de_BE.ISO8859-1',\n    'de_ch':                                'de_CH.ISO8859-1',\n    'de_de':                                'de_DE.ISO8859-1',\n    'de_it':                                'de_IT.ISO8859-1',\n    'de_li.utf8':                           'de_LI.UTF-8',\n    'de_lu':                                'de_LU.ISO8859-1',\n    'deutsch':                              'de_DE.ISO8859-1',\n    'doi_in':                               'doi_IN.UTF-8',\n    'dutch':                                'nl_NL.ISO8859-1',\n    'dutch.iso88591':                       'nl_BE.ISO8859-1',\n    'dv_mv':                                'dv_MV.UTF-8',\n    'dz_bt':                                'dz_BT.UTF-8',\n    'ee':                                   'ee_EE.ISO8859-4',\n    'ee_ee':                                'ee_EE.ISO8859-4',\n    'eesti':                                'et_EE.ISO8859-1',\n    'el':                                   'el_GR.ISO8859-7',\n    'el_cy':                                'el_CY.ISO8859-7',\n    'el_gr':                                'el_GR.ISO8859-7',\n    'el_gr@euro':                           'el_GR.ISO8859-15',\n    'en':                                   'en_US.ISO8859-1',\n    'en_ag':                                'en_AG.UTF-8',\n    'en_au':                                'en_AU.ISO8859-1',\n    'en_be':                                'en_BE.ISO8859-1',\n    'en_bw':                                'en_BW.ISO8859-1',\n    'en_ca':                                'en_CA.ISO8859-1',\n    'en_dk':                                'en_DK.ISO8859-1',\n    'en_dl.utf8':                           'en_DL.UTF-8',\n    'en_gb':                                'en_GB.ISO8859-1',\n    'en_hk':                                'en_HK.ISO8859-1',\n    'en_ie':                                'en_IE.ISO8859-1',\n    'en_il':                                'en_IL.UTF-8',\n    'en_in':                                'en_IN.ISO8859-1',\n    'en_ng':                                'en_NG.UTF-8',\n    'en_nz':                                'en_NZ.ISO8859-1',\n    'en_ph':                                'en_PH.ISO8859-1',\n    'en_sc.utf8':                           'en_SC.UTF-8',\n    'en_sg':                                'en_SG.ISO8859-1',\n    'en_uk':                                'en_GB.ISO8859-1',\n    'en_us':                                'en_US.ISO8859-1',\n    'en_us@euro@euro':                      'en_US.ISO8859-15',\n    'en_za':                                'en_ZA.ISO8859-1',\n    'en_zm':                                'en_ZM.UTF-8',\n    'en_zw':                                'en_ZW.ISO8859-1',\n    'en_zw.utf8':                           'en_ZS.UTF-8',\n    'eng_gb':                               'en_GB.ISO8859-1',\n    'english':                              'en_EN.ISO8859-1',\n    'english.iso88591':                     'en_US.ISO8859-1',\n    'english_uk':                           'en_GB.ISO8859-1',\n    'english_united-states':                'en_US.ISO8859-1',\n    'english_united-states.437':            'C',\n    'english_us':                           'en_US.ISO8859-1',\n    'eo':                                   'eo_XX.ISO8859-3',\n    'eo.utf8':                              'eo.UTF-8',\n    'eo_eo':                                'eo_EO.ISO8859-3',\n    'eo_us.utf8':                           'eo_US.UTF-8',\n    'eo_xx':                                'eo_XX.ISO8859-3',\n    'es':                                   'es_ES.ISO8859-1',\n    'es_ar':                                'es_AR.ISO8859-1',\n    'es_bo':                                'es_BO.ISO8859-1',\n    'es_cl':                                'es_CL.ISO8859-1',\n    'es_co':                                'es_CO.ISO8859-1',\n    'es_cr':                                'es_CR.ISO8859-1',\n    'es_cu':                                'es_CU.UTF-8',\n    'es_do':                                'es_DO.ISO8859-1',\n    'es_ec':                                'es_EC.ISO8859-1',\n    'es_es':                                'es_ES.ISO8859-1',\n    'es_gt':                                'es_GT.ISO8859-1',\n    'es_hn':                                'es_HN.ISO8859-1',\n    'es_mx':                                'es_MX.ISO8859-1',\n    'es_ni':                                'es_NI.ISO8859-1',\n    'es_pa':                                'es_PA.ISO8859-1',\n    'es_pe':                                'es_PE.ISO8859-1',\n    'es_pr':                                'es_PR.ISO8859-1',\n    'es_py':                                'es_PY.ISO8859-1',\n    'es_sv':                                'es_SV.ISO8859-1',\n    'es_us':                                'es_US.ISO8859-1',\n    'es_uy':                                'es_UY.ISO8859-1',\n    'es_ve':                                'es_VE.ISO8859-1',\n    'estonian':                             'et_EE.ISO8859-1',\n    'et':                                   'et_EE.ISO8859-15',\n    'et_ee':                                'et_EE.ISO8859-15',\n    'eu':                                   'eu_ES.ISO8859-1',\n    'eu_es':                                'eu_ES.ISO8859-1',\n    'eu_fr':                                'eu_FR.ISO8859-1',\n    'fa':                                   'fa_IR.UTF-8',\n    'fa_ir':                                'fa_IR.UTF-8',\n    'fa_ir.isiri3342':                      'fa_IR.ISIRI-3342',\n    'ff_sn':                                'ff_SN.UTF-8',\n    'fi':                                   'fi_FI.ISO8859-15',\n    'fi_fi':                                'fi_FI.ISO8859-15',\n    'fil_ph':                               'fil_PH.UTF-8',\n    'finnish':                              'fi_FI.ISO8859-1',\n    'fo':                                   'fo_FO.ISO8859-1',\n    'fo_fo':                                'fo_FO.ISO8859-1',\n    'fr':                                   'fr_FR.ISO8859-1',\n    'fr_be':                                'fr_BE.ISO8859-1',\n    'fr_ca':                                'fr_CA.ISO8859-1',\n    'fr_ch':                                'fr_CH.ISO8859-1',\n    'fr_fr':                                'fr_FR.ISO8859-1',\n    'fr_lu':                                'fr_LU.ISO8859-1',\n    'fran\\xe7ais':                          'fr_FR.ISO8859-1',\n    'fre_fr':                               'fr_FR.ISO8859-1',\n    'french':                               'fr_FR.ISO8859-1',\n    'french.iso88591':                      'fr_CH.ISO8859-1',\n    'french_france':                        'fr_FR.ISO8859-1',\n    'fur_it':                               'fur_IT.UTF-8',\n    'fy_de':                                'fy_DE.UTF-8',\n    'fy_nl':                                'fy_NL.UTF-8',\n    'ga':                                   'ga_IE.ISO8859-1',\n    'ga_ie':                                'ga_IE.ISO8859-1',\n    'galego':                               'gl_ES.ISO8859-1',\n    'galician':                             'gl_ES.ISO8859-1',\n    'gd':                                   'gd_GB.ISO8859-1',\n    'gd_gb':                                'gd_GB.ISO8859-1',\n    'ger_de':                               'de_DE.ISO8859-1',\n    'german':                               'de_DE.ISO8859-1',\n    'german.iso88591':                      'de_CH.ISO8859-1',\n    'german_germany':                       'de_DE.ISO8859-1',\n    'gez_er':                               'gez_ER.UTF-8',\n    'gez_et':                               'gez_ET.UTF-8',\n    'gl':                                   'gl_ES.ISO8859-1',\n    'gl_es':                                'gl_ES.ISO8859-1',\n    'greek':                                'el_GR.ISO8859-7',\n    'gu_in':                                'gu_IN.UTF-8',\n    'gv':                                   'gv_GB.ISO8859-1',\n    'gv_gb':                                'gv_GB.ISO8859-1',\n    'ha_ng':                                'ha_NG.UTF-8',\n    'hak_tw':                               'hak_TW.UTF-8',\n    'he':                                   'he_IL.ISO8859-8',\n    'he_il':                                'he_IL.ISO8859-8',\n    'hebrew':                               'he_IL.ISO8859-8',\n    'hi':                                   'hi_IN.ISCII-DEV',\n    'hi_in':                                'hi_IN.ISCII-DEV',\n    'hi_in.isciidev':                       'hi_IN.ISCII-DEV',\n    'hif_fj':                               'hif_FJ.UTF-8',\n    'hne':                                  'hne_IN.UTF-8',\n    'hne_in':                               'hne_IN.UTF-8',\n    'hr':                                   'hr_HR.ISO8859-2',\n    'hr_hr':                                'hr_HR.ISO8859-2',\n    'hrvatski':                             'hr_HR.ISO8859-2',\n    'hsb_de':                               'hsb_DE.ISO8859-2',\n    'ht_ht':                                'ht_HT.UTF-8',\n    'hu':                                   'hu_HU.ISO8859-2',\n    'hu_hu':                                'hu_HU.ISO8859-2',\n    'hungarian':                            'hu_HU.ISO8859-2',\n    'hy_am':                                'hy_AM.UTF-8',\n    'hy_am.armscii8':                       'hy_AM.ARMSCII_8',\n    'ia':                                   'ia.UTF-8',\n    'ia_fr':                                'ia_FR.UTF-8',\n    'icelandic':                            'is_IS.ISO8859-1',\n    'id':                                   'id_ID.ISO8859-1',\n    'id_id':                                'id_ID.ISO8859-1',\n    'ig_ng':                                'ig_NG.UTF-8',\n    'ik_ca':                                'ik_CA.UTF-8',\n    'in':                                   'id_ID.ISO8859-1',\n    'in_id':                                'id_ID.ISO8859-1',\n    'is':                                   'is_IS.ISO8859-1',\n    'is_is':                                'is_IS.ISO8859-1',\n    'iso-8859-1':                           'en_US.ISO8859-1',\n    'iso-8859-15':                          'en_US.ISO8859-15',\n    'iso8859-1':                            'en_US.ISO8859-1',\n    'iso8859-15':                           'en_US.ISO8859-15',\n    'iso_8859_1':                           'en_US.ISO8859-1',\n    'iso_8859_15':                          'en_US.ISO8859-15',\n    'it':                                   'it_IT.ISO8859-1',\n    'it_ch':                                'it_CH.ISO8859-1',\n    'it_it':                                'it_IT.ISO8859-1',\n    'italian':                              'it_IT.ISO8859-1',\n    'iu':                                   'iu_CA.NUNACOM-8',\n    'iu_ca':                                'iu_CA.NUNACOM-8',\n    'iu_ca.nunacom8':                       'iu_CA.NUNACOM-8',\n    'iw':                                   'he_IL.ISO8859-8',\n    'iw_il':                                'he_IL.ISO8859-8',\n    'iw_il.utf8':                           'iw_IL.UTF-8',\n    'ja':                                   'ja_JP.eucJP',\n    'ja_jp':                                'ja_JP.eucJP',\n    'ja_jp.euc':                            'ja_JP.eucJP',\n    'ja_jp.mscode':                         'ja_JP.SJIS',\n    'ja_jp.pck':                            'ja_JP.SJIS',\n    'japan':                                'ja_JP.eucJP',\n    'japanese':                             'ja_JP.eucJP',\n    'japanese-euc':                         'ja_JP.eucJP',\n    'japanese.euc':                         'ja_JP.eucJP',\n    'jp_jp':                                'ja_JP.eucJP',\n    'ka':                                   'ka_GE.GEORGIAN-ACADEMY',\n    'ka_ge':                                'ka_GE.GEORGIAN-ACADEMY',\n    'ka_ge.georgianacademy':                'ka_GE.GEORGIAN-ACADEMY',\n    'ka_ge.georgianps':                     'ka_GE.GEORGIAN-PS',\n    'ka_ge.georgianrs':                     'ka_GE.GEORGIAN-ACADEMY',\n    'kab_dz':                               'kab_DZ.UTF-8',\n    'kk_kz':                                'kk_KZ.ptcp154',\n    'kl':                                   'kl_GL.ISO8859-1',\n    'kl_gl':                                'kl_GL.ISO8859-1',\n    'km_kh':                                'km_KH.UTF-8',\n    'kn':                                   'kn_IN.UTF-8',\n    'kn_in':                                'kn_IN.UTF-8',\n    'ko':                                   'ko_KR.eucKR',\n    'ko_kr':                                'ko_KR.eucKR',\n    'ko_kr.euc':                            'ko_KR.eucKR',\n    'kok_in':                               'kok_IN.UTF-8',\n    'korean':                               'ko_KR.eucKR',\n    'korean.euc':                           'ko_KR.eucKR',\n    'ks':                                   'ks_IN.UTF-8',\n    'ks_in':                                'ks_IN.UTF-8',\n    'ks_in@devanagari.utf8':                'ks_IN.UTF-8@devanagari',\n    'ku_tr':                                'ku_TR.ISO8859-9',\n    'kw':                                   'kw_GB.ISO8859-1',\n    'kw_gb':                                'kw_GB.ISO8859-1',\n    'ky':                                   'ky_KG.UTF-8',\n    'ky_kg':                                'ky_KG.UTF-8',\n    'lb_lu':                                'lb_LU.UTF-8',\n    'lg_ug':                                'lg_UG.ISO8859-10',\n    'li_be':                                'li_BE.UTF-8',\n    'li_nl':                                'li_NL.UTF-8',\n    'lij_it':                               'lij_IT.UTF-8',\n    'lithuanian':                           'lt_LT.ISO8859-13',\n    'ln_cd':                                'ln_CD.UTF-8',\n    'lo':                                   'lo_LA.MULELAO-1',\n    'lo_la':                                'lo_LA.MULELAO-1',\n    'lo_la.cp1133':                         'lo_LA.IBM-CP1133',\n    'lo_la.ibmcp1133':                      'lo_LA.IBM-CP1133',\n    'lo_la.mulelao1':                       'lo_LA.MULELAO-1',\n    'lt':                                   'lt_LT.ISO8859-13',\n    'lt_lt':                                'lt_LT.ISO8859-13',\n    'lv':                                   'lv_LV.ISO8859-13',\n    'lv_lv':                                'lv_LV.ISO8859-13',\n    'lzh_tw':                               'lzh_TW.UTF-8',\n    'mag_in':                               'mag_IN.UTF-8',\n    'mai':                                  'mai_IN.UTF-8',\n    'mai_in':                               'mai_IN.UTF-8',\n    'mai_np':                               'mai_NP.UTF-8',\n    'mfe_mu':                               'mfe_MU.UTF-8',\n    'mg_mg':                                'mg_MG.ISO8859-15',\n    'mhr_ru':                               'mhr_RU.UTF-8',\n    'mi':                                   'mi_NZ.ISO8859-1',\n    'mi_nz':                                'mi_NZ.ISO8859-1',\n    'miq_ni':                               'miq_NI.UTF-8',\n    'mjw_in':                               'mjw_IN.UTF-8',\n    'mk':                                   'mk_MK.ISO8859-5',\n    'mk_mk':                                'mk_MK.ISO8859-5',\n    'ml':                                   'ml_IN.UTF-8',\n    'ml_in':                                'ml_IN.UTF-8',\n    'mn_mn':                                'mn_MN.UTF-8',\n    'mni_in':                               'mni_IN.UTF-8',\n    'mr':                                   'mr_IN.UTF-8',\n    'mr_in':                                'mr_IN.UTF-8',\n    'ms':                                   'ms_MY.ISO8859-1',\n    'ms_my':                                'ms_MY.ISO8859-1',\n    'mt':                                   'mt_MT.ISO8859-3',\n    'mt_mt':                                'mt_MT.ISO8859-3',\n    'my_mm':                                'my_MM.UTF-8',\n    'nan_tw':                               'nan_TW.UTF-8',\n    'nb':                                   'nb_NO.ISO8859-1',\n    'nb_no':                                'nb_NO.ISO8859-1',\n    'nds_de':                               'nds_DE.UTF-8',\n    'nds_nl':                               'nds_NL.UTF-8',\n    'ne_np':                                'ne_NP.UTF-8',\n    'nhn_mx':                               'nhn_MX.UTF-8',\n    'niu_nu':                               'niu_NU.UTF-8',\n    'niu_nz':                               'niu_NZ.UTF-8',\n    'nl':                                   'nl_NL.ISO8859-1',\n    'nl_aw':                                'nl_AW.UTF-8',\n    'nl_be':                                'nl_BE.ISO8859-1',\n    'nl_nl':                                'nl_NL.ISO8859-1',\n    'nn':                                   'nn_NO.ISO8859-1',\n    'nn_no':                                'nn_NO.ISO8859-1',\n    'no':                                   'no_NO.ISO8859-1',\n    'no@nynorsk':                           'ny_NO.ISO8859-1',\n    'no_no':                                'no_NO.ISO8859-1',\n    'no_no.iso88591@bokmal':                'no_NO.ISO8859-1',\n    'no_no.iso88591@nynorsk':               'no_NO.ISO8859-1',\n    'norwegian':                            'no_NO.ISO8859-1',\n    'nr':                                   'nr_ZA.ISO8859-1',\n    'nr_za':                                'nr_ZA.ISO8859-1',\n    'nso':                                  'nso_ZA.ISO8859-15',\n    'nso_za':                               'nso_ZA.ISO8859-15',\n    'ny':                                   'ny_NO.ISO8859-1',\n    'ny_no':                                'ny_NO.ISO8859-1',\n    'nynorsk':                              'nn_NO.ISO8859-1',\n    'oc':                                   'oc_FR.ISO8859-1',\n    'oc_fr':                                'oc_FR.ISO8859-1',\n    'om_et':                                'om_ET.UTF-8',\n    'om_ke':                                'om_KE.ISO8859-1',\n    'or':                                   'or_IN.UTF-8',\n    'or_in':                                'or_IN.UTF-8',\n    'os_ru':                                'os_RU.UTF-8',\n    'pa':                                   'pa_IN.UTF-8',\n    'pa_in':                                'pa_IN.UTF-8',\n    'pa_pk':                                'pa_PK.UTF-8',\n    'pap_an':                               'pap_AN.UTF-8',\n    'pap_aw':                               'pap_AW.UTF-8',\n    'pap_cw':                               'pap_CW.UTF-8',\n    'pd':                                   'pd_US.ISO8859-1',\n    'pd_de':                                'pd_DE.ISO8859-1',\n    'pd_us':                                'pd_US.ISO8859-1',\n    'ph':                                   'ph_PH.ISO8859-1',\n    'ph_ph':                                'ph_PH.ISO8859-1',\n    'pl':                                   'pl_PL.ISO8859-2',\n    'pl_pl':                                'pl_PL.ISO8859-2',\n    'polish':                               'pl_PL.ISO8859-2',\n    'portuguese':                           'pt_PT.ISO8859-1',\n    'portuguese_brazil':                    'pt_BR.ISO8859-1',\n    'posix':                                'C',\n    'posix-utf2':                           'C',\n    'pp':                                   'pp_AN.ISO8859-1',\n    'pp_an':                                'pp_AN.ISO8859-1',\n    'ps_af':                                'ps_AF.UTF-8',\n    'pt':                                   'pt_PT.ISO8859-1',\n    'pt_br':                                'pt_BR.ISO8859-1',\n    'pt_pt':                                'pt_PT.ISO8859-1',\n    'quz_pe':                               'quz_PE.UTF-8',\n    'raj_in':                               'raj_IN.UTF-8',\n    'ro':                                   'ro_RO.ISO8859-2',\n    'ro_ro':                                'ro_RO.ISO8859-2',\n    'romanian':                             'ro_RO.ISO8859-2',\n    'ru':                                   'ru_RU.UTF-8',\n    'ru_ru':                                'ru_RU.UTF-8',\n    'ru_ua':                                'ru_UA.KOI8-U',\n    'rumanian':                             'ro_RO.ISO8859-2',\n    'russian':                              'ru_RU.KOI8-R',\n    'rw':                                   'rw_RW.ISO8859-1',\n    'rw_rw':                                'rw_RW.ISO8859-1',\n    'sa_in':                                'sa_IN.UTF-8',\n    'sat_in':                               'sat_IN.UTF-8',\n    'sc_it':                                'sc_IT.UTF-8',\n    'sd':                                   'sd_IN.UTF-8',\n    'sd_in':                                'sd_IN.UTF-8',\n    'sd_in@devanagari.utf8':                'sd_IN.UTF-8@devanagari',\n    'sd_pk':                                'sd_PK.UTF-8',\n    'se_no':                                'se_NO.UTF-8',\n    'serbocroatian':                        'sr_RS.UTF-8@latin',\n    'sgs_lt':                               'sgs_LT.UTF-8',\n    'sh':                                   'sr_RS.UTF-8@latin',\n    'sh_ba.iso88592@bosnia':                'sr_CS.ISO8859-2',\n    'sh_hr':                                'sh_HR.ISO8859-2',\n    'sh_hr.iso88592':                       'hr_HR.ISO8859-2',\n    'sh_sp':                                'sr_CS.ISO8859-2',\n    'sh_yu':                                'sr_RS.UTF-8@latin',\n    'shn_mm':                               'shn_MM.UTF-8',\n    'shs_ca':                               'shs_CA.UTF-8',\n    'si':                                   'si_LK.UTF-8',\n    'si_lk':                                'si_LK.UTF-8',\n    'sid_et':                               'sid_ET.UTF-8',\n    'sinhala':                              'si_LK.UTF-8',\n    'sk':                                   'sk_SK.ISO8859-2',\n    'sk_sk':                                'sk_SK.ISO8859-2',\n    'sl':                                   'sl_SI.ISO8859-2',\n    'sl_cs':                                'sl_CS.ISO8859-2',\n    'sl_si':                                'sl_SI.ISO8859-2',\n    'slovak':                               'sk_SK.ISO8859-2',\n    'slovene':                              'sl_SI.ISO8859-2',\n    'slovenian':                            'sl_SI.ISO8859-2',\n    'sm_ws':                                'sm_WS.UTF-8',\n    'so_dj':                                'so_DJ.ISO8859-1',\n    'so_et':                                'so_ET.UTF-8',\n    'so_ke':                                'so_KE.ISO8859-1',\n    'so_so':                                'so_SO.ISO8859-1',\n    'sp':                                   'sr_CS.ISO8859-5',\n    'sp_yu':                                'sr_CS.ISO8859-5',\n    'spanish':                              'es_ES.ISO8859-1',\n    'spanish_spain':                        'es_ES.ISO8859-1',\n    'sq':                                   'sq_AL.ISO8859-2',\n    'sq_al':                                'sq_AL.ISO8859-2',\n    'sq_mk':                                'sq_MK.UTF-8',\n    'sr':                                   'sr_RS.UTF-8',\n    'sr@cyrillic':                          'sr_RS.UTF-8',\n    'sr@latn':                              'sr_CS.UTF-8@latin',\n    'sr_cs':                                'sr_CS.UTF-8',\n    'sr_cs.iso88592@latn':                  'sr_CS.ISO8859-2',\n    'sr_cs@latn':                           'sr_CS.UTF-8@latin',\n    'sr_me':                                'sr_ME.UTF-8',\n    'sr_rs':                                'sr_RS.UTF-8',\n    'sr_rs@latn':                           'sr_RS.UTF-8@latin',\n    'sr_sp':                                'sr_CS.ISO8859-2',\n    'sr_yu':                                'sr_RS.UTF-8@latin',\n    'sr_yu.cp1251@cyrillic':                'sr_CS.CP1251',\n    'sr_yu.iso88592':                       'sr_CS.ISO8859-2',\n    'sr_yu.iso88595':                       'sr_CS.ISO8859-5',\n    'sr_yu.iso88595@cyrillic':              'sr_CS.ISO8859-5',\n    'sr_yu.microsoftcp1251@cyrillic':       'sr_CS.CP1251',\n    'sr_yu.utf8':                           'sr_RS.UTF-8',\n    'sr_yu.utf8@cyrillic':                  'sr_RS.UTF-8',\n    'sr_yu@cyrillic':                       'sr_RS.UTF-8',\n    'ss':                                   'ss_ZA.ISO8859-1',\n    'ss_za':                                'ss_ZA.ISO8859-1',\n    'st':                                   'st_ZA.ISO8859-1',\n    'st_za':                                'st_ZA.ISO8859-1',\n    'sv':                                   'sv_SE.ISO8859-1',\n    'sv_fi':                                'sv_FI.ISO8859-1',\n    'sv_se':                                'sv_SE.ISO8859-1',\n    'sw_ke':                                'sw_KE.UTF-8',\n    'sw_tz':                                'sw_TZ.UTF-8',\n    'swedish':                              'sv_SE.ISO8859-1',\n    'szl_pl':                               'szl_PL.UTF-8',\n    'ta':                                   'ta_IN.TSCII-0',\n    'ta_in':                                'ta_IN.TSCII-0',\n    'ta_in.tscii':                          'ta_IN.TSCII-0',\n    'ta_in.tscii0':                         'ta_IN.TSCII-0',\n    'ta_lk':                                'ta_LK.UTF-8',\n    'tcy_in.utf8':                          'tcy_IN.UTF-8',\n    'te':                                   'te_IN.UTF-8',\n    'te_in':                                'te_IN.UTF-8',\n    'tg':                                   'tg_TJ.KOI8-C',\n    'tg_tj':                                'tg_TJ.KOI8-C',\n    'th':                                   'th_TH.ISO8859-11',\n    'th_th':                                'th_TH.ISO8859-11',\n    'th_th.tactis':                         'th_TH.TIS620',\n    'th_th.tis620':                         'th_TH.TIS620',\n    'thai':                                 'th_TH.ISO8859-11',\n    'the_np':                               'the_NP.UTF-8',\n    'ti_er':                                'ti_ER.UTF-8',\n    'ti_et':                                'ti_ET.UTF-8',\n    'tig_er':                               'tig_ER.UTF-8',\n    'tk_tm':                                'tk_TM.UTF-8',\n    'tl':                                   'tl_PH.ISO8859-1',\n    'tl_ph':                                'tl_PH.ISO8859-1',\n    'tn':                                   'tn_ZA.ISO8859-15',\n    'tn_za':                                'tn_ZA.ISO8859-15',\n    'to_to':                                'to_TO.UTF-8',\n    'tpi_pg':                               'tpi_PG.UTF-8',\n    'tr':                                   'tr_TR.ISO8859-9',\n    'tr_cy':                                'tr_CY.ISO8859-9',\n    'tr_tr':                                'tr_TR.ISO8859-9',\n    'ts':                                   'ts_ZA.ISO8859-1',\n    'ts_za':                                'ts_ZA.ISO8859-1',\n    'tt':                                   'tt_RU.TATAR-CYR',\n    'tt_ru':                                'tt_RU.TATAR-CYR',\n    'tt_ru.tatarcyr':                       'tt_RU.TATAR-CYR',\n    'tt_ru@iqtelif':                        'tt_RU.UTF-8@iqtelif',\n    'turkish':                              'tr_TR.ISO8859-9',\n    'ug_cn':                                'ug_CN.UTF-8',\n    'uk':                                   'uk_UA.KOI8-U',\n    'uk_ua':                                'uk_UA.KOI8-U',\n    'univ':                                 'en_US.utf',\n    'universal':                            'en_US.utf',\n    'universal.utf8@ucs4':                  'en_US.UTF-8',\n    'unm_us':                               'unm_US.UTF-8',\n    'ur':                                   'ur_PK.CP1256',\n    'ur_in':                                'ur_IN.UTF-8',\n    'ur_pk':                                'ur_PK.CP1256',\n    'uz':                                   'uz_UZ.UTF-8',\n    'uz_uz':                                'uz_UZ.UTF-8',\n    'uz_uz@cyrillic':                       'uz_UZ.UTF-8',\n    've':                                   've_ZA.UTF-8',\n    've_za':                                've_ZA.UTF-8',\n    'vi':                                   'vi_VN.TCVN',\n    'vi_vn':                                'vi_VN.TCVN',\n    'vi_vn.tcvn':                           'vi_VN.TCVN',\n    'vi_vn.tcvn5712':                       'vi_VN.TCVN',\n    'vi_vn.viscii':                         'vi_VN.VISCII',\n    'vi_vn.viscii111':                      'vi_VN.VISCII',\n    'wa':                                   'wa_BE.ISO8859-1',\n    'wa_be':                                'wa_BE.ISO8859-1',\n    'wae_ch':                               'wae_CH.UTF-8',\n    'wal_et':                               'wal_ET.UTF-8',\n    'wo_sn':                                'wo_SN.UTF-8',\n    'xh':                                   'xh_ZA.ISO8859-1',\n    'xh_za':                                'xh_ZA.ISO8859-1',\n    'yi':                                   'yi_US.CP1255',\n    'yi_us':                                'yi_US.CP1255',\n    'yo_ng':                                'yo_NG.UTF-8',\n    'yue_hk':                               'yue_HK.UTF-8',\n    'yuw_pg':                               'yuw_PG.UTF-8',\n    'zh':                                   'zh_CN.eucCN',\n    'zh_cn':                                'zh_CN.gb2312',\n    'zh_cn.big5':                           'zh_TW.big5',\n    'zh_cn.euc':                            'zh_CN.eucCN',\n    'zh_hk':                                'zh_HK.big5hkscs',\n    'zh_hk.big5hk':                         'zh_HK.big5hkscs',\n    'zh_sg':                                'zh_SG.GB2312',\n    'zh_sg.gbk':                            'zh_SG.GBK',\n    'zh_tw':                                'zh_TW.big5',\n    'zh_tw.euc':                            'zh_TW.eucTW',\n    'zh_tw.euctw':                          'zh_TW.eucTW',\n    'zu':                                   'zu_ZA.ISO8859-1',\n    'zu_za':                                'zu_ZA.ISO8859-1',\n}\nwindows_locale = {\n    0x0436: \"af_ZA\", # Afrikaans\n    0x041c: \"sq_AL\", # Albanian\n    0x0484: \"gsw_FR\",# Alsatian - France\n    0x045e: \"am_ET\", # Amharic - Ethiopia\n    0x0401: \"ar_SA\", # Arabic - Saudi Arabia\n    0x0801: \"ar_IQ\", # Arabic - Iraq\n    0x0c01: \"ar_EG\", # Arabic - Egypt\n    0x1001: \"ar_LY\", # Arabic - Libya\n    0x1401: \"ar_DZ\", # Arabic - Algeria\n    0x1801: \"ar_MA\", # Arabic - Morocco\n    0x1c01: \"ar_TN\", # Arabic - Tunisia\n    0x2001: \"ar_OM\", # Arabic - Oman\n    0x2401: \"ar_YE\", # Arabic - Yemen\n    0x2801: \"ar_SY\", # Arabic - Syria\n    0x2c01: \"ar_JO\", # Arabic - Jordan\n    0x3001: \"ar_LB\", # Arabic - Lebanon\n    0x3401: \"ar_KW\", # Arabic - Kuwait\n    0x3801: \"ar_AE\", # Arabic - United Arab Emirates\n    0x3c01: \"ar_BH\", # Arabic - Bahrain\n    0x4001: \"ar_QA\", # Arabic - Qatar\n    0x042b: \"hy_AM\", # Armenian\n    0x044d: \"as_IN\", # Assamese - India\n    0x042c: \"az_AZ\", # Azeri - Latin\n    0x082c: \"az_AZ\", # Azeri - Cyrillic\n    0x046d: \"ba_RU\", # Bashkir\n    0x042d: \"eu_ES\", # Basque - Russia\n    0x0423: \"be_BY\", # Belarusian\n    0x0445: \"bn_IN\", # Begali\n    0x201a: \"bs_BA\", # Bosnian - Cyrillic\n    0x141a: \"bs_BA\", # Bosnian - Latin\n    0x047e: \"br_FR\", # Breton - France\n    0x0402: \"bg_BG\", # Bulgarian\n#    0x0455: \"my_MM\", # Burmese - Not supported\n    0x0403: \"ca_ES\", # Catalan\n    0x0004: \"zh_CHS\",# Chinese - Simplified\n    0x0404: \"zh_TW\", # Chinese - Taiwan\n    0x0804: \"zh_CN\", # Chinese - PRC\n    0x0c04: \"zh_HK\", # Chinese - Hong Kong S.A.R.\n    0x1004: \"zh_SG\", # Chinese - Singapore\n    0x1404: \"zh_MO\", # Chinese - Macao S.A.R.\n    0x7c04: \"zh_CHT\",# Chinese - Traditional\n    0x0483: \"co_FR\", # Corsican - France\n    0x041a: \"hr_HR\", # Croatian\n    0x101a: \"hr_BA\", # Croatian - Bosnia\n    0x0405: \"cs_CZ\", # Czech\n    0x0406: \"da_DK\", # Danish\n    0x048c: \"gbz_AF\",# Dari - Afghanistan\n    0x0465: \"div_MV\",# Divehi - Maldives\n    0x0413: \"nl_NL\", # Dutch - The Netherlands\n    0x0813: \"nl_BE\", # Dutch - Belgium\n    0x0409: \"en_US\", # English - United States\n    0x0809: \"en_GB\", # English - United Kingdom\n    0x0c09: \"en_AU\", # English - Australia\n    0x1009: \"en_CA\", # English - Canada\n    0x1409: \"en_NZ\", # English - New Zealand\n    0x1809: \"en_IE\", # English - Ireland\n    0x1c09: \"en_ZA\", # English - South Africa\n    0x2009: \"en_JA\", # English - Jamaica\n    0x2409: \"en_CB\", # English - Caribbean\n    0x2809: \"en_BZ\", # English - Belize\n    0x2c09: \"en_TT\", # English - Trinidad\n    0x3009: \"en_ZW\", # English - Zimbabwe\n    0x3409: \"en_PH\", # English - Philippines\n    0x4009: \"en_IN\", # English - India\n    0x4409: \"en_MY\", # English - Malaysia\n    0x4809: \"en_IN\", # English - Singapore\n    0x0425: \"et_EE\", # Estonian\n    0x0438: \"fo_FO\", # Faroese\n    0x0464: \"fil_PH\",# Filipino\n    0x040b: \"fi_FI\", # Finnish\n    0x040c: \"fr_FR\", # French - France\n    0x080c: \"fr_BE\", # French - Belgium\n    0x0c0c: \"fr_CA\", # French - Canada\n    0x100c: \"fr_CH\", # French - Switzerland\n    0x140c: \"fr_LU\", # French - Luxembourg\n    0x180c: \"fr_MC\", # French - Monaco\n    0x0462: \"fy_NL\", # Frisian - Netherlands\n    0x0456: \"gl_ES\", # Galician\n    0x0437: \"ka_GE\", # Georgian\n    0x0407: \"de_DE\", # German - Germany\n    0x0807: \"de_CH\", # German - Switzerland\n    0x0c07: \"de_AT\", # German - Austria\n    0x1007: \"de_LU\", # German - Luxembourg\n    0x1407: \"de_LI\", # German - Liechtenstein\n    0x0408: \"el_GR\", # Greek\n    0x046f: \"kl_GL\", # Greenlandic - Greenland\n    0x0447: \"gu_IN\", # Gujarati\n    0x0468: \"ha_NG\", # Hausa - Latin\n    0x040d: \"he_IL\", # Hebrew\n    0x0439: \"hi_IN\", # Hindi\n    0x040e: \"hu_HU\", # Hungarian\n    0x040f: \"is_IS\", # Icelandic\n    0x0421: \"id_ID\", # Indonesian\n    0x045d: \"iu_CA\", # Inuktitut - Syllabics\n    0x085d: \"iu_CA\", # Inuktitut - Latin\n    0x083c: \"ga_IE\", # Irish - Ireland\n    0x0410: \"it_IT\", # Italian - Italy\n    0x0810: \"it_CH\", # Italian - Switzerland\n    0x0411: \"ja_JP\", # Japanese\n    0x044b: \"kn_IN\", # Kannada - India\n    0x043f: \"kk_KZ\", # Kazakh\n    0x0453: \"kh_KH\", # Khmer - Cambodia\n    0x0486: \"qut_GT\",# K'iche - Guatemala\n    0x0487: \"rw_RW\", # Kinyarwanda - Rwanda\n    0x0457: \"kok_IN\",# Konkani\n    0x0412: \"ko_KR\", # Korean\n    0x0440: \"ky_KG\", # Kyrgyz\n    0x0454: \"lo_LA\", # Lao - Lao PDR\n    0x0426: \"lv_LV\", # Latvian\n    0x0427: \"lt_LT\", # Lithuanian\n    0x082e: \"dsb_DE\",# Lower Sorbian - Germany\n    0x046e: \"lb_LU\", # Luxembourgish\n    0x042f: \"mk_MK\", # FYROM Macedonian\n    0x043e: \"ms_MY\", # Malay - Malaysia\n    0x083e: \"ms_BN\", # Malay - Brunei Darussalam\n    0x044c: \"ml_IN\", # Malayalam - India\n    0x043a: \"mt_MT\", # Maltese\n    0x0481: \"mi_NZ\", # Maori\n    0x047a: \"arn_CL\",# Mapudungun\n    0x044e: \"mr_IN\", # Marathi\n    0x047c: \"moh_CA\",# Mohawk - Canada\n    0x0450: \"mn_MN\", # Mongolian - Cyrillic\n    0x0850: \"mn_CN\", # Mongolian - PRC\n    0x0461: \"ne_NP\", # Nepali\n    0x0414: \"nb_NO\", # Norwegian - Bokmal\n    0x0814: \"nn_NO\", # Norwegian - Nynorsk\n    0x0482: \"oc_FR\", # Occitan - France\n    0x0448: \"or_IN\", # Oriya - India\n    0x0463: \"ps_AF\", # Pashto - Afghanistan\n    0x0429: \"fa_IR\", # Persian\n    0x0415: \"pl_PL\", # Polish\n    0x0416: \"pt_BR\", # Portuguese - Brazil\n    0x0816: \"pt_PT\", # Portuguese - Portugal\n    0x0446: \"pa_IN\", # Punjabi\n    0x046b: \"quz_BO\",# Quechua (Bolivia)\n    0x086b: \"quz_EC\",# Quechua (Ecuador)\n    0x0c6b: \"quz_PE\",# Quechua (Peru)\n    0x0418: \"ro_RO\", # Romanian - Romania\n    0x0417: \"rm_CH\", # Romansh\n    0x0419: \"ru_RU\", # Russian\n    0x243b: \"smn_FI\",# Sami Finland\n    0x103b: \"smj_NO\",# Sami Norway\n    0x143b: \"smj_SE\",# Sami Sweden\n    0x043b: \"se_NO\", # Sami Northern Norway\n    0x083b: \"se_SE\", # Sami Northern Sweden\n    0x0c3b: \"se_FI\", # Sami Northern Finland\n    0x203b: \"sms_FI\",# Sami Skolt\n    0x183b: \"sma_NO\",# Sami Southern Norway\n    0x1c3b: \"sma_SE\",# Sami Southern Sweden\n    0x044f: \"sa_IN\", # Sanskrit\n    0x0c1a: \"sr_SP\", # Serbian - Cyrillic\n    0x1c1a: \"sr_BA\", # Serbian - Bosnia Cyrillic\n    0x081a: \"sr_SP\", # Serbian - Latin\n    0x181a: \"sr_BA\", # Serbian - Bosnia Latin\n    0x045b: \"si_LK\", # Sinhala - Sri Lanka\n    0x046c: \"ns_ZA\", # Northern Sotho\n    0x0432: \"tn_ZA\", # Setswana - Southern Africa\n    0x041b: \"sk_SK\", # Slovak\n    0x0424: \"sl_SI\", # Slovenian\n    0x040a: \"es_ES\", # Spanish - Spain\n    0x080a: \"es_MX\", # Spanish - Mexico\n    0x0c0a: \"es_ES\", # Spanish - Spain (Modern)\n    0x100a: \"es_GT\", # Spanish - Guatemala\n    0x140a: \"es_CR\", # Spanish - Costa Rica\n    0x180a: \"es_PA\", # Spanish - Panama\n    0x1c0a: \"es_DO\", # Spanish - Dominican Republic\n    0x200a: \"es_VE\", # Spanish - Venezuela\n    0x240a: \"es_CO\", # Spanish - Colombia\n    0x280a: \"es_PE\", # Spanish - Peru\n    0x2c0a: \"es_AR\", # Spanish - Argentina\n    0x300a: \"es_EC\", # Spanish - Ecuador\n    0x340a: \"es_CL\", # Spanish - Chile\n    0x380a: \"es_UR\", # Spanish - Uruguay\n    0x3c0a: \"es_PY\", # Spanish - Paraguay\n    0x400a: \"es_BO\", # Spanish - Bolivia\n    0x440a: \"es_SV\", # Spanish - El Salvador\n    0x480a: \"es_HN\", # Spanish - Honduras\n    0x4c0a: \"es_NI\", # Spanish - Nicaragua\n    0x500a: \"es_PR\", # Spanish - Puerto Rico\n    0x540a: \"es_US\", # Spanish - United States\n#    0x0430: \"\", # Sutu - Not supported\n    0x0441: \"sw_KE\", # Swahili\n    0x041d: \"sv_SE\", # Swedish - Sweden\n    0x081d: \"sv_FI\", # Swedish - Finland\n    0x045a: \"syr_SY\",# Syriac\n    0x0428: \"tg_TJ\", # Tajik - Cyrillic\n    0x085f: \"tmz_DZ\",# Tamazight - Latin\n    0x0449: \"ta_IN\", # Tamil\n    0x0444: \"tt_RU\", # Tatar\n    0x044a: \"te_IN\", # Telugu\n    0x041e: \"th_TH\", # Thai\n    0x0851: \"bo_BT\", # Tibetan - Bhutan\n    0x0451: \"bo_CN\", # Tibetan - PRC\n    0x041f: \"tr_TR\", # Turkish\n    0x0442: \"tk_TM\", # Turkmen - Cyrillic\n    0x0480: \"ug_CN\", # Uighur - Arabic\n    0x0422: \"uk_UA\", # Ukrainian\n    0x042e: \"wen_DE\",# Upper Sorbian - Germany\n    0x0420: \"ur_PK\", # Urdu\n    0x0820: \"ur_IN\", # Urdu - India\n    0x0443: \"uz_UZ\", # Uzbek - Latin\n    0x0843: \"uz_UZ\", # Uzbek - Cyrillic\n    0x042a: \"vi_VN\", # Vietnamese\n    0x0452: \"cy_GB\", # Welsh\n    0x0488: \"wo_SN\", # Wolof - Senegal\n    0x0434: \"xh_ZA\", # Xhosa - South Africa\n    0x0485: \"sah_RU\",# Yakut - Cyrillic\n    0x0478: \"ii_CN\", # Yi - PRC\n    0x046a: \"yo_NG\", # Yoruba - Nigeria\n    0x0435: \"zu_ZA\", # Zulu\n}\ntry:\n    LC_MESSAGES\nexcept NameError:\n    pass\nelse:\n    __all__.append(\"LC_MESSAGES\")\nif __name__=='__main__':\n    print('Locale aliasing:')\n    print()\n    _print_locale()\n    print()\n    print('Number formatting:')\n    print()\n    _test()",
        "name_type": "stdlib"
    },
    "locale._strcoll": {
        "API_name": "locale._strcoll",
        "loc_name": "locale._strcoll",
        "args": "a;b",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 33,
        "namespace": "*",
        "body": "def _strcoll(a,b):\n    \"\"\" strcoll(string,string) -> int.\n        Compares two strings according to the locale.\n    \"\"\"\n    return (a > b) - (a < b)",
        "name_type": "stdlib"
    },
    "locale._strxfrm": {
        "API_name": "locale._strxfrm",
        "loc_name": "locale._strxfrm",
        "args": "s",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 39,
        "namespace": "*",
        "body": "def _strxfrm(s):\n    \"\"\" strxfrm(string) -> string.\n        Returns a string that behaves for cmp locale-aware.\n    \"\"\"\n    return s",
        "name_type": "stdlib"
    },
    "locale.localeconv": {
        "API_name": "locale.localeconv",
        "loc_name": "locale.localeconv",
        "args": "",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 109,
        "namespace": "*",
        "body": "def localeconv():\n    d = _localeconv()\n    if _override_localeconv:\n        d.update(_override_localeconv)\n    return d",
        "name_type": "stdlib"
    },
    "locale.setlocale": {
        "API_name": "locale.setlocale",
        "loc_name": "locale.setlocale",
        "args": "category;locale",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 595,
        "namespace": "*",
        "body": "def setlocale(category, locale=None):\n\n    \"\"\" Set the locale for the given category.  The locale can be\n        a string, an iterable of two strings (language code and encoding),\n        or None.\n\n        Iterables are converted to strings using the locale aliasing\n        engine.  Locale strings are passed directly to the C lib.\n\n        category may be given as one of the LC_* values.\n\n    \"\"\"\n    if locale and not isinstance(locale, _builtin_str):\n        # convert to string\n        locale = normalize(_build_localename(locale))\n    return _setlocale(category, locale)",
        "name_type": "stdlib"
    },
    "locale._grouping_intervals": {
        "API_name": "locale._grouping_intervals",
        "loc_name": "locale._grouping_intervals",
        "args": "grouping",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 122,
        "namespace": "*",
        "body": "def _grouping_intervals(grouping):\n    last_interval = None\n    for interval in grouping:\n        # if grouping is -1, we are done\n        if interval == CHAR_MAX:\n            return\n        # 0: re-use last group ad infinitum\n        if interval == 0:\n            if last_interval is None:\n                raise ValueError(\"invalid grouping\")\n            while True:\n                yield last_interval\n        yield interval\n        last_interval = interval",
        "name_type": "stdlib"
    },
    "locale._group": {
        "API_name": "locale._group",
        "loc_name": "locale._group",
        "args": "s;monetary",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 138,
        "namespace": "*",
        "body": "def _group(s, monetary=False):\n    conv = localeconv()\n    thousands_sep = conv[monetary and 'mon_thousands_sep' or 'thousands_sep']\n    grouping = conv[monetary and 'mon_grouping' or 'grouping']\n    if not grouping:\n        return (s, 0)\n    if s[-1] == ' ':\n        stripped = s.rstrip()\n        right_spaces = s[len(stripped):]\n        s = stripped\n    else:\n        right_spaces = ''\n    left_spaces = ''\n    groups = []\n    for interval in _grouping_intervals(grouping):\n        if not s or s[-1] not in \"0123456789\":\n            # only non-digit characters remain (sign, spaces)\n            left_spaces = s\n            s = ''\n            break\n        groups.append(s[-interval:])\n        s = s[:-interval]\n    if s:\n        groups.append(s)\n    groups.reverse()\n    return (\n        left_spaces + thousands_sep.join(groups) + right_spaces,\n        len(thousands_sep) * (len(groups) - 1)\n    )",
        "name_type": "stdlib"
    },
    "locale._strip_padding": {
        "API_name": "locale._strip_padding",
        "loc_name": "locale._strip_padding",
        "args": "s;amount",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 169,
        "namespace": "*",
        "body": "def _strip_padding(s, amount):\n    lpos = 0\n    while amount and s[lpos] == ' ':\n        lpos += 1\n        amount -= 1\n    rpos = len(s) - 1\n    while amount and s[rpos] == ' ':\n        rpos -= 1\n        amount -= 1\n    return s[lpos:rpos+1]",
        "name_type": "stdlib"
    },
    "locale._format": {
        "API_name": "locale._format",
        "loc_name": "locale._format",
        "args": "percent;value;grouping;monetary",
        "args_default": 2,
        "filepath": "locale",
        "lineno": 183,
        "namespace": "*",
        "body": "def _format(percent, value, grouping=False, monetary=False, *additional):\n    if additional:\n        formatted = percent % ((value,) + additional)\n    else:\n        formatted = percent % value\n    # floats and decimal ints need special action!\n    if percent[-1] in 'eEfFgG':\n        seps = 0\n        parts = formatted.split('.')\n        if grouping:\n            parts[0], seps = _group(parts[0], monetary=monetary)\n        decimal_point = localeconv()[monetary and 'mon_decimal_point'\n                                              or 'decimal_point']\n        formatted = decimal_point.join(parts)\n        if seps:\n            formatted = _strip_padding(formatted, seps)\n    elif percent[-1] in 'diu':\n        seps = 0\n        if grouping:\n            formatted, seps = _group(formatted, monetary=monetary)\n        if seps:\n            formatted = _strip_padding(formatted, seps)\n    return formatted",
        "name_type": "stdlib"
    },
    "locale.format_string": {
        "API_name": "locale.format_string",
        "loc_name": "locale.format_string",
        "args": "f;val;grouping;monetary",
        "args_default": 2,
        "filepath": "locale",
        "lineno": 207,
        "namespace": "*",
        "body": "def format_string(f, val, grouping=False, monetary=False):\n    \"\"\"Formats a string in the same way that the % formatting would use,\n    but takes the current locale into account.\n\n    Grouping is applied if the third parameter is true.\n    Conversion uses monetary thousands separator and grouping strings if\n    forth parameter monetary is true.\"\"\"\n    percents = list(_percent_re.finditer(f))\n    new_f = _percent_re.sub('%s', f)\n\n    if isinstance(val, _collections_abc.Mapping):\n        new_val = []\n        for perc in percents:\n            if perc.group()[-1]=='%':\n                new_val.append('%')\n            else:\n                new_val.append(_format(perc.group(), val, grouping, monetary))\n    else:\n        if not isinstance(val, tuple):\n            val = (val,)\n        new_val = []\n        i = 0\n        for perc in percents:\n            if perc.group()[-1]=='%':\n                new_val.append('%')\n            else:\n                starcount = perc.group('modifiers').count('*')\n                new_val.append(_format(perc.group(),\n                                      val[i],\n                                      grouping,\n                                      monetary,\n                                      *val[i+1:i+1+starcount]))\n                i += (1 + starcount)\n    val = tuple(new_val)\n\n    return new_f % val",
        "name_type": "stdlib"
    },
    "locale.format": {
        "API_name": "locale.format",
        "loc_name": "locale.format",
        "args": "percent;value;grouping;monetary",
        "args_default": 2,
        "filepath": "locale",
        "lineno": 244,
        "namespace": "*",
        "body": "def format(percent, value, grouping=False, monetary=False, *additional):\n    \"\"\"Deprecated, use format_string instead.\"\"\"\n    import warnings\n    warnings.warn(\n        \"This method will be removed in a future version of Python. \"\n        \"Use 'locale.format_string()' instead.\",\n        DeprecationWarning, stacklevel=2\n    )\n\n    match = _percent_re.match(percent)\n    if not match or len(match.group())!= len(percent):\n        raise ValueError((\"format() must be given exactly one %%char \"\n                         \"format specifier, %s not valid\") % repr(percent))\n    return _format(percent, value, grouping, monetary, *additional)",
        "name_type": "stdlib"
    },
    "locale.currency": {
        "API_name": "locale.currency",
        "loc_name": "locale.currency",
        "args": "val;symbol;grouping;international",
        "args_default": 3,
        "filepath": "locale",
        "lineno": 259,
        "namespace": "*",
        "body": "def currency(val, symbol=True, grouping=False, international=False):\n    \"\"\"Formats val according to the currency settings\n    in the current locale.\"\"\"\n    conv = localeconv()\n\n    # check for illegal values\n    digits = conv[international and 'int_frac_digits' or 'frac_digits']\n    if digits == 127:\n        raise ValueError(\"Currency formatting is not possible using \"\n                         \"the 'C' locale.\")\n\n    s = _format('%%.%if' % digits, abs(val), grouping, monetary=True)\n    # '<' and '>' are markers if the sign must be inserted between symbol and value\n    s = '<' + s + '>'\n\n    if symbol:\n        smb = conv[international and 'int_curr_symbol' or 'currency_symbol']\n        precedes = conv[val<0 and 'n_cs_precedes' or 'p_cs_precedes']\n        separated = conv[val<0 and 'n_sep_by_space' or 'p_sep_by_space']\n\n        if precedes:\n            s = smb + (separated and ' ' or '') + s\n        else:\n            if international and smb[-1] == ' ':\n                smb = smb[:-1]\n            s = s + (separated and ' ' or '') + smb\n\n    sign_pos = conv[val<0 and 'n_sign_posn' or 'p_sign_posn']\n    sign = conv[val<0 and 'negative_sign' or 'positive_sign']\n\n    if sign_pos == 0:\n        s = '(' + s + ')'\n    elif sign_pos == 1:\n        s = sign + s\n    elif sign_pos == 2:\n        s = s + sign\n    elif sign_pos == 3:\n        s = s.replace('<', sign)\n    elif sign_pos == 4:\n        s = s.replace('>', sign)\n    else:\n        # the default if nothing specified;\n        # this should be the most fitting sign position\n        s = sign + s\n\n    return s.replace('<', '').replace('>', '')",
        "name_type": "stdlib"
    },
    "locale.str": {
        "API_name": "locale.str",
        "loc_name": "locale.str",
        "args": "val",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 306,
        "namespace": "*",
        "body": "def str(val):\n    \"\"\"Convert float to string, taking the locale into account.\"\"\"\n    return _format(\"%.12g\", val)",
        "name_type": "stdlib"
    },
    "locale.delocalize": {
        "API_name": "locale.delocalize",
        "loc_name": "locale.delocalize",
        "args": "string",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 310,
        "namespace": "*",
        "body": "def delocalize(string):\n    \"Parses a string as a normalized number according to the locale settings.\"\n\n    conv = localeconv()\n\n    #First, get rid of the grouping\n    ts = conv['thousands_sep']\n    if ts:\n        string = string.replace(ts, '')\n\n    #next, replace the decimal point with a dot\n    dd = conv['decimal_point']\n    if dd:\n        string = string.replace(dd, '.')\n    return string",
        "name_type": "stdlib"
    },
    "locale.atof": {
        "API_name": "locale.atof",
        "loc_name": "locale.atof",
        "args": "string;func",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 326,
        "namespace": "*",
        "body": "def atof(string, func=float):\n    \"Parses a string as a float according to the locale settings.\"\n    return func(delocalize(string))",
        "name_type": "stdlib"
    },
    "locale.atoi": {
        "API_name": "locale.atoi",
        "loc_name": "locale.atoi",
        "args": "string",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 330,
        "namespace": "*",
        "body": "def atoi(string):\n    \"Converts a string to an integer according to the locale settings.\"\n    return int(delocalize(string))",
        "name_type": "stdlib"
    },
    "locale._test": {
        "API_name": "locale._test",
        "loc_name": "locale._test",
        "args": "",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 334,
        "namespace": "*",
        "body": "def _test():\n    setlocale(LC_ALL, \"\")\n    #do grouping\n    s1 = format_string(\"%d\", 123456789,1)\n    print(s1, \"is\", atoi(s1))\n    #standard formatting\n    s1 = str(3.14)\n    print(s1, \"is\", atof(s1))",
        "name_type": "stdlib"
    },
    "locale._replace_encoding": {
        "API_name": "locale._replace_encoding",
        "loc_name": "locale._replace_encoding",
        "args": "code;encoding",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 352,
        "namespace": "*",
        "body": "def _replace_encoding(code, encoding):\n    if '.' in code:\n        langname = code[:code.index('.')]\n    else:\n        langname = code\n    # Convert the encoding to a C lib compatible encoding string\n    norm_encoding = encodings.normalize_encoding(encoding)\n    #print('norm encoding: %r' % norm_encoding)\n    norm_encoding = encodings.aliases.aliases.get(norm_encoding.lower(),\n                                                  norm_encoding)\n    #print('aliased encoding: %r' % norm_encoding)\n    encoding = norm_encoding\n    norm_encoding = norm_encoding.lower()\n    if norm_encoding in locale_encoding_alias:\n        encoding = locale_encoding_alias[norm_encoding]\n    else:\n        norm_encoding = norm_encoding.replace('_', '')\n        norm_encoding = norm_encoding.replace('-', '')\n        if norm_encoding in locale_encoding_alias:\n            encoding = locale_encoding_alias[norm_encoding]\n    #print('found encoding %r' % encoding)\n    return langname + '.' + encoding",
        "name_type": "stdlib"
    },
    "locale._append_modifier": {
        "API_name": "locale._append_modifier",
        "loc_name": "locale._append_modifier",
        "args": "code;modifier",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 375,
        "namespace": "*",
        "body": "def _append_modifier(code, modifier):\n    if modifier == 'euro':\n        if '.' not in code:\n            return code + '.ISO8859-15'\n        _, _, encoding = code.partition('.')\n        if encoding in ('ISO8859-15', 'UTF-8'):\n            return code\n        if encoding == 'ISO8859-1':\n            return _replace_encoding(code, 'ISO8859-15')\n    return code + '@' + modifier",
        "name_type": "stdlib"
    },
    "locale.normalize": {
        "API_name": "locale.normalize",
        "loc_name": "locale.normalize",
        "args": "localename",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 386,
        "namespace": "*",
        "body": "def normalize(localename):\n\n    \"\"\" Returns a normalized locale code for the given locale\n        name.\n\n        The returned locale code is formatted for use with\n        setlocale().\n\n        If normalization fails, the original name is returned\n        unchanged.\n\n        If the given encoding is not known, the function defaults to\n        the default encoding for the locale code just like setlocale()\n        does.\n\n    \"\"\"\n    # Normalize the locale name and extract the encoding and modifier\n    code = localename.lower()\n    if ':' in code:\n        # ':' is sometimes used as encoding delimiter.\n        code = code.replace(':', '.')\n    if '@' in code:\n        code, modifier = code.split('@', 1)\n    else:\n        modifier = ''\n    if '.' in code:\n        langname, encoding = code.split('.')[:2]\n    else:\n        langname = code\n        encoding = ''\n\n    # First lookup: fullname (possibly with encoding and modifier)\n    lang_enc = langname\n    if encoding:\n        norm_encoding = encoding.replace('-', '')\n        norm_encoding = norm_encoding.replace('_', '')\n        lang_enc += '.' + norm_encoding\n    lookup_name = lang_enc\n    if modifier:\n        lookup_name += '@' + modifier\n    code = locale_alias.get(lookup_name, None)\n    if code is not None:\n        return code\n    #print('first lookup failed')\n\n    if modifier:\n        # Second try: fullname without modifier (possibly with encoding)\n        code = locale_alias.get(lang_enc, None)\n        if code is not None:\n            #print('lookup without modifier succeeded')\n            if '@' not in code:\n                return _append_modifier(code, modifier)\n            if code.split('@', 1)[1].lower() == modifier:\n                return code\n        #print('second lookup failed')\n\n    if encoding:\n        # Third try: langname (without encoding, possibly with modifier)\n        lookup_name = langname\n        if modifier:\n            lookup_name += '@' + modifier\n        code = locale_alias.get(lookup_name, None)\n        if code is not None:\n            #print('lookup without encoding succeeded')\n            if '@' not in code:\n                return _replace_encoding(code, encoding)\n            code, modifier = code.split('@', 1)\n            return _replace_encoding(code, encoding) + '@' + modifier\n\n        if modifier:\n            # Fourth try: langname (without encoding and modifier)\n            code = locale_alias.get(langname, None)\n            if code is not None:\n                #print('lookup without modifier and encoding succeeded')\n                if '@' not in code:\n                    code = _replace_encoding(code, encoding)\n                    return _append_modifier(code, modifier)\n                code, defmod = code.split('@', 1)\n                if defmod.lower() == modifier:\n                    return _replace_encoding(code, encoding) + '@' + defmod\n\n    return localename",
        "name_type": "stdlib"
    },
    "locale._parse_localename": {
        "API_name": "locale._parse_localename",
        "loc_name": "locale._parse_localename",
        "args": "localename",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 469,
        "namespace": "*",
        "body": "def _parse_localename(localename):\n\n    \"\"\" Parses the locale code for localename and returns the\n        result as tuple (language code, encoding).\n\n        The localename is normalized and passed through the locale\n        alias engine. A ValueError is raised in case the locale name\n        cannot be parsed.\n\n        The language code corresponds to RFC 1766.  code and encoding\n        can be None in case the values cannot be determined or are\n        unknown to this implementation.\n\n    \"\"\"\n    code = normalize(localename)\n    if '@' in code:\n        # Deal with locale modifiers\n        code, modifier = code.split('@', 1)\n        if modifier == 'euro' and '.' not in code:\n            # Assume Latin-9 for @euro locales. This is bogus,\n            # since some systems may use other encodings for these\n            # locales. Also, we ignore other modifiers.\n            return code, 'iso-8859-15'\n\n    if '.' in code:\n        return tuple(code.split('.')[:2])\n    elif code == 'C':\n        return None, None\n    elif code == 'UTF-8':\n        # On macOS \"LC_CTYPE=UTF-8\" is a valid locale setting\n        # for getting UTF-8 handling for text.\n        return None, 'UTF-8'\n    raise ValueError('unknown locale: %s' % localename)",
        "name_type": "stdlib"
    },
    "locale._build_localename": {
        "API_name": "locale._build_localename",
        "loc_name": "locale._build_localename",
        "args": "localetuple",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 503,
        "namespace": "*",
        "body": "def _build_localename(localetuple):\n\n    \"\"\" Builds a locale code from the given tuple (language code,\n        encoding).\n\n        No aliasing or normalizing takes place.\n\n    \"\"\"\n    try:\n        language, encoding = localetuple\n\n        if language is None:\n            language = 'C'\n        if encoding is None:\n            return language\n        else:\n            return language + '.' + encoding\n    except (TypeError, ValueError):\n        raise TypeError('Locale must be None, a string, or an iterable of '\n                        'two strings -- language code, encoding.') from None",
        "name_type": "stdlib"
    },
    "locale.getdefaultlocale": {
        "API_name": "locale.getdefaultlocale",
        "loc_name": "locale.getdefaultlocale",
        "args": "envvars",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 524,
        "namespace": "*",
        "body": "def getdefaultlocale(envvars=('LC_ALL', 'LC_CTYPE', 'LANG', 'LANGUAGE')):\n\n    \"\"\" Tries to determine the default locale settings and returns\n        them as tuple (language code, encoding).\n\n        According to POSIX, a program which has not called\n        setlocale(LC_ALL, \"\") runs using the portable 'C' locale.\n        Calling setlocale(LC_ALL, \"\") lets it use the default locale as\n        defined by the LANG variable. Since we don't want to interfere\n        with the current locale setting we thus emulate the behavior\n        in the way described above.\n\n        To maintain compatibility with other platforms, not only the\n        LANG variable is tested, but a list of variables given as\n        envvars parameter. The first found to be defined will be\n        used. envvars defaults to the search path used in GNU gettext;\n        it must always contain the variable name 'LANG'.\n\n        Except for the code 'C', the language code corresponds to RFC\n        1766.  code and encoding can be None in case the values cannot\n        be determined.\n\n    \"\"\"\n\n    try:\n        # check if it's supported by the _locale module\n        import _locale\n        code, encoding = _locale._getdefaultlocale()\n    except (ImportError, AttributeError):\n        pass\n    else:\n        # make sure the code/encoding values are valid\n        if sys.platform == \"win32\" and code and code[:2] == \"0x\":\n            # map windows language identifier to language name\n            code = windows_locale.get(int(code, 0))\n        # ...add other platform-specific processing here, if\n        # necessary...\n        return code, encoding\n\n    # fall back on POSIX behaviour\n    import os\n    lookup = os.environ.get\n    for variable in envvars:\n        localename = lookup(variable,None)\n        if localename:\n            if variable == 'LANGUAGE':\n                localename = localename.split(':')[0]\n            break\n    else:\n        localename = 'C'\n    return _parse_localename(localename)",
        "name_type": "stdlib"
    },
    "locale.getlocale": {
        "API_name": "locale.getlocale",
        "loc_name": "locale.getlocale",
        "args": "category",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 577,
        "namespace": "*",
        "body": "def getlocale(category=LC_CTYPE):\n\n    \"\"\" Returns the current setting for the given locale category as\n        tuple (language code, encoding).\n\n        category may be one of the LC_* value except LC_ALL. It\n        defaults to LC_CTYPE.\n\n        Except for the code 'C', the language code corresponds to RFC\n        1766.  code and encoding can be None in case the values cannot\n        be determined.\n\n    \"\"\"\n    localename = _setlocale(category)\n    if category == LC_ALL and ';' in localename:\n        raise TypeError('category LC_ALL is not supported')\n    return _parse_localename(localename)",
        "name_type": "stdlib"
    },
    "locale.resetlocale": {
        "API_name": "locale.resetlocale",
        "loc_name": "locale.resetlocale",
        "args": "category",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 612,
        "namespace": "*",
        "body": "def resetlocale(category=LC_ALL):\n\n    \"\"\" Sets the locale for category to the default setting.\n\n        The default setting is determined by calling\n        getdefaultlocale(). category defaults to LC_ALL.\n\n    \"\"\"\n    _setlocale(category, _build_localename(getdefaultlocale()))",
        "name_type": "stdlib"
    },
    "locale.getpreferredencoding": {
        "API_name": "locale.getpreferredencoding",
        "loc_name": "locale.getpreferredencoding",
        "args": "do_setlocale",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 653,
        "namespace": "*",
        "body": "        def getpreferredencoding(do_setlocale = True):\n            \"\"\"Return the charset that the user is likely using,\n            according to the system configuration.\"\"\"\n            if sys.flags.utf8_mode:\n                return 'UTF-8'\n            import _bootlocale\n            if do_setlocale:\n                oldloc = setlocale(LC_CTYPE)\n                try:\n                    setlocale(LC_CTYPE, \"\")\n                except Error:\n                    pass\n            result = _bootlocale.getpreferredencoding(False)\n            if do_setlocale:\n                setlocale(LC_CTYPE, oldloc)\n            return result",
        "name_type": "stdlib"
    },
    "locale._print_locale": {
        "API_name": "locale._print_locale",
        "loc_name": "locale._print_locale",
        "args": "",
        "args_default": 0,
        "filepath": "locale",
        "lineno": 1683,
        "namespace": "*",
        "body": "def _print_locale():\n\n    \"\"\" Test function.\n    \"\"\"\n    categories = {}\n    def _init_categories(categories=categories):\n        for k,v in globals().items():\n            if k[:3] == 'LC_':\n                categories[k] = v\n    _init_categories()\n    del categories['LC_ALL']\n\n    print('Locale defaults as determined by getdefaultlocale():')\n    print('-'*72)\n    lang, enc = getdefaultlocale()\n    print('Language: ', lang or '(undefined)')\n    print('Encoding: ', enc or '(undefined)')\n    print()\n\n    print('Locale settings on startup:')\n    print('-'*72)\n    for name,category in categories.items():\n        print(name, '...')\n        lang, enc = getlocale(category)\n        print('   Language: ', lang or '(undefined)')\n        print('   Encoding: ', enc or '(undefined)')\n        print()\n\n    print()\n    print('Locale settings after calling resetlocale():')\n    print('-'*72)\n    resetlocale()\n    for name,category in categories.items():\n        print(name, '...')\n        lang, enc = getlocale(category)\n        print('   Language: ', lang or '(undefined)')\n        print('   Encoding: ', enc or '(undefined)')\n        print()\n\n    try:\n        setlocale(LC_ALL, \"\")\n    except:\n        print('NOTE:')\n        print('setlocale(LC_ALL, \"\") does not support the default locale')\n        print('given in the OS environment variables.')\n    else:\n        print()\n        print('Locale settings after calling setlocale(LC_ALL, \"\"):')\n        print('-'*72)\n        for name,category in categories.items():\n            print(name, '...')\n            lang, enc = getlocale(category)\n            print('   Language: ', lang or '(undefined)')\n            print('   Encoding: ', enc or '(undefined)')\n            print()",
        "name_type": "stdlib"
    },
    "locale._print_locale._init_categories": {
        "API_name": "locale._print_locale._init_categories",
        "loc_name": "locale._print_locale._init_categories",
        "args": "categories",
        "args_default": 1,
        "filepath": "locale",
        "lineno": 1688,
        "namespace": "*",
        "body": "    def _init_categories(categories=categories):\n        for k,v in globals().items():\n            if k[:3] == 'LC_':\n                categories[k] = v",
        "name_type": "stdlib"
    },
    "os": {
        "API_name": "os",
        "loc_name": "os",
        "args": "*",
        "args_default": "*",
        "filepath": "os",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"OS routines for NT or Posix depending on what system we're on.\n\nThis exports:\n  - all functions from posix or nt, e.g. unlink, stat, etc.\n  - os.path is either posixpath or ntpath\n  - os.name is either 'posix' or 'nt'\n  - os.curdir is a string representing the current directory (always '.')\n  - os.pardir is a string representing the parent directory (always '..')\n  - os.sep is the (or a most common) pathname separator ('/' or '\\\\')\n  - os.extsep is the extension separator (always '.')\n  - os.altsep is the alternate pathname separator (None or '/')\n  - os.pathsep is the component separator used in $PATH etc\n  - os.linesep is the line separator in text files ('\\r' or '\\n' or '\\r\\n')\n  - os.defpath is the default search path for executables\n  - os.devnull is the file path of the null device ('/dev/null', etc.)\n\nPrograms that import and use 'os' stand a better chance of being\nportable between different platforms.  Of course, they must then\nonly use functions that are defined by all platforms (e.g., unlink\nand opendir), and leave all pathname manipulation to os.path\n(e.g., split and join).\n\"\"\"\nGenericAlias = type(list[int])\n_names = sys.builtin_module_names\n__all__ = [\"altsep\", \"curdir\", \"pardir\", \"sep\", \"pathsep\", \"linesep\",\n           \"defpath\", \"name\", \"path\", \"devnull\", \"SEEK_SET\", \"SEEK_CUR\",\n           \"SEEK_END\", \"fsencode\", \"fsdecode\", \"get_exec_path\", \"fdopen\",\n           \"popen\", \"extsep\"]\nif 'posix' in _names:\n    name = 'posix'\n    linesep = '\\n'\n    from posix import *\n    try:\n        from posix import _exit\n        __all__.append('_exit')\n    except ImportError:\n        pass\n    import posixpath as path\n\n    try:\n        from posix import _have_functions\n    except ImportError:\n        pass\n\n    import posix\n    __all__.extend(_get_exports_list(posix))\n    del posix\n\nelif 'nt' in _names:\n    name = 'nt'\n    linesep = '\\r\\n'\n    from nt import *\n    try:\n        from nt import _exit\n        __all__.append('_exit')\n    except ImportError:\n        pass\n    import ntpath as path\n\n    import nt\n    __all__.extend(_get_exports_list(nt))\n    del nt\n\n    try:\n        from nt import _have_functions\n    except ImportError:\n        pass\n\nelse:\n    raise ImportError('no os specific module found')\nsys.modules['os.path'] = path\ndel _names\nif _exists(\"_have_functions\"):\n    _globals = globals()\n    def _add(str, fn):\n        if (fn in _globals) and (str in _have_functions):\n            _set.add(_globals[fn])\n\n    _set = set()\n    _add(\"HAVE_FACCESSAT\",  \"access\")\n    _add(\"HAVE_FCHMODAT\",   \"chmod\")\n    _add(\"HAVE_FCHOWNAT\",   \"chown\")\n    _add(\"HAVE_FSTATAT\",    \"stat\")\n    _add(\"HAVE_FUTIMESAT\",  \"utime\")\n    _add(\"HAVE_LINKAT\",     \"link\")\n    _add(\"HAVE_MKDIRAT\",    \"mkdir\")\n    _add(\"HAVE_MKFIFOAT\",   \"mkfifo\")\n    _add(\"HAVE_MKNODAT\",    \"mknod\")\n    _add(\"HAVE_OPENAT\",     \"open\")\n    _add(\"HAVE_READLINKAT\", \"readlink\")\n    _add(\"HAVE_RENAMEAT\",   \"rename\")\n    _add(\"HAVE_SYMLINKAT\",  \"symlink\")\n    _add(\"HAVE_UNLINKAT\",   \"unlink\")\n    _add(\"HAVE_UNLINKAT\",   \"rmdir\")\n    _add(\"HAVE_UTIMENSAT\",  \"utime\")\n    supports_dir_fd = _set\n\n    _set = set()\n    _add(\"HAVE_FACCESSAT\",  \"access\")\n    supports_effective_ids = _set\n\n    _set = set()\n    _add(\"HAVE_FCHDIR\",     \"chdir\")\n    _add(\"HAVE_FCHMOD\",     \"chmod\")\n    _add(\"HAVE_FCHOWN\",     \"chown\")\n    _add(\"HAVE_FDOPENDIR\",  \"listdir\")\n    _add(\"HAVE_FDOPENDIR\",  \"scandir\")\n    _add(\"HAVE_FEXECVE\",    \"execve\")\n    _set.add(stat) # fstat always works\n    _add(\"HAVE_FTRUNCATE\",  \"truncate\")\n    _add(\"HAVE_FUTIMENS\",   \"utime\")\n    _add(\"HAVE_FUTIMES\",    \"utime\")\n    _add(\"HAVE_FPATHCONF\",  \"pathconf\")\n    if _exists(\"statvfs\") and _exists(\"fstatvfs\"): # mac os x10.3\n        _add(\"HAVE_FSTATVFS\", \"statvfs\")\n    supports_fd = _set\n\n    _set = set()\n    _add(\"HAVE_FACCESSAT\",  \"access\")\n    # Some platforms don't support lchmod().  Often the function exists\n    # anyway, as a stub that always returns ENOSUP or perhaps EOPNOTSUPP.\n    # (No, I don't know why that's a good design.)  ./configure will detect\n    # this and reject it--so HAVE_LCHMOD still won't be defined on such\n    # platforms.  This is Very Helpful.\n    #\n    # However, sometimes platforms without a working lchmod() *do* have\n    # fchmodat().  (Examples: Linux kernel 3.2 with glibc 2.15,\n    # OpenIndiana 3.x.)  And fchmodat() has a flag that theoretically makes\n    # it behave like lchmod().  So in theory it would be a suitable\n    # replacement for lchmod().  But when lchmod() doesn't work, fchmodat()'s\n    # flag doesn't work *either*.  Sadly ./configure isn't sophisticated\n    # enough to detect this condition--it only determines whether or not\n    # fchmodat() minimally works.\n    #\n    # Therefore we simply ignore fchmodat() when deciding whether or not\n    # os.chmod supports follow_symlinks.  Just checking lchmod() is\n    # sufficient.  After all--if you have a working fchmodat(), your\n    # lchmod() almost certainly works too.\n    #\n    # _add(\"HAVE_FCHMODAT\",   \"chmod\")\n    _add(\"HAVE_FCHOWNAT\",   \"chown\")\n    _add(\"HAVE_FSTATAT\",    \"stat\")\n    _add(\"HAVE_LCHFLAGS\",   \"chflags\")\n    _add(\"HAVE_LCHMOD\",     \"chmod\")\n    if _exists(\"lchown\"): # mac os x10.3\n        _add(\"HAVE_LCHOWN\", \"chown\")\n    _add(\"HAVE_LINKAT\",     \"link\")\n    _add(\"HAVE_LUTIMES\",    \"utime\")\n    _add(\"HAVE_LSTAT\",      \"stat\")\n    _add(\"HAVE_FSTATAT\",    \"stat\")\n    _add(\"HAVE_UTIMENSAT\",  \"utime\")\n    _add(\"MS_WINDOWS\",      \"stat\")\n    supports_follow_symlinks = _set\n\n    del _set\n    del _have_functions\n    del _globals\n    del _add\nSEEK_SET = 0\nSEEK_CUR = 1\nSEEK_END = 2\n__all__.extend([\"makedirs\", \"removedirs\", \"renames\"])\n__all__.append(\"walk\")\nif {open, stat} <= supports_dir_fd and {scandir, stat} <= supports_fd:\n\n    def fwalk(top=\".\", topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None):\n        \"\"\"Directory tree generator.\n\n        This behaves exactly like walk(), except that it yields a 4-tuple\n\n            dirpath, dirnames, filenames, dirfd\n\n        `dirpath`, `dirnames` and `filenames` are identical to walk() output,\n        and `dirfd` is a file descriptor referring to the directory `dirpath`.\n\n        The advantage of fwalk() over walk() is that it's safe against symlink\n        races (when follow_symlinks is False).\n\n        If dir_fd is not None, it should be a file descriptor open to a directory,\n          and top should be relative; top will then be relative to that directory.\n          (dir_fd is always supported for fwalk.)\n\n        Caution:\n        Since fwalk() yields file descriptors, those are only valid until the\n        next iteration step, so you should dup() them if you want to keep them\n        for a longer period.\n\n        Example:\n\n        import os\n        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):\n            print(root, \"consumes\", end=\"\")\n            print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),\n                  end=\"\")\n            print(\"bytes in\", len(files), \"non-directory files\")\n            if 'CVS' in dirs:\n                dirs.remove('CVS')  # don't visit CVS directories\n        \"\"\"\n        sys.audit(\"os.fwalk\", top, topdown, onerror, follow_symlinks, dir_fd)\n        if not isinstance(top, int) or not hasattr(top, '__index__'):\n            top = fspath(top)\n        # Note: To guard against symlink races, we use the standard\n        # lstat()/open()/fstat() trick.\n        if not follow_symlinks:\n            orig_st = stat(top, follow_symlinks=False, dir_fd=dir_fd)\n        topfd = open(top, O_RDONLY, dir_fd=dir_fd)\n        try:\n            if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode) and\n                                    path.samestat(orig_st, stat(topfd)))):\n                yield from _fwalk(topfd, top, isinstance(top, bytes),\n                                  topdown, onerror, follow_symlinks)\n        finally:\n            close(topfd)\n\n    def _fwalk(topfd, toppath, isbytes, topdown, onerror, follow_symlinks):\n        # Note: This uses O(depth of the directory tree) file descriptors: if\n        # necessary, it can be adapted to only require O(1) FDs, see issue\n        # #13734.\n\n        scandir_it = scandir(topfd)\n        dirs = []\n        nondirs = []\n        entries = None if topdown or follow_symlinks else []\n        for entry in scandir_it:\n            name = entry.name\n            if isbytes:\n                name = fsencode(name)\n            try:\n                if entry.is_dir():\n                    dirs.append(name)\n                    if entries is not None:\n                        entries.append(entry)\n                else:\n                    nondirs.append(name)\n            except OSError:\n                try:\n                    # Add dangling symlinks, ignore disappeared files\n                    if entry.is_symlink():\n                        nondirs.append(name)\n                except OSError:\n                    pass\n\n        if topdown:\n            yield toppath, dirs, nondirs, topfd\n\n        for name in dirs if entries is None else zip(dirs, entries):\n            try:\n                if not follow_symlinks:\n                    if topdown:\n                        orig_st = stat(name, dir_fd=topfd, follow_symlinks=False)\n                    else:\n                        assert entries is not None\n                        name, entry = name\n                        orig_st = entry.stat(follow_symlinks=False)\n                dirfd = open(name, O_RDONLY, dir_fd=topfd)\n            except OSError as err:\n                if onerror is not None:\n                    onerror(err)\n                continue\n            try:\n                if follow_symlinks or path.samestat(orig_st, stat(dirfd)):\n                    dirpath = path.join(toppath, name)\n                    yield from _fwalk(dirfd, dirpath, isbytes,\n                                      topdown, onerror, follow_symlinks)\n            finally:\n                close(dirfd)\n\n        if not topdown:\n            yield toppath, dirs, nondirs, topfd\n\n    __all__.append(\"fwalk\")\n__all__.extend([\"execl\",\"execle\",\"execlp\",\"execlpe\",\"execvp\",\"execvpe\"])\nenviron = _createenviron()\ndel _createenviron\nsupports_bytes_environ = (name != 'nt')\n__all__.extend((\"getenv\", \"supports_bytes_environ\"))\nif supports_bytes_environ:\n    def _check_bytes(value):\n        if not isinstance(value, bytes):\n            raise TypeError(\"bytes expected, not %s\" % type(value).__name__)\n        return value\n\n    # bytes environ\n    environb = _Environ(environ._data,\n        _check_bytes, bytes,\n        _check_bytes, bytes)\n    del _check_bytes\n\n    def getenvb(key, default=None):\n        \"\"\"Get an environment variable, return None if it doesn't exist.\n        The optional second argument can specify an alternate default.\n        key, default and the result are bytes.\"\"\"\n        return environb.get(key, default)\n\n    __all__.extend((\"environb\", \"getenvb\"))\nfsencode, fsdecode = _fscodec()\ndel _fscodec\nif _exists(\"fork\") and not _exists(\"spawnv\") and _exists(\"execv\"):\n\n    P_WAIT = 0\n    P_NOWAIT = P_NOWAITO = 1\n\n    __all__.extend([\"P_WAIT\", \"P_NOWAIT\", \"P_NOWAITO\"])\n\n    # XXX Should we support P_DETACH?  I suppose it could fork()**2\n    # and close the std I/O streams.  Also, P_OVERLAY is the same\n    # as execv*()?\n\n    def _spawnvef(mode, file, args, env, func):\n        # Internal helper; func is the exec*() function to use\n        if not isinstance(args, (tuple, list)):\n            raise TypeError('argv must be a tuple or a list')\n        if not args or not args[0]:\n            raise ValueError('argv first element cannot be empty')\n        pid = fork()\n        if not pid:\n            # Child\n            try:\n                if env is None:\n                    func(file, args)\n                else:\n                    func(file, args, env)\n            except:\n                _exit(127)\n        else:\n            # Parent\n            if mode == P_NOWAIT:\n                return pid # Caller is responsible for waiting!\n            while 1:\n                wpid, sts = waitpid(pid, 0)\n                if WIFSTOPPED(sts):\n                    continue\n\n                return waitstatus_to_exitcode(sts)\n\n    def spawnv(mode, file, args):\n        \"\"\"spawnv(mode, file, args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execv)\n\n    def spawnve(mode, file, args, env):\n        \"\"\"spawnve(mode, file, args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nspecified environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execve)\n\n    # Note: spawnvp[e] isn't currently supported on Windows\n\n    def spawnvp(mode, file, args):\n        \"\"\"spawnvp(mode, file, args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execvp)\n\n    def spawnvpe(mode, file, args, env):\n        \"\"\"spawnvpe(mode, file, args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execvpe)\n\n\n    __all__.extend([\"spawnv\", \"spawnve\", \"spawnvp\", \"spawnvpe\"])\nif _exists(\"spawnv\"):\n    # These aren't supplied by the basic Windows code\n    # but can be easily implemented in Python\n\n    def spawnl(mode, file, *args):\n        \"\"\"spawnl(mode, file, *args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnv(mode, file, args)\n\n    def spawnle(mode, file, *args):\n        \"\"\"spawnle(mode, file, *args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nsupplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnve(mode, file, args[:-1], env)\n\n\n    __all__.extend([\"spawnl\", \"spawnle\"])\nif _exists(\"spawnvp\"):\n    # At the moment, Windows doesn't implement spawnvp[e],\n    # so it won't have spawnlp[e] either.\n    def spawnlp(mode, file, *args):\n        \"\"\"spawnlp(mode, file, *args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnvp(mode, file, args)\n\n    def spawnlpe(mode, file, *args):\n        \"\"\"spawnlpe(mode, file, *args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnvpe(mode, file, args[:-1], env)\n\n\n    __all__.extend([\"spawnlp\", \"spawnlpe\"])\nif not _exists('fspath'):\n    fspath = _fspath\n    fspath.__name__ = \"fspath\"\nif name == 'nt':\n    class _AddedDllDirectory:\n        def __init__(self, path, cookie, remove_dll_directory):\n            self.path = path\n            self._cookie = cookie\n            self._remove_dll_directory = remove_dll_directory\n        def close(self):\n            self._remove_dll_directory(self._cookie)\n            self.path = None\n        def __enter__(self):\n            return self\n        def __exit__(self, *args):\n            self.close()\n        def __repr__(self):\n            if self.path:\n                return \"<AddedDllDirectory({!r})>\".format(self.path)\n            return \"<AddedDllDirectory()>\"\n\n    def add_dll_directory(path):\n        \"\"\"Add a path to the DLL search path.\n\n        This search path is used when resolving dependencies for imported\n        extension modules (the module itself is resolved through sys.path),\n        and also by ctypes.\n\n        Remove the directory by calling close() on the returned object or\n        using it in a with statement.\n        \"\"\"\n        import nt\n        cookie = nt._add_dll_directory(path)\n        return _AddedDllDirectory(\n            path,\n            cookie,\n            nt._remove_dll_directory\n        )",
        "name_type": "stdlib"
    },
    "os._exists": {
        "API_name": "os._exists",
        "loc_name": "os._exists",
        "args": "name",
        "args_default": 0,
        "filepath": "os",
        "lineno": 41,
        "namespace": "*",
        "body": "def _exists(name):\n    return name in globals()",
        "name_type": "stdlib"
    },
    "os._get_exports_list": {
        "API_name": "os._get_exports_list",
        "loc_name": "os._get_exports_list",
        "args": "module",
        "args_default": 0,
        "filepath": "os",
        "lineno": 44,
        "namespace": "*",
        "body": "def _get_exports_list(module):\n    try:\n        return list(module.__all__)\n    except AttributeError:\n        return [n for n in dir(module) if n[0] != '_']",
        "name_type": "stdlib"
    },
    "os._add": {
        "API_name": "os._add",
        "loc_name": "os._add",
        "args": "str;fn",
        "args_default": 0,
        "filepath": "os",
        "lineno": 104,
        "namespace": "*",
        "body": "    def _add(str, fn):\n        if (fn in _globals) and (str in _have_functions):\n            _set.add(_globals[fn])",
        "name_type": "stdlib"
    },
    "os.makedirs": {
        "API_name": "os.makedirs",
        "loc_name": "os.makedirs",
        "args": "name;mode;exist_ok",
        "args_default": 2,
        "filepath": "os",
        "lineno": 200,
        "namespace": "*",
        "body": "def makedirs(name, mode=0o777, exist_ok=False):\n    \"\"\"makedirs(name [, mode=0o777][, exist_ok=False])\n\n    Super-mkdir; create a leaf directory and all intermediate ones.  Works like\n    mkdir, except that any intermediate path segment (not just the rightmost)\n    will be created if it does not exist. If the target directory already\n    exists, raise an OSError if exist_ok is False. Otherwise no exception is\n    raised.  This is recursive.\n\n    \"\"\"\n    head, tail = path.split(name)\n    if not tail:\n        head, tail = path.split(head)\n    if head and tail and not path.exists(head):\n        try:\n            makedirs(head, exist_ok=exist_ok)\n        except FileExistsError:\n            # Defeats race condition when another thread created the path\n            pass\n        cdir = curdir\n        if isinstance(tail, bytes):\n            cdir = bytes(curdir, 'ASCII')\n        if tail == cdir:           # xxx/newdir/. exists if xxx/newdir exists\n            return\n    try:\n        mkdir(name, mode)\n    except OSError:\n        # Cannot rely on checking for EEXIST, since the operating system\n        # could give priority to other errors like EACCES or EROFS\n        if not exist_ok or not path.isdir(name):\n            raise",
        "name_type": "stdlib"
    },
    "os.removedirs": {
        "API_name": "os.removedirs",
        "loc_name": "os.removedirs",
        "args": "name",
        "args_default": 0,
        "filepath": "os",
        "lineno": 232,
        "namespace": "*",
        "body": "def removedirs(name):\n    \"\"\"removedirs(name)\n\n    Super-rmdir; remove a leaf directory and all empty intermediate\n    ones.  Works like rmdir except that, if the leaf directory is\n    successfully removed, directories corresponding to rightmost path\n    segments will be pruned away until either the whole path is\n    consumed or an error occurs.  Errors during this latter phase are\n    ignored -- they generally mean that a directory was not empty.\n\n    \"\"\"\n    rmdir(name)\n    head, tail = path.split(name)\n    if not tail:\n        head, tail = path.split(head)\n    while head and tail:\n        try:\n            rmdir(head)\n        except OSError:\n            break\n        head, tail = path.split(head)",
        "name_type": "stdlib"
    },
    "os.renames": {
        "API_name": "os.renames",
        "loc_name": "os.renames",
        "args": "old;new",
        "args_default": 0,
        "filepath": "os",
        "lineno": 254,
        "namespace": "*",
        "body": "def renames(old, new):\n    \"\"\"renames(old, new)\n\n    Super-rename; create directories as necessary and delete any left\n    empty.  Works like rename, except creation of any intermediate\n    directories needed to make the new pathname good is attempted\n    first.  After the rename, directories corresponding to rightmost\n    path segments of the old name will be pruned until either the\n    whole path is consumed or a nonempty directory is found.\n\n    Note: this function can fail with the new directory structure made\n    if you lack permissions needed to unlink the leaf directory or\n    file.\n\n    \"\"\"\n    head, tail = path.split(new)\n    if head and tail and not path.exists(head):\n        makedirs(head)\n    rename(old, new)\n    head, tail = path.split(old)\n    if head and tail:\n        try:\n            removedirs(head)\n        except OSError:\n            pass",
        "name_type": "stdlib"
    },
    "os.walk": {
        "API_name": "os.walk",
        "loc_name": "os.walk",
        "args": "top;topdown;onerror;followlinks",
        "args_default": 3,
        "filepath": "os",
        "lineno": 282,
        "namespace": "*",
        "body": "def walk(top, topdown=True, onerror=None, followlinks=False):\n    \"\"\"Directory tree generator.\n\n    For each directory in the directory tree rooted at top (including top\n    itself, but excluding '.' and '..'), yields a 3-tuple\n\n        dirpath, dirnames, filenames\n\n    dirpath is a string, the path to the directory.  dirnames is a list of\n    the names of the subdirectories in dirpath (excluding '.' and '..').\n    filenames is a list of the names of the non-directory files in dirpath.\n    Note that the names in the lists are just names, with no path components.\n    To get a full path (which begins with top) to a file or directory in\n    dirpath, do os.path.join(dirpath, name).\n\n    If optional arg 'topdown' is true or not specified, the triple for a\n    directory is generated before the triples for any of its subdirectories\n    (directories are generated top down).  If topdown is false, the triple\n    for a directory is generated after the triples for all of its\n    subdirectories (directories are generated bottom up).\n\n    When topdown is true, the caller can modify the dirnames list in-place\n    (e.g., via del or slice assignment), and walk will only recurse into the\n    subdirectories whose names remain in dirnames; this can be used to prune the\n    search, or to impose a specific order of visiting.  Modifying dirnames when\n    topdown is false has no effect on the behavior of os.walk(), since the\n    directories in dirnames have already been generated by the time dirnames\n    itself is generated. No matter the value of topdown, the list of\n    subdirectories is retrieved before the tuples for the directory and its\n    subdirectories are generated.\n\n    By default errors from the os.scandir() call are ignored.  If\n    optional arg 'onerror' is specified, it should be a function; it\n    will be called with one argument, an OSError instance.  It can\n    report the error to continue with the walk, or raise the exception\n    to abort the walk.  Note that the filename is available as the\n    filename attribute of the exception object.\n\n    By default, os.walk does not follow symbolic links to subdirectories on\n    systems that support them.  In order to get this functionality, set the\n    optional argument 'followlinks' to true.\n\n    Caution:  if you pass a relative pathname for top, don't change the\n    current working directory between resumptions of walk.  walk never\n    changes the current directory, and assumes that the client doesn't\n    either.\n\n    Example:\n\n    import os\n    from os.path import join, getsize\n    for root, dirs, files in os.walk('python/Lib/email'):\n        print(root, \"consumes\", end=\"\")\n        print(sum(getsize(join(root, name)) for name in files), end=\"\")\n        print(\"bytes in\", len(files), \"non-directory files\")\n        if 'CVS' in dirs:\n            dirs.remove('CVS')  # don't visit CVS directories\n\n    \"\"\"\n    sys.audit(\"os.walk\", top, topdown, onerror, followlinks)\n    return _walk(fspath(top), topdown, onerror, followlinks)",
        "name_type": "stdlib"
    },
    "os._walk": {
        "API_name": "os._walk",
        "loc_name": "os._walk",
        "args": "top;topdown;onerror;followlinks",
        "args_default": 0,
        "filepath": "os",
        "lineno": 344,
        "namespace": "*",
        "body": "def _walk(top, topdown, onerror, followlinks):\n    dirs = []\n    nondirs = []\n    walk_dirs = []\n\n    # We may not have read permission for top, in which case we can't\n    # get a list of the files the directory contains.  os.walk\n    # always suppressed the exception then, rather than blow up for a\n    # minor reason when (say) a thousand readable directories are still\n    # left to visit.  That logic is copied here.\n    try:\n        # Note that scandir is global in this module due\n        # to earlier import-*.\n        scandir_it = scandir(top)\n    except OSError as error:\n        if onerror is not None:\n            onerror(error)\n        return\n\n    with scandir_it:\n        while True:\n            try:\n                try:\n                    entry = next(scandir_it)\n                except StopIteration:\n                    break\n            except OSError as error:\n                if onerror is not None:\n                    onerror(error)\n                return\n\n            try:\n                is_dir = entry.is_dir()\n            except OSError:\n                # If is_dir() raises an OSError, consider that the entry is not\n                # a directory, same behaviour than os.path.isdir().\n                is_dir = False\n\n            if is_dir:\n                dirs.append(entry.name)\n            else:\n                nondirs.append(entry.name)\n\n            if not topdown and is_dir:\n                # Bottom-up: recurse into sub-directory, but exclude symlinks to\n                # directories if followlinks is False\n                if followlinks:\n                    walk_into = True\n                else:\n                    try:\n                        is_symlink = entry.is_symlink()\n                    except OSError:\n                        # If is_symlink() raises an OSError, consider that the\n                        # entry is not a symbolic link, same behaviour than\n                        # os.path.islink().\n                        is_symlink = False\n                    walk_into = not is_symlink\n\n                if walk_into:\n                    walk_dirs.append(entry.path)\n\n    # Yield before recursion if going top down\n    if topdown:\n        yield top, dirs, nondirs\n\n        # Recurse into sub-directories\n        islink, join = path.islink, path.join\n        for dirname in dirs:\n            new_path = join(top, dirname)\n            # Issue #23605: os.path.islink() is used instead of caching\n            # entry.is_symlink() result during the loop on os.scandir() because\n            # the caller can replace the directory entry during the \"yield\"\n            # above.\n            if followlinks or not islink(new_path):\n                yield from _walk(new_path, topdown, onerror, followlinks)\n    else:\n        # Recurse into sub-directories\n        for new_path in walk_dirs:\n            yield from _walk(new_path, topdown, onerror, followlinks)\n        # Yield after recursion if going bottom up\n        yield top, dirs, nondirs",
        "name_type": "stdlib"
    },
    "os.fwalk": {
        "API_name": "os.fwalk",
        "loc_name": "os.fwalk",
        "args": "top;topdown;onerror",
        "args_default": 3,
        "filepath": "os",
        "lineno": 430,
        "namespace": "*",
        "body": "    def fwalk(top=\".\", topdown=True, onerror=None, *, follow_symlinks=False, dir_fd=None):\n        \"\"\"Directory tree generator.\n\n        This behaves exactly like walk(), except that it yields a 4-tuple\n\n            dirpath, dirnames, filenames, dirfd\n\n        `dirpath`, `dirnames` and `filenames` are identical to walk() output,\n        and `dirfd` is a file descriptor referring to the directory `dirpath`.\n\n        The advantage of fwalk() over walk() is that it's safe against symlink\n        races (when follow_symlinks is False).\n\n        If dir_fd is not None, it should be a file descriptor open to a directory,\n          and top should be relative; top will then be relative to that directory.\n          (dir_fd is always supported for fwalk.)\n\n        Caution:\n        Since fwalk() yields file descriptors, those are only valid until the\n        next iteration step, so you should dup() them if you want to keep them\n        for a longer period.\n\n        Example:\n\n        import os\n        for root, dirs, files, rootfd in os.fwalk('python/Lib/email'):\n            print(root, \"consumes\", end=\"\")\n            print(sum(os.stat(name, dir_fd=rootfd).st_size for name in files),\n                  end=\"\")\n            print(\"bytes in\", len(files), \"non-directory files\")\n            if 'CVS' in dirs:\n                dirs.remove('CVS')  # don't visit CVS directories\n        \"\"\"\n        sys.audit(\"os.fwalk\", top, topdown, onerror, follow_symlinks, dir_fd)\n        if not isinstance(top, int) or not hasattr(top, '__index__'):\n            top = fspath(top)\n        # Note: To guard against symlink races, we use the standard\n        # lstat()/open()/fstat() trick.\n        if not follow_symlinks:\n            orig_st = stat(top, follow_symlinks=False, dir_fd=dir_fd)\n        topfd = open(top, O_RDONLY, dir_fd=dir_fd)\n        try:\n            if (follow_symlinks or (st.S_ISDIR(orig_st.st_mode) and\n                                    path.samestat(orig_st, stat(topfd)))):\n                yield from _fwalk(topfd, top, isinstance(top, bytes),\n                                  topdown, onerror, follow_symlinks)\n        finally:\n            close(topfd)",
        "name_type": "stdlib"
    },
    "os._fwalk": {
        "API_name": "os._fwalk",
        "loc_name": "os._fwalk",
        "args": "topfd;toppath;isbytes;topdown;onerror;follow_symlinks",
        "args_default": 0,
        "filepath": "os",
        "lineno": 479,
        "namespace": "*",
        "body": "    def _fwalk(topfd, toppath, isbytes, topdown, onerror, follow_symlinks):\n        # Note: This uses O(depth of the directory tree) file descriptors: if\n        # necessary, it can be adapted to only require O(1) FDs, see issue\n        # #13734.\n\n        scandir_it = scandir(topfd)\n        dirs = []\n        nondirs = []\n        entries = None if topdown or follow_symlinks else []\n        for entry in scandir_it:\n            name = entry.name\n            if isbytes:\n                name = fsencode(name)\n            try:\n                if entry.is_dir():\n                    dirs.append(name)\n                    if entries is not None:\n                        entries.append(entry)\n                else:\n                    nondirs.append(name)\n            except OSError:\n                try:\n                    # Add dangling symlinks, ignore disappeared files\n                    if entry.is_symlink():\n                        nondirs.append(name)\n                except OSError:\n                    pass\n\n        if topdown:\n            yield toppath, dirs, nondirs, topfd\n\n        for name in dirs if entries is None else zip(dirs, entries):\n            try:\n                if not follow_symlinks:\n                    if topdown:\n                        orig_st = stat(name, dir_fd=topfd, follow_symlinks=False)\n                    else:\n                        assert entries is not None\n                        name, entry = name\n                        orig_st = entry.stat(follow_symlinks=False)\n                dirfd = open(name, O_RDONLY, dir_fd=topfd)\n            except OSError as err:\n                if onerror is not None:\n                    onerror(err)\n                continue\n            try:\n                if follow_symlinks or path.samestat(orig_st, stat(dirfd)):\n                    dirpath = path.join(toppath, name)\n                    yield from _fwalk(dirfd, dirpath, isbytes,\n                                      topdown, onerror, follow_symlinks)\n            finally:\n                close(dirfd)\n\n        if not topdown:\n            yield toppath, dirs, nondirs, topfd",
        "name_type": "stdlib"
    },
    "os.execl": {
        "API_name": "os.execl",
        "loc_name": "os.execl",
        "args": "file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 537,
        "namespace": "*",
        "body": "def execl(file, *args):\n    \"\"\"execl(file, *args)\n\n    Execute the executable file with argument list args, replacing the\n    current process. \"\"\"\n    execv(file, args)",
        "name_type": "stdlib"
    },
    "os.execle": {
        "API_name": "os.execle",
        "loc_name": "os.execle",
        "args": "file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 544,
        "namespace": "*",
        "body": "def execle(file, *args):\n    \"\"\"execle(file, *args, env)\n\n    Execute the executable file with argument list args and\n    environment env, replacing the current process. \"\"\"\n    env = args[-1]\n    execve(file, args[:-1], env)",
        "name_type": "stdlib"
    },
    "os.execlp": {
        "API_name": "os.execlp",
        "loc_name": "os.execlp",
        "args": "file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 552,
        "namespace": "*",
        "body": "def execlp(file, *args):\n    \"\"\"execlp(file, *args)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args, replacing the current process. \"\"\"\n    execvp(file, args)",
        "name_type": "stdlib"
    },
    "os.execlpe": {
        "API_name": "os.execlpe",
        "loc_name": "os.execlpe",
        "args": "file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 559,
        "namespace": "*",
        "body": "def execlpe(file, *args):\n    \"\"\"execlpe(file, *args, env)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args and environment env, replacing the current\n    process. \"\"\"\n    env = args[-1]\n    execvpe(file, args[:-1], env)",
        "name_type": "stdlib"
    },
    "os.execvp": {
        "API_name": "os.execvp",
        "loc_name": "os.execvp",
        "args": "file;args",
        "args_default": 0,
        "filepath": "os",
        "lineno": 568,
        "namespace": "*",
        "body": "def execvp(file, args):\n    \"\"\"execvp(file, args)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args, replacing the current process.\n    args may be a list or tuple of strings. \"\"\"\n    _execvpe(file, args)",
        "name_type": "stdlib"
    },
    "os.execvpe": {
        "API_name": "os.execvpe",
        "loc_name": "os.execvpe",
        "args": "file;args;env",
        "args_default": 0,
        "filepath": "os",
        "lineno": 576,
        "namespace": "*",
        "body": "def execvpe(file, args, env):\n    \"\"\"execvpe(file, args, env)\n\n    Execute the executable file (which is searched for along $PATH)\n    with argument list args and environment env, replacing the\n    current process.\n    args may be a list or tuple of strings. \"\"\"\n    _execvpe(file, args, env)",
        "name_type": "stdlib"
    },
    "os._execvpe": {
        "API_name": "os._execvpe",
        "loc_name": "os._execvpe",
        "args": "file;args;env",
        "args_default": 1,
        "filepath": "os",
        "lineno": 587,
        "namespace": "*",
        "body": "def _execvpe(file, args, env=None):\n    if env is not None:\n        exec_func = execve\n        argrest = (args, env)\n    else:\n        exec_func = execv\n        argrest = (args,)\n        env = environ\n\n    if path.dirname(file):\n        exec_func(file, *argrest)\n        return\n    saved_exc = None\n    path_list = get_exec_path(env)\n    if name != 'nt':\n        file = fsencode(file)\n        path_list = map(fsencode, path_list)\n    for dir in path_list:\n        fullname = path.join(dir, file)\n        try:\n            exec_func(fullname, *argrest)\n        except (FileNotFoundError, NotADirectoryError) as e:\n            last_exc = e\n        except OSError as e:\n            last_exc = e\n            if saved_exc is None:\n                saved_exc = e\n    if saved_exc is not None:\n        raise saved_exc\n    raise last_exc",
        "name_type": "stdlib"
    },
    "os.get_exec_path": {
        "API_name": "os.get_exec_path",
        "loc_name": "os.get_exec_path",
        "args": "env",
        "args_default": 1,
        "filepath": "os",
        "lineno": 619,
        "namespace": "*",
        "body": "def get_exec_path(env=None):\n    \"\"\"Returns the sequence of directories that will be searched for the\n    named executable (similar to a shell) when launching a process.\n\n    *env* must be an environment variable dict or None.  If *env* is None,\n    os.environ will be used.\n    \"\"\"\n    # Use a local import instead of a global import to limit the number of\n    # modules loaded at startup: the os module is always loaded at startup by\n    # Python. It may also avoid a bootstrap issue.\n    import warnings\n\n    if env is None:\n        env = environ\n\n    # {b'PATH': ...}.get('PATH') and {'PATH': ...}.get(b'PATH') emit a\n    # BytesWarning when using python -b or python -bb: ignore the warning\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", BytesWarning)\n\n        try:\n            path_list = env.get('PATH')\n        except TypeError:\n            path_list = None\n\n        if supports_bytes_environ:\n            try:\n                path_listb = env[b'PATH']\n            except (KeyError, TypeError):\n                pass\n            else:\n                if path_list is not None:\n                    raise ValueError(\n                        \"env cannot contain 'PATH' and b'PATH' keys\")\n                path_list = path_listb\n\n            if path_list is not None and isinstance(path_list, bytes):\n                path_list = fsdecode(path_list)\n\n    if path_list is None:\n        path_list = defpath\n    return path_list.split(pathsep)",
        "name_type": "stdlib"
    },
    "os._Environ": {
        "API_name": "os._Environ",
        "loc_name": "os._Environ",
        "args": "*",
        "args_default": "*",
        "filepath": "os",
        "lineno": 666,
        "namespace": "_Environ",
        "body": "",
        "name_type": "stdlib"
    },
    "os._Environ.__init__": {
        "API_name": "os._Environ.__init__",
        "loc_name": "os._Environ.__init__",
        "args": "self;data;encodekey;decodekey;encodevalue;decodevalue",
        "args_default": 0,
        "filepath": "os",
        "lineno": 667,
        "namespace": "_Environ",
        "body": "    def __init__(self, data, encodekey, decodekey, encodevalue, decodevalue):\n        self.encodekey = encodekey\n        self.decodekey = decodekey\n        self.encodevalue = encodevalue\n        self.decodevalue = decodevalue\n        self._data = data",
        "name_type": "stdlib"
    },
    "os._Environ.__getitem__": {
        "API_name": "os._Environ.__getitem__",
        "loc_name": "os._Environ.__getitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "os",
        "lineno": 674,
        "namespace": "_Environ",
        "body": "    def __getitem__(self, key):\n        try:\n            value = self._data[self.encodekey(key)]\n        except KeyError:\n            # raise KeyError with the original key value\n            raise KeyError(key) from None\n        return self.decodevalue(value)",
        "name_type": "stdlib"
    },
    "os._Environ.__setitem__": {
        "API_name": "os._Environ.__setitem__",
        "loc_name": "os._Environ.__setitem__",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "os",
        "lineno": 682,
        "namespace": "_Environ",
        "body": "    def __setitem__(self, key, value):\n        key = self.encodekey(key)\n        value = self.encodevalue(value)\n        putenv(key, value)\n        self._data[key] = value",
        "name_type": "stdlib"
    },
    "os._Environ.__delitem__": {
        "API_name": "os._Environ.__delitem__",
        "loc_name": "os._Environ.__delitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "os",
        "lineno": 688,
        "namespace": "_Environ",
        "body": "    def __delitem__(self, key):\n        encodedkey = self.encodekey(key)\n        unsetenv(encodedkey)\n        try:\n            del self._data[encodedkey]\n        except KeyError:\n            # raise KeyError with the original key value\n            raise KeyError(key) from None",
        "name_type": "stdlib"
    },
    "os._Environ.__iter__": {
        "API_name": "os._Environ.__iter__",
        "loc_name": "os._Environ.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 697,
        "namespace": "_Environ",
        "body": "    def __iter__(self):\n        # list() from dict object is an atomic operation\n        keys = list(self._data)\n        for key in keys:\n            yield self.decodekey(key)",
        "name_type": "stdlib"
    },
    "os._Environ.__len__": {
        "API_name": "os._Environ.__len__",
        "loc_name": "os._Environ.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 703,
        "namespace": "_Environ",
        "body": "    def __len__(self):\n        return len(self._data)",
        "name_type": "stdlib"
    },
    "os._Environ.__repr__": {
        "API_name": "os._Environ.__repr__",
        "loc_name": "os._Environ.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 706,
        "namespace": "_Environ",
        "body": "    def __repr__(self):\n        return 'environ({{{}}})'.format(', '.join(\n            ('{!r}: {!r}'.format(self.decodekey(key), self.decodevalue(value))\n            for key, value in self._data.items())))",
        "name_type": "stdlib"
    },
    "os._Environ.copy": {
        "API_name": "os._Environ.copy",
        "loc_name": "os._Environ.copy",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 711,
        "namespace": "_Environ",
        "body": "    def copy(self):\n        return dict(self)",
        "name_type": "stdlib"
    },
    "os._Environ.setdefault": {
        "API_name": "os._Environ.setdefault",
        "loc_name": "os._Environ.setdefault",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "os",
        "lineno": 714,
        "namespace": "_Environ",
        "body": "    def setdefault(self, key, value):\n        if key not in self:\n            self[key] = value\n        return self[key]",
        "name_type": "stdlib"
    },
    "os._Environ.__ior__": {
        "API_name": "os._Environ.__ior__",
        "loc_name": "os._Environ.__ior__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "os",
        "lineno": 719,
        "namespace": "_Environ",
        "body": "    def __ior__(self, other):\n        self.update(other)\n        return self",
        "name_type": "stdlib"
    },
    "os._Environ.__or__": {
        "API_name": "os._Environ.__or__",
        "loc_name": "os._Environ.__or__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "os",
        "lineno": 723,
        "namespace": "_Environ",
        "body": "    def __or__(self, other):\n        if not isinstance(other, Mapping):\n            return NotImplemented\n        new = dict(self)\n        new.update(other)\n        return new",
        "name_type": "stdlib"
    },
    "os._Environ.__ror__": {
        "API_name": "os._Environ.__ror__",
        "loc_name": "os._Environ.__ror__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "os",
        "lineno": 730,
        "namespace": "_Environ",
        "body": "    def __ror__(self, other):\n        if not isinstance(other, Mapping):\n            return NotImplemented\n        new = dict(other)\n        new.update(self)\n        return new",
        "name_type": "stdlib"
    },
    "os._createenviron": {
        "API_name": "os._createenviron",
        "loc_name": "os._createenviron",
        "args": "",
        "args_default": 0,
        "filepath": "os",
        "lineno": 737,
        "namespace": "*",
        "body": "def _createenviron():\n    if name == 'nt':\n        # Where Env Var Names Must Be UPPERCASE\n        def check_str(value):\n            if not isinstance(value, str):\n                raise TypeError(\"str expected, not %s\" % type(value).__name__)\n            return value\n        encode = check_str\n        decode = str\n        def encodekey(key):\n            return encode(key).upper()\n        data = {}\n        for key, value in environ.items():\n            data[encodekey(key)] = value\n    else:\n        # Where Env Var Names Can Be Mixed Case\n        encoding = sys.getfilesystemencoding()\n        def encode(value):\n            if not isinstance(value, str):\n                raise TypeError(\"str expected, not %s\" % type(value).__name__)\n            return value.encode(encoding, 'surrogateescape')\n        def decode(value):\n            return value.decode(encoding, 'surrogateescape')\n        encodekey = encode\n        data = environ\n    return _Environ(data,\n        encodekey, decode,\n        encode, decode)",
        "name_type": "stdlib"
    },
    "os.getenv": {
        "API_name": "os.getenv",
        "loc_name": "os.getenv",
        "args": "key;default",
        "args_default": 1,
        "filepath": "os",
        "lineno": 771,
        "namespace": "*",
        "body": "def getenv(key, default=None):\n    \"\"\"Get an environment variable, return None if it doesn't exist.\n    The optional second argument can specify an alternate default.\n    key, default and the result are str.\"\"\"\n    return environ.get(key, default)",
        "name_type": "stdlib"
    },
    "os._check_bytes": {
        "API_name": "os._check_bytes",
        "loc_name": "os._check_bytes",
        "args": "value",
        "args_default": 0,
        "filepath": "os",
        "lineno": 781,
        "namespace": "*",
        "body": "    def _check_bytes(value):\n        if not isinstance(value, bytes):\n            raise TypeError(\"bytes expected, not %s\" % type(value).__name__)\n        return value",
        "name_type": "stdlib"
    },
    "os.getenvb": {
        "API_name": "os.getenvb",
        "loc_name": "os.getenvb",
        "args": "key;default",
        "args_default": 1,
        "filepath": "os",
        "lineno": 792,
        "namespace": "*",
        "body": "    def getenvb(key, default=None):\n        \"\"\"Get an environment variable, return None if it doesn't exist.\n        The optional second argument can specify an alternate default.\n        key, default and the result are bytes.\"\"\"\n        return environb.get(key, default)",
        "name_type": "stdlib"
    },
    "os._fscodec": {
        "API_name": "os._fscodec",
        "loc_name": "os._fscodec",
        "args": "",
        "args_default": 0,
        "filepath": "os",
        "lineno": 800,
        "namespace": "*",
        "body": "def _fscodec():\n    encoding = sys.getfilesystemencoding()\n    errors = sys.getfilesystemencodeerrors()\n\n    def fsencode(filename):\n        \"\"\"Encode filename (an os.PathLike, bytes, or str) to the filesystem\n        encoding with 'surrogateescape' error handler, return bytes unchanged.\n        On Windows, use 'strict' error handler if the file system encoding is\n        'mbcs' (which is the default encoding).\n        \"\"\"\n        filename = fspath(filename)  # Does type-checking of `filename`.\n        if isinstance(filename, str):\n            return filename.encode(encoding, errors)\n        else:\n            return filename\n\n    def fsdecode(filename):\n        \"\"\"Decode filename (an os.PathLike, bytes, or str) from the filesystem\n        encoding with 'surrogateescape' error handler, return str unchanged. On\n        Windows, use 'strict' error handler if the file system encoding is\n        'mbcs' (which is the default encoding).\n        \"\"\"\n        filename = fspath(filename)  # Does type-checking of `filename`.\n        if isinstance(filename, bytes):\n            return filename.decode(encoding, errors)\n        else:\n            return filename\n\n    return fsencode, fsdecode",
        "name_type": "stdlib"
    },
    "os._fscodec.fsencode": {
        "API_name": "os._fscodec.fsencode",
        "loc_name": "os._fscodec.fsencode",
        "args": "filename",
        "args_default": 0,
        "filepath": "os",
        "lineno": 804,
        "namespace": "*",
        "body": "    def fsencode(filename):\n        \"\"\"Encode filename (an os.PathLike, bytes, or str) to the filesystem\n        encoding with 'surrogateescape' error handler, return bytes unchanged.\n        On Windows, use 'strict' error handler if the file system encoding is\n        'mbcs' (which is the default encoding).\n        \"\"\"\n        filename = fspath(filename)  # Does type-checking of `filename`.\n        if isinstance(filename, str):\n            return filename.encode(encoding, errors)\n        else:\n            return filename",
        "name_type": "stdlib"
    },
    "os._fscodec.fsdecode": {
        "API_name": "os._fscodec.fsdecode",
        "loc_name": "os._fscodec.fsdecode",
        "args": "filename",
        "args_default": 0,
        "filepath": "os",
        "lineno": 816,
        "namespace": "*",
        "body": "    def fsdecode(filename):\n        \"\"\"Decode filename (an os.PathLike, bytes, or str) from the filesystem\n        encoding with 'surrogateescape' error handler, return str unchanged. On\n        Windows, use 'strict' error handler if the file system encoding is\n        'mbcs' (which is the default encoding).\n        \"\"\"\n        filename = fspath(filename)  # Does type-checking of `filename`.\n        if isinstance(filename, bytes):\n            return filename.decode(encoding, errors)\n        else:\n            return filename",
        "name_type": "stdlib"
    },
    "os._spawnvef": {
        "API_name": "os._spawnvef",
        "loc_name": "os._spawnvef",
        "args": "mode;file;args;env;func",
        "args_default": 0,
        "filepath": "os",
        "lineno": 845,
        "namespace": "*",
        "body": "    def _spawnvef(mode, file, args, env, func):\n        # Internal helper; func is the exec*() function to use\n        if not isinstance(args, (tuple, list)):\n            raise TypeError('argv must be a tuple or a list')\n        if not args or not args[0]:\n            raise ValueError('argv first element cannot be empty')\n        pid = fork()\n        if not pid:\n            # Child\n            try:\n                if env is None:\n                    func(file, args)\n                else:\n                    func(file, args, env)\n            except:\n                _exit(127)\n        else:\n            # Parent\n            if mode == P_NOWAIT:\n                return pid # Caller is responsible for waiting!\n            while 1:\n                wpid, sts = waitpid(pid, 0)\n                if WIFSTOPPED(sts):\n                    continue\n\n                return waitstatus_to_exitcode(sts)",
        "name_type": "stdlib"
    },
    "os.spawnv": {
        "API_name": "os.spawnv",
        "loc_name": "os.spawnv",
        "args": "mode;file;args",
        "args_default": 0,
        "filepath": "os",
        "lineno": 872,
        "namespace": "*",
        "body": "    def spawnv(mode, file, args):\n        \"\"\"spawnv(mode, file, args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execv)",
        "name_type": "stdlib"
    },
    "os.spawnve": {
        "API_name": "os.spawnve",
        "loc_name": "os.spawnve",
        "args": "mode;file;args;env",
        "args_default": 0,
        "filepath": "os",
        "lineno": 881,
        "namespace": "*",
        "body": "    def spawnve(mode, file, args, env):\n        \"\"\"spawnve(mode, file, args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nspecified environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execve)",
        "name_type": "stdlib"
    },
    "os.spawnvp": {
        "API_name": "os.spawnvp",
        "loc_name": "os.spawnvp",
        "args": "mode;file;args",
        "args_default": 0,
        "filepath": "os",
        "lineno": 893,
        "namespace": "*",
        "body": "    def spawnvp(mode, file, args):\n        \"\"\"spawnvp(mode, file, args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, None, execvp)",
        "name_type": "stdlib"
    },
    "os.spawnvpe": {
        "API_name": "os.spawnvpe",
        "loc_name": "os.spawnvpe",
        "args": "mode;file;args;env",
        "args_default": 0,
        "filepath": "os",
        "lineno": 903,
        "namespace": "*",
        "body": "    def spawnvpe(mode, file, args, env):\n        \"\"\"spawnvpe(mode, file, args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return _spawnvef(mode, file, args, env, execvpe)",
        "name_type": "stdlib"
    },
    "os.spawnl": {
        "API_name": "os.spawnl",
        "loc_name": "os.spawnl",
        "args": "mode;file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 921,
        "namespace": "*",
        "body": "    def spawnl(mode, file, *args):\n        \"\"\"spawnl(mode, file, *args) -> integer\n\nExecute file with arguments from args in a subprocess.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnv(mode, file, args)",
        "name_type": "stdlib"
    },
    "os.spawnle": {
        "API_name": "os.spawnle",
        "loc_name": "os.spawnle",
        "args": "mode;file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 930,
        "namespace": "*",
        "body": "    def spawnle(mode, file, *args):\n        \"\"\"spawnle(mode, file, *args, env) -> integer\n\nExecute file with arguments from args in a subprocess with the\nsupplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnve(mode, file, args[:-1], env)",
        "name_type": "stdlib"
    },
    "os.spawnlp": {
        "API_name": "os.spawnlp",
        "loc_name": "os.spawnlp",
        "args": "mode;file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 948,
        "namespace": "*",
        "body": "    def spawnlp(mode, file, *args):\n        \"\"\"spawnlp(mode, file, *args) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        return spawnvp(mode, file, args)",
        "name_type": "stdlib"
    },
    "os.spawnlpe": {
        "API_name": "os.spawnlpe",
        "loc_name": "os.spawnlpe",
        "args": "mode;file",
        "args_default": 0,
        "filepath": "os",
        "lineno": 958,
        "namespace": "*",
        "body": "    def spawnlpe(mode, file, *args):\n        \"\"\"spawnlpe(mode, file, *args, env) -> integer\n\nExecute file (which is looked for along $PATH) with arguments from\nargs in a subprocess with the supplied environment.\nIf mode == P_NOWAIT return the pid of the process.\nIf mode == P_WAIT return the process's exit code if it exits normally;\notherwise return -SIG, where SIG is the signal that killed it. \"\"\"\n        env = args[-1]\n        return spawnvpe(mode, file, args[:-1], env)",
        "name_type": "stdlib"
    },
    "os.popen": {
        "API_name": "os.popen",
        "loc_name": "os.popen",
        "args": "cmd;mode;buffering",
        "args_default": 2,
        "filepath": "os",
        "lineno": 974,
        "namespace": "*",
        "body": "def popen(cmd, mode=\"r\", buffering=-1):\n    if not isinstance(cmd, str):\n        raise TypeError(\"invalid cmd type (%s, expected string)\" % type(cmd))\n    if mode not in (\"r\", \"w\"):\n        raise ValueError(\"invalid mode %r\" % mode)\n    if buffering == 0 or buffering is None:\n        raise ValueError(\"popen() does not support unbuffered streams\")\n    import subprocess, io\n    if mode == \"r\":\n        proc = subprocess.Popen(cmd,\n                                shell=True,\n                                stdout=subprocess.PIPE,\n                                bufsize=buffering)\n        return _wrap_close(io.TextIOWrapper(proc.stdout), proc)\n    else:\n        proc = subprocess.Popen(cmd,\n                                shell=True,\n                                stdin=subprocess.PIPE,\n                                bufsize=buffering)\n        return _wrap_close(io.TextIOWrapper(proc.stdin), proc)",
        "name_type": "stdlib"
    },
    "os._wrap_close": {
        "API_name": "os._wrap_close",
        "loc_name": "os._wrap_close",
        "args": "*",
        "args_default": "*",
        "filepath": "os",
        "lineno": 996,
        "namespace": "_wrap_close",
        "body": "",
        "name_type": "stdlib"
    },
    "os._wrap_close.__init__": {
        "API_name": "os._wrap_close.__init__",
        "loc_name": "os._wrap_close.__init__",
        "args": "self;stream;proc",
        "args_default": 0,
        "filepath": "os",
        "lineno": 997,
        "namespace": "_wrap_close",
        "body": "    def __init__(self, stream, proc):\n        self._stream = stream\n        self._proc = proc",
        "name_type": "stdlib"
    },
    "os._wrap_close.close": {
        "API_name": "os._wrap_close.close",
        "loc_name": "os._wrap_close.close",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1000,
        "namespace": "_wrap_close",
        "body": "    def close(self):\n        self._stream.close()\n        returncode = self._proc.wait()\n        if returncode == 0:\n            return None\n        if name == 'nt':\n            return returncode\n        else:\n            return returncode << 8  # Shift left to match old behavior",
        "name_type": "stdlib"
    },
    "os._wrap_close.__enter__": {
        "API_name": "os._wrap_close.__enter__",
        "loc_name": "os._wrap_close.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1009,
        "namespace": "_wrap_close",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "os._wrap_close.__exit__": {
        "API_name": "os._wrap_close.__exit__",
        "loc_name": "os._wrap_close.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1011,
        "namespace": "_wrap_close",
        "body": "    def __exit__(self, *args):\n        self.close()",
        "name_type": "stdlib"
    },
    "os._wrap_close.__getattr__": {
        "API_name": "os._wrap_close.__getattr__",
        "loc_name": "os._wrap_close.__getattr__",
        "args": "self;name",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1013,
        "namespace": "_wrap_close",
        "body": "    def __getattr__(self, name):\n        return getattr(self._stream, name)",
        "name_type": "stdlib"
    },
    "os._wrap_close.__iter__": {
        "API_name": "os._wrap_close.__iter__",
        "loc_name": "os._wrap_close.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1015,
        "namespace": "_wrap_close",
        "body": "    def __iter__(self):\n        return iter(self._stream)",
        "name_type": "stdlib"
    },
    "os.fdopen": {
        "API_name": "os.fdopen",
        "loc_name": "os.fdopen",
        "args": "fd",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1019,
        "namespace": "*",
        "body": "def fdopen(fd, *args, **kwargs):\n    if not isinstance(fd, int):\n        raise TypeError(\"invalid fd type (%s, expected integer)\" % type(fd))\n    import io\n    return io.open(fd, *args, **kwargs)",
        "name_type": "stdlib"
    },
    "os._fspath": {
        "API_name": "os._fspath",
        "loc_name": "os._fspath",
        "args": "path",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1028,
        "namespace": "*",
        "body": "def _fspath(path):\n    \"\"\"Return the path representation of a path-like object.\n\n    If str or bytes is passed in, it is returned unchanged. Otherwise the\n    os.PathLike interface is used to get the path representation. If the\n    path representation is not str or bytes, TypeError is raised. If the\n    provided path is not str, bytes, or os.PathLike, TypeError is raised.\n    \"\"\"\n    if isinstance(path, (str, bytes)):\n        return path\n\n    # Work from the object's type to match method resolution of other magic\n    # methods.\n    path_type = type(path)\n    try:\n        path_repr = path_type.__fspath__(path)\n    except AttributeError:\n        if hasattr(path_type, '__fspath__'):\n            raise\n        else:\n            raise TypeError(\"expected str, bytes or os.PathLike object, \"\n                            \"not \" + path_type.__name__)\n    if isinstance(path_repr, (str, bytes)):\n        return path_repr\n    else:\n        raise TypeError(\"expected {}.__fspath__() to return str or bytes, \"\n                        \"not {}\".format(path_type.__name__,\n                                        type(path_repr).__name__))",
        "name_type": "stdlib"
    },
    "os.PathLike.__fspath__": {
        "API_name": "os.PathLike.__fspath__",
        "loc_name": "os.PathLike.__fspath__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1069,
        "namespace": "PathLike",
        "body": "    def __fspath__(self):\n        \"\"\"Return the file system path representation of the object.\"\"\"\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "os.PathLike.__subclasshook__": {
        "API_name": "os.PathLike.__subclasshook__",
        "loc_name": "os.PathLike.__subclasshook__",
        "args": "cls;subclass",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1074,
        "namespace": "PathLike",
        "body": "    def __subclasshook__(cls, subclass):\n        if cls is PathLike:\n            return _check_methods(subclass, '__fspath__')\n        return NotImplemented",
        "name_type": "stdlib"
    },
    "os.PathLike": {
        "API_name": "os.PathLike",
        "loc_name": "os.PathLike",
        "args": "*",
        "args_default": "*",
        "filepath": "os",
        "lineno": 1064,
        "namespace": "PathLike",
        "body": "",
        "name_type": "stdlib"
    },
    "os._AddedDllDirectory": {
        "API_name": "os._AddedDllDirectory",
        "loc_name": "os._AddedDllDirectory",
        "args": "*",
        "args_default": "*",
        "filepath": "os",
        "lineno": 1083,
        "namespace": "_AddedDllDirectory",
        "body": "",
        "name_type": "stdlib"
    },
    "os._AddedDllDirectory.__init__": {
        "API_name": "os._AddedDllDirectory.__init__",
        "loc_name": "os._AddedDllDirectory.__init__",
        "args": "self;path;cookie;remove_dll_directory",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1084,
        "namespace": "_AddedDllDirectory",
        "body": "        def __init__(self, path, cookie, remove_dll_directory):\n            self.path = path\n            self._cookie = cookie\n            self._remove_dll_directory = remove_dll_directory",
        "name_type": "stdlib"
    },
    "os._AddedDllDirectory.close": {
        "API_name": "os._AddedDllDirectory.close",
        "loc_name": "os._AddedDllDirectory.close",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1088,
        "namespace": "_AddedDllDirectory",
        "body": "        def close(self):\n            self._remove_dll_directory(self._cookie)\n            self.path = None",
        "name_type": "stdlib"
    },
    "os._AddedDllDirectory.__enter__": {
        "API_name": "os._AddedDllDirectory.__enter__",
        "loc_name": "os._AddedDllDirectory.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1091,
        "namespace": "_AddedDllDirectory",
        "body": "        def __enter__(self):\n            return self",
        "name_type": "stdlib"
    },
    "os._AddedDllDirectory.__exit__": {
        "API_name": "os._AddedDllDirectory.__exit__",
        "loc_name": "os._AddedDllDirectory.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1093,
        "namespace": "_AddedDllDirectory",
        "body": "        def __exit__(self, *args):\n            self.close()",
        "name_type": "stdlib"
    },
    "os._AddedDllDirectory.__repr__": {
        "API_name": "os._AddedDllDirectory.__repr__",
        "loc_name": "os._AddedDllDirectory.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1095,
        "namespace": "_AddedDllDirectory",
        "body": "        def __repr__(self):\n            if self.path:\n                return \"<AddedDllDirectory({!r})>\".format(self.path)\n            return \"<AddedDllDirectory()>\"",
        "name_type": "stdlib"
    },
    "os.add_dll_directory": {
        "API_name": "os.add_dll_directory",
        "loc_name": "os.add_dll_directory",
        "args": "path",
        "args_default": 0,
        "filepath": "os",
        "lineno": 1100,
        "namespace": "*",
        "body": "    def add_dll_directory(path):\n        \"\"\"Add a path to the DLL search path.\n\n        This search path is used when resolving dependencies for imported\n        extension modules (the module itself is resolved through sys.path),\n        and also by ctypes.\n\n        Remove the directory by calling close() on the returned object or\n        using it in a with statement.\n        \"\"\"\n        import nt\n        cookie = nt._add_dll_directory(path)\n        return _AddedDllDirectory(\n            path,\n            cookie,\n            nt._remove_dll_directory\n        )",
        "name_type": "stdlib"
    },
    "platform": {
        "API_name": "platform",
        "loc_name": "platform",
        "args": "*",
        "args_default": "*",
        "filepath": "platform",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\" This module tries to retrieve as much platform-identifying data as\n    possible. It makes this information available via function APIs.\n\n    If called from the command line, it prints the platform\n    information concatenated as single string to stdout. The output\n    format is useable as part of a filename.\n\n\"\"\"\n__copyright__ = \"\"\"\n    Copyright (c) 1999-2000, Marc-Andre Lemburg; mailto:mal@lemburg.com\n    Copyright (c) 2000-2010, eGenix.com Software GmbH; mailto:info@egenix.com\n\n    Permission to use, copy, modify, and distribute this software and its\n    documentation for any purpose and without fee or royalty is hereby granted,\n    provided that the above copyright notice appear in all copies and that\n    both that copyright notice and this permission notice appear in\n    supporting documentation or portions thereof, including modifications,\n    that you make.\n\n    EGENIX.COM SOFTWARE GMBH DISCLAIMS ALL WARRANTIES WITH REGARD TO\n    THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND\n    FITNESS, IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL,\n    INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING\n    FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT,\n    NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION\n    WITH THE USE OR PERFORMANCE OF THIS SOFTWARE !\n\n\"\"\"\n__version__ = '1.0.8'\n_ver_stages = {\n    # any string not found in this dict, will get 0 assigned\n    'dev': 10,\n    'alpha': 20, 'a': 20,\n    'beta': 30, 'b': 30,\n    'c': 40,\n    'RC': 50, 'rc': 50,\n    # number, will get 100 assigned\n    'pl': 200, 'p': 200,\n}\n_component_re = re.compile(r'([0-9]+|[._+-])')\n_libc_search = re.compile(b'(__libc_init)'\n                          b'|'\n                          b'(GLIBC_([0-9.]+))'\n                          b'|'\n                          br'(libc(_\\w+)?\\.so(?:\\.(\\d[0-9.]*))?)', re.ASCII)\n_ver_output = re.compile(r'(?:([\\w ]+) ([\\w.]+) '\n                         r'.*'\n                         r'\\[.* ([\\d.]+)\\])')\n_WIN32_CLIENT_RELEASES = {\n    (5, 0): \"2000\",\n    (5, 1): \"XP\",\n    # Strictly, 5.2 client is XP 64-bit, but platform.py historically\n    # has always called it 2003 Server\n    (5, 2): \"2003Server\",\n    (5, None): \"post2003\",\n\n    (6, 0): \"Vista\",\n    (6, 1): \"7\",\n    (6, 2): \"8\",\n    (6, 3): \"8.1\",\n    (6, None): \"post8.1\",\n\n    (10, 0): \"10\",\n    (10, None): \"post10\",\n}\n_WIN32_SERVER_RELEASES = {\n    (5, 2): \"2003Server\",\n\n    (6, 0): \"2008Server\",\n    (6, 1): \"2008ServerR2\",\n    (6, 2): \"2012Server\",\n    (6, 3): \"2012ServerR2\",\n    (6, None): \"post2012ServerR2\",\n}\n_default_architecture = {\n    'win32': ('', 'WindowsPE'),\n    'win16': ('', 'Windows'),\n    'dos': ('', 'MSDOS'),\n}\n_uname_cache = None\n_sys_version_parser = re.compile(\n    r'([\\w.+]+)\\s*'  # \"version<space>\"\n    r'(?:\\|[^|]*\\|)?\\s*' # version extra\n    r'\\(#?([^,]+)'  # \"(#buildno\"\n    r'(?:,\\s*([\\w ]*)'  # \", builddate\"\n    r'(?:,\\s*([\\w :]*))?)?\\)\\s*'  # \", buildtime)<space>\"\n    r'\\[([^\\]]+)\\]?', re.ASCII)  # \"[compiler]\"\n_ironpython_sys_version_parser = re.compile(\n    r'IronPython\\s*'\n    r'([\\d\\.]+)'\n    r'(?: \\(([\\d\\.]+)\\))?'\n    r' on (.NET [\\d\\.]+)', re.ASCII)\n_ironpython26_sys_version_parser = re.compile(\n    r'([\\d.]+)\\s*'\n    r'\\(IronPython\\s*'\n    r'[\\d.]+\\s*'\n    r'\\(([\\d.]+)\\) on ([\\w.]+ [\\d.]+(?: \\(\\d+-bit\\))?)\\)'\n)\n_pypy_sys_version_parser = re.compile(\n    r'([\\w.+]+)\\s*'\n    r'\\(#?([^,]+),\\s*([\\w ]+),\\s*([\\w :]+)\\)\\s*'\n    r'\\[PyPy [^\\]]+\\]?')\n_sys_version_cache = {}\n_platform_cache = {}\nif __name__ == '__main__':\n    # Default is to print the aliased verbose platform string\n    terse = ('terse' in sys.argv or '--terse' in sys.argv)\n    aliased = (not 'nonaliased' in sys.argv and not '--nonaliased' in sys.argv)\n    print(platform(aliased, terse))\n    sys.exit(0)",
        "name_type": "stdlib"
    },
    "platform._comparable_version": {
        "API_name": "platform._comparable_version",
        "loc_name": "platform._comparable_version",
        "args": "version",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 142,
        "namespace": "*",
        "body": "def _comparable_version(version):\n    result = []\n    for v in _component_re.split(version):\n        if v not in '._+-':\n            try:\n                v = int(v, 10)\n                t = 100\n            except ValueError:\n                t = _ver_stages.get(v, 0)\n            result.extend((t, v))\n    return result",
        "name_type": "stdlib"
    },
    "platform.libc_ver": {
        "API_name": "platform.libc_ver",
        "loc_name": "platform.libc_ver",
        "args": "executable;lib;version;chunksize",
        "args_default": 4,
        "filepath": "platform",
        "lineno": 162,
        "namespace": "*",
        "body": "def libc_ver(executable=None, lib='', version='', chunksize=16384):\n\n    \"\"\" Tries to determine the libc version that the file executable\n        (which defaults to the Python interpreter) is linked against.\n\n        Returns a tuple of strings (lib,version) which default to the\n        given parameters in case the lookup fails.\n\n        Note that the function has intimate knowledge of how different\n        libc versions add symbols to the executable and thus is probably\n        only useable for executables compiled using gcc.\n\n        The file is read and scanned in chunks of chunksize bytes.\n\n    \"\"\"\n    if executable is None:\n        try:\n            ver = os.confstr('CS_GNU_LIBC_VERSION')\n            # parse 'glibc 2.28' as ('glibc', '2.28')\n            parts = ver.split(maxsplit=1)\n            if len(parts) == 2:\n                return tuple(parts)\n        except (AttributeError, ValueError, OSError):\n            # os.confstr() or CS_GNU_LIBC_VERSION value not available\n            pass\n\n        executable = sys.executable\n\n    V = _comparable_version\n    if hasattr(os.path, 'realpath'):\n        # Python 2.2 introduced os.path.realpath(); it is used\n        # here to work around problems with Cygwin not being\n        # able to open symlinks for reading\n        executable = os.path.realpath(executable)\n    with open(executable, 'rb') as f:\n        binary = f.read(chunksize)\n        pos = 0\n        while pos < len(binary):\n            if b'libc' in binary or b'GLIBC' in binary:\n                m = _libc_search.search(binary, pos)\n            else:\n                m = None\n            if not m or m.end() == len(binary):\n                chunk = f.read(chunksize)\n                if chunk:\n                    binary = binary[max(pos, len(binary) - 1000):] + chunk\n                    pos = 0\n                    continue\n                if not m:\n                    break\n            libcinit, glibc, glibcversion, so, threads, soversion = [\n                s.decode('latin1') if s is not None else s\n                for s in m.groups()]\n            if libcinit and not lib:\n                lib = 'libc'\n            elif glibc:\n                if lib != 'glibc':\n                    lib = 'glibc'\n                    version = glibcversion\n                elif V(glibcversion) > V(version):\n                    version = glibcversion\n            elif so:\n                if lib != 'glibc':\n                    lib = 'libc'\n                    if soversion and (not version or V(soversion) > V(version)):\n                        version = soversion\n                    if threads and version[-len(threads):] != threads:\n                        version = version + threads\n            pos = m.end()\n    return lib, version",
        "name_type": "stdlib"
    },
    "platform._norm_version": {
        "API_name": "platform._norm_version",
        "loc_name": "platform._norm_version",
        "args": "version;build",
        "args_default": 1,
        "filepath": "platform",
        "lineno": 233,
        "namespace": "*",
        "body": "def _norm_version(version, build=''):\n\n    \"\"\" Normalize the version and build strings and return a single\n        version string using the format major.minor.build (or patchlevel).\n    \"\"\"\n    l = version.split('.')\n    if build:\n        l.append(build)\n    try:\n        strings = list(map(str, map(int, l)))\n    except ValueError:\n        strings = l\n    version = '.'.join(strings[:3])\n    return version",
        "name_type": "stdlib"
    },
    "platform._syscmd_ver": {
        "API_name": "platform._syscmd_ver",
        "loc_name": "platform._syscmd_ver",
        "args": "system;release;version;supported_platforms",
        "args_default": 4,
        "filepath": "platform",
        "lineno": 261,
        "namespace": "*",
        "body": "def _syscmd_ver(system='', release='', version='',\n\n               supported_platforms=('win32', 'win16', 'dos')):\n\n    \"\"\" Tries to figure out the OS version used and returns\n        a tuple (system, release, version).\n\n        It uses the \"ver\" shell command for this which is known\n        to exists on Windows, DOS. XXX Others too ?\n\n        In case this fails, the given parameters are used as\n        defaults.\n\n    \"\"\"\n    if sys.platform not in supported_platforms:\n        return system, release, version\n\n    # Try some common cmd strings\n    import subprocess\n    for cmd in ('ver', 'command /c ver', 'cmd /c ver'):\n        try:\n            info = subprocess.check_output(cmd,\n                                           stdin=subprocess.DEVNULL,\n                                           stderr=subprocess.DEVNULL,\n                                           text=True,\n                                           shell=True)\n        except (OSError, subprocess.CalledProcessError) as why:\n            #print('Command %s failed: %s' % (cmd, why))\n            continue\n        else:\n            break\n    else:\n        return system, release, version\n\n    # Parse the output\n    info = info.strip()\n    m = _ver_output.match(info)\n    if m is not None:\n        system, release, version = m.groups()\n        # Strip trailing dots from version and release\n        if release[-1] == '.':\n            release = release[:-1]\n        if version[-1] == '.':\n            version = version[:-1]\n        # Normalize the version and build strings (eliminating additional\n        # zeros)\n        version = _norm_version(version)\n    return system, release, version",
        "name_type": "stdlib"
    },
    "platform.win32_is_iot": {
        "API_name": "platform.win32_is_iot",
        "loc_name": "platform.win32_is_iot",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 339,
        "namespace": "*",
        "body": "def win32_is_iot():\n    return win32_edition() in ('IoTUAP', 'NanoServer', 'WindowsCoreHeadless', 'IoTEdgeOS')",
        "name_type": "stdlib"
    },
    "platform.win32_edition": {
        "API_name": "platform.win32_edition",
        "loc_name": "platform.win32_edition",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 342,
        "namespace": "*",
        "body": "def win32_edition():\n    try:\n        try:\n            import winreg\n        except ImportError:\n            import _winreg as winreg\n    except ImportError:\n        pass\n    else:\n        try:\n            cvkey = r'SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion'\n            with winreg.OpenKeyEx(winreg.HKEY_LOCAL_MACHINE, cvkey) as key:\n                return winreg.QueryValueEx(key, 'EditionId')[0]\n        except OSError:\n            pass\n\n    return None",
        "name_type": "stdlib"
    },
    "platform.win32_ver": {
        "API_name": "platform.win32_ver",
        "loc_name": "platform.win32_ver",
        "args": "release;version;csd;ptype",
        "args_default": 4,
        "filepath": "platform",
        "lineno": 360,
        "namespace": "*",
        "body": "def win32_ver(release='', version='', csd='', ptype=''):\n    try:\n        from sys import getwindowsversion\n    except ImportError:\n        return release, version, csd, ptype\n\n    winver = getwindowsversion()\n    try:\n        major, minor, build = map(int, _syscmd_ver()[2].split('.'))\n    except ValueError:\n        major, minor, build = winver.platform_version or winver[:3]\n    version = '{0}.{1}.{2}'.format(major, minor, build)\n\n    release = (_WIN32_CLIENT_RELEASES.get((major, minor)) or\n               _WIN32_CLIENT_RELEASES.get((major, None)) or\n               release)\n\n    # getwindowsversion() reflect the compatibility mode Python is\n    # running under, and so the service pack value is only going to be\n    # valid if the versions match.\n    if winver[:2] == (major, minor):\n        try:\n            csd = 'SP{}'.format(winver.service_pack_major)\n        except AttributeError:\n            if csd[:13] == 'Service Pack ':\n                csd = 'SP' + csd[13:]\n\n    # VER_NT_SERVER = 3\n    if getattr(winver, 'product_type', None) == 3:\n        release = (_WIN32_SERVER_RELEASES.get((major, minor)) or\n                   _WIN32_SERVER_RELEASES.get((major, None)) or\n                   release)\n\n    try:\n        try:\n            import winreg\n        except ImportError:\n            import _winreg as winreg\n    except ImportError:\n        pass\n    else:\n        try:\n            cvkey = r'SOFTWARE\\Microsoft\\Windows NT\\CurrentVersion'\n            with winreg.OpenKeyEx(winreg.HKEY_LOCAL_MACHINE, cvkey) as key:\n                ptype = winreg.QueryValueEx(key, 'CurrentType')[0]\n        except OSError:\n            pass\n\n    return release, version, csd, ptype",
        "name_type": "stdlib"
    },
    "platform._mac_ver_xml": {
        "API_name": "platform._mac_ver_xml",
        "loc_name": "platform._mac_ver_xml",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 411,
        "namespace": "*",
        "body": "def _mac_ver_xml():\n    fn = '/System/Library/CoreServices/SystemVersion.plist'\n    if not os.path.exists(fn):\n        if 'SDKROOT' in os.environ:\n            fn = os.environ['SDKROOT'] + fn\n            if not os.path.exists(fn):\n                return None\n        else:\n            return None\n\n    try:\n        import plistlib\n    except ImportError:\n        return None\n\n    with open(fn, 'rb') as f:\n        pl = plistlib.load(f)\n    release = pl['ProductVersion']\n    versioninfo = ('', '', '')\n    machine = os.uname().machine\n    if machine in ('ppc', 'Power Macintosh'):\n        # Canonical name\n        machine = 'PowerPC'\n\n    return release, versioninfo, machine",
        "name_type": "stdlib"
    },
    "platform.mac_ver": {
        "API_name": "platform.mac_ver",
        "loc_name": "platform.mac_ver",
        "args": "release;versioninfo;machine",
        "args_default": 3,
        "filepath": "platform",
        "lineno": 438,
        "namespace": "*",
        "body": "def mac_ver(release='', versioninfo=('', '', ''), machine=''):\n\n    \"\"\" Get macOS version information and return it as tuple (release,\n        versioninfo, machine) with versioninfo being a tuple (version,\n        dev_stage, non_release_version).\n\n        Entries which cannot be determined are set to the parameter values\n        which default to ''. All tuple entries are strings.\n    \"\"\"\n\n    # First try reading the information from an XML file which should\n    # always be present\n    info = _mac_ver_xml()\n    if info is not None:\n        return info\n\n    # If that also doesn't work return the default values\n    return release, versioninfo, machine",
        "name_type": "stdlib"
    },
    "platform._java_getprop": {
        "API_name": "platform._java_getprop",
        "loc_name": "platform._java_getprop",
        "args": "name;default",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 457,
        "namespace": "*",
        "body": "def _java_getprop(name, default):\n\n    from java.lang import System\n    try:\n        value = System.getProperty(name)\n        if value is None:\n            return default\n        return value\n    except AttributeError:\n        return default",
        "name_type": "stdlib"
    },
    "platform.java_ver": {
        "API_name": "platform.java_ver",
        "loc_name": "platform.java_ver",
        "args": "release;vendor;vminfo;osinfo",
        "args_default": 4,
        "filepath": "platform",
        "lineno": 468,
        "namespace": "*",
        "body": "def java_ver(release='', vendor='', vminfo=('', '', ''), osinfo=('', '', '')):\n\n    \"\"\" Version interface for Jython.\n\n        Returns a tuple (release, vendor, vminfo, osinfo) with vminfo being\n        a tuple (vm_name, vm_release, vm_vendor) and osinfo being a\n        tuple (os_name, os_version, os_arch).\n\n        Values which cannot be determined are set to the defaults\n        given as parameters (which all default to '').\n\n    \"\"\"\n    # Import the needed APIs\n    try:\n        import java.lang\n    except ImportError:\n        return release, vendor, vminfo, osinfo\n\n    vendor = _java_getprop('java.vendor', vendor)\n    release = _java_getprop('java.version', release)\n    vm_name, vm_release, vm_vendor = vminfo\n    vm_name = _java_getprop('java.vm.name', vm_name)\n    vm_vendor = _java_getprop('java.vm.vendor', vm_vendor)\n    vm_release = _java_getprop('java.vm.version', vm_release)\n    vminfo = vm_name, vm_release, vm_vendor\n    os_name, os_version, os_arch = osinfo\n    os_arch = _java_getprop('java.os.arch', os_arch)\n    os_name = _java_getprop('java.os.name', os_name)\n    os_version = _java_getprop('java.os.version', os_version)\n    osinfo = os_name, os_version, os_arch\n\n    return release, vendor, vminfo, osinfo",
        "name_type": "stdlib"
    },
    "platform.system_alias": {
        "API_name": "platform.system_alias",
        "loc_name": "platform.system_alias",
        "args": "system;release;version",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 503,
        "namespace": "*",
        "body": "def system_alias(system, release, version):\n\n    \"\"\" Returns (system, release, version) aliased to common\n        marketing names used for some systems.\n\n        It also does some reordering of the information in some cases\n        where it would otherwise cause confusion.\n\n    \"\"\"\n    if system == 'SunOS':\n        # Sun's OS\n        if release < '5':\n            # These releases use the old name SunOS\n            return system, release, version\n        # Modify release (marketing release = SunOS release - 3)\n        l = release.split('.')\n        if l:\n            try:\n                major = int(l[0])\n            except ValueError:\n                pass\n            else:\n                major = major - 3\n                l[0] = str(major)\n                release = '.'.join(l)\n        if release < '6':\n            system = 'Solaris'\n        else:\n            # XXX Whatever the new SunOS marketing name is...\n            system = 'Solaris'\n\n    elif system == 'IRIX64':\n        # IRIX reports IRIX64 on platforms with 64-bit support; yet it\n        # is really a version and not a different platform, since 32-bit\n        # apps are also supported..\n        system = 'IRIX'\n        if version:\n            version = version + ' (64bit)'\n        else:\n            version = '64bit'\n\n    elif system in ('win32', 'win16'):\n        # In case one of the other tricks\n        system = 'Windows'\n\n    # bpo-35516: Don't replace Darwin with macOS since input release and\n    # version arguments can be different than the currently running version.\n\n    return system, release, version",
        "name_type": "stdlib"
    },
    "platform._platform": {
        "API_name": "platform._platform",
        "loc_name": "platform._platform",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 555,
        "namespace": "*",
        "body": "def _platform(*args):\n\n    \"\"\" Helper to format the platform string in a filename\n        compatible format e.g. \"system-version-machine\".\n    \"\"\"\n    # Format the platform string\n    platform = '-'.join(x.strip() for x in filter(len, args))\n\n    # Cleanup some possible filename obstacles...\n    platform = platform.replace(' ', '_')\n    platform = platform.replace('/', '-')\n    platform = platform.replace('\\\\', '-')\n    platform = platform.replace(':', '-')\n    platform = platform.replace(';', '-')\n    platform = platform.replace('\"', '-')\n    platform = platform.replace('(', '-')\n    platform = platform.replace(')', '-')\n\n    # No need to report 'unknown' information...\n    platform = platform.replace('unknown', '')\n\n    # Fold '--'s and remove trailing '-'\n    while 1:\n        cleaned = platform.replace('--', '-')\n        if cleaned == platform:\n            break\n        platform = cleaned\n    while platform[-1] == '-':\n        platform = platform[:-1]\n\n    return platform",
        "name_type": "stdlib"
    },
    "platform._node": {
        "API_name": "platform._node",
        "loc_name": "platform._node",
        "args": "default",
        "args_default": 1,
        "filepath": "platform",
        "lineno": 587,
        "namespace": "*",
        "body": "def _node(default=''):\n\n    \"\"\" Helper to determine the node name of this machine.\n    \"\"\"\n    try:\n        import socket\n    except ImportError:\n        # No sockets...\n        return default\n    try:\n        return socket.gethostname()\n    except OSError:\n        # Still not working...\n        return default",
        "name_type": "stdlib"
    },
    "platform._follow_symlinks": {
        "API_name": "platform._follow_symlinks",
        "loc_name": "platform._follow_symlinks",
        "args": "filepath",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 602,
        "namespace": "*",
        "body": "def _follow_symlinks(filepath):\n\n    \"\"\" In case filepath is a symlink, follow it until a\n        real file is reached.\n    \"\"\"\n    filepath = os.path.abspath(filepath)\n    while os.path.islink(filepath):\n        filepath = os.path.normpath(\n            os.path.join(os.path.dirname(filepath), os.readlink(filepath)))\n    return filepath",
        "name_type": "stdlib"
    },
    "platform._syscmd_file": {
        "API_name": "platform._syscmd_file",
        "loc_name": "platform._syscmd_file",
        "args": "target;default",
        "args_default": 1,
        "filepath": "platform",
        "lineno": 614,
        "namespace": "*",
        "body": "def _syscmd_file(target, default=''):\n\n    \"\"\" Interface to the system's file command.\n\n        The function uses the -b option of the file command to have it\n        omit the filename in its output. Follow the symlinks. It returns\n        default in case the command should fail.\n\n    \"\"\"\n    if sys.platform in ('dos', 'win32', 'win16'):\n        # XXX Others too ?\n        return default\n\n    import subprocess\n    target = _follow_symlinks(target)\n    # \"file\" output is locale dependent: force the usage of the C locale\n    # to get deterministic behavior.\n    env = dict(os.environ, LC_ALL='C')\n    try:\n        # -b: do not prepend filenames to output lines (brief mode)\n        output = subprocess.check_output(['file', '-b', target],\n                                         stderr=subprocess.DEVNULL,\n                                         env=env)\n    except (OSError, subprocess.CalledProcessError):\n        return default\n    if not output:\n        return default\n    # With the C locale, the output should be mostly ASCII-compatible.\n    # Decode from Latin-1 to prevent Unicode decode error.\n    return output.decode('latin-1')",
        "name_type": "stdlib"
    },
    "platform.architecture": {
        "API_name": "platform.architecture",
        "loc_name": "platform.architecture",
        "args": "executable;bits;linkage",
        "args_default": 3,
        "filepath": "platform",
        "lineno": 655,
        "namespace": "*",
        "body": "def architecture(executable=sys.executable, bits='', linkage=''):\n\n    \"\"\" Queries the given executable (defaults to the Python interpreter\n        binary) for various architecture information.\n\n        Returns a tuple (bits, linkage) which contains information about\n        the bit architecture and the linkage format used for the\n        executable. Both values are returned as strings.\n\n        Values that cannot be determined are returned as given by the\n        parameter presets. If bits is given as '', the sizeof(pointer)\n        (or sizeof(long) on Python version < 1.5.2) is used as\n        indicator for the supported pointer size.\n\n        The function relies on the system's \"file\" command to do the\n        actual work. This is available on most if not all Unix\n        platforms. On some non-Unix platforms where the \"file\" command\n        does not exist and the executable is set to the Python interpreter\n        binary defaults from _default_architecture are used.\n\n    \"\"\"\n    # Use the sizeof(pointer) as default number of bits if nothing\n    # else is given as default.\n    if not bits:\n        import struct\n        size = struct.calcsize('P')\n        bits = str(size * 8) + 'bit'\n\n    # Get data from the 'file' system command\n    if executable:\n        fileout = _syscmd_file(executable, '')\n    else:\n        fileout = ''\n\n    if not fileout and \\\n       executable == sys.executable:\n        # \"file\" command did not return anything; we'll try to provide\n        # some sensible defaults then...\n        if sys.platform in _default_architecture:\n            b, l = _default_architecture[sys.platform]\n            if b:\n                bits = b\n            if l:\n                linkage = l\n        return bits, linkage\n\n    if 'executable' not in fileout and 'shared object' not in fileout:\n        # Format not supported\n        return bits, linkage\n\n    # Bits\n    if '32-bit' in fileout:\n        bits = '32bit'\n    elif 'N32' in fileout:\n        # On Irix only\n        bits = 'n32bit'\n    elif '64-bit' in fileout:\n        bits = '64bit'\n\n    # Linkage\n    if 'ELF' in fileout:\n        linkage = 'ELF'\n    elif 'PE' in fileout:\n        # E.g. Windows uses this format\n        if 'Windows' in fileout:\n            linkage = 'WindowsPE'\n        else:\n            linkage = 'PE'\n    elif 'COFF' in fileout:\n        linkage = 'COFF'\n    elif 'MS-DOS' in fileout:\n        linkage = 'MSDOS'\n    else:\n        # XXX the A.OUT format also falls under this class...\n        pass\n\n    return bits, linkage",
        "name_type": "stdlib"
    },
    "platform._get_machine_win32": {
        "API_name": "platform._get_machine_win32",
        "loc_name": "platform._get_machine_win32",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 734,
        "namespace": "*",
        "body": "def _get_machine_win32():\n    # Try to use the PROCESSOR_* environment variables\n    # available on Win XP and later; see\n    # http://support.microsoft.com/kb/888731 and\n    # http://www.geocities.com/rick_lively/MANUALS/ENV/MSWIN/PROCESSI.HTM\n\n    # WOW64 processes mask the native architecture\n    return (\n        os.environ.get('PROCESSOR_ARCHITEW6432', '') or\n        os.environ.get('PROCESSOR_ARCHITECTURE', '')\n    )",
        "name_type": "stdlib"
    },
    "platform._Processor.get": {
        "API_name": "platform._Processor.get",
        "loc_name": "platform._Processor.get",
        "args": "cls",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 749,
        "namespace": "_Processor",
        "body": "    def get(cls):\n        func = getattr(cls, f'get_{sys.platform}', cls.from_subprocess)\n        return func() or ''",
        "name_type": "stdlib"
    },
    "platform._Processor.get_win32": {
        "API_name": "platform._Processor.get_win32",
        "loc_name": "platform._Processor.get_win32",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 753,
        "namespace": "_Processor",
        "body": "    def get_win32():\n        return os.environ.get('PROCESSOR_IDENTIFIER', _get_machine_win32())",
        "name_type": "stdlib"
    },
    "platform._Processor.get_OpenVMS": {
        "API_name": "platform._Processor.get_OpenVMS",
        "loc_name": "platform._Processor.get_OpenVMS",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 756,
        "namespace": "_Processor",
        "body": "    def get_OpenVMS():\n        try:\n            import vms_lib\n        except ImportError:\n            pass\n        else:\n            csid, cpu_number = vms_lib.getsyi('SYI$_CPU', 0)\n            return 'Alpha' if cpu_number >= 128 else 'VAX'",
        "name_type": "stdlib"
    },
    "platform._Processor.from_subprocess": {
        "API_name": "platform._Processor.from_subprocess",
        "loc_name": "platform._Processor.from_subprocess",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 765,
        "namespace": "_Processor",
        "body": "    def from_subprocess():\n        \"\"\"\n        Fall back to `uname -p`\n        \"\"\"\n        try:\n            return subprocess.check_output(\n                ['uname', '-p'],\n                stderr=subprocess.DEVNULL,\n                text=True,\n            ).strip()\n        except (OSError, subprocess.CalledProcessError):\n            pass",
        "name_type": "stdlib"
    },
    "platform._Processor": {
        "API_name": "platform._Processor",
        "loc_name": "platform._Processor",
        "args": "*",
        "args_default": "*",
        "filepath": "platform",
        "lineno": 747,
        "namespace": "_Processor",
        "body": "",
        "name_type": "stdlib"
    },
    "platform._unknown_as_blank": {
        "API_name": "platform._unknown_as_blank",
        "loc_name": "platform._unknown_as_blank",
        "args": "val",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 779,
        "namespace": "*",
        "body": "def _unknown_as_blank(val):\n    return '' if val == 'unknown' else val",
        "name_type": "stdlib"
    },
    "platform.uname_result.processor": {
        "API_name": "platform.uname_result.processor",
        "loc_name": "platform.uname_result.processor",
        "args": "self",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 798,
        "namespace": "uname_result",
        "body": "    def processor(self):\n        return _unknown_as_blank(_Processor.get())",
        "name_type": "stdlib"
    },
    "platform.uname_result.__iter__": {
        "API_name": "platform.uname_result.__iter__",
        "loc_name": "platform.uname_result.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 801,
        "namespace": "uname_result",
        "body": "    def __iter__(self):\n        return itertools.chain(\n            super().__iter__(),\n            (self.processor,)\n        )",
        "name_type": "stdlib"
    },
    "platform.uname_result._make": {
        "API_name": "platform.uname_result._make",
        "loc_name": "platform.uname_result._make",
        "args": "cls;iterable",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 808,
        "namespace": "uname_result",
        "body": "    def _make(cls, iterable):\n        # override factory to affect length check\n        num_fields = len(cls._fields)\n        result = cls.__new__(cls, *iterable)\n        if len(result) != num_fields + 1:\n            msg = f'Expected {num_fields} arguments, got {len(result)}'\n            raise TypeError(msg)\n        return result",
        "name_type": "stdlib"
    },
    "platform.uname_result.__getitem__": {
        "API_name": "platform.uname_result.__getitem__",
        "loc_name": "platform.uname_result.__getitem__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 817,
        "namespace": "uname_result",
        "body": "    def __getitem__(self, key):\n        return tuple(self)[key]",
        "name_type": "stdlib"
    },
    "platform.uname_result.__len__": {
        "API_name": "platform.uname_result.__len__",
        "loc_name": "platform.uname_result.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 820,
        "namespace": "uname_result",
        "body": "    def __len__(self):\n        return len(tuple(iter(self)))",
        "name_type": "stdlib"
    },
    "platform.uname_result.__reduce__": {
        "API_name": "platform.uname_result.__reduce__",
        "loc_name": "platform.uname_result.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 823,
        "namespace": "uname_result",
        "body": "    def __reduce__(self):\n        return uname_result, tuple(self)[:len(self._fields)]",
        "name_type": "stdlib"
    },
    "platform.uname_result": {
        "API_name": "platform.uname_result",
        "loc_name": "platform.uname_result",
        "args": "*",
        "args_default": "*",
        "filepath": "platform",
        "lineno": 785,
        "namespace": "uname_result",
        "body": "",
        "name_type": "stdlib"
    },
    "platform.uname": {
        "API_name": "platform.uname",
        "loc_name": "platform.uname",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 830,
        "namespace": "*",
        "body": "def uname():\n\n    \"\"\" Fairly portable uname interface. Returns a tuple\n        of strings (system, node, release, version, machine, processor)\n        identifying the underlying platform.\n\n        Note that unlike the os.uname function this also returns\n        possible processor information as an additional tuple entry.\n\n        Entries which cannot be determined are set to ''.\n\n    \"\"\"\n    global _uname_cache\n\n    if _uname_cache is not None:\n        return _uname_cache\n\n    # Get some infos from the builtin os.uname API...\n    try:\n        system, node, release, version, machine = infos = os.uname()\n    except AttributeError:\n        system = sys.platform\n        node = _node()\n        release = version = machine = ''\n        infos = ()\n\n    if not any(infos):\n        # uname is not available\n\n        # Try win32_ver() on win32 platforms\n        if system == 'win32':\n            release, version, csd, ptype = win32_ver()\n            machine = machine or _get_machine_win32()\n\n        # Try the 'ver' system command available on some\n        # platforms\n        if not (release and version):\n            system, release, version = _syscmd_ver(system)\n            # Normalize system to what win32_ver() normally returns\n            # (_syscmd_ver() tends to return the vendor name as well)\n            if system == 'Microsoft Windows':\n                system = 'Windows'\n            elif system == 'Microsoft' and release == 'Windows':\n                # Under Windows Vista and Windows Server 2008,\n                # Microsoft changed the output of the ver command. The\n                # release is no longer printed.  This causes the\n                # system and release to be misidentified.\n                system = 'Windows'\n                if '6.0' == version[:3]:\n                    release = 'Vista'\n                else:\n                    release = ''\n\n        # In case we still don't know anything useful, we'll try to\n        # help ourselves\n        if system in ('win32', 'win16'):\n            if not version:\n                if system == 'win32':\n                    version = '32bit'\n                else:\n                    version = '16bit'\n            system = 'Windows'\n\n        elif system[:4] == 'java':\n            release, vendor, vminfo, osinfo = java_ver()\n            system = 'Java'\n            version = ', '.join(vminfo)\n            if not version:\n                version = vendor\n\n    # System specific extensions\n    if system == 'OpenVMS':\n        # OpenVMS seems to have release and version mixed up\n        if not release or release == '0':\n            release = version\n            version = ''\n\n    #  normalize name\n    if system == 'Microsoft' and release == 'Windows':\n        system = 'Windows'\n        release = 'Vista'\n\n    vals = system, node, release, version, machine\n    # Replace 'unknown' values with the more portable ''\n    _uname_cache = uname_result(*map(_unknown_as_blank, vals))\n    return _uname_cache",
        "name_type": "stdlib"
    },
    "platform.system": {
        "API_name": "platform.system",
        "loc_name": "platform.system",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 919,
        "namespace": "*",
        "body": "def system():\n\n    \"\"\" Returns the system/OS name, e.g. 'Linux', 'Windows' or 'Java'.\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().system",
        "name_type": "stdlib"
    },
    "platform.node": {
        "API_name": "platform.node",
        "loc_name": "platform.node",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 928,
        "namespace": "*",
        "body": "def node():\n\n    \"\"\" Returns the computer's network name (which may not be fully\n        qualified)\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().node",
        "name_type": "stdlib"
    },
    "platform.release": {
        "API_name": "platform.release",
        "loc_name": "platform.release",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 938,
        "namespace": "*",
        "body": "def release():\n\n    \"\"\" Returns the system's release, e.g. '2.2.0' or 'NT'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().release",
        "name_type": "stdlib"
    },
    "platform.version": {
        "API_name": "platform.version",
        "loc_name": "platform.version",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 947,
        "namespace": "*",
        "body": "def version():\n\n    \"\"\" Returns the system's release version, e.g. '#3 on degas'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().version",
        "name_type": "stdlib"
    },
    "platform.machine": {
        "API_name": "platform.machine",
        "loc_name": "platform.machine",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 956,
        "namespace": "*",
        "body": "def machine():\n\n    \"\"\" Returns the machine type, e.g. 'i386'\n\n        An empty string is returned if the value cannot be determined.\n\n    \"\"\"\n    return uname().machine",
        "name_type": "stdlib"
    },
    "platform.processor": {
        "API_name": "platform.processor",
        "loc_name": "platform.processor",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 965,
        "namespace": "*",
        "body": "def processor():\n\n    \"\"\" Returns the (true) processor name, e.g. 'amdk6'\n\n        An empty string is returned if the value cannot be\n        determined. Note that many platforms do not provide this\n        information or simply return the same value as for machine(),\n        e.g.  NetBSD does this.\n\n    \"\"\"\n    return uname().processor",
        "name_type": "stdlib"
    },
    "platform._sys_version": {
        "API_name": "platform._sys_version",
        "loc_name": "platform._sys_version",
        "args": "sys_version",
        "args_default": 1,
        "filepath": "platform",
        "lineno": 1008,
        "namespace": "*",
        "body": "def _sys_version(sys_version=None):\n\n    \"\"\" Returns a parsed version of Python's sys.version as tuple\n        (name, version, branch, revision, buildno, builddate, compiler)\n        referring to the Python implementation name, version, branch,\n        revision, build number, build date/time as string and the compiler\n        identification string.\n\n        Note that unlike the Python sys.version, the returned value\n        for the Python version will always include the patchlevel (it\n        defaults to '.0').\n\n        The function returns empty strings for tuple entries that\n        cannot be determined.\n\n        sys_version may be given to parse an alternative version\n        string, e.g. if the version was read from a different Python\n        interpreter.\n\n    \"\"\"\n    # Get the Python version\n    if sys_version is None:\n        sys_version = sys.version\n\n    # Try the cache first\n    result = _sys_version_cache.get(sys_version, None)\n    if result is not None:\n        return result\n\n    # Parse it\n    if 'IronPython' in sys_version:\n        # IronPython\n        name = 'IronPython'\n        if sys_version.startswith('IronPython'):\n            match = _ironpython_sys_version_parser.match(sys_version)\n        else:\n            match = _ironpython26_sys_version_parser.match(sys_version)\n\n        if match is None:\n            raise ValueError(\n                'failed to parse IronPython sys.version: %s' %\n                repr(sys_version))\n\n        version, alt_version, compiler = match.groups()\n        buildno = ''\n        builddate = ''\n\n    elif sys.platform.startswith('java'):\n        # Jython\n        name = 'Jython'\n        match = _sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\n                'failed to parse Jython sys.version: %s' %\n                repr(sys_version))\n        version, buildno, builddate, buildtime, _ = match.groups()\n        if builddate is None:\n            builddate = ''\n        compiler = sys.platform\n\n    elif \"PyPy\" in sys_version:\n        # PyPy\n        name = \"PyPy\"\n        match = _pypy_sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\"failed to parse PyPy sys.version: %s\" %\n                             repr(sys_version))\n        version, buildno, builddate, buildtime = match.groups()\n        compiler = \"\"\n\n    else:\n        # CPython\n        match = _sys_version_parser.match(sys_version)\n        if match is None:\n            raise ValueError(\n                'failed to parse CPython sys.version: %s' %\n                repr(sys_version))\n        version, buildno, builddate, buildtime, compiler = \\\n              match.groups()\n        name = 'CPython'\n        if builddate is None:\n            builddate = ''\n        elif buildtime:\n            builddate = builddate + ' ' + buildtime\n\n    if hasattr(sys, '_git'):\n        _, branch, revision = sys._git\n    elif hasattr(sys, '_mercurial'):\n        _, branch, revision = sys._mercurial\n    else:\n        branch = ''\n        revision = ''\n\n    # Add the patchlevel version if missing\n    l = version.split('.')\n    if len(l) == 2:\n        l.append('0')\n        version = '.'.join(l)\n\n    # Build and cache the result\n    result = (name, version, branch, revision, buildno, builddate, compiler)\n    _sys_version_cache[sys_version] = result\n    return result",
        "name_type": "stdlib"
    },
    "platform.python_implementation": {
        "API_name": "platform.python_implementation",
        "loc_name": "platform.python_implementation",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1112,
        "namespace": "*",
        "body": "def python_implementation():\n\n    \"\"\" Returns a string identifying the Python implementation.\n\n        Currently, the following implementations are identified:\n          'CPython' (C implementation of Python),\n          'IronPython' (.NET implementation of Python),\n          'Jython' (Java implementation of Python),\n          'PyPy' (Python implementation of Python).\n\n    \"\"\"\n    return _sys_version()[0]",
        "name_type": "stdlib"
    },
    "platform.python_version": {
        "API_name": "platform.python_version",
        "loc_name": "platform.python_version",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1125,
        "namespace": "*",
        "body": "def python_version():\n\n    \"\"\" Returns the Python version as string 'major.minor.patchlevel'\n\n        Note that unlike the Python sys.version, the returned value\n        will always include the patchlevel (it defaults to 0).\n\n    \"\"\"\n    return _sys_version()[1]",
        "name_type": "stdlib"
    },
    "platform.python_version_tuple": {
        "API_name": "platform.python_version_tuple",
        "loc_name": "platform.python_version_tuple",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1135,
        "namespace": "*",
        "body": "def python_version_tuple():\n\n    \"\"\" Returns the Python version as tuple (major, minor, patchlevel)\n        of strings.\n\n        Note that unlike the Python sys.version, the returned value\n        will always include the patchlevel (it defaults to 0).\n\n    \"\"\"\n    return tuple(_sys_version()[1].split('.'))",
        "name_type": "stdlib"
    },
    "platform.python_branch": {
        "API_name": "platform.python_branch",
        "loc_name": "platform.python_branch",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1146,
        "namespace": "*",
        "body": "def python_branch():\n\n    \"\"\" Returns a string identifying the Python implementation\n        branch.\n\n        For CPython this is the SCM branch from which the\n        Python binary was built.\n\n        If not available, an empty string is returned.\n\n    \"\"\"\n\n    return _sys_version()[2]",
        "name_type": "stdlib"
    },
    "platform.python_revision": {
        "API_name": "platform.python_revision",
        "loc_name": "platform.python_revision",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1160,
        "namespace": "*",
        "body": "def python_revision():\n\n    \"\"\" Returns a string identifying the Python implementation\n        revision.\n\n        For CPython this is the SCM revision from which the\n        Python binary was built.\n\n        If not available, an empty string is returned.\n\n    \"\"\"\n    return _sys_version()[3]",
        "name_type": "stdlib"
    },
    "platform.python_build": {
        "API_name": "platform.python_build",
        "loc_name": "platform.python_build",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1173,
        "namespace": "*",
        "body": "def python_build():\n\n    \"\"\" Returns a tuple (buildno, builddate) stating the Python\n        build number and date as strings.\n\n    \"\"\"\n    return _sys_version()[4:6]",
        "name_type": "stdlib"
    },
    "platform.python_compiler": {
        "API_name": "platform.python_compiler",
        "loc_name": "platform.python_compiler",
        "args": "",
        "args_default": 0,
        "filepath": "platform",
        "lineno": 1181,
        "namespace": "*",
        "body": "def python_compiler():\n\n    \"\"\" Returns a string identifying the compiler used for compiling\n        Python.\n\n    \"\"\"\n    return _sys_version()[6]",
        "name_type": "stdlib"
    },
    "platform.platform": {
        "API_name": "platform.platform",
        "loc_name": "platform.platform",
        "args": "aliased;terse",
        "args_default": 2,
        "filepath": "platform",
        "lineno": 1193,
        "namespace": "*",
        "body": "def platform(aliased=0, terse=0):\n\n    \"\"\" Returns a single string identifying the underlying platform\n        with as much useful information as possible (but no more :).\n\n        The output is intended to be human readable rather than\n        machine parseable. It may look different on different\n        platforms and this is intended.\n\n        If \"aliased\" is true, the function will use aliases for\n        various platforms that report system names which differ from\n        their common names, e.g. SunOS will be reported as\n        Solaris. The system_alias() function is used to implement\n        this.\n\n        Setting terse to true causes the function to return only the\n        absolute minimum information needed to identify the platform.\n\n    \"\"\"\n    result = _platform_cache.get((aliased, terse), None)\n    if result is not None:\n        return result\n\n    # Get uname information and then apply platform specific cosmetics\n    # to it...\n    system, node, release, version, machine, processor = uname()\n    if machine == processor:\n        processor = ''\n    if aliased:\n        system, release, version = system_alias(system, release, version)\n\n    if system == 'Darwin':\n        # macOS (darwin kernel)\n        macos_release = mac_ver()[0]\n        if macos_release:\n            system = 'macOS'\n            release = macos_release\n\n    if system == 'Windows':\n        # MS platforms\n        rel, vers, csd, ptype = win32_ver(version)\n        if terse:\n            platform = _platform(system, release)\n        else:\n            platform = _platform(system, release, version, csd)\n\n    elif system in ('Linux',):\n        # check for libc vs. glibc\n        libcname, libcversion = libc_ver()\n        platform = _platform(system, release, machine, processor,\n                             'with',\n                             libcname+libcversion)\n    elif system == 'Java':\n        # Java platforms\n        r, v, vminfo, (os_name, os_version, os_arch) = java_ver()\n        if terse or not os_name:\n            platform = _platform(system, release, version)\n        else:\n            platform = _platform(system, release, version,\n                                 'on',\n                                 os_name, os_version, os_arch)\n\n    else:\n        # Generic handler\n        if terse:\n            platform = _platform(system, release)\n        else:\n            bits, linkage = architecture(sys.executable)\n            platform = _platform(system, release, machine,\n                                 processor, bits, linkage)\n\n    _platform_cache[(aliased, terse)] = platform\n    return platform",
        "name_type": "stdlib"
    },
    "queue": {
        "API_name": "queue",
        "loc_name": "queue",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": "*",
        "namespace": "*",
        "body": "'''A multi-producer, multi-consumer queue.'''\ntry:\n    from _queue import SimpleQueue\nexcept ImportError:\n    SimpleQueue = None\n__all__ = ['Empty', 'Full', 'Queue', 'PriorityQueue', 'LifoQueue', 'SimpleQueue']\ntry:\n    from _queue import Empty\nexcept ImportError:\n    class Empty(Exception):\n        'Exception raised by Queue.get(block=0)/get_nowait().'\n        pass\nif SimpleQueue is None:\n    SimpleQueue = _PySimpleQueue",
        "name_type": "stdlib"
    },
    "queue.Empty": {
        "API_name": "queue.Empty",
        "loc_name": "queue.Empty",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": 19,
        "namespace": "Empty",
        "body": "",
        "name_type": "stdlib"
    },
    "queue.Full": {
        "API_name": "queue.Full",
        "loc_name": "queue.Full",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": 23,
        "namespace": "Full",
        "body": "",
        "name_type": "stdlib"
    },
    "queue.Queue": {
        "API_name": "queue.Queue",
        "loc_name": "queue.Queue",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": 28,
        "namespace": "Queue",
        "body": "",
        "name_type": "stdlib"
    },
    "queue.Queue.__init__": {
        "API_name": "queue.Queue.__init__",
        "loc_name": "queue.Queue.__init__",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "queue",
        "lineno": 34,
        "namespace": "Queue",
        "body": "    def __init__(self, maxsize=0):\n        self.maxsize = maxsize\n        self._init(maxsize)\n\n        # mutex must be held whenever the queue is mutating.  All methods\n        # that acquire mutex must release it before returning.  mutex\n        # is shared between the three conditions, so acquiring and\n        # releasing the conditions also acquires and releases mutex.\n        self.mutex = threading.Lock()\n\n        # Notify not_empty whenever an item is added to the queue; a\n        # thread waiting to get is notified then.\n        self.not_empty = threading.Condition(self.mutex)\n\n        # Notify not_full whenever an item is removed from the queue;\n        # a thread waiting to put is notified then.\n        self.not_full = threading.Condition(self.mutex)\n\n        # Notify all_tasks_done whenever the number of unfinished tasks\n        # drops to zero; thread waiting to join() is notified to resume\n        self.all_tasks_done = threading.Condition(self.mutex)\n        self.unfinished_tasks = 0",
        "name_type": "stdlib"
    },
    "queue.Queue.task_done": {
        "API_name": "queue.Queue.task_done",
        "loc_name": "queue.Queue.task_done",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 57,
        "namespace": "Queue",
        "body": "    def task_done(self):\n        '''Indicate that a formerly enqueued task is complete.\n\n        Used by Queue consumer threads.  For each get() used to fetch a task,\n        a subsequent call to task_done() tells the queue that the processing\n        on the task is complete.\n\n        If a join() is currently blocking, it will resume when all items\n        have been processed (meaning that a task_done() call was received\n        for every item that had been put() into the queue).\n\n        Raises a ValueError if called more times than there were items\n        placed in the queue.\n        '''\n        with self.all_tasks_done:\n            unfinished = self.unfinished_tasks - 1\n            if unfinished <= 0:\n                if unfinished < 0:\n                    raise ValueError('task_done() called too many times')\n                self.all_tasks_done.notify_all()\n            self.unfinished_tasks = unfinished",
        "name_type": "stdlib"
    },
    "queue.Queue.join": {
        "API_name": "queue.Queue.join",
        "loc_name": "queue.Queue.join",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 79,
        "namespace": "Queue",
        "body": "    def join(self):\n        '''Blocks until all items in the Queue have been gotten and processed.\n\n        The count of unfinished tasks goes up whenever an item is added to the\n        queue. The count goes down whenever a consumer thread calls task_done()\n        to indicate the item was retrieved and all work on it is complete.\n\n        When the count of unfinished tasks drops to zero, join() unblocks.\n        '''\n        with self.all_tasks_done:\n            while self.unfinished_tasks:\n                self.all_tasks_done.wait()",
        "name_type": "stdlib"
    },
    "queue.Queue.qsize": {
        "API_name": "queue.Queue.qsize",
        "loc_name": "queue.Queue.qsize",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 92,
        "namespace": "Queue",
        "body": "    def qsize(self):\n        '''Return the approximate size of the queue (not reliable!).'''\n        with self.mutex:\n            return self._qsize()",
        "name_type": "stdlib"
    },
    "queue.Queue.empty": {
        "API_name": "queue.Queue.empty",
        "loc_name": "queue.Queue.empty",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 97,
        "namespace": "Queue",
        "body": "    def empty(self):\n        '''Return True if the queue is empty, False otherwise (not reliable!).\n\n        This method is likely to be removed at some point.  Use qsize() == 0\n        as a direct substitute, but be aware that either approach risks a race\n        condition where a queue can grow before the result of empty() or\n        qsize() can be used.\n\n        To create code that needs to wait for all queued tasks to be\n        completed, the preferred technique is to use the join() method.\n        '''\n        with self.mutex:\n            return not self._qsize()",
        "name_type": "stdlib"
    },
    "queue.Queue.full": {
        "API_name": "queue.Queue.full",
        "loc_name": "queue.Queue.full",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 111,
        "namespace": "Queue",
        "body": "    def full(self):\n        '''Return True if the queue is full, False otherwise (not reliable!).\n\n        This method is likely to be removed at some point.  Use qsize() >= n\n        as a direct substitute, but be aware that either approach risks a race\n        condition where a queue can shrink before the result of full() or\n        qsize() can be used.\n        '''\n        with self.mutex:\n            return 0 < self.maxsize <= self._qsize()",
        "name_type": "stdlib"
    },
    "queue.Queue.put": {
        "API_name": "queue.Queue.put",
        "loc_name": "queue.Queue.put",
        "args": "self;item;block;timeout",
        "args_default": 2,
        "filepath": "queue",
        "lineno": 122,
        "namespace": "Queue",
        "body": "    def put(self, item, block=True, timeout=None):\n        '''Put an item into the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until a free slot is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Full exception if no free slot was available within that time.\n        Otherwise ('block' is false), put an item on the queue if a free slot\n        is immediately available, else raise the Full exception ('timeout'\n        is ignored in that case).\n        '''\n        with self.not_full:\n            if self.maxsize > 0:\n                if not block:\n                    if self._qsize() >= self.maxsize:\n                        raise Full\n                elif timeout is None:\n                    while self._qsize() >= self.maxsize:\n                        self.not_full.wait()\n                elif timeout < 0:\n                    raise ValueError(\"'timeout' must be a non-negative number\")\n                else:\n                    endtime = time() + timeout\n                    while self._qsize() >= self.maxsize:\n                        remaining = endtime - time()\n                        if remaining <= 0.0:\n                            raise Full\n                        self.not_full.wait(remaining)\n            self._put(item)\n            self.unfinished_tasks += 1\n            self.not_empty.notify()",
        "name_type": "stdlib"
    },
    "queue.Queue.get": {
        "API_name": "queue.Queue.get",
        "loc_name": "queue.Queue.get",
        "args": "self;block;timeout",
        "args_default": 2,
        "filepath": "queue",
        "lineno": 154,
        "namespace": "Queue",
        "body": "    def get(self, block=True, timeout=None):\n        '''Remove and return an item from the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until an item is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Empty exception if no item was available within that time.\n        Otherwise ('block' is false), return an item if one is immediately\n        available, else raise the Empty exception ('timeout' is ignored\n        in that case).\n        '''\n        with self.not_empty:\n            if not block:\n                if not self._qsize():\n                    raise Empty\n            elif timeout is None:\n                while not self._qsize():\n                    self.not_empty.wait()\n            elif timeout < 0:\n                raise ValueError(\"'timeout' must be a non-negative number\")\n            else:\n                endtime = time() + timeout\n                while not self._qsize():\n                    remaining = endtime - time()\n                    if remaining <= 0.0:\n                        raise Empty\n                    self.not_empty.wait(remaining)\n            item = self._get()\n            self.not_full.notify()\n            return item",
        "name_type": "stdlib"
    },
    "queue.Queue.put_nowait": {
        "API_name": "queue.Queue.put_nowait",
        "loc_name": "queue.Queue.put_nowait",
        "args": "self;item",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 185,
        "namespace": "Queue",
        "body": "    def put_nowait(self, item):\n        '''Put an item into the queue without blocking.\n\n        Only enqueue the item if a free slot is immediately available.\n        Otherwise raise the Full exception.\n        '''\n        return self.put(item, block=False)",
        "name_type": "stdlib"
    },
    "queue.Queue.get_nowait": {
        "API_name": "queue.Queue.get_nowait",
        "loc_name": "queue.Queue.get_nowait",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 193,
        "namespace": "Queue",
        "body": "    def get_nowait(self):\n        '''Remove and return an item from the queue without blocking.\n\n        Only get an item if one is immediately available. Otherwise\n        raise the Empty exception.\n        '''\n        return self.get(block=False)",
        "name_type": "stdlib"
    },
    "queue.Queue._init": {
        "API_name": "queue.Queue._init",
        "loc_name": "queue.Queue._init",
        "args": "self;maxsize",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 206,
        "namespace": "Queue",
        "body": "    def _init(self, maxsize):\n        self.queue = deque()",
        "name_type": "stdlib"
    },
    "queue.Queue._qsize": {
        "API_name": "queue.Queue._qsize",
        "loc_name": "queue.Queue._qsize",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 209,
        "namespace": "Queue",
        "body": "    def _qsize(self):\n        return len(self.queue)",
        "name_type": "stdlib"
    },
    "queue.Queue._put": {
        "API_name": "queue.Queue._put",
        "loc_name": "queue.Queue._put",
        "args": "self;item",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 213,
        "namespace": "Queue",
        "body": "    def _put(self, item):\n        self.queue.append(item)",
        "name_type": "stdlib"
    },
    "queue.Queue._get": {
        "API_name": "queue.Queue._get",
        "loc_name": "queue.Queue._get",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 217,
        "namespace": "Queue",
        "body": "    def _get(self):\n        return self.queue.popleft()",
        "name_type": "stdlib"
    },
    "queue.PriorityQueue._init": {
        "API_name": "queue.PriorityQueue._init",
        "loc_name": "queue.PriorityQueue._init",
        "args": "self;maxsize",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 229,
        "namespace": "PriorityQueue",
        "body": "    def _init(self, maxsize):\n        self.queue = []",
        "name_type": "stdlib"
    },
    "queue.PriorityQueue._qsize": {
        "API_name": "queue.PriorityQueue._qsize",
        "loc_name": "queue.PriorityQueue._qsize",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 232,
        "namespace": "PriorityQueue",
        "body": "    def _qsize(self):\n        return len(self.queue)",
        "name_type": "stdlib"
    },
    "queue.PriorityQueue._put": {
        "API_name": "queue.PriorityQueue._put",
        "loc_name": "queue.PriorityQueue._put",
        "args": "self;item",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 235,
        "namespace": "PriorityQueue",
        "body": "    def _put(self, item):\n        heappush(self.queue, item)",
        "name_type": "stdlib"
    },
    "queue.PriorityQueue._get": {
        "API_name": "queue.PriorityQueue._get",
        "loc_name": "queue.PriorityQueue._get",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 238,
        "namespace": "PriorityQueue",
        "body": "    def _get(self):\n        return heappop(self.queue)",
        "name_type": "stdlib"
    },
    "queue.PriorityQueue": {
        "API_name": "queue.PriorityQueue",
        "loc_name": "queue.PriorityQueue",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": 223,
        "namespace": "PriorityQueue",
        "body": "",
        "name_type": "stdlib"
    },
    "queue.LifoQueue._init": {
        "API_name": "queue.LifoQueue._init",
        "loc_name": "queue.LifoQueue._init",
        "args": "self;maxsize",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 245,
        "namespace": "LifoQueue",
        "body": "    def _init(self, maxsize):\n        self.queue = []",
        "name_type": "stdlib"
    },
    "queue.LifoQueue._qsize": {
        "API_name": "queue.LifoQueue._qsize",
        "loc_name": "queue.LifoQueue._qsize",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 248,
        "namespace": "LifoQueue",
        "body": "    def _qsize(self):\n        return len(self.queue)",
        "name_type": "stdlib"
    },
    "queue.LifoQueue._put": {
        "API_name": "queue.LifoQueue._put",
        "loc_name": "queue.LifoQueue._put",
        "args": "self;item",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 251,
        "namespace": "LifoQueue",
        "body": "    def _put(self, item):\n        self.queue.append(item)",
        "name_type": "stdlib"
    },
    "queue.LifoQueue._get": {
        "API_name": "queue.LifoQueue._get",
        "loc_name": "queue.LifoQueue._get",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 254,
        "namespace": "LifoQueue",
        "body": "    def _get(self):\n        return self.queue.pop()",
        "name_type": "stdlib"
    },
    "queue.LifoQueue": {
        "API_name": "queue.LifoQueue",
        "loc_name": "queue.LifoQueue",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": 242,
        "namespace": "LifoQueue",
        "body": "",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue": {
        "API_name": "queue._PySimpleQueue",
        "loc_name": "queue._PySimpleQueue",
        "args": "*",
        "args_default": "*",
        "filepath": "queue",
        "lineno": 258,
        "namespace": "_PySimpleQueue",
        "body": "",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.__init__": {
        "API_name": "queue._PySimpleQueue.__init__",
        "loc_name": "queue._PySimpleQueue.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 268,
        "namespace": "_PySimpleQueue",
        "body": "    def __init__(self):\n        self._queue = deque()\n        self._count = threading.Semaphore(0)",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.put": {
        "API_name": "queue._PySimpleQueue.put",
        "loc_name": "queue._PySimpleQueue.put",
        "args": "self;item;block;timeout",
        "args_default": 2,
        "filepath": "queue",
        "lineno": 272,
        "namespace": "_PySimpleQueue",
        "body": "    def put(self, item, block=True, timeout=None):\n        '''Put the item on the queue.\n\n        The optional 'block' and 'timeout' arguments are ignored, as this method\n        never blocks.  They are provided for compatibility with the Queue class.\n        '''\n        self._queue.append(item)\n        self._count.release()",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.get": {
        "API_name": "queue._PySimpleQueue.get",
        "loc_name": "queue._PySimpleQueue.get",
        "args": "self;block;timeout",
        "args_default": 2,
        "filepath": "queue",
        "lineno": 281,
        "namespace": "_PySimpleQueue",
        "body": "    def get(self, block=True, timeout=None):\n        '''Remove and return an item from the queue.\n\n        If optional args 'block' is true and 'timeout' is None (the default),\n        block if necessary until an item is available. If 'timeout' is\n        a non-negative number, it blocks at most 'timeout' seconds and raises\n        the Empty exception if no item was available within that time.\n        Otherwise ('block' is false), return an item if one is immediately\n        available, else raise the Empty exception ('timeout' is ignored\n        in that case).\n        '''\n        if timeout is not None and timeout < 0:\n            raise ValueError(\"'timeout' must be a non-negative number\")\n        if not self._count.acquire(block, timeout):\n            raise Empty\n        return self._queue.popleft()",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.put_nowait": {
        "API_name": "queue._PySimpleQueue.put_nowait",
        "loc_name": "queue._PySimpleQueue.put_nowait",
        "args": "self;item",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 298,
        "namespace": "_PySimpleQueue",
        "body": "    def put_nowait(self, item):\n        '''Put an item into the queue without blocking.\n\n        This is exactly equivalent to `put(item, block=False)` and is only provided\n        for compatibility with the Queue class.\n        '''\n        return self.put(item, block=False)",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.get_nowait": {
        "API_name": "queue._PySimpleQueue.get_nowait",
        "loc_name": "queue._PySimpleQueue.get_nowait",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 306,
        "namespace": "_PySimpleQueue",
        "body": "    def get_nowait(self):\n        '''Remove and return an item from the queue without blocking.\n\n        Only get an item if one is immediately available. Otherwise\n        raise the Empty exception.\n        '''\n        return self.get(block=False)",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.empty": {
        "API_name": "queue._PySimpleQueue.empty",
        "loc_name": "queue._PySimpleQueue.empty",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 314,
        "namespace": "_PySimpleQueue",
        "body": "    def empty(self):\n        '''Return True if the queue is empty, False otherwise (not reliable!).'''\n        return len(self._queue) == 0",
        "name_type": "stdlib"
    },
    "queue._PySimpleQueue.qsize": {
        "API_name": "queue._PySimpleQueue.qsize",
        "loc_name": "queue._PySimpleQueue.qsize",
        "args": "self",
        "args_default": 0,
        "filepath": "queue",
        "lineno": 318,
        "namespace": "_PySimpleQueue",
        "body": "    def qsize(self):\n        '''Return the approximate size of the queue (not reliable!).'''\n        return len(self._queue)",
        "name_type": "stdlib"
    },
    "re": {
        "API_name": "re",
        "loc_name": "re",
        "args": "*",
        "args_default": "*",
        "filepath": "re",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"Support for regular expressions (RE).\n\nThis module provides regular expression matching operations similar to\nthose found in Perl.  It supports both 8-bit and Unicode strings; both\nthe pattern and the strings being processed can contain null bytes and\ncharacters outside the US ASCII range.\n\nRegular expressions can contain both special and ordinary characters.\nMost ordinary characters, like \"A\", \"a\", or \"0\", are the simplest\nregular expressions; they simply match themselves.  You can\nconcatenate ordinary characters, so last matches the string 'last'.\n\nThe special characters are:\n    \".\"      Matches any character except a newline.\n    \"^\"      Matches the start of the string.\n    \"$\"      Matches the end of the string or just before the newline at\n             the end of the string.\n    \"*\"      Matches 0 or more (greedy) repetitions of the preceding RE.\n             Greedy means that it will match as many repetitions as possible.\n    \"+\"      Matches 1 or more (greedy) repetitions of the preceding RE.\n    \"?\"      Matches 0 or 1 (greedy) of the preceding RE.\n    *?,+?,?? Non-greedy versions of the previous three special characters.\n    {m,n}    Matches from m to n repetitions of the preceding RE.\n    {m,n}?   Non-greedy version of the above.\n    \"\\\\\"     Either escapes special characters or signals a special sequence.\n    []       Indicates a set of characters.\n             A \"^\" as the first character indicates a complementing set.\n    \"|\"      A|B, creates an RE that will match either A or B.\n    (...)    Matches the RE inside the parentheses.\n             The contents can be retrieved or matched later in the string.\n    (?aiLmsux) The letters set the corresponding flags defined below.\n    (?:...)  Non-grouping version of regular parentheses.\n    (?P<name>...) The substring matched by the group is accessible by name.\n    (?P=name)     Matches the text matched earlier by the group named name.\n    (?#...)  A comment; ignored.\n    (?=...)  Matches if ... matches next, but doesn't consume the string.\n    (?!...)  Matches if ... doesn't match next.\n    (?<=...) Matches if preceded by ... (must be fixed length).\n    (?<!...) Matches if not preceded by ... (must be fixed length).\n    (?(id/name)yes|no) Matches yes pattern if the group with id/name matched,\n                       the (optional) no pattern otherwise.\n\nThe special sequences consist of \"\\\\\" and a character from the list\nbelow.  If the ordinary character is not on the list, then the\nresulting RE will match the second character.\n    \\number  Matches the contents of the group of the same number.\n    \\A       Matches only at the start of the string.\n    \\Z       Matches only at the end of the string.\n    \\b       Matches the empty string, but only at the start or end of a word.\n    \\B       Matches the empty string, but not at the start or end of a word.\n    \\d       Matches any decimal digit; equivalent to the set [0-9] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode digits.\n    \\D       Matches any non-digit character; equivalent to [^\\d].\n    \\s       Matches any whitespace character; equivalent to [ \\t\\n\\r\\f\\v] in\n             bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the whole\n             range of Unicode whitespace characters.\n    \\S       Matches any non-whitespace character; equivalent to [^\\s].\n    \\w       Matches any alphanumeric character; equivalent to [a-zA-Z0-9_]\n             in bytes patterns or string patterns with the ASCII flag.\n             In string patterns without the ASCII flag, it will match the\n             range of Unicode alphanumeric characters (letters plus digits\n             plus underscore).\n             With LOCALE, it will match the set [0-9_] plus characters defined\n             as letters for the current locale.\n    \\W       Matches the complement of \\w.\n    \\\\       Matches a literal backslash.\n\nThis module exports the following functions:\n    match     Match a regular expression pattern to the beginning of a string.\n    fullmatch Match a regular expression pattern to all of a string.\n    search    Search a string for the presence of a pattern.\n    sub       Substitute occurrences of a pattern found in a string.\n    subn      Same as sub, but also return the number of substitutions made.\n    split     Split a string by the occurrences of a pattern.\n    findall   Find all occurrences of a pattern in a string.\n    finditer  Return an iterator yielding a Match object for each match.\n    compile   Compile a pattern into a Pattern object.\n    purge     Clear the regular expression cache.\n    escape    Backslash all non-alphanumerics in a string.\n\nEach function other than purge and escape can take an optional 'flags' argument\nconsisting of one or more of the following module constants, joined by \"|\".\nA, L, and U are mutually exclusive.\n    A  ASCII       For string patterns, make \\w, \\W, \\b, \\B, \\d, \\D\n                   match the corresponding ASCII character categories\n                   (rather than the whole Unicode categories, which is the\n                   default).\n                   For bytes patterns, this flag is the only available\n                   behaviour and needn't be specified.\n    I  IGNORECASE  Perform case-insensitive matching.\n    L  LOCALE      Make \\w, \\W, \\b, \\B, dependent on the current locale.\n    M  MULTILINE   \"^\" matches the beginning of lines (after a newline)\n                   as well as the string.\n                   \"$\" matches the end of lines (before a newline) as well\n                   as the end of the string.\n    S  DOTALL      \".\" matches any character at all, including the newline.\n    X  VERBOSE     Ignore whitespace and comments for nicer looking RE's.\n    U  UNICODE     For compatibility only. Ignored for string patterns (it\n                   is the default), and forbidden for bytes patterns.\n\nThis module also defines an exception 'error'.\n\n\"\"\"\ntry:\n    import _locale\nexcept ImportError:\n    _locale = None\n__all__ = [\n    \"match\", \"fullmatch\", \"search\", \"sub\", \"subn\", \"split\",\n    \"findall\", \"finditer\", \"compile\", \"purge\", \"template\", \"escape\",\n    \"error\", \"Pattern\", \"Match\", \"A\", \"I\", \"L\", \"M\", \"S\", \"X\", \"U\",\n    \"ASCII\", \"IGNORECASE\", \"LOCALE\", \"MULTILINE\", \"DOTALL\", \"VERBOSE\",\n    \"UNICODE\",\n]\n__version__ = \"2.2.1\"\nglobals().update(RegexFlag.__members__)\nerror = sre_compile.error\n_special_chars_map = {i: '\\\\' + chr(i) for i in b'()[]{}?*+-|^$\\\\.&~# \\t\\n\\r\\v\\f'}\nPattern = type(sre_compile.compile('', 0))\nMatch = type(sre_compile.compile('', 0).match(''))\n_cache = {}  # ordered!\n_MAXCACHE = 512\ncopyreg.pickle(Pattern, _pickle, _compile)",
        "name_type": "stdlib"
    },
    "re.RegexFlag.__repr__": {
        "API_name": "re.RegexFlag.__repr__",
        "loc_name": "re.RegexFlag.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "re",
        "lineno": 157,
        "namespace": "RegexFlag",
        "body": "    def __repr__(self):\n        if self._name_ is not None:\n            return f're.{self._name_}'\n        value = self._value_\n        members = []\n        negative = value < 0\n        if negative:\n            value = ~value\n        for m in self.__class__:\n            if value & m._value_:\n                value &= ~m._value_\n                members.append(f're.{m._name_}')\n        if value:\n            members.append(hex(value))\n        res = '|'.join(members)\n        if negative:\n            if len(members) > 1:\n                res = f'~({res})'\n            else:\n                res = f'~{res}'\n        return res",
        "name_type": "stdlib"
    },
    "re.RegexFlag": {
        "API_name": "re.RegexFlag",
        "loc_name": "re.RegexFlag",
        "args": "*",
        "args_default": "*",
        "filepath": "re",
        "lineno": 145,
        "namespace": "RegexFlag",
        "body": "",
        "name_type": "stdlib"
    },
    "re.match": {
        "API_name": "re.match",
        "loc_name": "re.match",
        "args": "pattern;string;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 188,
        "namespace": "*",
        "body": "def match(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern at the start of the string, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).match(string)",
        "name_type": "stdlib"
    },
    "re.fullmatch": {
        "API_name": "re.fullmatch",
        "loc_name": "re.fullmatch",
        "args": "pattern;string;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 193,
        "namespace": "*",
        "body": "def fullmatch(pattern, string, flags=0):\n    \"\"\"Try to apply the pattern to all of the string, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).fullmatch(string)",
        "name_type": "stdlib"
    },
    "re.search": {
        "API_name": "re.search",
        "loc_name": "re.search",
        "args": "pattern;string;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 198,
        "namespace": "*",
        "body": "def search(pattern, string, flags=0):\n    \"\"\"Scan through string looking for a match to the pattern, returning\n    a Match object, or None if no match was found.\"\"\"\n    return _compile(pattern, flags).search(string)",
        "name_type": "stdlib"
    },
    "re.sub": {
        "API_name": "re.sub",
        "loc_name": "re.sub",
        "args": "pattern;repl;string;count;flags",
        "args_default": 2,
        "filepath": "re",
        "lineno": 203,
        "namespace": "*",
        "body": "def sub(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in string by the\n    replacement repl.  repl can be either a string or a callable;\n    if a string, backslash escapes in it are processed.  If it is\n    a callable, it's passed the Match object and must return\n    a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).sub(repl, string, count)",
        "name_type": "stdlib"
    },
    "re.subn": {
        "API_name": "re.subn",
        "loc_name": "re.subn",
        "args": "pattern;repl;string;count;flags",
        "args_default": 2,
        "filepath": "re",
        "lineno": 212,
        "namespace": "*",
        "body": "def subn(pattern, repl, string, count=0, flags=0):\n    \"\"\"Return a 2-tuple containing (new_string, number).\n    new_string is the string obtained by replacing the leftmost\n    non-overlapping occurrences of the pattern in the source\n    string by the replacement repl.  number is the number of\n    substitutions that were made. repl can be either a string or a\n    callable; if a string, backslash escapes in it are processed.\n    If it is a callable, it's passed the Match object and must\n    return a replacement string to be used.\"\"\"\n    return _compile(pattern, flags).subn(repl, string, count)",
        "name_type": "stdlib"
    },
    "re.split": {
        "API_name": "re.split",
        "loc_name": "re.split",
        "args": "pattern;string;maxsplit;flags",
        "args_default": 2,
        "filepath": "re",
        "lineno": 223,
        "namespace": "*",
        "body": "def split(pattern, string, maxsplit=0, flags=0):\n    \"\"\"Split the source string by the occurrences of the pattern,\n    returning a list containing the resulting substrings.  If\n    capturing parentheses are used in pattern, then the text of all\n    groups in the pattern are also returned as part of the resulting\n    list.  If maxsplit is nonzero, at most maxsplit splits occur,\n    and the remainder of the string is returned as the final element\n    of the list.\"\"\"\n    return _compile(pattern, flags).split(string, maxsplit)",
        "name_type": "stdlib"
    },
    "re.findall": {
        "API_name": "re.findall",
        "loc_name": "re.findall",
        "args": "pattern;string;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 233,
        "namespace": "*",
        "body": "def findall(pattern, string, flags=0):\n    \"\"\"Return a list of all non-overlapping matches in the string.\n\n    If one or more capturing groups are present in the pattern, return\n    a list of groups; this will be a list of tuples if the pattern\n    has more than one group.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).findall(string)",
        "name_type": "stdlib"
    },
    "re.finditer": {
        "API_name": "re.finditer",
        "loc_name": "re.finditer",
        "args": "pattern;string;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 243,
        "namespace": "*",
        "body": "def finditer(pattern, string, flags=0):\n    \"\"\"Return an iterator over all non-overlapping matches in the\n    string.  For each match, the iterator returns a Match object.\n\n    Empty matches are included in the result.\"\"\"\n    return _compile(pattern, flags).finditer(string)",
        "name_type": "stdlib"
    },
    "re.compile": {
        "API_name": "re.compile",
        "loc_name": "re.compile",
        "args": "pattern;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 250,
        "namespace": "*",
        "body": "def compile(pattern, flags=0):\n    \"Compile a regular expression pattern, returning a Pattern object.\"\n    return _compile(pattern, flags)",
        "name_type": "stdlib"
    },
    "re.purge": {
        "API_name": "re.purge",
        "loc_name": "re.purge",
        "args": "",
        "args_default": 0,
        "filepath": "re",
        "lineno": 254,
        "namespace": "*",
        "body": "def purge():\n    \"Clear the regular expression caches\"\n    _cache.clear()\n    _compile_repl.cache_clear()",
        "name_type": "stdlib"
    },
    "re.template": {
        "API_name": "re.template",
        "loc_name": "re.template",
        "args": "pattern;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 259,
        "namespace": "*",
        "body": "def template(pattern, flags=0):\n    \"Compile a template pattern, returning a Pattern object\"\n    return _compile(pattern, flags|T)",
        "name_type": "stdlib"
    },
    "re.escape": {
        "API_name": "re.escape",
        "loc_name": "re.escape",
        "args": "pattern",
        "args_default": 0,
        "filepath": "re",
        "lineno": 270,
        "namespace": "*",
        "body": "def escape(pattern):\n    \"\"\"\n    Escape special characters in a string.\n    \"\"\"\n    if isinstance(pattern, str):\n        return pattern.translate(_special_chars_map)\n    else:\n        pattern = str(pattern, 'latin1')\n        return pattern.translate(_special_chars_map).encode('latin1')",
        "name_type": "stdlib"
    },
    "re._compile": {
        "API_name": "re._compile",
        "loc_name": "re._compile",
        "args": "pattern;flags",
        "args_default": 0,
        "filepath": "re",
        "lineno": 289,
        "namespace": "*",
        "body": "def _compile(pattern, flags):\n    # internal: compile pattern\n    if isinstance(flags, RegexFlag):\n        flags = flags.value\n    try:\n        return _cache[type(pattern), pattern, flags]\n    except KeyError:\n        pass\n    if isinstance(pattern, Pattern):\n        if flags:\n            raise ValueError(\n                \"cannot process flags argument with a compiled pattern\")\n        return pattern\n    if not sre_compile.isstring(pattern):\n        raise TypeError(\"first argument must be string or compiled pattern\")\n    p = sre_compile.compile(pattern, flags)\n    if not (flags & DEBUG):\n        if len(_cache) >= _MAXCACHE:\n            # Drop the oldest item\n            try:\n                del _cache[next(iter(_cache))]\n            except (StopIteration, RuntimeError, KeyError):\n                pass\n        _cache[type(pattern), pattern, flags] = p\n    return p",
        "name_type": "stdlib"
    },
    "re._compile_repl": {
        "API_name": "re._compile_repl",
        "loc_name": "re._compile_repl",
        "args": "repl;pattern",
        "args_default": 0,
        "filepath": "re",
        "lineno": 316,
        "namespace": "*",
        "body": "def _compile_repl(repl, pattern):\n    # internal: compile replacement pattern\n    return sre_parse.parse_template(repl, pattern)",
        "name_type": "stdlib"
    },
    "re._expand": {
        "API_name": "re._expand",
        "loc_name": "re._expand",
        "args": "pattern;match;template",
        "args_default": 0,
        "filepath": "re",
        "lineno": 320,
        "namespace": "*",
        "body": "def _expand(pattern, match, template):\n    # internal: Match.expand implementation hook\n    template = sre_parse.parse_template(template, pattern)\n    return sre_parse.expand_template(template, match)",
        "name_type": "stdlib"
    },
    "re._subx": {
        "API_name": "re._subx",
        "loc_name": "re._subx",
        "args": "pattern;template",
        "args_default": 0,
        "filepath": "re",
        "lineno": 325,
        "namespace": "*",
        "body": "def _subx(pattern, template):\n    # internal: Pattern.sub/subn implementation helper\n    template = _compile_repl(template, pattern)\n    if not template[0] and len(template[1]) == 1:\n        # literal replacement\n        return template[1][0]\n    def filter(match, template=template):\n        return sre_parse.expand_template(template, match)\n    return filter",
        "name_type": "stdlib"
    },
    "re._subx.filter": {
        "API_name": "re._subx.filter",
        "loc_name": "re._subx.filter",
        "args": "match;template",
        "args_default": 1,
        "filepath": "re",
        "lineno": 331,
        "namespace": "*",
        "body": "    def filter(match, template=template):\n        return sre_parse.expand_template(template, match)",
        "name_type": "stdlib"
    },
    "re._pickle": {
        "API_name": "re._pickle",
        "loc_name": "re._pickle",
        "args": "p",
        "args_default": 0,
        "filepath": "re",
        "lineno": 339,
        "namespace": "*",
        "body": "def _pickle(p):\n    return _compile, (p.pattern, p.flags)",
        "name_type": "stdlib"
    },
    "re.Scanner": {
        "API_name": "re.Scanner",
        "loc_name": "re.Scanner",
        "args": "*",
        "args_default": "*",
        "filepath": "re",
        "lineno": 347,
        "namespace": "Scanner",
        "body": "",
        "name_type": "stdlib"
    },
    "re.Scanner.__init__": {
        "API_name": "re.Scanner.__init__",
        "loc_name": "re.Scanner.__init__",
        "args": "self;lexicon;flags",
        "args_default": 1,
        "filepath": "re",
        "lineno": 348,
        "namespace": "Scanner",
        "body": "    def __init__(self, lexicon, flags=0):\n        from sre_constants import BRANCH, SUBPATTERN\n        if isinstance(flags, RegexFlag):\n            flags = flags.value\n        self.lexicon = lexicon\n        # combine phrases into a compound pattern\n        p = []\n        s = sre_parse.State()\n        s.flags = flags\n        for phrase, action in lexicon:\n            gid = s.opengroup()\n            p.append(sre_parse.SubPattern(s, [\n                (SUBPATTERN, (gid, 0, 0, sre_parse.parse(phrase, flags))),\n                ]))\n            s.closegroup(gid, p[-1])\n        p = sre_parse.SubPattern(s, [(BRANCH, (None, p))])\n        self.scanner = sre_compile.compile(p)",
        "name_type": "stdlib"
    },
    "re.Scanner.scan": {
        "API_name": "re.Scanner.scan",
        "loc_name": "re.Scanner.scan",
        "args": "self;string",
        "args_default": 0,
        "filepath": "re",
        "lineno": 365,
        "namespace": "Scanner",
        "body": "    def scan(self, string):\n        result = []\n        append = result.append\n        match = self.scanner.scanner(string).match\n        i = 0\n        while True:\n            m = match()\n            if not m:\n                break\n            j = m.end()\n            if i == j:\n                break\n            action = self.lexicon[m.lastindex-1][1]\n            if callable(action):\n                self.match = m\n                action = action(self, m.group())\n            if action is not None:\n                append(action)\n            i = j\n        return result, string[i:]",
        "name_type": "stdlib"
    },
    "select": {
        "API_name": "select",
        "loc_name": "select",
        "args": "*",
        "args_default": "*",
        "filepath": "select",
        "lineno": "*",
        "namespace": "*",
        "body": null,
        "name_type": "stdlib"
    },
    "shlex": {
        "API_name": "shlex",
        "loc_name": "shlex",
        "args": "*",
        "args_default": "*",
        "filepath": "shlex",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"A lexical analyzer class for simple shell-like syntaxes.\"\"\"\n__all__ = [\"shlex\", \"split\", \"quote\", \"join\"]\n_find_unsafe = re.compile(r'[^\\w@%+=:,./-]', re.ASCII).search\nif __name__ == '__main__':\n    if len(sys.argv) == 1:\n        _print_tokens(shlex())\n    else:\n        fn = sys.argv[1]\n        with open(fn) as f:\n            _print_tokens(shlex(f, fn))",
        "name_type": "stdlib"
    },
    "shlex.shlex": {
        "API_name": "shlex.shlex",
        "loc_name": "shlex.shlex",
        "args": "*",
        "args_default": "*",
        "filepath": "shlex",
        "lineno": 19,
        "namespace": "shlex",
        "body": "",
        "name_type": "stdlib"
    },
    "shlex.shlex.__init__": {
        "API_name": "shlex.shlex.__init__",
        "loc_name": "shlex.shlex.__init__",
        "args": "self;instream;infile;posix;punctuation_chars",
        "args_default": 4,
        "filepath": "shlex",
        "lineno": 21,
        "namespace": "shlex",
        "body": "    def __init__(self, instream=None, infile=None, posix=False,\n                 punctuation_chars=False):\n        if isinstance(instream, str):\n            instream = StringIO(instream)\n        if instream is not None:\n            self.instream = instream\n            self.infile = infile\n        else:\n            self.instream = sys.stdin\n            self.infile = None\n        self.posix = posix\n        if posix:\n            self.eof = None\n        else:\n            self.eof = ''\n        self.commenters = '#'\n        self.wordchars = ('abcdfeghijklmnopqrstuvwxyz'\n                          'ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789_')\n        if self.posix:\n            self.wordchars += ('\u00df\u00e0\u00e1\u00e2\u00e3\u00e4\u00e5\u00e6\u00e7\u00e8\u00e9\u00ea\u00eb\u00ec\u00ed\u00ee\u00ef\u00f0\u00f1\u00f2\u00f3\u00f4\u00f5\u00f6\u00f8\u00f9\u00fa\u00fb\u00fc\u00fd\u00fe\u00ff'\n                               '\u00c0\u00c1\u00c2\u00c3\u00c4\u00c5\u00c6\u00c7\u00c8\u00c9\u00ca\u00cb\u00cc\u00cd\u00ce\u00cf\u00d0\u00d1\u00d2\u00d3\u00d4\u00d5\u00d6\u00d8\u00d9\u00da\u00db\u00dc\u00dd\u00de')\n        self.whitespace = ' \\t\\r\\n'\n        self.whitespace_split = False\n        self.quotes = '\\'\"'\n        self.escape = '\\\\'\n        self.escapedquotes = '\"'\n        self.state = ' '\n        self.pushback = deque()\n        self.lineno = 1\n        self.debug = 0\n        self.token = ''\n        self.filestack = deque()\n        self.source = None\n        if not punctuation_chars:\n            punctuation_chars = ''\n        elif punctuation_chars is True:\n            punctuation_chars = '();<>|&'\n        self._punctuation_chars = punctuation_chars\n        if punctuation_chars:\n            # _pushback_chars is a push back queue used by lookahead logic\n            self._pushback_chars = deque()\n            # these chars added because allowed in file names, args, wildcards\n            self.wordchars += '~-./*?='\n            #remove any punctuation chars from wordchars\n            t = self.wordchars.maketrans(dict.fromkeys(punctuation_chars))\n            self.wordchars = self.wordchars.translate(t)",
        "name_type": "stdlib"
    },
    "shlex.shlex.punctuation_chars": {
        "API_name": "shlex.shlex.punctuation_chars",
        "loc_name": "shlex.shlex.punctuation_chars",
        "args": "self",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 69,
        "namespace": "shlex",
        "body": "    def punctuation_chars(self):\n        return self._punctuation_chars",
        "name_type": "stdlib"
    },
    "shlex.shlex.push_token": {
        "API_name": "shlex.shlex.push_token",
        "loc_name": "shlex.shlex.push_token",
        "args": "self;tok",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 72,
        "namespace": "shlex",
        "body": "    def push_token(self, tok):\n        \"Push a token onto the stack popped by the get_token method\"\n        if self.debug >= 1:\n            print(\"shlex: pushing token \" + repr(tok))\n        self.pushback.appendleft(tok)",
        "name_type": "stdlib"
    },
    "shlex.shlex.push_source": {
        "API_name": "shlex.shlex.push_source",
        "loc_name": "shlex.shlex.push_source",
        "args": "self;newstream;newfile",
        "args_default": 1,
        "filepath": "shlex",
        "lineno": 78,
        "namespace": "shlex",
        "body": "    def push_source(self, newstream, newfile=None):\n        \"Push an input source onto the lexer's input source stack.\"\n        if isinstance(newstream, str):\n            newstream = StringIO(newstream)\n        self.filestack.appendleft((self.infile, self.instream, self.lineno))\n        self.infile = newfile\n        self.instream = newstream\n        self.lineno = 1\n        if self.debug:\n            if newfile is not None:\n                print('shlex: pushing to file %s' % (self.infile,))\n            else:\n                print('shlex: pushing to stream %s' % (self.instream,))",
        "name_type": "stdlib"
    },
    "shlex.shlex.pop_source": {
        "API_name": "shlex.shlex.pop_source",
        "loc_name": "shlex.shlex.pop_source",
        "args": "self",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 92,
        "namespace": "shlex",
        "body": "    def pop_source(self):\n        \"Pop the input source stack.\"\n        self.instream.close()\n        (self.infile, self.instream, self.lineno) = self.filestack.popleft()\n        if self.debug:\n            print('shlex: popping to %s, line %d' \\\n                  % (self.instream, self.lineno))\n        self.state = ' '",
        "name_type": "stdlib"
    },
    "shlex.shlex.get_token": {
        "API_name": "shlex.shlex.get_token",
        "loc_name": "shlex.shlex.get_token",
        "args": "self",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 101,
        "namespace": "shlex",
        "body": "    def get_token(self):\n        \"Get a token from the input stream (or from stack if it's nonempty)\"\n        if self.pushback:\n            tok = self.pushback.popleft()\n            if self.debug >= 1:\n                print(\"shlex: popping token \" + repr(tok))\n            return tok\n        # No pushback.  Get a token.\n        raw = self.read_token()\n        # Handle inclusions\n        if self.source is not None:\n            while raw == self.source:\n                spec = self.sourcehook(self.read_token())\n                if spec:\n                    (newfile, newstream) = spec\n                    self.push_source(newstream, newfile)\n                raw = self.get_token()\n        # Maybe we got EOF instead?\n        while raw == self.eof:\n            if not self.filestack:\n                return self.eof\n            else:\n                self.pop_source()\n                raw = self.get_token()\n        # Neither inclusion nor EOF\n        if self.debug >= 1:\n            if raw != self.eof:\n                print(\"shlex: token=\" + repr(raw))\n            else:\n                print(\"shlex: token=EOF\")\n        return raw",
        "name_type": "stdlib"
    },
    "shlex.shlex.read_token": {
        "API_name": "shlex.shlex.read_token",
        "loc_name": "shlex.shlex.read_token",
        "args": "self",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 133,
        "namespace": "shlex",
        "body": "    def read_token(self):\n        quoted = False\n        escapedstate = ' '\n        while True:\n            if self.punctuation_chars and self._pushback_chars:\n                nextchar = self._pushback_chars.pop()\n            else:\n                nextchar = self.instream.read(1)\n            if nextchar == '\\n':\n                self.lineno += 1\n            if self.debug >= 3:\n                print(\"shlex: in state %r I see character: %r\" % (self.state,\n                                                                  nextchar))\n            if self.state is None:\n                self.token = ''        # past end of file\n                break\n            elif self.state == ' ':\n                if not nextchar:\n                    self.state = None  # end of file\n                    break\n                elif nextchar in self.whitespace:\n                    if self.debug >= 2:\n                        print(\"shlex: I see whitespace in whitespace state\")\n                    if self.token or (self.posix and quoted):\n                        break   # emit current token\n                    else:\n                        continue\n                elif nextchar in self.commenters:\n                    self.instream.readline()\n                    self.lineno += 1\n                elif self.posix and nextchar in self.escape:\n                    escapedstate = 'a'\n                    self.state = nextchar\n                elif nextchar in self.wordchars:\n                    self.token = nextchar\n                    self.state = 'a'\n                elif nextchar in self.punctuation_chars:\n                    self.token = nextchar\n                    self.state = 'c'\n                elif nextchar in self.quotes:\n                    if not self.posix:\n                        self.token = nextchar\n                    self.state = nextchar\n                elif self.whitespace_split:\n                    self.token = nextchar\n                    self.state = 'a'\n                else:\n                    self.token = nextchar\n                    if self.token or (self.posix and quoted):\n                        break   # emit current token\n                    else:\n                        continue\n            elif self.state in self.quotes:\n                quoted = True\n                if not nextchar:      # end of file\n                    if self.debug >= 2:\n                        print(\"shlex: I see EOF in quotes state\")\n                    # XXX what error should be raised here?\n                    raise ValueError(\"No closing quotation\")\n                if nextchar == self.state:\n                    if not self.posix:\n                        self.token += nextchar\n                        self.state = ' '\n                        break\n                    else:\n                        self.state = 'a'\n                elif (self.posix and nextchar in self.escape and self.state\n                      in self.escapedquotes):\n                    escapedstate = self.state\n                    self.state = nextchar\n                else:\n                    self.token += nextchar\n            elif self.state in self.escape:\n                if not nextchar:      # end of file\n                    if self.debug >= 2:\n                        print(\"shlex: I see EOF in escape state\")\n                    # XXX what error should be raised here?\n                    raise ValueError(\"No escaped character\")\n                # In posix shells, only the quote itself or the escape\n                # character may be escaped within quotes.\n                if (escapedstate in self.quotes and\n                        nextchar != self.state and nextchar != escapedstate):\n                    self.token += self.state\n                self.token += nextchar\n                self.state = escapedstate\n            elif self.state in ('a', 'c'):\n                if not nextchar:\n                    self.state = None   # end of file\n                    break\n                elif nextchar in self.whitespace:\n                    if self.debug >= 2:\n                        print(\"shlex: I see whitespace in word state\")\n                    self.state = ' '\n                    if self.token or (self.posix and quoted):\n                        break   # emit current token\n                    else:\n                        continue\n                elif nextchar in self.commenters:\n                    self.instream.readline()\n                    self.lineno += 1\n                    if self.posix:\n                        self.state = ' '\n                        if self.token or (self.posix and quoted):\n                            break   # emit current token\n                        else:\n                            continue\n                elif self.state == 'c':\n                    if nextchar in self.punctuation_chars:\n                        self.token += nextchar\n                    else:\n                        if nextchar not in self.whitespace:\n                            self._pushback_chars.append(nextchar)\n                        self.state = ' '\n                        break\n                elif self.posix and nextchar in self.quotes:\n                    self.state = nextchar\n                elif self.posix and nextchar in self.escape:\n                    escapedstate = 'a'\n                    self.state = nextchar\n                elif (nextchar in self.wordchars or nextchar in self.quotes\n                      or (self.whitespace_split and\n                          nextchar not in self.punctuation_chars)):\n                    self.token += nextchar\n                else:\n                    if self.punctuation_chars:\n                        self._pushback_chars.append(nextchar)\n                    else:\n                        self.pushback.appendleft(nextchar)\n                    if self.debug >= 2:\n                        print(\"shlex: I see punctuation in word state\")\n                    self.state = ' '\n                    if self.token or (self.posix and quoted):\n                        break   # emit current token\n                    else:\n                        continue\n        result = self.token\n        self.token = ''\n        if self.posix and not quoted and result == '':\n            result = None\n        if self.debug > 1:\n            if result:\n                print(\"shlex: raw token=\" + repr(result))\n            else:\n                print(\"shlex: raw token=EOF\")\n        return result",
        "name_type": "stdlib"
    },
    "shlex.shlex.sourcehook": {
        "API_name": "shlex.shlex.sourcehook",
        "loc_name": "shlex.shlex.sourcehook",
        "args": "self;newfile",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 279,
        "namespace": "shlex",
        "body": "    def sourcehook(self, newfile):\n        \"Hook called on a filename to be sourced.\"\n        if newfile[0] == '\"':\n            newfile = newfile[1:-1]\n        # This implements cpp-like semantics for relative-path inclusion.\n        if isinstance(self.infile, str) and not os.path.isabs(newfile):\n            newfile = os.path.join(os.path.dirname(self.infile), newfile)\n        return (newfile, open(newfile, \"r\"))",
        "name_type": "stdlib"
    },
    "shlex.shlex.error_leader": {
        "API_name": "shlex.shlex.error_leader",
        "loc_name": "shlex.shlex.error_leader",
        "args": "self;infile;lineno",
        "args_default": 2,
        "filepath": "shlex",
        "lineno": 288,
        "namespace": "shlex",
        "body": "    def error_leader(self, infile=None, lineno=None):\n        \"Emit a C-compiler-like, Emacs-friendly error-message leader.\"\n        if infile is None:\n            infile = self.infile\n        if lineno is None:\n            lineno = self.lineno\n        return \"\\\"%s\\\", line %d: \" % (infile, lineno)",
        "name_type": "stdlib"
    },
    "shlex.shlex.__iter__": {
        "API_name": "shlex.shlex.__iter__",
        "loc_name": "shlex.shlex.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 296,
        "namespace": "shlex",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "shlex.shlex.__next__": {
        "API_name": "shlex.shlex.__next__",
        "loc_name": "shlex.shlex.__next__",
        "args": "self",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 299,
        "namespace": "shlex",
        "body": "    def __next__(self):\n        token = self.get_token()\n        if token == self.eof:\n            raise StopIteration\n        return token",
        "name_type": "stdlib"
    },
    "shlex.split": {
        "API_name": "shlex.split",
        "loc_name": "shlex.split",
        "args": "s;comments;posix",
        "args_default": 2,
        "filepath": "shlex",
        "lineno": 305,
        "namespace": "*",
        "body": "def split(s, comments=False, posix=True):\n    \"\"\"Split the string *s* using shell-like syntax.\"\"\"\n    if s is None:\n        import warnings\n        warnings.warn(\"Passing None for 's' to shlex.split() is deprecated.\",\n                      DeprecationWarning, stacklevel=2)\n    lex = shlex(s, posix=posix)\n    lex.whitespace_split = True\n    if not comments:\n        lex.commenters = ''\n    return list(lex)",
        "name_type": "stdlib"
    },
    "shlex.join": {
        "API_name": "shlex.join",
        "loc_name": "shlex.join",
        "args": "split_command",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 318,
        "namespace": "*",
        "body": "def join(split_command):\n    \"\"\"Return a shell-escaped string from *split_command*.\"\"\"\n    return ' '.join(quote(arg) for arg in split_command)",
        "name_type": "stdlib"
    },
    "shlex.quote": {
        "API_name": "shlex.quote",
        "loc_name": "shlex.quote",
        "args": "s",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 325,
        "namespace": "*",
        "body": "def quote(s):\n    \"\"\"Return a shell-escaped version of the string *s*.\"\"\"\n    if not s:\n        return \"''\"\n    if _find_unsafe(s) is None:\n        return s\n\n    # use single quotes, and put single quotes into double quotes\n    # the string $'b is then quoted as '$'\"'\"'b'\n    return \"'\" + s.replace(\"'\", \"'\\\"'\\\"'\") + \"'\"",
        "name_type": "stdlib"
    },
    "shlex._print_tokens": {
        "API_name": "shlex._print_tokens",
        "loc_name": "shlex._print_tokens",
        "args": "lexer",
        "args_default": 0,
        "filepath": "shlex",
        "lineno": 337,
        "namespace": "*",
        "body": "def _print_tokens(lexer):\n    while 1:\n        tt = lexer.get_token()\n        if not tt:\n            break\n        print(\"Token: \" + repr(tt))",
        "name_type": "stdlib"
    },
    "shutil": {
        "API_name": "shutil",
        "loc_name": "shutil",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Utility functions for copying and archiving files and directory trees.\n\nXXX The functions here don't copy the resource fork or other metadata on Mac.\n\n\"\"\"\ntry:\n    import zlib\n    del zlib\n    _ZLIB_SUPPORTED = True\nexcept ImportError:\n    _ZLIB_SUPPORTED = False\ntry:\n    import bz2\n    del bz2\n    _BZ2_SUPPORTED = True\nexcept ImportError:\n    _BZ2_SUPPORTED = False\ntry:\n    import lzma\n    del lzma\n    _LZMA_SUPPORTED = True\nexcept ImportError:\n    _LZMA_SUPPORTED = False\ntry:\n    from pwd import getpwnam\nexcept ImportError:\n    getpwnam = None\ntry:\n    from grp import getgrnam\nexcept ImportError:\n    getgrnam = None\n_WINDOWS = os.name == 'nt'\nposix = nt = None\nif os.name == 'posix':\n    import posix\nelif _WINDOWS:\n    import nt\nCOPY_BUFSIZE = 1024 * 1024 if _WINDOWS else 64 * 1024\n_USE_CP_SENDFILE = hasattr(os, \"sendfile\") and sys.platform.startswith(\"linux\")\n_HAS_FCOPYFILE = posix and hasattr(posix, \"_fcopyfile\")  # macOS\n_WIN_DEFAULT_PATHEXT = \".COM;.EXE;.BAT;.CMD;.VBS;.JS;.WS;.MSC\"\n__all__ = [\"copyfileobj\", \"copyfile\", \"copymode\", \"copystat\", \"copy\", \"copy2\",\n           \"copytree\", \"move\", \"rmtree\", \"Error\", \"SpecialFileError\",\n           \"ExecError\", \"make_archive\", \"get_archive_formats\",\n           \"register_archive_format\", \"unregister_archive_format\",\n           \"get_unpack_formats\", \"register_unpack_format\",\n           \"unregister_unpack_format\", \"unpack_archive\",\n           \"ignore_patterns\", \"chown\", \"which\", \"get_terminal_size\",\n           \"SameFileError\"]\nif hasattr(os, 'listxattr'):\n    def _copyxattr(src, dst, *, follow_symlinks=True):\n        \"\"\"Copy extended filesystem attributes from `src` to `dst`.\n\n        Overwrite existing attributes.\n\n        If `follow_symlinks` is false, symlinks won't be followed.\n\n        \"\"\"\n\n        try:\n            names = os.listxattr(src, follow_symlinks=follow_symlinks)\n        except OSError as e:\n            if e.errno not in (errno.ENOTSUP, errno.ENODATA, errno.EINVAL):\n                raise\n            return\n        for name in names:\n            try:\n                value = os.getxattr(src, name, follow_symlinks=follow_symlinks)\n                os.setxattr(dst, name, value, follow_symlinks=follow_symlinks)\n            except OSError as e:\n                if e.errno not in (errno.EPERM, errno.ENOTSUP, errno.ENODATA,\n                                   errno.EINVAL):\n                    raise\nelse:\n    def _copyxattr(*args, **kwargs):\n        pass\nif hasattr(os.stat_result, 'st_file_attributes'):\n    # Special handling for directory junctions to make them behave like\n    # symlinks for shutil.rmtree, since in general they do not appear as\n    # regular links.\n    def _rmtree_isdir(entry):\n        try:\n            st = entry.stat(follow_symlinks=False)\n            return (stat.S_ISDIR(st.st_mode) and not\n                (st.st_file_attributes & stat.FILE_ATTRIBUTE_REPARSE_POINT\n                 and st.st_reparse_tag == stat.IO_REPARSE_TAG_MOUNT_POINT))\n        except OSError:\n            return False\n\n    def _rmtree_islink(path):\n        try:\n            st = os.lstat(path)\n            return (stat.S_ISLNK(st.st_mode) or\n                (st.st_file_attributes & stat.FILE_ATTRIBUTE_REPARSE_POINT\n                 and st.st_reparse_tag == stat.IO_REPARSE_TAG_MOUNT_POINT))\n        except OSError:\n            return False\nelse:\n    def _rmtree_isdir(entry):\n        try:\n            return entry.is_dir(follow_symlinks=False)\n        except OSError:\n            return False\n\n    def _rmtree_islink(path):\n        return os.path.islink(path)\n_use_fd_functions = ({os.open, os.stat, os.unlink, os.rmdir} <=\n                     os.supports_dir_fd and\n                     os.scandir in os.supports_fd and\n                     os.stat in os.supports_follow_symlinks)\nrmtree.avoids_symlink_attacks = _use_fd_functions\n_ARCHIVE_FORMATS = {\n    'tar':   (_make_tarball, [('compress', None)], \"uncompressed tar file\"),\n}\nif _ZLIB_SUPPORTED:\n    _ARCHIVE_FORMATS['gztar'] = (_make_tarball, [('compress', 'gzip')],\n                                \"gzip'ed tar-file\")\n    _ARCHIVE_FORMATS['zip'] = (_make_zipfile, [], \"ZIP file\")\nif _BZ2_SUPPORTED:\n    _ARCHIVE_FORMATS['bztar'] = (_make_tarball, [('compress', 'bzip2')],\n                                \"bzip2'ed tar-file\")\nif _LZMA_SUPPORTED:\n    _ARCHIVE_FORMATS['xztar'] = (_make_tarball, [('compress', 'xz')],\n                                \"xz'ed tar-file\")\n_UNPACK_FORMATS = {\n    'tar':   (['.tar'], _unpack_tarfile, [], \"uncompressed tar file\"),\n    'zip':   (['.zip'], _unpack_zipfile, [], \"ZIP file\"),\n}\nif _ZLIB_SUPPORTED:\n    _UNPACK_FORMATS['gztar'] = (['.tar.gz', '.tgz'], _unpack_tarfile, [],\n                                \"gzip'ed tar-file\")\nif _BZ2_SUPPORTED:\n    _UNPACK_FORMATS['bztar'] = (['.tar.bz2', '.tbz2'], _unpack_tarfile, [],\n                                \"bzip2'ed tar-file\")\nif _LZMA_SUPPORTED:\n    _UNPACK_FORMATS['xztar'] = (['.tar.xz', '.txz'], _unpack_tarfile, [],\n                                \"xz'ed tar-file\")\nif hasattr(os, 'statvfs'):\n\n    __all__.append('disk_usage')\n    _ntuple_diskusage = collections.namedtuple('usage', 'total used free')\n    _ntuple_diskusage.total.__doc__ = 'Total space in bytes'\n    _ntuple_diskusage.used.__doc__ = 'Used space in bytes'\n    _ntuple_diskusage.free.__doc__ = 'Free space in bytes'\n\n    def disk_usage(path):\n        \"\"\"Return disk usage statistics about the given path.\n\n        Returned value is a named tuple with attributes 'total', 'used' and\n        'free', which are the amount of total, used and free space, in bytes.\n        \"\"\"\n        st = os.statvfs(path)\n        free = st.f_bavail * st.f_frsize\n        total = st.f_blocks * st.f_frsize\n        used = (st.f_blocks - st.f_bfree) * st.f_frsize\n        return _ntuple_diskusage(total, used, free)\n\nelif _WINDOWS:\n\n    __all__.append('disk_usage')\n    _ntuple_diskusage = collections.namedtuple('usage', 'total used free')\n\n    def disk_usage(path):\n        \"\"\"Return disk usage statistics about the given path.\n\n        Returned values is a named tuple with attributes 'total', 'used' and\n        'free', which are the amount of total, used and free space, in bytes.\n        \"\"\"\n        total, free = nt._getdiskusage(path)\n        used = total - free\n        return _ntuple_diskusage(total, used, free)",
        "name_type": "stdlib"
    },
    "shutil.Error": {
        "API_name": "shutil.Error",
        "loc_name": "shutil.Error",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 69,
        "namespace": "Error",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil.SameFileError": {
        "API_name": "shutil.SameFileError",
        "loc_name": "shutil.SameFileError",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 72,
        "namespace": "SameFileError",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil.SpecialFileError": {
        "API_name": "shutil.SpecialFileError",
        "loc_name": "shutil.SpecialFileError",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 75,
        "namespace": "SpecialFileError",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil.ExecError": {
        "API_name": "shutil.ExecError",
        "loc_name": "shutil.ExecError",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 79,
        "namespace": "ExecError",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil.ReadError": {
        "API_name": "shutil.ReadError",
        "loc_name": "shutil.ReadError",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 82,
        "namespace": "ReadError",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil.RegistryError": {
        "API_name": "shutil.RegistryError",
        "loc_name": "shutil.RegistryError",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 85,
        "namespace": "RegistryError",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil._GiveupOnFastCopy": {
        "API_name": "shutil._GiveupOnFastCopy",
        "loc_name": "shutil._GiveupOnFastCopy",
        "args": "*",
        "args_default": "*",
        "filepath": "shutil",
        "lineno": 89,
        "namespace": "_GiveupOnFastCopy",
        "body": "",
        "name_type": "stdlib"
    },
    "shutil._fastcopy_fcopyfile": {
        "API_name": "shutil._fastcopy_fcopyfile",
        "loc_name": "shutil._fastcopy_fcopyfile",
        "args": "fsrc;fdst;flags",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 94,
        "namespace": "*",
        "body": "def _fastcopy_fcopyfile(fsrc, fdst, flags):\n    \"\"\"Copy a regular file content or metadata by using high-performance\n    fcopyfile(3) syscall (macOS).\n    \"\"\"\n    try:\n        infd = fsrc.fileno()\n        outfd = fdst.fileno()\n    except Exception as err:\n        raise _GiveupOnFastCopy(err)  # not a regular file\n\n    try:\n        posix._fcopyfile(infd, outfd, flags)\n    except OSError as err:\n        err.filename = fsrc.name\n        err.filename2 = fdst.name\n        if err.errno in {errno.EINVAL, errno.ENOTSUP}:\n            raise _GiveupOnFastCopy(err)\n        else:\n            raise err from None",
        "name_type": "stdlib"
    },
    "shutil._fastcopy_sendfile": {
        "API_name": "shutil._fastcopy_sendfile",
        "loc_name": "shutil._fastcopy_sendfile",
        "args": "fsrc;fdst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 114,
        "namespace": "*",
        "body": "def _fastcopy_sendfile(fsrc, fdst):\n    \"\"\"Copy data from one regular mmap-like fd to another by using\n    high-performance sendfile(2) syscall.\n    This should work on Linux >= 2.6.33 only.\n    \"\"\"\n    # Note: copyfileobj() is left alone in order to not introduce any\n    # unexpected breakage. Possible risks by using zero-copy calls\n    # in copyfileobj() are:\n    # - fdst cannot be open in \"a\"(ppend) mode\n    # - fsrc and fdst may be open in \"t\"(ext) mode\n    # - fsrc may be a BufferedReader (which hides unread data in a buffer),\n    #   GzipFile (which decompresses data), HTTPResponse (which decodes\n    #   chunks).\n    # - possibly others (e.g. encrypted fs/partition?)\n    global _USE_CP_SENDFILE\n    try:\n        infd = fsrc.fileno()\n        outfd = fdst.fileno()\n    except Exception as err:\n        raise _GiveupOnFastCopy(err)  # not a regular file\n\n    # Hopefully the whole file will be copied in a single call.\n    # sendfile() is called in a loop 'till EOF is reached (0 return)\n    # so a bufsize smaller or bigger than the actual file size\n    # should not make any difference, also in case the file content\n    # changes while being copied.\n    try:\n        blocksize = max(os.fstat(infd).st_size, 2 ** 23)  # min 8MiB\n    except OSError:\n        blocksize = 2 ** 27  # 128MiB\n    # On 32-bit architectures truncate to 1GiB to avoid OverflowError,\n    # see bpo-38319.\n    if sys.maxsize < 2 ** 32:\n        blocksize = min(blocksize, 2 ** 30)\n\n    offset = 0\n    while True:\n        try:\n            sent = os.sendfile(outfd, infd, offset, blocksize)\n        except OSError as err:\n            # ...in oder to have a more informative exception.\n            err.filename = fsrc.name\n            err.filename2 = fdst.name\n\n            if err.errno == errno.ENOTSOCK:\n                # sendfile() on this platform (probably Linux < 2.6.33)\n                # does not support copies between regular files (only\n                # sockets).\n                _USE_CP_SENDFILE = False\n                raise _GiveupOnFastCopy(err)\n\n            if err.errno == errno.ENOSPC:  # filesystem is full\n                raise err from None\n\n            # Give up on first call and if no data was copied.\n            if offset == 0 and os.lseek(outfd, 0, os.SEEK_CUR) == 0:\n                raise _GiveupOnFastCopy(err)\n\n            raise err\n        else:\n            if sent == 0:\n                break  # EOF\n            offset += sent",
        "name_type": "stdlib"
    },
    "shutil._copyfileobj_readinto": {
        "API_name": "shutil._copyfileobj_readinto",
        "loc_name": "shutil._copyfileobj_readinto",
        "args": "fsrc;fdst;length",
        "args_default": 1,
        "filepath": "shutil",
        "lineno": 178,
        "namespace": "*",
        "body": "def _copyfileobj_readinto(fsrc, fdst, length=COPY_BUFSIZE):\n    \"\"\"readinto()/memoryview() based variant of copyfileobj().\n    *fsrc* must support readinto() method and both files must be\n    open in binary mode.\n    \"\"\"\n    # Localize variable access to minimize overhead.\n    fsrc_readinto = fsrc.readinto\n    fdst_write = fdst.write\n    with memoryview(bytearray(length)) as mv:\n        while True:\n            n = fsrc_readinto(mv)\n            if not n:\n                break\n            elif n < length:\n                with mv[:n] as smv:\n                    fdst.write(smv)\n            else:\n                fdst_write(mv)",
        "name_type": "stdlib"
    },
    "shutil.copyfileobj": {
        "API_name": "shutil.copyfileobj",
        "loc_name": "shutil.copyfileobj",
        "args": "fsrc;fdst;length",
        "args_default": 1,
        "filepath": "shutil",
        "lineno": 197,
        "namespace": "*",
        "body": "def copyfileobj(fsrc, fdst, length=0):\n    \"\"\"copy data from file-like object fsrc to file-like object fdst\"\"\"\n    # Localize variable access to minimize overhead.\n    if not length:\n        length = COPY_BUFSIZE\n    fsrc_read = fsrc.read\n    fdst_write = fdst.write\n    while True:\n        buf = fsrc_read(length)\n        if not buf:\n            break\n        fdst_write(buf)",
        "name_type": "stdlib"
    },
    "shutil._samefile": {
        "API_name": "shutil._samefile",
        "loc_name": "shutil._samefile",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 210,
        "namespace": "*",
        "body": "def _samefile(src, dst):\n    # Macintosh, Unix.\n    if isinstance(src, os.DirEntry) and hasattr(os.path, 'samestat'):\n        try:\n            return os.path.samestat(src.stat(), os.stat(dst))\n        except OSError:\n            return False\n\n    if hasattr(os.path, 'samefile'):\n        try:\n            return os.path.samefile(src, dst)\n        except OSError:\n            return False\n\n    # All other platforms: check for same pathname.\n    return (os.path.normcase(os.path.abspath(src)) ==\n            os.path.normcase(os.path.abspath(dst)))",
        "name_type": "stdlib"
    },
    "shutil._stat": {
        "API_name": "shutil._stat",
        "loc_name": "shutil._stat",
        "args": "fn",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 228,
        "namespace": "*",
        "body": "def _stat(fn):\n    return fn.stat() if isinstance(fn, os.DirEntry) else os.stat(fn)",
        "name_type": "stdlib"
    },
    "shutil._islink": {
        "API_name": "shutil._islink",
        "loc_name": "shutil._islink",
        "args": "fn",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 231,
        "namespace": "*",
        "body": "def _islink(fn):\n    return fn.is_symlink() if isinstance(fn, os.DirEntry) else os.path.islink(fn)",
        "name_type": "stdlib"
    },
    "shutil.copyfile": {
        "API_name": "shutil.copyfile",
        "loc_name": "shutil.copyfile",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 234,
        "namespace": "*",
        "body": "def copyfile(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy data from src to dst in the most efficient way possible.\n\n    If follow_symlinks is not set and src is a symbolic link, a new\n    symlink will be created instead of copying the file it points to.\n\n    \"\"\"\n    sys.audit(\"shutil.copyfile\", src, dst)\n\n    if _samefile(src, dst):\n        raise SameFileError(\"{!r} and {!r} are the same file\".format(src, dst))\n\n    file_size = 0\n    for i, fn in enumerate([src, dst]):\n        try:\n            st = _stat(fn)\n        except OSError:\n            # File most likely does not exist\n            pass\n        else:\n            # XXX What about other special files? (sockets, devices...)\n            if stat.S_ISFIFO(st.st_mode):\n                fn = fn.path if isinstance(fn, os.DirEntry) else fn\n                raise SpecialFileError(\"`%s` is a named pipe\" % fn)\n            if _WINDOWS and i == 0:\n                file_size = st.st_size\n\n    if not follow_symlinks and _islink(src):\n        os.symlink(os.readlink(src), dst)\n    else:\n        with open(src, 'rb') as fsrc:\n            try:\n                with open(dst, 'wb') as fdst:\n                    # macOS\n                    if _HAS_FCOPYFILE:\n                        try:\n                            _fastcopy_fcopyfile(fsrc, fdst, posix._COPYFILE_DATA)\n                            return dst\n                        except _GiveupOnFastCopy:\n                            pass\n                    # Linux\n                    elif _USE_CP_SENDFILE:\n                        try:\n                            _fastcopy_sendfile(fsrc, fdst)\n                            return dst\n                        except _GiveupOnFastCopy:\n                            pass\n                    # Windows, see:\n                    # https://github.com/python/cpython/pull/7160#discussion_r195405230\n                    elif _WINDOWS and file_size > 0:\n                        _copyfileobj_readinto(fsrc, fdst, min(file_size, COPY_BUFSIZE))\n                        return dst\n\n                    copyfileobj(fsrc, fdst)\n\n            # Issue 43219, raise a less confusing exception\n            except IsADirectoryError as e:\n                if not os.path.exists(dst):\n                    raise FileNotFoundError(f'Directory does not exist: {dst}') from e\n                else:\n                    raise\n\n    return dst",
        "name_type": "stdlib"
    },
    "shutil.copymode": {
        "API_name": "shutil.copymode",
        "loc_name": "shutil.copymode",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 298,
        "namespace": "*",
        "body": "def copymode(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy mode bits from src to dst.\n\n    If follow_symlinks is not set, symlinks aren't followed if and only\n    if both `src` and `dst` are symlinks.  If `lchmod` isn't available\n    (e.g. Linux) this method does nothing.\n\n    \"\"\"\n    sys.audit(\"shutil.copymode\", src, dst)\n\n    if not follow_symlinks and _islink(src) and os.path.islink(dst):\n        if hasattr(os, 'lchmod'):\n            stat_func, chmod_func = os.lstat, os.lchmod\n        else:\n            return\n    else:\n        stat_func, chmod_func = _stat, os.chmod\n\n    st = stat_func(src)\n    chmod_func(dst, stat.S_IMODE(st.st_mode))",
        "name_type": "stdlib"
    },
    "shutil._copyxattr": {
        "API_name": "shutil._copyxattr",
        "loc_name": "shutil._copyxattr",
        "args": "",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 344,
        "namespace": "*",
        "body": "    def _copyxattr(*args, **kwargs):\n        pass",
        "name_type": "stdlib"
    },
    "shutil.copystat": {
        "API_name": "shutil.copystat",
        "loc_name": "shutil.copystat",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 347,
        "namespace": "*",
        "body": "def copystat(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy file metadata\n\n    Copy the permission bits, last access time, last modification time, and\n    flags from `src` to `dst`. On Linux, copystat() also copies the \"extended\n    attributes\" where possible. The file contents, owner, and group are\n    unaffected. `src` and `dst` are path-like objects or path names given as\n    strings.\n\n    If the optional flag `follow_symlinks` is not set, symlinks aren't\n    followed if and only if both `src` and `dst` are symlinks.\n    \"\"\"\n    sys.audit(\"shutil.copystat\", src, dst)\n\n    def _nop(*args, ns=None, follow_symlinks=None):\n        pass\n\n    # follow symlinks (aka don't not follow symlinks)\n    follow = follow_symlinks or not (_islink(src) and os.path.islink(dst))\n    if follow:\n        # use the real function if it exists\n        def lookup(name):\n            return getattr(os, name, _nop)\n    else:\n        # use the real function only if it exists\n        # *and* it supports follow_symlinks\n        def lookup(name):\n            fn = getattr(os, name, _nop)\n            if fn in os.supports_follow_symlinks:\n                return fn\n            return _nop\n\n    if isinstance(src, os.DirEntry):\n        st = src.stat(follow_symlinks=follow)\n    else:\n        st = lookup(\"stat\")(src, follow_symlinks=follow)\n    mode = stat.S_IMODE(st.st_mode)\n    lookup(\"utime\")(dst, ns=(st.st_atime_ns, st.st_mtime_ns),\n        follow_symlinks=follow)\n    # We must copy extended attributes before the file is (potentially)\n    # chmod()'ed read-only, otherwise setxattr() will error with -EACCES.\n    _copyxattr(src, dst, follow_symlinks=follow)\n    try:\n        lookup(\"chmod\")(dst, mode, follow_symlinks=follow)\n    except NotImplementedError:\n        # if we got a NotImplementedError, it's because\n        #   * follow_symlinks=False,\n        #   * lchown() is unavailable, and\n        #   * either\n        #       * fchownat() is unavailable or\n        #       * fchownat() doesn't implement AT_SYMLINK_NOFOLLOW.\n        #         (it returned ENOSUP.)\n        # therefore we're out of options--we simply cannot chown the\n        # symlink.  give up, suppress the error.\n        # (which is what shutil always did in this circumstance.)\n        pass\n    if hasattr(st, 'st_flags'):\n        try:\n            lookup(\"chflags\")(dst, st.st_flags, follow_symlinks=follow)\n        except OSError as why:\n            for err in 'EOPNOTSUPP', 'ENOTSUP':\n                if hasattr(errno, err) and why.errno == getattr(errno, err):\n                    break\n            else:\n                raise",
        "name_type": "stdlib"
    },
    "shutil.copystat._nop": {
        "API_name": "shutil.copystat._nop",
        "loc_name": "shutil.copystat._nop",
        "args": "",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 361,
        "namespace": "*",
        "body": "    def _nop(*args, ns=None, follow_symlinks=None):\n        pass",
        "name_type": "stdlib"
    },
    "shutil.copy": {
        "API_name": "shutil.copy",
        "loc_name": "shutil.copy",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 413,
        "namespace": "*",
        "body": "def copy(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy data and mode bits (\"cp src dst\"). Return the file's destination.\n\n    The destination may be a directory.\n\n    If follow_symlinks is false, symlinks won't be followed. This\n    resembles GNU's \"cp -P src dst\".\n\n    If source and destination are the same file, a SameFileError will be\n    raised.\n\n    \"\"\"\n    if os.path.isdir(dst):\n        dst = os.path.join(dst, os.path.basename(src))\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\n    copymode(src, dst, follow_symlinks=follow_symlinks)\n    return dst",
        "name_type": "stdlib"
    },
    "shutil.copy2": {
        "API_name": "shutil.copy2",
        "loc_name": "shutil.copy2",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 431,
        "namespace": "*",
        "body": "def copy2(src, dst, *, follow_symlinks=True):\n    \"\"\"Copy data and metadata. Return the file's destination.\n\n    Metadata is copied with copystat(). Please see the copystat function\n    for more information.\n\n    The destination may be a directory.\n\n    If follow_symlinks is false, symlinks won't be followed. This\n    resembles GNU's \"cp -P src dst\".\n    \"\"\"\n    if os.path.isdir(dst):\n        dst = os.path.join(dst, os.path.basename(src))\n    copyfile(src, dst, follow_symlinks=follow_symlinks)\n    copystat(src, dst, follow_symlinks=follow_symlinks)\n    return dst",
        "name_type": "stdlib"
    },
    "shutil.ignore_patterns": {
        "API_name": "shutil.ignore_patterns",
        "loc_name": "shutil.ignore_patterns",
        "args": "",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 448,
        "namespace": "*",
        "body": "def ignore_patterns(*patterns):\n    \"\"\"Function that can be used as copytree() ignore parameter.\n\n    Patterns is a sequence of glob-style patterns\n    that are used to exclude files\"\"\"\n    def _ignore_patterns(path, names):\n        ignored_names = []\n        for pattern in patterns:\n            ignored_names.extend(fnmatch.filter(names, pattern))\n        return set(ignored_names)\n    return _ignore_patterns",
        "name_type": "stdlib"
    },
    "shutil.ignore_patterns._ignore_patterns": {
        "API_name": "shutil.ignore_patterns._ignore_patterns",
        "loc_name": "shutil.ignore_patterns._ignore_patterns",
        "args": "path;names",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 453,
        "namespace": "*",
        "body": "    def _ignore_patterns(path, names):\n        ignored_names = []\n        for pattern in patterns:\n            ignored_names.extend(fnmatch.filter(names, pattern))\n        return set(ignored_names)",
        "name_type": "stdlib"
    },
    "shutil._copytree": {
        "API_name": "shutil._copytree",
        "loc_name": "shutil._copytree",
        "args": "entries;src;dst;symlinks;ignore;copy_function;ignore_dangling_symlinks;dirs_exist_ok",
        "args_default": 1,
        "filepath": "shutil",
        "lineno": 460,
        "namespace": "*",
        "body": "def _copytree(entries, src, dst, symlinks, ignore, copy_function,\n              ignore_dangling_symlinks, dirs_exist_ok=False):\n    if ignore is not None:\n        ignored_names = ignore(os.fspath(src), [x.name for x in entries])\n    else:\n        ignored_names = set()\n\n    os.makedirs(dst, exist_ok=dirs_exist_ok)\n    errors = []\n    use_srcentry = copy_function is copy2 or copy_function is copy\n\n    for srcentry in entries:\n        if srcentry.name in ignored_names:\n            continue\n        srcname = os.path.join(src, srcentry.name)\n        dstname = os.path.join(dst, srcentry.name)\n        srcobj = srcentry if use_srcentry else srcname\n        try:\n            is_symlink = srcentry.is_symlink()\n            if is_symlink and os.name == 'nt':\n                # Special check for directory junctions, which appear as\n                # symlinks but we want to recurse.\n                lstat = srcentry.stat(follow_symlinks=False)\n                if lstat.st_reparse_tag == stat.IO_REPARSE_TAG_MOUNT_POINT:\n                    is_symlink = False\n            if is_symlink:\n                linkto = os.readlink(srcname)\n                if symlinks:\n                    # We can't just leave it to `copy_function` because legacy\n                    # code with a custom `copy_function` may rely on copytree\n                    # doing the right thing.\n                    os.symlink(linkto, dstname)\n                    copystat(srcobj, dstname, follow_symlinks=not symlinks)\n                else:\n                    # ignore dangling symlink if the flag is on\n                    if not os.path.exists(linkto) and ignore_dangling_symlinks:\n                        continue\n                    # otherwise let the copy occur. copy2 will raise an error\n                    if srcentry.is_dir():\n                        copytree(srcobj, dstname, symlinks, ignore,\n                                 copy_function, dirs_exist_ok=dirs_exist_ok)\n                    else:\n                        copy_function(srcobj, dstname)\n            elif srcentry.is_dir():\n                copytree(srcobj, dstname, symlinks, ignore, copy_function,\n                         dirs_exist_ok=dirs_exist_ok)\n            else:\n                # Will raise a SpecialFileError for unsupported file types\n                copy_function(srcobj, dstname)\n        # catch the Error from the recursive copytree so that we can\n        # continue with other files\n        except Error as err:\n            errors.extend(err.args[0])\n        except OSError as why:\n            errors.append((srcname, dstname, str(why)))\n    try:\n        copystat(src, dst)\n    except OSError as why:\n        # Copying file access times may fail on Windows\n        if getattr(why, 'winerror', None) is None:\n            errors.append((src, dst, str(why)))\n    if errors:\n        raise Error(errors)\n    return dst",
        "name_type": "stdlib"
    },
    "shutil.copytree": {
        "API_name": "shutil.copytree",
        "loc_name": "shutil.copytree",
        "args": "src;dst;symlinks;ignore;copy_function;ignore_dangling_symlinks;dirs_exist_ok",
        "args_default": 5,
        "filepath": "shutil",
        "lineno": 525,
        "namespace": "*",
        "body": "def copytree(src, dst, symlinks=False, ignore=None, copy_function=copy2,\n             ignore_dangling_symlinks=False, dirs_exist_ok=False):\n    \"\"\"Recursively copy a directory tree and return the destination directory.\n\n    If exception(s) occur, an Error is raised with a list of reasons.\n\n    If the optional symlinks flag is true, symbolic links in the\n    source tree result in symbolic links in the destination tree; if\n    it is false, the contents of the files pointed to by symbolic\n    links are copied. If the file pointed by the symlink doesn't\n    exist, an exception will be added in the list of errors raised in\n    an Error exception at the end of the copy process.\n\n    You can set the optional ignore_dangling_symlinks flag to true if you\n    want to silence this exception. Notice that this has no effect on\n    platforms that don't support os.symlink.\n\n    The optional ignore argument is a callable. If given, it\n    is called with the `src` parameter, which is the directory\n    being visited by copytree(), and `names` which is the list of\n    `src` contents, as returned by os.listdir():\n\n        callable(src, names) -> ignored_names\n\n    Since copytree() is called recursively, the callable will be\n    called once for each directory that is copied. It returns a\n    list of names relative to the `src` directory that should\n    not be copied.\n\n    The optional copy_function argument is a callable that will be used\n    to copy each file. It will be called with the source path and the\n    destination path as arguments. By default, copy2() is used, but any\n    function that supports the same signature (like copy()) can be used.\n\n    If dirs_exist_ok is false (the default) and `dst` already exists, a\n    `FileExistsError` is raised. If `dirs_exist_ok` is true, the copying\n    operation will continue if it encounters existing directories, and files\n    within the `dst` tree will be overwritten by corresponding files from the\n    `src` tree.\n    \"\"\"\n    sys.audit(\"shutil.copytree\", src, dst)\n    with os.scandir(src) as itr:\n        entries = list(itr)\n    return _copytree(entries=entries, src=src, dst=dst, symlinks=symlinks,\n                     ignore=ignore, copy_function=copy_function,\n                     ignore_dangling_symlinks=ignore_dangling_symlinks,\n                     dirs_exist_ok=dirs_exist_ok)",
        "name_type": "stdlib"
    },
    "shutil._rmtree_isdir": {
        "API_name": "shutil._rmtree_isdir",
        "loc_name": "shutil._rmtree_isdir",
        "args": "entry",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 595,
        "namespace": "*",
        "body": "    def _rmtree_isdir(entry):\n        try:\n            return entry.is_dir(follow_symlinks=False)\n        except OSError:\n            return False",
        "name_type": "stdlib"
    },
    "shutil._rmtree_islink": {
        "API_name": "shutil._rmtree_islink",
        "loc_name": "shutil._rmtree_islink",
        "args": "path",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 601,
        "namespace": "*",
        "body": "    def _rmtree_islink(path):\n        return os.path.islink(path)",
        "name_type": "stdlib"
    },
    "shutil._rmtree_unsafe": {
        "API_name": "shutil._rmtree_unsafe",
        "loc_name": "shutil._rmtree_unsafe",
        "args": "path;onerror",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 605,
        "namespace": "*",
        "body": "def _rmtree_unsafe(path, onerror):\n    try:\n        with os.scandir(path) as scandir_it:\n            entries = list(scandir_it)\n    except OSError:\n        onerror(os.scandir, path, sys.exc_info())\n        entries = []\n    for entry in entries:\n        fullname = entry.path\n        if _rmtree_isdir(entry):\n            try:\n                if entry.is_symlink():\n                    # This can only happen if someone replaces\n                    # a directory with a symlink after the call to\n                    # os.scandir or entry.is_dir above.\n                    raise OSError(\"Cannot call rmtree on a symbolic link\")\n            except OSError:\n                onerror(os.path.islink, fullname, sys.exc_info())\n                continue\n            _rmtree_unsafe(fullname, onerror)\n        else:\n            try:\n                os.unlink(fullname)\n            except OSError:\n                onerror(os.unlink, fullname, sys.exc_info())\n    try:\n        os.rmdir(path)\n    except OSError:\n        onerror(os.rmdir, path, sys.exc_info())",
        "name_type": "stdlib"
    },
    "shutil._rmtree_safe_fd": {
        "API_name": "shutil._rmtree_safe_fd",
        "loc_name": "shutil._rmtree_safe_fd",
        "args": "topfd;path;onerror",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 636,
        "namespace": "*",
        "body": "def _rmtree_safe_fd(topfd, path, onerror):\n    try:\n        with os.scandir(topfd) as scandir_it:\n            entries = list(scandir_it)\n    except OSError as err:\n        err.filename = path\n        onerror(os.scandir, path, sys.exc_info())\n        return\n    for entry in entries:\n        fullname = os.path.join(path, entry.name)\n        try:\n            is_dir = entry.is_dir(follow_symlinks=False)\n        except OSError:\n            is_dir = False\n        else:\n            if is_dir:\n                try:\n                    orig_st = entry.stat(follow_symlinks=False)\n                    is_dir = stat.S_ISDIR(orig_st.st_mode)\n                except OSError:\n                    onerror(os.lstat, fullname, sys.exc_info())\n                    continue\n        if is_dir:\n            try:\n                dirfd = os.open(entry.name, os.O_RDONLY, dir_fd=topfd)\n                dirfd_closed = False\n            except OSError:\n                onerror(os.open, fullname, sys.exc_info())\n            else:\n                try:\n                    if os.path.samestat(orig_st, os.fstat(dirfd)):\n                        _rmtree_safe_fd(dirfd, fullname, onerror)\n                        try:\n                            os.close(dirfd)\n                            dirfd_closed = True\n                            os.rmdir(entry.name, dir_fd=topfd)\n                        except OSError:\n                            onerror(os.rmdir, fullname, sys.exc_info())\n                    else:\n                        try:\n                            # This can only happen if someone replaces\n                            # a directory with a symlink after the call to\n                            # os.scandir or stat.S_ISDIR above.\n                            raise OSError(\"Cannot call rmtree on a symbolic \"\n                                          \"link\")\n                        except OSError:\n                            onerror(os.path.islink, fullname, sys.exc_info())\n                finally:\n                    if not dirfd_closed:\n                        os.close(dirfd)\n        else:\n            try:\n                os.unlink(entry.name, dir_fd=topfd)\n            except OSError:\n                onerror(os.unlink, fullname, sys.exc_info())",
        "name_type": "stdlib"
    },
    "shutil.rmtree": {
        "API_name": "shutil.rmtree",
        "loc_name": "shutil.rmtree",
        "args": "path;ignore_errors;onerror",
        "args_default": 2,
        "filepath": "shutil",
        "lineno": 697,
        "namespace": "*",
        "body": "def rmtree(path, ignore_errors=False, onerror=None):\n    \"\"\"Recursively delete a directory tree.\n\n    If ignore_errors is set, errors are ignored; otherwise, if onerror\n    is set, it is called to handle the error with arguments (func,\n    path, exc_info) where func is platform and implementation dependent;\n    path is the argument to that function that caused it to fail; and\n    exc_info is a tuple returned by sys.exc_info().  If ignore_errors\n    is false and onerror is None, an exception is raised.\n\n    \"\"\"\n    sys.audit(\"shutil.rmtree\", path)\n    if ignore_errors:\n        def onerror(*args):\n            pass\n    elif onerror is None:\n        def onerror(*args):\n            raise\n    if _use_fd_functions:\n        # While the unsafe rmtree works fine on bytes, the fd based does not.\n        if isinstance(path, bytes):\n            path = os.fsdecode(path)\n        # Note: To guard against symlink races, we use the standard\n        # lstat()/open()/fstat() trick.\n        try:\n            orig_st = os.lstat(path)\n        except Exception:\n            onerror(os.lstat, path, sys.exc_info())\n            return\n        try:\n            fd = os.open(path, os.O_RDONLY)\n            fd_closed = False\n        except Exception:\n            onerror(os.open, path, sys.exc_info())\n            return\n        try:\n            if os.path.samestat(orig_st, os.fstat(fd)):\n                _rmtree_safe_fd(fd, path, onerror)\n                try:\n                    os.close(fd)\n                    fd_closed = True\n                    os.rmdir(path)\n                except OSError:\n                    onerror(os.rmdir, path, sys.exc_info())\n            else:\n                try:\n                    # symlinks to directories are forbidden, see bug #1669\n                    raise OSError(\"Cannot call rmtree on a symbolic link\")\n                except OSError:\n                    onerror(os.path.islink, path, sys.exc_info())\n        finally:\n            if not fd_closed:\n                os.close(fd)\n    else:\n        try:\n            if _rmtree_islink(path):\n                # symlinks to directories are forbidden, see bug #1669\n                raise OSError(\"Cannot call rmtree on a symbolic link\")\n        except OSError:\n            onerror(os.path.islink, path, sys.exc_info())\n            # can't continue even if onerror hook returns\n            return\n        return _rmtree_unsafe(path, onerror)",
        "name_type": "stdlib"
    },
    "shutil._basename": {
        "API_name": "shutil._basename",
        "loc_name": "shutil._basename",
        "args": "path",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 765,
        "namespace": "*",
        "body": "def _basename(path):\n    \"\"\"A basename() variant which first strips the trailing slash, if present.\n    Thus we always get the last component of the path, even for directories.\n\n    path: Union[PathLike, str]\n\n    e.g.\n    >>> os.path.basename('/bar/foo')\n    'foo'\n    >>> os.path.basename('/bar/foo/')\n    ''\n    >>> _basename('/bar/foo/')\n    'foo'\n    \"\"\"\n    path = os.fspath(path)\n    sep = os.path.sep + (os.path.altsep or '')\n    return os.path.basename(path.rstrip(sep))",
        "name_type": "stdlib"
    },
    "shutil.move": {
        "API_name": "shutil.move",
        "loc_name": "shutil.move",
        "args": "src;dst;copy_function",
        "args_default": 1,
        "filepath": "shutil",
        "lineno": 783,
        "namespace": "*",
        "body": "def move(src, dst, copy_function=copy2):\n    \"\"\"Recursively move a file or directory to another location. This is\n    similar to the Unix \"mv\" command. Return the file or directory's\n    destination.\n\n    If the destination is a directory or a symlink to a directory, the source\n    is moved inside the directory. The destination path must not already\n    exist.\n\n    If the destination already exists but is not a directory, it may be\n    overwritten depending on os.rename() semantics.\n\n    If the destination is on our current filesystem, then rename() is used.\n    Otherwise, src is copied to the destination and then removed. Symlinks are\n    recreated under the new name if os.rename() fails because of cross\n    filesystem renames.\n\n    The optional `copy_function` argument is a callable that will be used\n    to copy the source or it will be delegated to `copytree`.\n    By default, copy2() is used, but any function that supports the same\n    signature (like copy()) can be used.\n\n    A lot more could be done here...  A look at a mv.c shows a lot of\n    the issues this implementation glosses over.\n\n    \"\"\"\n    sys.audit(\"shutil.move\", src, dst)\n    real_dst = dst\n    if os.path.isdir(dst):\n        if _samefile(src, dst):\n            # We might be on a case insensitive filesystem,\n            # perform the rename anyway.\n            os.rename(src, dst)\n            return\n\n        # Using _basename instead of os.path.basename is important, as we must\n        # ignore any trailing slash to avoid the basename returning ''\n        real_dst = os.path.join(dst, _basename(src))\n\n        if os.path.exists(real_dst):\n            raise Error(\"Destination path '%s' already exists\" % real_dst)\n    try:\n        os.rename(src, real_dst)\n    except OSError:\n        if os.path.islink(src):\n            linkto = os.readlink(src)\n            os.symlink(linkto, real_dst)\n            os.unlink(src)\n        elif os.path.isdir(src):\n            if _destinsrc(src, dst):\n                raise Error(\"Cannot move a directory '%s' into itself\"\n                            \" '%s'.\" % (src, dst))\n            if (_is_immutable(src)\n                    or (not os.access(src, os.W_OK) and os.listdir(src)\n                        and sys.platform == 'darwin')):\n                raise PermissionError(\"Cannot move the non-empty directory \"\n                                      \"'%s': Lacking write permission to '%s'.\"\n                                      % (src, src))\n            copytree(src, real_dst, copy_function=copy_function,\n                     symlinks=True)\n            rmtree(src)\n        else:\n            copy_function(src, real_dst)\n            os.unlink(src)\n    return real_dst",
        "name_type": "stdlib"
    },
    "shutil._destinsrc": {
        "API_name": "shutil._destinsrc",
        "loc_name": "shutil._destinsrc",
        "args": "src;dst",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 849,
        "namespace": "*",
        "body": "def _destinsrc(src, dst):\n    src = os.path.abspath(src)\n    dst = os.path.abspath(dst)\n    if not src.endswith(os.path.sep):\n        src += os.path.sep\n    if not dst.endswith(os.path.sep):\n        dst += os.path.sep\n    return dst.startswith(src)",
        "name_type": "stdlib"
    },
    "shutil._is_immutable": {
        "API_name": "shutil._is_immutable",
        "loc_name": "shutil._is_immutable",
        "args": "src",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 858,
        "namespace": "*",
        "body": "def _is_immutable(src):\n    st = _stat(src)\n    immutable_states = [stat.UF_IMMUTABLE, stat.SF_IMMUTABLE]\n    return hasattr(st, 'st_flags') and st.st_flags in immutable_states",
        "name_type": "stdlib"
    },
    "shutil._get_gid": {
        "API_name": "shutil._get_gid",
        "loc_name": "shutil._get_gid",
        "args": "name",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 863,
        "namespace": "*",
        "body": "def _get_gid(name):\n    \"\"\"Returns a gid, given a group name.\"\"\"\n    if getgrnam is None or name is None:\n        return None\n    try:\n        result = getgrnam(name)\n    except KeyError:\n        result = None\n    if result is not None:\n        return result[2]\n    return None",
        "name_type": "stdlib"
    },
    "shutil._get_uid": {
        "API_name": "shutil._get_uid",
        "loc_name": "shutil._get_uid",
        "args": "name",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 875,
        "namespace": "*",
        "body": "def _get_uid(name):\n    \"\"\"Returns an uid, given a user name.\"\"\"\n    if getpwnam is None or name is None:\n        return None\n    try:\n        result = getpwnam(name)\n    except KeyError:\n        result = None\n    if result is not None:\n        return result[2]\n    return None",
        "name_type": "stdlib"
    },
    "shutil._make_tarball": {
        "API_name": "shutil._make_tarball",
        "loc_name": "shutil._make_tarball",
        "args": "base_name;base_dir;compress;verbose;dry_run;owner;group;logger",
        "args_default": 6,
        "filepath": "shutil",
        "lineno": 887,
        "namespace": "*",
        "body": "def _make_tarball(base_name, base_dir, compress=\"gzip\", verbose=0, dry_run=0,\n                  owner=None, group=None, logger=None):\n    \"\"\"Create a (possibly compressed) tar file from all the files under\n    'base_dir'.\n\n    'compress' must be \"gzip\" (the default), \"bzip2\", \"xz\", or None.\n\n    'owner' and 'group' can be used to define an owner and a group for the\n    archive that is being built. If not provided, the current owner and group\n    will be used.\n\n    The output tar file will be named 'base_name' +  \".tar\", possibly plus\n    the appropriate compression extension (\".gz\", \".bz2\", or \".xz\").\n\n    Returns the output filename.\n    \"\"\"\n    if compress is None:\n        tar_compression = ''\n    elif _ZLIB_SUPPORTED and compress == 'gzip':\n        tar_compression = 'gz'\n    elif _BZ2_SUPPORTED and compress == 'bzip2':\n        tar_compression = 'bz2'\n    elif _LZMA_SUPPORTED and compress == 'xz':\n        tar_compression = 'xz'\n    else:\n        raise ValueError(\"bad value for 'compress', or compression format not \"\n                         \"supported : {0}\".format(compress))\n\n    import tarfile  # late import for breaking circular dependency\n\n    compress_ext = '.' + tar_compression if compress else ''\n    archive_name = base_name + '.tar' + compress_ext\n    archive_dir = os.path.dirname(archive_name)\n\n    if archive_dir and not os.path.exists(archive_dir):\n        if logger is not None:\n            logger.info(\"creating %s\", archive_dir)\n        if not dry_run:\n            os.makedirs(archive_dir)\n\n    # creating the tarball\n    if logger is not None:\n        logger.info('Creating tar archive')\n\n    uid = _get_uid(owner)\n    gid = _get_gid(group)\n\n    def _set_uid_gid(tarinfo):\n        if gid is not None:\n            tarinfo.gid = gid\n            tarinfo.gname = group\n        if uid is not None:\n            tarinfo.uid = uid\n            tarinfo.uname = owner\n        return tarinfo\n\n    if not dry_run:\n        tar = tarfile.open(archive_name, 'w|%s' % tar_compression)\n        try:\n            tar.add(base_dir, filter=_set_uid_gid)\n        finally:\n            tar.close()\n\n    return archive_name",
        "name_type": "stdlib"
    },
    "shutil._make_tarball._set_uid_gid": {
        "API_name": "shutil._make_tarball._set_uid_gid",
        "loc_name": "shutil._make_tarball._set_uid_gid",
        "args": "tarinfo",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 934,
        "namespace": "*",
        "body": "    def _set_uid_gid(tarinfo):\n        if gid is not None:\n            tarinfo.gid = gid\n            tarinfo.gname = group\n        if uid is not None:\n            tarinfo.uid = uid\n            tarinfo.uname = owner\n        return tarinfo",
        "name_type": "stdlib"
    },
    "shutil._make_zipfile": {
        "API_name": "shutil._make_zipfile",
        "loc_name": "shutil._make_zipfile",
        "args": "base_name;base_dir;verbose;dry_run;logger",
        "args_default": 3,
        "filepath": "shutil",
        "lineno": 952,
        "namespace": "*",
        "body": "def _make_zipfile(base_name, base_dir, verbose=0, dry_run=0, logger=None):\n    \"\"\"Create a zip file from all the files under 'base_dir'.\n\n    The output zip file will be named 'base_name' + \".zip\".  Returns the\n    name of the output zip file.\n    \"\"\"\n    import zipfile  # late import for breaking circular dependency\n\n    zip_filename = base_name + \".zip\"\n    archive_dir = os.path.dirname(base_name)\n\n    if archive_dir and not os.path.exists(archive_dir):\n        if logger is not None:\n            logger.info(\"creating %s\", archive_dir)\n        if not dry_run:\n            os.makedirs(archive_dir)\n\n    if logger is not None:\n        logger.info(\"creating '%s' and adding '%s' to it\",\n                    zip_filename, base_dir)\n\n    if not dry_run:\n        with zipfile.ZipFile(zip_filename, \"w\",\n                             compression=zipfile.ZIP_DEFLATED) as zf:\n            path = os.path.normpath(base_dir)\n            if path != os.curdir:\n                zf.write(path, path)\n                if logger is not None:\n                    logger.info(\"adding '%s'\", path)\n            for dirpath, dirnames, filenames in os.walk(base_dir):\n                for name in sorted(dirnames):\n                    path = os.path.normpath(os.path.join(dirpath, name))\n                    zf.write(path, path)\n                    if logger is not None:\n                        logger.info(\"adding '%s'\", path)\n                for name in filenames:\n                    path = os.path.normpath(os.path.join(dirpath, name))\n                    if os.path.isfile(path):\n                        zf.write(path, path)\n                        if logger is not None:\n                            logger.info(\"adding '%s'\", path)\n\n    return zip_filename",
        "name_type": "stdlib"
    },
    "shutil.get_archive_formats": {
        "API_name": "shutil.get_archive_formats",
        "loc_name": "shutil.get_archive_formats",
        "args": "",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1013,
        "namespace": "*",
        "body": "def get_archive_formats():\n    \"\"\"Returns a list of supported formats for archiving and unarchiving.\n\n    Each element of the returned sequence is a tuple (name, description)\n    \"\"\"\n    formats = [(name, registry[2]) for name, registry in\n               _ARCHIVE_FORMATS.items()]\n    formats.sort()\n    return formats",
        "name_type": "stdlib"
    },
    "shutil.register_archive_format": {
        "API_name": "shutil.register_archive_format",
        "loc_name": "shutil.register_archive_format",
        "args": "name;function;extra_args;description",
        "args_default": 2,
        "filepath": "shutil",
        "lineno": 1023,
        "namespace": "*",
        "body": "def register_archive_format(name, function, extra_args=None, description=''):\n    \"\"\"Registers an archive format.\n\n    name is the name of the format. function is the callable that will be\n    used to create archives. If provided, extra_args is a sequence of\n    (name, value) tuples that will be passed as arguments to the callable.\n    description can be provided to describe the format, and will be returned\n    by the get_archive_formats() function.\n    \"\"\"\n    if extra_args is None:\n        extra_args = []\n    if not callable(function):\n        raise TypeError('The %s object is not callable' % function)\n    if not isinstance(extra_args, (tuple, list)):\n        raise TypeError('extra_args needs to be a sequence')\n    for element in extra_args:\n        if not isinstance(element, (tuple, list)) or len(element) !=2:\n            raise TypeError('extra_args elements are : (arg_name, value)')\n\n    _ARCHIVE_FORMATS[name] = (function, extra_args, description)",
        "name_type": "stdlib"
    },
    "shutil.unregister_archive_format": {
        "API_name": "shutil.unregister_archive_format",
        "loc_name": "shutil.unregister_archive_format",
        "args": "name",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1044,
        "namespace": "*",
        "body": "def unregister_archive_format(name):\n    del _ARCHIVE_FORMATS[name]",
        "name_type": "stdlib"
    },
    "shutil.make_archive": {
        "API_name": "shutil.make_archive",
        "loc_name": "shutil.make_archive",
        "args": "base_name;format;root_dir;base_dir;verbose;dry_run;owner;group;logger",
        "args_default": 7,
        "filepath": "shutil",
        "lineno": 1047,
        "namespace": "*",
        "body": "def make_archive(base_name, format, root_dir=None, base_dir=None, verbose=0,\n                 dry_run=0, owner=None, group=None, logger=None):\n    \"\"\"Create an archive file (eg. zip or tar).\n\n    'base_name' is the name of the file to create, minus any format-specific\n    extension; 'format' is the archive format: one of \"zip\", \"tar\", \"gztar\",\n    \"bztar\", or \"xztar\".  Or any other registered format.\n\n    'root_dir' is a directory that will be the root directory of the\n    archive; ie. we typically chdir into 'root_dir' before creating the\n    archive.  'base_dir' is the directory where we start archiving from;\n    ie. 'base_dir' will be the common prefix of all files and\n    directories in the archive.  'root_dir' and 'base_dir' both default\n    to the current directory.  Returns the name of the archive file.\n\n    'owner' and 'group' are used when creating a tar archive. By default,\n    uses the current owner and group.\n    \"\"\"\n    sys.audit(\"shutil.make_archive\", base_name, format, root_dir, base_dir)\n    save_cwd = os.getcwd()\n    if root_dir is not None:\n        if logger is not None:\n            logger.debug(\"changing into '%s'\", root_dir)\n        base_name = os.path.abspath(base_name)\n        if not dry_run:\n            os.chdir(root_dir)\n\n    if base_dir is None:\n        base_dir = os.curdir\n\n    kwargs = {'dry_run': dry_run, 'logger': logger}\n\n    try:\n        format_info = _ARCHIVE_FORMATS[format]\n    except KeyError:\n        raise ValueError(\"unknown archive format '%s'\" % format) from None\n\n    func = format_info[0]\n    for arg, val in format_info[1]:\n        kwargs[arg] = val\n\n    if format != 'zip':\n        kwargs['owner'] = owner\n        kwargs['group'] = group\n\n    try:\n        filename = func(base_name, base_dir, **kwargs)\n    finally:\n        if root_dir is not None:\n            if logger is not None:\n                logger.debug(\"changing back to '%s'\", save_cwd)\n            os.chdir(save_cwd)\n\n    return filename",
        "name_type": "stdlib"
    },
    "shutil.get_unpack_formats": {
        "API_name": "shutil.get_unpack_formats",
        "loc_name": "shutil.get_unpack_formats",
        "args": "",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1103,
        "namespace": "*",
        "body": "def get_unpack_formats():\n    \"\"\"Returns a list of supported formats for unpacking.\n\n    Each element of the returned sequence is a tuple\n    (name, extensions, description)\n    \"\"\"\n    formats = [(name, info[0], info[3]) for name, info in\n               _UNPACK_FORMATS.items()]\n    formats.sort()\n    return formats",
        "name_type": "stdlib"
    },
    "shutil._check_unpack_options": {
        "API_name": "shutil._check_unpack_options",
        "loc_name": "shutil._check_unpack_options",
        "args": "extensions;function;extra_args",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1114,
        "namespace": "*",
        "body": "def _check_unpack_options(extensions, function, extra_args):\n    \"\"\"Checks what gets registered as an unpacker.\"\"\"\n    # first make sure no other unpacker is registered for this extension\n    existing_extensions = {}\n    for name, info in _UNPACK_FORMATS.items():\n        for ext in info[0]:\n            existing_extensions[ext] = name\n\n    for extension in extensions:\n        if extension in existing_extensions:\n            msg = '%s is already registered for \"%s\"'\n            raise RegistryError(msg % (extension,\n                                       existing_extensions[extension]))\n\n    if not callable(function):\n        raise TypeError('The registered function must be a callable')",
        "name_type": "stdlib"
    },
    "shutil.register_unpack_format": {
        "API_name": "shutil.register_unpack_format",
        "loc_name": "shutil.register_unpack_format",
        "args": "name;extensions;function;extra_args;description",
        "args_default": 2,
        "filepath": "shutil",
        "lineno": 1132,
        "namespace": "*",
        "body": "def register_unpack_format(name, extensions, function, extra_args=None,\n                           description=''):\n    \"\"\"Registers an unpack format.\n\n    `name` is the name of the format. `extensions` is a list of extensions\n    corresponding to the format.\n\n    `function` is the callable that will be\n    used to unpack archives. The callable will receive archives to unpack.\n    If it's unable to handle an archive, it needs to raise a ReadError\n    exception.\n\n    If provided, `extra_args` is a sequence of\n    (name, value) tuples that will be passed as arguments to the callable.\n    description can be provided to describe the format, and will be returned\n    by the get_unpack_formats() function.\n    \"\"\"\n    if extra_args is None:\n        extra_args = []\n    _check_unpack_options(extensions, function, extra_args)\n    _UNPACK_FORMATS[name] = extensions, function, extra_args, description",
        "name_type": "stdlib"
    },
    "shutil.unregister_unpack_format": {
        "API_name": "shutil.unregister_unpack_format",
        "loc_name": "shutil.unregister_unpack_format",
        "args": "name",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1154,
        "namespace": "*",
        "body": "def unregister_unpack_format(name):\n    \"\"\"Removes the pack format from the registry.\"\"\"\n    del _UNPACK_FORMATS[name]",
        "name_type": "stdlib"
    },
    "shutil._ensure_directory": {
        "API_name": "shutil._ensure_directory",
        "loc_name": "shutil._ensure_directory",
        "args": "path",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1158,
        "namespace": "*",
        "body": "def _ensure_directory(path):\n    \"\"\"Ensure that the parent directory of `path` exists\"\"\"\n    dirname = os.path.dirname(path)\n    if not os.path.isdir(dirname):\n        os.makedirs(dirname)",
        "name_type": "stdlib"
    },
    "shutil._unpack_zipfile": {
        "API_name": "shutil._unpack_zipfile",
        "loc_name": "shutil._unpack_zipfile",
        "args": "filename;extract_dir",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1164,
        "namespace": "*",
        "body": "def _unpack_zipfile(filename, extract_dir):\n    \"\"\"Unpack zip `filename` to `extract_dir`\n    \"\"\"\n    import zipfile  # late import for breaking circular dependency\n\n    if not zipfile.is_zipfile(filename):\n        raise ReadError(\"%s is not a zip file\" % filename)\n\n    zip = zipfile.ZipFile(filename)\n    try:\n        for info in zip.infolist():\n            name = info.filename\n\n            # don't extract absolute paths or ones with .. in them\n            if name.startswith('/') or '..' in name:\n                continue\n\n            targetpath = os.path.join(extract_dir, *name.split('/'))\n            if not targetpath:\n                continue\n\n            _ensure_directory(targetpath)\n            if not name.endswith('/'):\n                # file\n                with zip.open(name, 'r') as source, \\\n                        open(targetpath, 'wb') as target:\n                    copyfileobj(source, target)\n    finally:\n        zip.close()",
        "name_type": "stdlib"
    },
    "shutil._unpack_tarfile": {
        "API_name": "shutil._unpack_tarfile",
        "loc_name": "shutil._unpack_tarfile",
        "args": "filename;extract_dir",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1194,
        "namespace": "*",
        "body": "def _unpack_tarfile(filename, extract_dir):\n    \"\"\"Unpack tar/tar.gz/tar.bz2/tar.xz `filename` to `extract_dir`\n    \"\"\"\n    import tarfile  # late import for breaking circular dependency\n    try:\n        tarobj = tarfile.open(filename)\n    except tarfile.TarError:\n        raise ReadError(\n            \"%s is not a compressed or uncompressed tar file\" % filename)\n    try:\n        tarobj.extractall(extract_dir)\n    finally:\n        tarobj.close()",
        "name_type": "stdlib"
    },
    "shutil._find_unpack_format": {
        "API_name": "shutil._find_unpack_format",
        "loc_name": "shutil._find_unpack_format",
        "args": "filename",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1225,
        "namespace": "*",
        "body": "def _find_unpack_format(filename):\n    for name, info in _UNPACK_FORMATS.items():\n        for extension in info[0]:\n            if filename.endswith(extension):\n                return name\n    return None",
        "name_type": "stdlib"
    },
    "shutil.unpack_archive": {
        "API_name": "shutil.unpack_archive",
        "loc_name": "shutil.unpack_archive",
        "args": "filename;extract_dir;format",
        "args_default": 2,
        "filepath": "shutil",
        "lineno": 1232,
        "namespace": "*",
        "body": "def unpack_archive(filename, extract_dir=None, format=None):\n    \"\"\"Unpack an archive.\n\n    `filename` is the name of the archive.\n\n    `extract_dir` is the name of the target directory, where the archive\n    is unpacked. If not provided, the current working directory is used.\n\n    `format` is the archive format: one of \"zip\", \"tar\", \"gztar\", \"bztar\",\n    or \"xztar\".  Or any other registered format.  If not provided,\n    unpack_archive will use the filename extension and see if an unpacker\n    was registered for that extension.\n\n    In case none is found, a ValueError is raised.\n    \"\"\"\n    sys.audit(\"shutil.unpack_archive\", filename, extract_dir, format)\n\n    if extract_dir is None:\n        extract_dir = os.getcwd()\n\n    extract_dir = os.fspath(extract_dir)\n    filename = os.fspath(filename)\n\n    if format is not None:\n        try:\n            format_info = _UNPACK_FORMATS[format]\n        except KeyError:\n            raise ValueError(\"Unknown unpack format '{0}'\".format(format)) from None\n\n        func = format_info[1]\n        func(filename, extract_dir, **dict(format_info[2]))\n    else:\n        # we need to look at the registered unpackers supported extensions\n        format = _find_unpack_format(filename)\n        if format is None:\n            raise ReadError(\"Unknown archive format '{0}'\".format(filename))\n\n        func = _UNPACK_FORMATS[format][1]\n        kwargs = dict(_UNPACK_FORMATS[format][2])\n        func(filename, extract_dir, **kwargs)",
        "name_type": "stdlib"
    },
    "shutil.disk_usage": {
        "API_name": "shutil.disk_usage",
        "loc_name": "shutil.disk_usage",
        "args": "path",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1299,
        "namespace": "*",
        "body": "    def disk_usage(path):\n        \"\"\"Return disk usage statistics about the given path.\n\n        Returned values is a named tuple with attributes 'total', 'used' and\n        'free', which are the amount of total, used and free space, in bytes.\n        \"\"\"\n        total, free = nt._getdiskusage(path)\n        used = total - free\n        return _ntuple_diskusage(total, used, free)",
        "name_type": "stdlib"
    },
    "shutil.chown": {
        "API_name": "shutil.chown",
        "loc_name": "shutil.chown",
        "args": "path;user;group",
        "args_default": 2,
        "filepath": "shutil",
        "lineno": 1310,
        "namespace": "*",
        "body": "def chown(path, user=None, group=None):\n    \"\"\"Change owner user and group of the given path.\n\n    user and group can be the uid/gid or the user/group names, and in that case,\n    they are converted to their respective uid/gid.\n    \"\"\"\n    sys.audit('shutil.chown', path, user, group)\n\n    if user is None and group is None:\n        raise ValueError(\"user and/or group must be set\")\n\n    _user = user\n    _group = group\n\n    # -1 means don't change it\n    if user is None:\n        _user = -1\n    # user can either be an int (the uid) or a string (the system username)\n    elif isinstance(user, str):\n        _user = _get_uid(user)\n        if _user is None:\n            raise LookupError(\"no such user: {!r}\".format(user))\n\n    if group is None:\n        _group = -1\n    elif not isinstance(group, int):\n        _group = _get_gid(group)\n        if _group is None:\n            raise LookupError(\"no such group: {!r}\".format(group))\n\n    os.chown(path, _user, _group)",
        "name_type": "stdlib"
    },
    "shutil.get_terminal_size": {
        "API_name": "shutil.get_terminal_size",
        "loc_name": "shutil.get_terminal_size",
        "args": "fallback",
        "args_default": 1,
        "filepath": "shutil",
        "lineno": 1342,
        "namespace": "*",
        "body": "def get_terminal_size(fallback=(80, 24)):\n    \"\"\"Get the size of the terminal window.\n\n    For each of the two dimensions, the environment variable, COLUMNS\n    and LINES respectively, is checked. If the variable is defined and\n    the value is a positive integer, it is used.\n\n    When COLUMNS or LINES is not defined, which is the common case,\n    the terminal connected to sys.__stdout__ is queried\n    by invoking os.get_terminal_size.\n\n    If the terminal size cannot be successfully queried, either because\n    the system doesn't support querying, or because we are not\n    connected to a terminal, the value given in fallback parameter\n    is used. Fallback defaults to (80, 24) which is the default\n    size used by many terminal emulators.\n\n    The value returned is a named tuple of type os.terminal_size.\n    \"\"\"\n    # columns, lines are the working values\n    try:\n        columns = int(os.environ['COLUMNS'])\n    except (KeyError, ValueError):\n        columns = 0\n\n    try:\n        lines = int(os.environ['LINES'])\n    except (KeyError, ValueError):\n        lines = 0\n\n    # only query if necessary\n    if columns <= 0 or lines <= 0:\n        try:\n            size = os.get_terminal_size(sys.__stdout__.fileno())\n        except (AttributeError, ValueError, OSError):\n            # stdout is None, closed, detached, or not a terminal, or\n            # os.get_terminal_size() is unsupported\n            size = os.terminal_size(fallback)\n        if columns <= 0:\n            columns = size.columns\n        if lines <= 0:\n            lines = size.lines\n\n    return os.terminal_size((columns, lines))",
        "name_type": "stdlib"
    },
    "shutil._access_check": {
        "API_name": "shutil._access_check",
        "loc_name": "shutil._access_check",
        "args": "fn;mode",
        "args_default": 0,
        "filepath": "shutil",
        "lineno": 1391,
        "namespace": "*",
        "body": "def _access_check(fn, mode):\n    return (os.path.exists(fn) and os.access(fn, mode)\n            and not os.path.isdir(fn))",
        "name_type": "stdlib"
    },
    "shutil.which": {
        "API_name": "shutil.which",
        "loc_name": "shutil.which",
        "args": "cmd;mode;path",
        "args_default": 2,
        "filepath": "shutil",
        "lineno": 1396,
        "namespace": "*",
        "body": "def which(cmd, mode=os.F_OK | os.X_OK, path=None):\n    \"\"\"Given a command, mode, and a PATH string, return the path which\n    conforms to the given mode on the PATH, or None if there is no such\n    file.\n\n    `mode` defaults to os.F_OK | os.X_OK. `path` defaults to the result\n    of os.environ.get(\"PATH\"), or can be overridden with a custom search\n    path.\n\n    \"\"\"\n    # If we're given a path with a directory part, look it up directly rather\n    # than referring to PATH directories. This includes checking relative to the\n    # current directory, e.g. ./script\n    if os.path.dirname(cmd):\n        if _access_check(cmd, mode):\n            return cmd\n        return None\n\n    use_bytes = isinstance(cmd, bytes)\n\n    if path is None:\n        path = os.environ.get(\"PATH\", None)\n        if path is None:\n            try:\n                path = os.confstr(\"CS_PATH\")\n            except (AttributeError, ValueError):\n                # os.confstr() or CS_PATH is not available\n                path = os.defpath\n        # bpo-35755: Don't use os.defpath if the PATH environment variable is\n        # set to an empty string\n\n    # PATH='' doesn't match, whereas PATH=':' looks in the current directory\n    if not path:\n        return None\n\n    if use_bytes:\n        path = os.fsencode(path)\n        path = path.split(os.fsencode(os.pathsep))\n    else:\n        path = os.fsdecode(path)\n        path = path.split(os.pathsep)\n\n    if sys.platform == \"win32\":\n        # The current directory takes precedence on Windows.\n        curdir = os.curdir\n        if use_bytes:\n            curdir = os.fsencode(curdir)\n        if curdir not in path:\n            path.insert(0, curdir)\n\n        # PATHEXT is necessary to check on Windows.\n        pathext_source = os.getenv(\"PATHEXT\") or _WIN_DEFAULT_PATHEXT\n        pathext = [ext for ext in pathext_source.split(os.pathsep) if ext]\n\n        if use_bytes:\n            pathext = [os.fsencode(ext) for ext in pathext]\n        # See if the given file matches any of the expected path extensions.\n        # This will allow us to short circuit when given \"python.exe\".\n        # If it does match, only test that one, otherwise we have to try\n        # others.\n        if any(cmd.lower().endswith(ext.lower()) for ext in pathext):\n            files = [cmd]\n        else:\n            files = [cmd + ext for ext in pathext]\n    else:\n        # On other platforms you don't have things like PATHEXT to tell you\n        # what file suffixes are executable, so just pass on cmd as-is.\n        files = [cmd]\n\n    seen = set()\n    for dir in path:\n        normdir = os.path.normcase(dir)\n        if not normdir in seen:\n            seen.add(normdir)\n            for thefile in files:\n                name = os.path.join(dir, thefile)\n                if _access_check(name, mode):\n                    return name\n    return None",
        "name_type": "stdlib"
    },
    "signal": {
        "API_name": "signal",
        "loc_name": "signal",
        "args": "*",
        "args_default": "*",
        "filepath": "signal",
        "lineno": "*",
        "namespace": "*",
        "body": "_globals = globals()\n_IntEnum._convert_(\n        'Signals', __name__,\n        lambda name:\n            name.isupper()\n            and (name.startswith('SIG') and not name.startswith('SIG_'))\n            or name.startswith('CTRL_'))\n_IntEnum._convert_(\n        'Handlers', __name__,\n        lambda name: name in ('SIG_DFL', 'SIG_IGN'))\nif 'pthread_sigmask' in _globals:\n    _IntEnum._convert_(\n            'Sigmasks', __name__,\n            lambda name: name in ('SIG_BLOCK', 'SIG_UNBLOCK', 'SIG_SETMASK'))\nif 'pthread_sigmask' in _globals:\n    @_wraps(_signal.pthread_sigmask)\n    def pthread_sigmask(how, mask):\n        sigs_set = _signal.pthread_sigmask(how, mask)\n        return set(_int_to_enum(x, Signals) for x in sigs_set)\nif 'sigpending' in _globals:\n    @_wraps(_signal.sigpending)\n    def sigpending():\n        return {_int_to_enum(x, Signals) for x in _signal.sigpending()}\nif 'sigwait' in _globals:\n    @_wraps(_signal.sigwait)\n    def sigwait(sigset):\n        retsig = _signal.sigwait(sigset)\n        return _int_to_enum(retsig, Signals)\nif 'valid_signals' in _globals:\n    @_wraps(_signal.valid_signals)\n    def valid_signals():\n        return {_int_to_enum(x, Signals) for x in _signal.valid_signals()}\ndel _globals, _wraps",
        "name_type": "stdlib"
    },
    "signal._int_to_enum": {
        "API_name": "signal._int_to_enum",
        "loc_name": "signal._int_to_enum",
        "args": "value;enum_klass",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 24,
        "namespace": "*",
        "body": "def _int_to_enum(value, enum_klass):\n    \"\"\"Convert a numeric value to an IntEnum member.\n    If it's not a known member, return the numeric value itself.\n    \"\"\"\n    try:\n        return enum_klass(value)\n    except ValueError:\n        return value",
        "name_type": "stdlib"
    },
    "signal._enum_to_int": {
        "API_name": "signal._enum_to_int",
        "loc_name": "signal._enum_to_int",
        "args": "value",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 34,
        "namespace": "*",
        "body": "def _enum_to_int(value):\n    \"\"\"Convert an IntEnum member to a numeric value.\n    If it's not an IntEnum member return the value itself.\n    \"\"\"\n    try:\n        return int(value)\n    except (ValueError, TypeError):\n        return value",
        "name_type": "stdlib"
    },
    "signal._wraps": {
        "API_name": "signal._wraps",
        "loc_name": "signal._wraps",
        "args": "wrapped",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 48,
        "namespace": "*",
        "body": "def _wraps(wrapped):\n    def decorator(wrapper):\n        wrapper.__doc__ = wrapped.__doc__\n        return wrapper\n    return decorator",
        "name_type": "stdlib"
    },
    "signal._wraps.decorator": {
        "API_name": "signal._wraps.decorator",
        "loc_name": "signal._wraps.decorator",
        "args": "wrapper",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 49,
        "namespace": "*",
        "body": "    def decorator(wrapper):\n        wrapper.__doc__ = wrapped.__doc__\n        return wrapper",
        "name_type": "stdlib"
    },
    "signal.signal": {
        "API_name": "signal.signal",
        "loc_name": "signal.signal",
        "args": "signalnum;handler",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 55,
        "namespace": "*",
        "body": "def signal(signalnum, handler):\n    handler = _signal.signal(_enum_to_int(signalnum), _enum_to_int(handler))\n    return _int_to_enum(handler, Handlers)",
        "name_type": "stdlib"
    },
    "signal.getsignal": {
        "API_name": "signal.getsignal",
        "loc_name": "signal.getsignal",
        "args": "signalnum",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 61,
        "namespace": "*",
        "body": "def getsignal(signalnum):\n    handler = _signal.getsignal(signalnum)\n    return _int_to_enum(handler, Handlers)",
        "name_type": "stdlib"
    },
    "signal.pthread_sigmask": {
        "API_name": "signal.pthread_sigmask",
        "loc_name": "signal.pthread_sigmask",
        "args": "how;mask",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 68,
        "namespace": "*",
        "body": "    def pthread_sigmask(how, mask):\n        sigs_set = _signal.pthread_sigmask(how, mask)\n        return set(_int_to_enum(x, Signals) for x in sigs_set)",
        "name_type": "stdlib"
    },
    "signal.sigpending": {
        "API_name": "signal.sigpending",
        "loc_name": "signal.sigpending",
        "args": "",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 75,
        "namespace": "*",
        "body": "    def sigpending():\n        return {_int_to_enum(x, Signals) for x in _signal.sigpending()}",
        "name_type": "stdlib"
    },
    "signal.sigwait": {
        "API_name": "signal.sigwait",
        "loc_name": "signal.sigwait",
        "args": "sigset",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 81,
        "namespace": "*",
        "body": "    def sigwait(sigset):\n        retsig = _signal.sigwait(sigset)\n        return _int_to_enum(retsig, Signals)",
        "name_type": "stdlib"
    },
    "signal.valid_signals": {
        "API_name": "signal.valid_signals",
        "loc_name": "signal.valid_signals",
        "args": "",
        "args_default": 0,
        "filepath": "signal",
        "lineno": 88,
        "namespace": "*",
        "body": "    def valid_signals():\n        return {_int_to_enum(x, Signals) for x in _signal.valid_signals()}",
        "name_type": "stdlib"
    },
    "struct": {
        "API_name": "struct",
        "loc_name": "struct",
        "args": "*",
        "args_default": "*",
        "filepath": "struct",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [\n    # Functions\n    'calcsize', 'pack', 'pack_into', 'unpack', 'unpack_from',\n    'iter_unpack',\n\n    # Classes\n    'Struct',\n\n    # Exceptions\n    'error'\n    ]",
        "name_type": "stdlib"
    },
    "subprocess": {
        "API_name": "subprocess",
        "loc_name": "subprocess",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"Subprocesses with accessible I/O streams\n\nThis module allows you to spawn processes, connect to their\ninput/output/error pipes, and obtain their return codes.\n\nFor a complete description of this module see the Python documentation.\n\nMain API\n========\nrun(...): Runs a command, waits for it to complete, then returns a\n          CompletedProcess instance.\nPopen(...): A class for flexibly executing a command in a new process\n\nConstants\n---------\nDEVNULL: Special value that indicates that os.devnull should be used\nPIPE:    Special value that indicates a pipe should be created\nSTDOUT:  Special value that indicates that stderr should go to stdout\n\n\nOlder API\n=========\ncall(...): Runs a command, waits for it to complete, then returns\n    the return code.\ncheck_call(...): Same as call() but raises CalledProcessError()\n    if return code is not 0\ncheck_output(...): Same as check_call() but returns the contents of\n    stdout instead of a return code\ngetoutput(...): Runs a command in the shell, waits for it to complete,\n    then returns the output\ngetstatusoutput(...): Runs a command in the shell, waits for it to complete,\n    then returns a (exitcode, output) tuple\n\"\"\"\ntry:\n    import pwd\nexcept ImportError:\n    pwd = None\ntry:\n    import grp\nexcept ImportError:\n    grp = None\n__all__ = [\"Popen\", \"PIPE\", \"STDOUT\", \"call\", \"check_call\", \"getstatusoutput\",\n           \"getoutput\", \"check_output\", \"run\", \"CalledProcessError\", \"DEVNULL\",\n           \"SubprocessError\", \"TimeoutExpired\", \"CompletedProcess\"]\ntry:\n    import msvcrt\n    import _winapi\n    _mswindows = True\nexcept ModuleNotFoundError:\n    _mswindows = False\n    import _posixsubprocess\n    import select\n    import selectors\nelse:\n    from _winapi import (CREATE_NEW_CONSOLE, CREATE_NEW_PROCESS_GROUP,\n                         STD_INPUT_HANDLE, STD_OUTPUT_HANDLE,\n                         STD_ERROR_HANDLE, SW_HIDE,\n                         STARTF_USESTDHANDLES, STARTF_USESHOWWINDOW,\n                         ABOVE_NORMAL_PRIORITY_CLASS, BELOW_NORMAL_PRIORITY_CLASS,\n                         HIGH_PRIORITY_CLASS, IDLE_PRIORITY_CLASS,\n                         NORMAL_PRIORITY_CLASS, REALTIME_PRIORITY_CLASS,\n                         CREATE_NO_WINDOW, DETACHED_PROCESS,\n                         CREATE_DEFAULT_ERROR_MODE, CREATE_BREAKAWAY_FROM_JOB)\n\n    __all__.extend([\"CREATE_NEW_CONSOLE\", \"CREATE_NEW_PROCESS_GROUP\",\n                    \"STD_INPUT_HANDLE\", \"STD_OUTPUT_HANDLE\",\n                    \"STD_ERROR_HANDLE\", \"SW_HIDE\",\n                    \"STARTF_USESTDHANDLES\", \"STARTF_USESHOWWINDOW\",\n                    \"STARTUPINFO\",\n                    \"ABOVE_NORMAL_PRIORITY_CLASS\", \"BELOW_NORMAL_PRIORITY_CLASS\",\n                    \"HIGH_PRIORITY_CLASS\", \"IDLE_PRIORITY_CLASS\",\n                    \"NORMAL_PRIORITY_CLASS\", \"REALTIME_PRIORITY_CLASS\",\n                    \"CREATE_NO_WINDOW\", \"DETACHED_PROCESS\",\n                    \"CREATE_DEFAULT_ERROR_MODE\", \"CREATE_BREAKAWAY_FROM_JOB\"])\nif _mswindows:\n    class STARTUPINFO:\n        def __init__(self, *, dwFlags=0, hStdInput=None, hStdOutput=None,\n                     hStdError=None, wShowWindow=0, lpAttributeList=None):\n            self.dwFlags = dwFlags\n            self.hStdInput = hStdInput\n            self.hStdOutput = hStdOutput\n            self.hStdError = hStdError\n            self.wShowWindow = wShowWindow\n            self.lpAttributeList = lpAttributeList or {\"handle_list\": []}\n\n        def copy(self):\n            attr_list = self.lpAttributeList.copy()\n            if 'handle_list' in attr_list:\n                attr_list['handle_list'] = list(attr_list['handle_list'])\n\n            return STARTUPINFO(dwFlags=self.dwFlags,\n                               hStdInput=self.hStdInput,\n                               hStdOutput=self.hStdOutput,\n                               hStdError=self.hStdError,\n                               wShowWindow=self.wShowWindow,\n                               lpAttributeList=attr_list)\n\n\n    class Handle(int):\n        closed = False\n\n        def Close(self, CloseHandle=_winapi.CloseHandle):\n            if not self.closed:\n                self.closed = True\n                CloseHandle(self)\n\n        def Detach(self):\n            if not self.closed:\n                self.closed = True\n                return int(self)\n            raise ValueError(\"already closed\")\n\n        def __repr__(self):\n            return \"%s(%d)\" % (self.__class__.__name__, int(self))\n\n        __del__ = Close\nelse:\n    # When select or poll has indicated that the file is writable,\n    # we can write up to _PIPE_BUF bytes without risk of blocking.\n    # POSIX defines PIPE_BUF as >= 512.\n    _PIPE_BUF = getattr(select, 'PIPE_BUF', 512)\n\n    # poll/select have the advantage of not requiring any extra file\n    # descriptor, contrarily to epoll/kqueue (also, they require a single\n    # syscall).\n    if hasattr(selectors, 'PollSelector'):\n        _PopenSelector = selectors.PollSelector\n    else:\n        _PopenSelector = selectors.SelectSelector\nif _mswindows:\n    # On Windows we just need to close `Popen._handle` when we no longer need\n    # it, so that the kernel can free it. `Popen._handle` gets closed\n    # implicitly when the `Popen` instance is finalized (see `Handle.__del__`,\n    # which is calling `CloseHandle` as requested in [1]), so there is nothing\n    # for `_cleanup` to do.\n    #\n    # [1] https://docs.microsoft.com/en-us/windows/desktop/ProcThread/\n    # creating-processes\n    _active = None\n\n    def _cleanup():\n        pass\nelse:\n    # This lists holds Popen instances for which the underlying process had not\n    # exited at the time its __del__ method got called: those processes are\n    # wait()ed for synchronously from _cleanup() when a new Popen object is\n    # created, to avoid zombie processes.\n    _active = []\n\n    def _cleanup():\n        if _active is None:\n            return\n        for inst in _active[:]:\n            res = inst._internal_poll(_deadstate=sys.maxsize)\n            if res is not None:\n                try:\n                    _active.remove(inst)\n                except ValueError:\n                    # This can happen if two threads create a new Popen instance.\n                    # It's harmless that it was already removed, so ignore.\n                    pass\nPIPE = -1\nSTDOUT = -2\nDEVNULL = -3\n_USE_POSIX_SPAWN = _use_posix_spawn()",
        "name_type": "stdlib"
    },
    "subprocess.SubprocessError": {
        "API_name": "subprocess.SubprocessError",
        "loc_name": "subprocess.SubprocessError",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 105,
        "namespace": "SubprocessError",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess.CalledProcessError": {
        "API_name": "subprocess.CalledProcessError",
        "loc_name": "subprocess.CalledProcessError",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 108,
        "namespace": "CalledProcessError",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess.CalledProcessError.__init__": {
        "API_name": "subprocess.CalledProcessError.__init__",
        "loc_name": "subprocess.CalledProcessError.__init__",
        "args": "self;returncode;cmd;output;stderr",
        "args_default": 2,
        "filepath": "subprocess",
        "lineno": 115,
        "namespace": "CalledProcessError",
        "body": "    def __init__(self, returncode, cmd, output=None, stderr=None):\n        self.returncode = returncode\n        self.cmd = cmd\n        self.output = output\n        self.stderr = stderr",
        "name_type": "stdlib"
    },
    "subprocess.CalledProcessError.__str__": {
        "API_name": "subprocess.CalledProcessError.__str__",
        "loc_name": "subprocess.CalledProcessError.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 121,
        "namespace": "CalledProcessError",
        "body": "    def __str__(self):\n        if self.returncode and self.returncode < 0:\n            try:\n                return \"Command '%s' died with %r.\" % (\n                        self.cmd, signal.Signals(-self.returncode))\n            except ValueError:\n                return \"Command '%s' died with unknown signal %d.\" % (\n                        self.cmd, -self.returncode)\n        else:\n            return \"Command '%s' returned non-zero exit status %d.\" % (\n                    self.cmd, self.returncode)",
        "name_type": "stdlib"
    },
    "subprocess.CalledProcessError.stdout": {
        "API_name": "subprocess.CalledProcessError.stdout",
        "loc_name": "subprocess.CalledProcessError.stdout",
        "args": "self;value",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 139,
        "namespace": "CalledProcessError",
        "body": "    def stdout(self, value):\n        # There's no obvious reason to set this, but allow it anyway so\n        # .stdout is a transparent alias for .output\n        self.output = value",
        "name_type": "stdlib"
    },
    "subprocess.TimeoutExpired": {
        "API_name": "subprocess.TimeoutExpired",
        "loc_name": "subprocess.TimeoutExpired",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 145,
        "namespace": "TimeoutExpired",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess.TimeoutExpired.__init__": {
        "API_name": "subprocess.TimeoutExpired.__init__",
        "loc_name": "subprocess.TimeoutExpired.__init__",
        "args": "self;cmd;timeout;output;stderr",
        "args_default": 2,
        "filepath": "subprocess",
        "lineno": 152,
        "namespace": "TimeoutExpired",
        "body": "    def __init__(self, cmd, timeout, output=None, stderr=None):\n        self.cmd = cmd\n        self.timeout = timeout\n        self.output = output\n        self.stderr = stderr",
        "name_type": "stdlib"
    },
    "subprocess.TimeoutExpired.__str__": {
        "API_name": "subprocess.TimeoutExpired.__str__",
        "loc_name": "subprocess.TimeoutExpired.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 158,
        "namespace": "TimeoutExpired",
        "body": "    def __str__(self):\n        return (\"Command '%s' timed out after %s seconds\" %\n                (self.cmd, self.timeout))",
        "name_type": "stdlib"
    },
    "subprocess.TimeoutExpired.stdout": {
        "API_name": "subprocess.TimeoutExpired.stdout",
        "loc_name": "subprocess.TimeoutExpired.stdout",
        "args": "self;value",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 167,
        "namespace": "TimeoutExpired",
        "body": "    def stdout(self, value):\n        # There's no obvious reason to set this, but allow it anyway so\n        # .stdout is a transparent alias for .output\n        self.output = value",
        "name_type": "stdlib"
    },
    "subprocess.STARTUPINFO": {
        "API_name": "subprocess.STARTUPINFO",
        "loc_name": "subprocess.STARTUPINFO",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 174,
        "namespace": "STARTUPINFO",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess.STARTUPINFO.__init__": {
        "API_name": "subprocess.STARTUPINFO.__init__",
        "loc_name": "subprocess.STARTUPINFO.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 175,
        "namespace": "STARTUPINFO",
        "body": "        def __init__(self, *, dwFlags=0, hStdInput=None, hStdOutput=None,\n                     hStdError=None, wShowWindow=0, lpAttributeList=None):\n            self.dwFlags = dwFlags\n            self.hStdInput = hStdInput\n            self.hStdOutput = hStdOutput\n            self.hStdError = hStdError\n            self.wShowWindow = wShowWindow\n            self.lpAttributeList = lpAttributeList or {\"handle_list\": []}",
        "name_type": "stdlib"
    },
    "subprocess.STARTUPINFO.copy": {
        "API_name": "subprocess.STARTUPINFO.copy",
        "loc_name": "subprocess.STARTUPINFO.copy",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 184,
        "namespace": "STARTUPINFO",
        "body": "        def copy(self):\n            attr_list = self.lpAttributeList.copy()\n            if 'handle_list' in attr_list:\n                attr_list['handle_list'] = list(attr_list['handle_list'])\n\n            return STARTUPINFO(dwFlags=self.dwFlags,\n                               hStdInput=self.hStdInput,\n                               hStdOutput=self.hStdOutput,\n                               hStdError=self.hStdError,\n                               wShowWindow=self.wShowWindow,\n                               lpAttributeList=attr_list)",
        "name_type": "stdlib"
    },
    "subprocess.Handle.Close": {
        "API_name": "subprocess.Handle.Close",
        "loc_name": "subprocess.Handle.Close",
        "args": "self;CloseHandle",
        "args_default": 1,
        "filepath": "subprocess",
        "lineno": 200,
        "namespace": "Handle",
        "body": "        def Close(self, CloseHandle=_winapi.CloseHandle):\n            if not self.closed:\n                self.closed = True\n                CloseHandle(self)",
        "name_type": "stdlib"
    },
    "subprocess.Handle.Detach": {
        "API_name": "subprocess.Handle.Detach",
        "loc_name": "subprocess.Handle.Detach",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 205,
        "namespace": "Handle",
        "body": "        def Detach(self):\n            if not self.closed:\n                self.closed = True\n                return int(self)\n            raise ValueError(\"already closed\")",
        "name_type": "stdlib"
    },
    "subprocess.Handle.__repr__": {
        "API_name": "subprocess.Handle.__repr__",
        "loc_name": "subprocess.Handle.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 211,
        "namespace": "Handle",
        "body": "        def __repr__(self):\n            return \"%s(%d)\" % (self.__class__.__name__, int(self))",
        "name_type": "stdlib"
    },
    "subprocess.Handle": {
        "API_name": "subprocess.Handle",
        "loc_name": "subprocess.Handle",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 197,
        "namespace": "Handle",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess._cleanup": {
        "API_name": "subprocess._cleanup",
        "loc_name": "subprocess._cleanup",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 250,
        "namespace": "*",
        "body": "    def _cleanup():\n        if _active is None:\n            return\n        for inst in _active[:]:\n            res = inst._internal_poll(_deadstate=sys.maxsize)\n            if res is not None:\n                try:\n                    _active.remove(inst)\n                except ValueError:\n                    # This can happen if two threads create a new Popen instance.\n                    # It's harmless that it was already removed, so ignore.\n                    pass",
        "name_type": "stdlib"
    },
    "subprocess._optim_args_from_interpreter_flags": {
        "API_name": "subprocess._optim_args_from_interpreter_flags",
        "loc_name": "subprocess._optim_args_from_interpreter_flags",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 272,
        "namespace": "*",
        "body": "def _optim_args_from_interpreter_flags():\n    \"\"\"Return a list of command-line arguments reproducing the current\n    optimization settings in sys.flags.\"\"\"\n    args = []\n    value = sys.flags.optimize\n    if value > 0:\n        args.append('-' + 'O' * value)\n    return args",
        "name_type": "stdlib"
    },
    "subprocess._args_from_interpreter_flags": {
        "API_name": "subprocess._args_from_interpreter_flags",
        "loc_name": "subprocess._args_from_interpreter_flags",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 282,
        "namespace": "*",
        "body": "def _args_from_interpreter_flags():\n    \"\"\"Return a list of command-line arguments reproducing the current\n    settings in sys.flags, sys.warnoptions and sys._xoptions.\"\"\"\n    flag_opt_map = {\n        'debug': 'd',\n        # 'inspect': 'i',\n        # 'interactive': 'i',\n        'dont_write_bytecode': 'B',\n        'no_site': 'S',\n        'verbose': 'v',\n        'bytes_warning': 'b',\n        'quiet': 'q',\n        # -O is handled in _optim_args_from_interpreter_flags()\n    }\n    args = _optim_args_from_interpreter_flags()\n    for flag, opt in flag_opt_map.items():\n        v = getattr(sys.flags, flag)\n        if v > 0:\n            args.append('-' + opt * v)\n\n    if sys.flags.isolated:\n        args.append('-I')\n    else:\n        if sys.flags.ignore_environment:\n            args.append('-E')\n        if sys.flags.no_user_site:\n            args.append('-s')\n\n    # -W options\n    warnopts = sys.warnoptions[:]\n    bytes_warning = sys.flags.bytes_warning\n    xoptions = getattr(sys, '_xoptions', {})\n    dev_mode = ('dev' in xoptions)\n\n    if bytes_warning > 1:\n        warnopts.remove(\"error::BytesWarning\")\n    elif bytes_warning:\n        warnopts.remove(\"default::BytesWarning\")\n    if dev_mode:\n        warnopts.remove('default')\n    for opt in warnopts:\n        args.append('-W' + opt)\n\n    # -X options\n    if dev_mode:\n        args.extend(('-X', 'dev'))\n    for opt in ('faulthandler', 'tracemalloc', 'importtime',\n                'showrefcount', 'utf8', 'oldparser'):\n        if opt in xoptions:\n            value = xoptions[opt]\n            if value is True:\n                arg = opt\n            else:\n                arg = '%s=%s' % (opt, value)\n            args.extend(('-X', arg))\n\n    return args",
        "name_type": "stdlib"
    },
    "subprocess.call": {
        "API_name": "subprocess.call",
        "loc_name": "subprocess.call",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 341,
        "namespace": "*",
        "body": "def call(*popenargs, timeout=None, **kwargs):\n    \"\"\"Run command with arguments.  Wait for command to complete or\n    timeout, then return the returncode attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    retcode = call([\"ls\", \"-l\"])\n    \"\"\"\n    with Popen(*popenargs, **kwargs) as p:\n        try:\n            return p.wait(timeout=timeout)\n        except:  # Including KeyboardInterrupt, wait handled that.\n            p.kill()\n            # We don't call p.wait() again as p.__exit__ does that for us.\n            raise",
        "name_type": "stdlib"
    },
    "subprocess.check_call": {
        "API_name": "subprocess.check_call",
        "loc_name": "subprocess.check_call",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 358,
        "namespace": "*",
        "body": "def check_call(*popenargs, **kwargs):\n    \"\"\"Run command with arguments.  Wait for command to complete.  If\n    the exit code was zero then return, otherwise raise\n    CalledProcessError.  The CalledProcessError object will have the\n    return code in the returncode attribute.\n\n    The arguments are the same as for the call function.  Example:\n\n    check_call([\"ls\", \"-l\"])\n    \"\"\"\n    retcode = call(*popenargs, **kwargs)\n    if retcode:\n        cmd = kwargs.get(\"args\")\n        if cmd is None:\n            cmd = popenargs[0]\n        raise CalledProcessError(retcode, cmd)\n    return 0",
        "name_type": "stdlib"
    },
    "subprocess.check_output": {
        "API_name": "subprocess.check_output",
        "loc_name": "subprocess.check_output",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 377,
        "namespace": "*",
        "body": "def check_output(*popenargs, timeout=None, **kwargs):\n    r\"\"\"Run command with arguments and return its output.\n\n    If the exit code was non-zero it raises a CalledProcessError.  The\n    CalledProcessError object will have the return code in the returncode\n    attribute and output in the output attribute.\n\n    The arguments are the same as for the Popen constructor.  Example:\n\n    >>> check_output([\"ls\", \"-l\", \"/dev/null\"])\n    b'crw-rw-rw- 1 root root 1, 3 Oct 18  2007 /dev/null\\n'\n\n    The stdout argument is not allowed as it is used internally.\n    To capture standard error in the result, use stderr=STDOUT.\n\n    >>> check_output([\"/bin/sh\", \"-c\",\n    ...               \"ls -l non_existent_file ; exit 0\"],\n    ...              stderr=STDOUT)\n    b'ls: non_existent_file: No such file or directory\\n'\n\n    There is an additional optional argument, \"input\", allowing you to\n    pass a string to the subprocess's stdin.  If you use this argument\n    you may not also use the Popen constructor's \"stdin\" argument, as\n    it too will be used internally.  Example:\n\n    >>> check_output([\"sed\", \"-e\", \"s/foo/bar/\"],\n    ...              input=b\"when in the course of fooman events\\n\")\n    b'when in the course of barman events\\n'\n\n    By default, all communication is in bytes, and therefore any \"input\"\n    should be bytes, and the return value will be bytes.  If in text mode,\n    any \"input\" should be a string, and the return value will be a string\n    decoded according to locale encoding, or by \"encoding\" if set. Text mode\n    is triggered by setting any of text, encoding, errors or universal_newlines.\n    \"\"\"\n    if 'stdout' in kwargs:\n        raise ValueError('stdout argument not allowed, it will be overridden.')\n\n    if 'input' in kwargs and kwargs['input'] is None:\n        # Explicitly passing input=None was previously equivalent to passing an\n        # empty string. That is maintained here for backwards compatibility.\n        if kwargs.get('universal_newlines') or kwargs.get('text'):\n            empty = ''\n        else:\n            empty = b''\n        kwargs['input'] = empty\n\n    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n               **kwargs).stdout",
        "name_type": "stdlib"
    },
    "subprocess.CompletedProcess": {
        "API_name": "subprocess.CompletedProcess",
        "loc_name": "subprocess.CompletedProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 428,
        "namespace": "CompletedProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess.CompletedProcess.__init__": {
        "API_name": "subprocess.CompletedProcess.__init__",
        "loc_name": "subprocess.CompletedProcess.__init__",
        "args": "self;args;returncode;stdout;stderr",
        "args_default": 2,
        "filepath": "subprocess",
        "lineno": 439,
        "namespace": "CompletedProcess",
        "body": "    def __init__(self, args, returncode, stdout=None, stderr=None):\n        self.args = args\n        self.returncode = returncode\n        self.stdout = stdout\n        self.stderr = stderr",
        "name_type": "stdlib"
    },
    "subprocess.CompletedProcess.__repr__": {
        "API_name": "subprocess.CompletedProcess.__repr__",
        "loc_name": "subprocess.CompletedProcess.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 445,
        "namespace": "CompletedProcess",
        "body": "    def __repr__(self):\n        args = ['args={!r}'.format(self.args),\n                'returncode={!r}'.format(self.returncode)]\n        if self.stdout is not None:\n            args.append('stdout={!r}'.format(self.stdout))\n        if self.stderr is not None:\n            args.append('stderr={!r}'.format(self.stderr))\n        return \"{}({})\".format(type(self).__name__, ', '.join(args))",
        "name_type": "stdlib"
    },
    "subprocess.CompletedProcess.check_returncode": {
        "API_name": "subprocess.CompletedProcess.check_returncode",
        "loc_name": "subprocess.CompletedProcess.check_returncode",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 457,
        "namespace": "CompletedProcess",
        "body": "    def check_returncode(self):\n        \"\"\"Raise CalledProcessError if the exit code is non-zero.\"\"\"\n        if self.returncode:\n            raise CalledProcessError(self.returncode, self.args, self.stdout,\n                                     self.stderr)",
        "name_type": "stdlib"
    },
    "subprocess.run": {
        "API_name": "subprocess.run",
        "loc_name": "subprocess.run",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 464,
        "namespace": "*",
        "body": "def run(*popenargs,\n        input=None, capture_output=False, timeout=None, check=False, **kwargs):\n    \"\"\"Run command with arguments and return a CompletedProcess instance.\n\n    The returned instance will have attributes args, returncode, stdout and\n    stderr. By default, stdout and stderr are not captured, and those attributes\n    will be None. Pass stdout=PIPE and/or stderr=PIPE in order to capture them.\n\n    If check is True and the exit code was non-zero, it raises a\n    CalledProcessError. The CalledProcessError object will have the return code\n    in the returncode attribute, and output & stderr attributes if those streams\n    were captured.\n\n    If timeout is given, and the process takes too long, a TimeoutExpired\n    exception will be raised.\n\n    There is an optional argument \"input\", allowing you to\n    pass bytes or a string to the subprocess's stdin.  If you use this argument\n    you may not also use the Popen constructor's \"stdin\" argument, as\n    it will be used internally.\n\n    By default, all communication is in bytes, and therefore any \"input\" should\n    be bytes, and the stdout and stderr will be bytes. If in text mode, any\n    \"input\" should be a string, and stdout and stderr will be strings decoded\n    according to locale encoding, or by \"encoding\" if set. Text mode is\n    triggered by setting any of text, encoding, errors or universal_newlines.\n\n    The other arguments are the same as for the Popen constructor.\n    \"\"\"\n    if input is not None:\n        if kwargs.get('stdin') is not None:\n            raise ValueError('stdin and input arguments may not both be used.')\n        kwargs['stdin'] = PIPE\n\n    if capture_output:\n        if kwargs.get('stdout') is not None or kwargs.get('stderr') is not None:\n            raise ValueError('stdout and stderr arguments may not be used '\n                             'with capture_output.')\n        kwargs['stdout'] = PIPE\n        kwargs['stderr'] = PIPE\n\n    with Popen(*popenargs, **kwargs) as process:\n        try:\n            stdout, stderr = process.communicate(input, timeout=timeout)\n        except TimeoutExpired as exc:\n            process.kill()\n            if _mswindows:\n                # Windows accumulates the output in a single blocking\n                # read() call run on child threads, with the timeout\n                # being done in a join() on those threads.  communicate()\n                # _after_ kill() is required to collect that and add it\n                # to the exception.\n                exc.stdout, exc.stderr = process.communicate()\n            else:\n                # POSIX _communicate already populated the output so\n                # far into the TimeoutExpired exception.\n                process.wait()\n            raise\n        except:  # Including KeyboardInterrupt, communicate handled that.\n            process.kill()\n            # We don't call process.wait() as .__exit__ does that for us.\n            raise\n        retcode = process.poll()\n        if check and retcode:\n            raise CalledProcessError(retcode, process.args,\n                                     output=stdout, stderr=stderr)\n    return CompletedProcess(process.args, retcode, stdout, stderr)",
        "name_type": "stdlib"
    },
    "subprocess.list2cmdline": {
        "API_name": "subprocess.list2cmdline",
        "loc_name": "subprocess.list2cmdline",
        "args": "seq",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 533,
        "namespace": "*",
        "body": "def list2cmdline(seq):\n    \"\"\"\n    Translate a sequence of arguments into a command line\n    string, using the same rules as the MS C runtime:\n\n    1) Arguments are delimited by white space, which is either a\n       space or a tab.\n\n    2) A string surrounded by double quotation marks is\n       interpreted as a single argument, regardless of white space\n       contained within.  A quoted string can be embedded in an\n       argument.\n\n    3) A double quotation mark preceded by a backslash is\n       interpreted as a literal double quotation mark.\n\n    4) Backslashes are interpreted literally, unless they\n       immediately precede a double quotation mark.\n\n    5) If backslashes immediately precede a double quotation mark,\n       every pair of backslashes is interpreted as a literal\n       backslash.  If the number of backslashes is odd, the last\n       backslash escapes the next double quotation mark as\n       described in rule 3.\n    \"\"\"\n\n    # See\n    # http://msdn.microsoft.com/en-us/library/17w5ykft.aspx\n    # or search http://msdn.microsoft.com for\n    # \"Parsing C++ Command-Line Arguments\"\n    result = []\n    needquote = False\n    for arg in map(os.fsdecode, seq):\n        bs_buf = []\n\n        # Add a space to separate this argument from the others\n        if result:\n            result.append(' ')\n\n        needquote = (\" \" in arg) or (\"\\t\" in arg) or not arg\n        if needquote:\n            result.append('\"')\n\n        for c in arg:\n            if c == '\\\\':\n                # Don't know if we need to double yet.\n                bs_buf.append(c)\n            elif c == '\"':\n                # Double backslashes.\n                result.append('\\\\' * len(bs_buf)*2)\n                bs_buf = []\n                result.append('\\\\\"')\n            else:\n                # Normal char\n                if bs_buf:\n                    result.extend(bs_buf)\n                    bs_buf = []\n                result.append(c)\n\n        # Add remaining backslashes, if any.\n        if bs_buf:\n            result.extend(bs_buf)\n\n        if needquote:\n            result.extend(bs_buf)\n            result.append('\"')\n\n    return ''.join(result)",
        "name_type": "stdlib"
    },
    "subprocess.getstatusoutput": {
        "API_name": "subprocess.getstatusoutput",
        "loc_name": "subprocess.getstatusoutput",
        "args": "cmd",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 606,
        "namespace": "*",
        "body": "def getstatusoutput(cmd):\n    \"\"\"Return (exitcode, output) of executing cmd in a shell.\n\n    Execute the string 'cmd' in a shell with 'check_output' and\n    return a 2-tuple (status, output). The locale encoding is used\n    to decode the output and process newlines.\n\n    A trailing newline is stripped from the output.\n    The exit status for the command can be interpreted\n    according to the rules for the function 'wait'. Example:\n\n    >>> import subprocess\n    >>> subprocess.getstatusoutput('ls /bin/ls')\n    (0, '/bin/ls')\n    >>> subprocess.getstatusoutput('cat /bin/junk')\n    (1, 'cat: /bin/junk: No such file or directory')\n    >>> subprocess.getstatusoutput('/bin/junk')\n    (127, 'sh: /bin/junk: not found')\n    >>> subprocess.getstatusoutput('/bin/kill $$')\n    (-15, '')\n    \"\"\"\n    try:\n        data = check_output(cmd, shell=True, text=True, stderr=STDOUT)\n        exitcode = 0\n    except CalledProcessError as ex:\n        data = ex.output\n        exitcode = ex.returncode\n    if data[-1:] == '\\n':\n        data = data[:-1]\n    return exitcode, data",
        "name_type": "stdlib"
    },
    "subprocess.getoutput": {
        "API_name": "subprocess.getoutput",
        "loc_name": "subprocess.getoutput",
        "args": "cmd",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 637,
        "namespace": "*",
        "body": "def getoutput(cmd):\n    \"\"\"Return output (stdout or stderr) of executing cmd in a shell.\n\n    Like getstatusoutput(), except the exit status is ignored and the return\n    value is a string containing the command's output.  Example:\n\n    >>> import subprocess\n    >>> subprocess.getoutput('ls /bin/ls')\n    '/bin/ls'\n    \"\"\"\n    return getstatusoutput(cmd)[1]",
        "name_type": "stdlib"
    },
    "subprocess._use_posix_spawn": {
        "API_name": "subprocess._use_posix_spawn",
        "loc_name": "subprocess._use_posix_spawn",
        "args": "",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 650,
        "namespace": "*",
        "body": "def _use_posix_spawn():\n    \"\"\"Check if posix_spawn() can be used for subprocess.\n\n    subprocess requires a posix_spawn() implementation that properly reports\n    errors to the parent process, & sets errno on the following failures:\n\n    * Process attribute actions failed.\n    * File actions failed.\n    * exec() failed.\n\n    Prefer an implementation which can use vfork() in some cases for best\n    performance.\n    \"\"\"\n    if _mswindows or not hasattr(os, 'posix_spawn'):\n        # os.posix_spawn() is not available\n        return False\n\n    if sys.platform == 'darwin':\n        # posix_spawn() is a syscall on macOS and properly reports errors\n        return True\n\n    # Check libc name and runtime libc version\n    try:\n        ver = os.confstr('CS_GNU_LIBC_VERSION')\n        # parse 'glibc 2.28' as ('glibc', (2, 28))\n        parts = ver.split(maxsplit=1)\n        if len(parts) != 2:\n            # reject unknown format\n            raise ValueError\n        libc = parts[0]\n        version = tuple(map(int, parts[1].split('.')))\n\n        if sys.platform == 'linux' and libc == 'glibc' and version >= (2, 24):\n            # glibc 2.24 has a new Linux posix_spawn implementation using vfork\n            # which properly reports errors to the parent process.\n            return True\n        # Note: Don't use the implementation in earlier glibc because it doesn't\n        # use vfork (even if glibc 2.26 added a pipe to properly report errors\n        # to the parent process).\n    except (AttributeError, ValueError, OSError):\n        # os.confstr() or CS_GNU_LIBC_VERSION value not available\n        pass\n\n    # By default, assume that posix_spawn() does not properly report errors.\n    return False",
        "name_type": "stdlib"
    },
    "subprocess.Popen": {
        "API_name": "subprocess.Popen",
        "loc_name": "subprocess.Popen",
        "args": "*",
        "args_default": "*",
        "filepath": "subprocess",
        "lineno": 700,
        "namespace": "Popen",
        "body": "",
        "name_type": "stdlib"
    },
    "subprocess.Popen.__init__": {
        "API_name": "subprocess.Popen.__init__",
        "loc_name": "subprocess.Popen.__init__",
        "args": "self;args;bufsize;executable;stdin;stdout;stderr;preexec_fn;close_fds;shell;cwd;env;universal_newlines;startupinfo;creationflags;restore_signals;start_new_session;pass_fds",
        "args_default": 16,
        "filepath": "subprocess",
        "lineno": 756,
        "namespace": "Popen",
        "body": "    def __init__(self, args, bufsize=-1, executable=None,\n                 stdin=None, stdout=None, stderr=None,\n                 preexec_fn=None, close_fds=True,\n                 shell=False, cwd=None, env=None, universal_newlines=None,\n                 startupinfo=None, creationflags=0,\n                 restore_signals=True, start_new_session=False,\n                 pass_fds=(), *, user=None, group=None, extra_groups=None,\n                 encoding=None, errors=None, text=None, umask=-1):\n        \"\"\"Create new Popen instance.\"\"\"\n        _cleanup()\n        # Held while anything is calling waitpid before returncode has been\n        # updated to prevent clobbering returncode if wait() or poll() are\n        # called from multiple threads at once.  After acquiring the lock,\n        # code must re-check self.returncode to see if another thread just\n        # finished a waitpid() call.\n        self._waitpid_lock = threading.Lock()\n\n        self._input = None\n        self._communication_started = False\n        if bufsize is None:\n            bufsize = -1  # Restore default\n        if not isinstance(bufsize, int):\n            raise TypeError(\"bufsize must be an integer\")\n\n        if _mswindows:\n            if preexec_fn is not None:\n                raise ValueError(\"preexec_fn is not supported on Windows \"\n                                 \"platforms\")\n        else:\n            # POSIX\n            if pass_fds and not close_fds:\n                warnings.warn(\"pass_fds overriding close_fds.\", RuntimeWarning)\n                close_fds = True\n            if startupinfo is not None:\n                raise ValueError(\"startupinfo is only supported on Windows \"\n                                 \"platforms\")\n            if creationflags != 0:\n                raise ValueError(\"creationflags is only supported on Windows \"\n                                 \"platforms\")\n\n        self.args = args\n        self.stdin = None\n        self.stdout = None\n        self.stderr = None\n        self.pid = None\n        self.returncode = None\n        self.encoding = encoding\n        self.errors = errors\n\n        # Validate the combinations of text and universal_newlines\n        if (text is not None and universal_newlines is not None\n            and bool(universal_newlines) != bool(text)):\n            raise SubprocessError('Cannot disambiguate when both text '\n                                  'and universal_newlines are supplied but '\n                                  'different. Pass one or the other.')\n\n        # Input and output objects. The general principle is like\n        # this:\n        #\n        # Parent                   Child\n        # ------                   -----\n        # p2cwrite   ---stdin--->  p2cread\n        # c2pread    <--stdout---  c2pwrite\n        # errread    <--stderr---  errwrite\n        #\n        # On POSIX, the child objects are file descriptors.  On\n        # Windows, these are Windows file handles.  The parent objects\n        # are file descriptors on both platforms.  The parent objects\n        # are -1 when not using PIPEs. The child objects are -1\n        # when not redirecting.\n\n        (p2cread, p2cwrite,\n         c2pread, c2pwrite,\n         errread, errwrite) = self._get_handles(stdin, stdout, stderr)\n\n        # We wrap OS handles *before* launching the child, otherwise a\n        # quickly terminating child could make our fds unwrappable\n        # (see #8458).\n\n        if _mswindows:\n            if p2cwrite != -1:\n                p2cwrite = msvcrt.open_osfhandle(p2cwrite.Detach(), 0)\n            if c2pread != -1:\n                c2pread = msvcrt.open_osfhandle(c2pread.Detach(), 0)\n            if errread != -1:\n                errread = msvcrt.open_osfhandle(errread.Detach(), 0)\n\n        self.text_mode = encoding or errors or text or universal_newlines\n\n        # How long to resume waiting on a child after the first ^C.\n        # There is no right value for this.  The purpose is to be polite\n        # yet remain good for interactive users trying to exit a tool.\n        self._sigint_wait_secs = 0.25  # 1/xkcd221.getRandomNumber()\n\n        self._closed_child_pipe_fds = False\n\n        if self.text_mode:\n            if bufsize == 1:\n                line_buffering = True\n                # Use the default buffer size for the underlying binary streams\n                # since they don't support line buffering.\n                bufsize = -1\n            else:\n                line_buffering = False\n\n        gid = None\n        if group is not None:\n            if not hasattr(os, 'setregid'):\n                raise ValueError(\"The 'group' parameter is not supported on the \"\n                                 \"current platform\")\n\n            elif isinstance(group, str):\n                if grp is None:\n                    raise ValueError(\"The group parameter cannot be a string \"\n                                     \"on systems without the grp module\")\n\n                gid = grp.getgrnam(group).gr_gid\n            elif isinstance(group, int):\n                gid = group\n            else:\n                raise TypeError(\"Group must be a string or an integer, not {}\"\n                                .format(type(group)))\n\n            if gid < 0:\n                raise ValueError(f\"Group ID cannot be negative, got {gid}\")\n\n        gids = None\n        if extra_groups is not None:\n            if not hasattr(os, 'setgroups'):\n                raise ValueError(\"The 'extra_groups' parameter is not \"\n                                 \"supported on the current platform\")\n\n            elif isinstance(extra_groups, str):\n                raise ValueError(\"Groups must be a list, not a string\")\n\n            gids = []\n            for extra_group in extra_groups:\n                if isinstance(extra_group, str):\n                    if grp is None:\n                        raise ValueError(\"Items in extra_groups cannot be \"\n                                         \"strings on systems without the \"\n                                         \"grp module\")\n\n                    gids.append(grp.getgrnam(extra_group).gr_gid)\n                elif isinstance(extra_group, int):\n                    gids.append(extra_group)\n                else:\n                    raise TypeError(\"Items in extra_groups must be a string \"\n                                    \"or integer, not {}\"\n                                    .format(type(extra_group)))\n\n            # make sure that the gids are all positive here so we can do less\n            # checking in the C code\n            for gid_check in gids:\n                if gid_check < 0:\n                    raise ValueError(f\"Group ID cannot be negative, got {gid_check}\")\n\n        uid = None\n        if user is not None:\n            if not hasattr(os, 'setreuid'):\n                raise ValueError(\"The 'user' parameter is not supported on \"\n                                 \"the current platform\")\n\n            elif isinstance(user, str):\n                if pwd is None:\n                    raise ValueError(\"The user parameter cannot be a string \"\n                                     \"on systems without the pwd module\")\n\n                uid = pwd.getpwnam(user).pw_uid\n            elif isinstance(user, int):\n                uid = user\n            else:\n                raise TypeError(\"User must be a string or an integer\")\n\n            if uid < 0:\n                raise ValueError(f\"User ID cannot be negative, got {uid}\")\n\n        try:\n            if p2cwrite != -1:\n                self.stdin = io.open(p2cwrite, 'wb', bufsize)\n                if self.text_mode:\n                    self.stdin = io.TextIOWrapper(self.stdin, write_through=True,\n                            line_buffering=line_buffering,\n                            encoding=encoding, errors=errors)\n            if c2pread != -1:\n                self.stdout = io.open(c2pread, 'rb', bufsize)\n                if self.text_mode:\n                    self.stdout = io.TextIOWrapper(self.stdout,\n                            encoding=encoding, errors=errors)\n            if errread != -1:\n                self.stderr = io.open(errread, 'rb', bufsize)\n                if self.text_mode:\n                    self.stderr = io.TextIOWrapper(self.stderr,\n                            encoding=encoding, errors=errors)\n\n            self._execute_child(args, executable, preexec_fn, close_fds,\n                                pass_fds, cwd, env,\n                                startupinfo, creationflags, shell,\n                                p2cread, p2cwrite,\n                                c2pread, c2pwrite,\n                                errread, errwrite,\n                                restore_signals,\n                                gid, gids, uid, umask,\n                                start_new_session)\n        except:\n            # Cleanup if the child failed starting.\n            for f in filter(None, (self.stdin, self.stdout, self.stderr)):\n                try:\n                    f.close()\n                except OSError:\n                    pass  # Ignore EBADF or other errors.\n\n            if not self._closed_child_pipe_fds:\n                to_close = []\n                if stdin == PIPE:\n                    to_close.append(p2cread)\n                if stdout == PIPE:\n                    to_close.append(c2pwrite)\n                if stderr == PIPE:\n                    to_close.append(errwrite)\n                if hasattr(self, '_devnull'):\n                    to_close.append(self._devnull)\n                for fd in to_close:\n                    try:\n                        if _mswindows and isinstance(fd, Handle):\n                            fd.Close()\n                        else:\n                            os.close(fd)\n                    except OSError:\n                        pass\n\n            raise",
        "name_type": "stdlib"
    },
    "subprocess.Popen.__repr__": {
        "API_name": "subprocess.Popen.__repr__",
        "loc_name": "subprocess.Popen.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 989,
        "namespace": "Popen",
        "body": "    def __repr__(self):\n        obj_repr = (\n            f\"<{self.__class__.__name__}: \"\n            f\"returncode: {self.returncode} args: {self.args!r}>\"\n        )\n        if len(obj_repr) > 80:\n            obj_repr = obj_repr[:76] + \"...>\"\n        return obj_repr",
        "name_type": "stdlib"
    },
    "subprocess.Popen.universal_newlines": {
        "API_name": "subprocess.Popen.universal_newlines",
        "loc_name": "subprocess.Popen.universal_newlines",
        "args": "self;universal_newlines",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1007,
        "namespace": "Popen",
        "body": "    def universal_newlines(self, universal_newlines):\n        self.text_mode = bool(universal_newlines)",
        "name_type": "stdlib"
    },
    "subprocess.Popen._translate_newlines": {
        "API_name": "subprocess.Popen._translate_newlines",
        "loc_name": "subprocess.Popen._translate_newlines",
        "args": "self;data;encoding;errors",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1010,
        "namespace": "Popen",
        "body": "    def _translate_newlines(self, data, encoding, errors):\n        data = data.decode(encoding, errors)\n        return data.replace(\"\\r\\n\", \"\\n\").replace(\"\\r\", \"\\n\")",
        "name_type": "stdlib"
    },
    "subprocess.Popen.__enter__": {
        "API_name": "subprocess.Popen.__enter__",
        "loc_name": "subprocess.Popen.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1014,
        "namespace": "Popen",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "subprocess.Popen.__exit__": {
        "API_name": "subprocess.Popen.__exit__",
        "loc_name": "subprocess.Popen.__exit__",
        "args": "self;exc_type;value;traceback",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1017,
        "namespace": "Popen",
        "body": "    def __exit__(self, exc_type, value, traceback):\n        if self.stdout:\n            self.stdout.close()\n        if self.stderr:\n            self.stderr.close()\n        try:  # Flushing a BufferedWriter may raise an error\n            if self.stdin:\n                self.stdin.close()\n        finally:\n            if exc_type == KeyboardInterrupt:\n                # https://bugs.python.org/issue25942\n                # In the case of a KeyboardInterrupt we assume the SIGINT\n                # was also already sent to our child processes.  We can't\n                # block indefinitely as that is not user friendly.\n                # If we have not already waited a brief amount of time in\n                # an interrupted .wait() or .communicate() call, do so here\n                # for consistency.\n                if self._sigint_wait_secs > 0:\n                    try:\n                        self._wait(timeout=self._sigint_wait_secs)\n                    except TimeoutExpired:\n                        pass\n                self._sigint_wait_secs = 0  # Note that this has been done.\n                return  # resume the KeyboardInterrupt\n\n            # Wait for the process to terminate, to avoid zombies.\n            self.wait()",
        "name_type": "stdlib"
    },
    "subprocess.Popen.__del__": {
        "API_name": "subprocess.Popen.__del__",
        "loc_name": "subprocess.Popen.__del__",
        "args": "self;_maxsize;_warn",
        "args_default": 2,
        "filepath": "subprocess",
        "lineno": 1045,
        "namespace": "Popen",
        "body": "    def __del__(self, _maxsize=sys.maxsize, _warn=warnings.warn):\n        if not self._child_created:\n            # We didn't get to successfully create a child process.\n            return\n        if self.returncode is None:\n            # Not reading subprocess exit status creates a zombie process which\n            # is only destroyed at the parent python process exit\n            _warn(\"subprocess %s is still running\" % self.pid,\n                  ResourceWarning, source=self)\n        # In case the child hasn't been waited on, check if it's done.\n        self._internal_poll(_deadstate=_maxsize)\n        if self.returncode is None and _active is not None:\n            # Child is still running, keep us alive until we can wait on it.\n            _active.append(self)",
        "name_type": "stdlib"
    },
    "subprocess.Popen._get_devnull": {
        "API_name": "subprocess.Popen._get_devnull",
        "loc_name": "subprocess.Popen._get_devnull",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1060,
        "namespace": "Popen",
        "body": "    def _get_devnull(self):\n        if not hasattr(self, '_devnull'):\n            self._devnull = os.open(os.devnull, os.O_RDWR)\n        return self._devnull",
        "name_type": "stdlib"
    },
    "subprocess.Popen._stdin_write": {
        "API_name": "subprocess.Popen._stdin_write",
        "loc_name": "subprocess.Popen._stdin_write",
        "args": "self;input",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1065,
        "namespace": "Popen",
        "body": "    def _stdin_write(self, input):\n        if input:\n            try:\n                self.stdin.write(input)\n            except BrokenPipeError:\n                pass  # communicate() must ignore broken pipe errors.\n            except OSError as exc:\n                if exc.errno == errno.EINVAL:\n                    # bpo-19612, bpo-30418: On Windows, stdin.write() fails\n                    # with EINVAL if the child process exited or if the child\n                    # process is still running but closed the pipe.\n                    pass\n                else:\n                    raise\n\n        try:\n            self.stdin.close()\n        except BrokenPipeError:\n            pass  # communicate() must ignore broken pipe errors.\n        except OSError as exc:\n            if exc.errno == errno.EINVAL:\n                pass\n            else:\n                raise",
        "name_type": "stdlib"
    },
    "subprocess.Popen.communicate": {
        "API_name": "subprocess.Popen.communicate",
        "loc_name": "subprocess.Popen.communicate",
        "args": "self;input;timeout",
        "args_default": 2,
        "filepath": "subprocess",
        "lineno": 1090,
        "namespace": "Popen",
        "body": "    def communicate(self, input=None, timeout=None):\n        \"\"\"Interact with process: Send data to stdin and close it.\n        Read data from stdout and stderr, until end-of-file is\n        reached.  Wait for process to terminate.\n\n        The optional \"input\" argument should be data to be sent to the\n        child process, or None, if no data should be sent to the child.\n        communicate() returns a tuple (stdout, stderr).\n\n        By default, all communication is in bytes, and therefore any\n        \"input\" should be bytes, and the (stdout, stderr) will be bytes.\n        If in text mode (indicated by self.text_mode), any \"input\" should\n        be a string, and (stdout, stderr) will be strings decoded\n        according to locale encoding, or by \"encoding\" if set. Text mode\n        is triggered by setting any of text, encoding, errors or\n        universal_newlines.\n        \"\"\"\n\n        if self._communication_started and input:\n            raise ValueError(\"Cannot send input after starting communication\")\n\n        # Optimization: If we are not worried about timeouts, we haven't\n        # started communicating, and we have one or zero pipes, using select()\n        # or threads is unnecessary.\n        if (timeout is None and not self._communication_started and\n            [self.stdin, self.stdout, self.stderr].count(None) >= 2):\n            stdout = None\n            stderr = None\n            if self.stdin:\n                self._stdin_write(input)\n            elif self.stdout:\n                stdout = self.stdout.read()\n                self.stdout.close()\n            elif self.stderr:\n                stderr = self.stderr.read()\n                self.stderr.close()\n            self.wait()\n        else:\n            if timeout is not None:\n                endtime = _time() + timeout\n            else:\n                endtime = None\n\n            try:\n                stdout, stderr = self._communicate(input, endtime, timeout)\n            except KeyboardInterrupt:\n                # https://bugs.python.org/issue25942\n                # See the detailed comment in .wait().\n                if timeout is not None:\n                    sigint_timeout = min(self._sigint_wait_secs,\n                                         self._remaining_time(endtime))\n                else:\n                    sigint_timeout = self._sigint_wait_secs\n                self._sigint_wait_secs = 0  # nothing else should wait.\n                try:\n                    self._wait(timeout=sigint_timeout)\n                except TimeoutExpired:\n                    pass\n                raise  # resume the KeyboardInterrupt\n\n            finally:\n                self._communication_started = True\n\n            sts = self.wait(timeout=self._remaining_time(endtime))\n\n        return (stdout, stderr)",
        "name_type": "stdlib"
    },
    "subprocess.Popen.poll": {
        "API_name": "subprocess.Popen.poll",
        "loc_name": "subprocess.Popen.poll",
        "args": "self",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1158,
        "namespace": "Popen",
        "body": "    def poll(self):\n        \"\"\"Check if child process has terminated. Set and return returncode\n        attribute.\"\"\"\n        return self._internal_poll()",
        "name_type": "stdlib"
    },
    "subprocess.Popen._remaining_time": {
        "API_name": "subprocess.Popen._remaining_time",
        "loc_name": "subprocess.Popen._remaining_time",
        "args": "self;endtime",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1164,
        "namespace": "Popen",
        "body": "    def _remaining_time(self, endtime):\n        \"\"\"Convenience for _communicate when computing timeouts.\"\"\"\n        if endtime is None:\n            return None\n        else:\n            return endtime - _time()",
        "name_type": "stdlib"
    },
    "subprocess.Popen._check_timeout": {
        "API_name": "subprocess.Popen._check_timeout",
        "loc_name": "subprocess.Popen._check_timeout",
        "args": "self;endtime;orig_timeout;stdout_seq;stderr_seq;skip_check_and_raise",
        "args_default": 1,
        "filepath": "subprocess",
        "lineno": 1172,
        "namespace": "Popen",
        "body": "    def _check_timeout(self, endtime, orig_timeout, stdout_seq, stderr_seq,\n                       skip_check_and_raise=False):\n        \"\"\"Convenience for checking if a timeout has expired.\"\"\"\n        if endtime is None:\n            return\n        if skip_check_and_raise or _time() > endtime:\n            raise TimeoutExpired(\n                    self.args, orig_timeout,\n                    output=b''.join(stdout_seq) if stdout_seq else None,\n                    stderr=b''.join(stderr_seq) if stderr_seq else None)",
        "name_type": "stdlib"
    },
    "subprocess.Popen.wait": {
        "API_name": "subprocess.Popen.wait",
        "loc_name": "subprocess.Popen.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "subprocess",
        "lineno": 1184,
        "namespace": "Popen",
        "body": "    def wait(self, timeout=None):\n        \"\"\"Wait for child process to terminate; returns self.returncode.\"\"\"\n        if timeout is not None:\n            endtime = _time() + timeout\n        try:\n            return self._wait(timeout=timeout)\n        except KeyboardInterrupt:\n            # https://bugs.python.org/issue25942\n            # The first keyboard interrupt waits briefly for the child to\n            # exit under the common assumption that it also received the ^C\n            # generated SIGINT and will exit rapidly.\n            if timeout is not None:\n                sigint_timeout = min(self._sigint_wait_secs,\n                                     self._remaining_time(endtime))\n            else:\n                sigint_timeout = self._sigint_wait_secs\n            self._sigint_wait_secs = 0  # nothing else should wait.\n            try:\n                self._wait(timeout=sigint_timeout)\n            except TimeoutExpired:\n                pass\n            raise  # resume the KeyboardInterrupt",
        "name_type": "stdlib"
    },
    "subprocess.Popen._close_pipe_fds": {
        "API_name": "subprocess.Popen._close_pipe_fds",
        "loc_name": "subprocess.Popen._close_pipe_fds",
        "args": "self;p2cread;p2cwrite;c2pread;c2pwrite;errread;errwrite",
        "args_default": 0,
        "filepath": "subprocess",
        "lineno": 1207,
        "namespace": "Popen",
        "body": "    def _close_pipe_fds(self,\n                        p2cread, p2cwrite,\n                        c2pread, c2pwrite,\n                        errread, errwrite):\n        # self._devnull is not always defined.\n        devnull_fd = getattr(self, '_devnull', None)\n\n        with contextlib.ExitStack() as stack:\n            if _mswindows:\n                if p2cread != -1:\n                    stack.callback(p2cread.Close)\n                if c2pwrite != -1:\n                    stack.callback(c2pwrite.Close)\n                if errwrite != -1:\n                    stack.callback(errwrite.Close)\n            else:\n                if p2cread != -1 and p2cwrite != -1 and p2cread != devnull_fd:\n                    stack.callback(os.close, p2cread)\n                if c2pwrite != -1 and c2pread != -1 and c2pwrite != devnull_fd:\n                    stack.callback(os.close, c2pwrite)\n                if errwrite != -1 and errread != -1 and errwrite != devnull_fd:\n                    stack.callback(os.close, errwrite)\n\n            if devnull_fd is not None:\n                stack.callback(os.close, devnull_fd)\n\n        # Prevent a double close of these handles/fds from __init__ on error.\n        self._closed_child_pipe_fds = True",
        "name_type": "stdlib"
    },
    "tempfile": {
        "API_name": "tempfile",
        "loc_name": "tempfile",
        "args": "*",
        "args_default": "*",
        "filepath": "tempfile",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Temporary files.\n\nThis module provides generic, low- and high-level interfaces for\ncreating temporary files and directories.  All of the interfaces\nprovided by this module can be used without fear of race conditions\nexcept for 'mktemp'.  'mktemp' is subject to race conditions and\nshould not be used; it is provided for backward compatibility only.\n\nThe default path names are returned as str.  If you supply bytes as\ninput, all return values will be in bytes.  Ex:\n\n    >>> tempfile.mkstemp()\n    (4, '/tmp/tmptpu9nin8')\n    >>> tempfile.mkdtemp(suffix=b'')\n    b'/tmp/tmppbi8f0hy'\n\nThis module also provides some data items to the user:\n\n  TMP_MAX  - maximum number of names that will be tried before\n             giving up.\n  tempdir  - If this is set to a string before the first use of\n             any routine from this module, it will be considered as\n             another candidate location to store temporary files.\n\"\"\"\n__all__ = [\n    \"NamedTemporaryFile\", \"TemporaryFile\", # high level safe interfaces\n    \"SpooledTemporaryFile\", \"TemporaryDirectory\",\n    \"mkstemp\", \"mkdtemp\",                  # low level safe interfaces\n    \"mktemp\",                              # deprecated unsafe interface\n    \"TMP_MAX\", \"gettempprefix\",            # constants\n    \"tempdir\", \"gettempdir\",\n    \"gettempprefixb\", \"gettempdirb\",\n   ]\n_allocate_lock = _thread.allocate_lock\n_text_openflags = _os.O_RDWR | _os.O_CREAT | _os.O_EXCL\nif hasattr(_os, 'O_NOFOLLOW'):\n    _text_openflags |= _os.O_NOFOLLOW\n_bin_openflags = _text_openflags\nif hasattr(_os, 'O_BINARY'):\n    _bin_openflags |= _os.O_BINARY\nif hasattr(_os, 'TMP_MAX'):\n    TMP_MAX = _os.TMP_MAX\nelse:\n    TMP_MAX = 10000\ntemplate = \"tmp\"\n_once_lock = _allocate_lock()\n_name_sequence = None\ntempdir = None\nif _os.name != 'posix' or _sys.platform == 'cygwin':\n    # On non-POSIX and Cygwin systems, assume that we cannot unlink a file\n    # while it is open.\n    TemporaryFile = NamedTemporaryFile\n\nelse:\n    # Is the O_TMPFILE flag available and does it work?\n    # The flag is set to False if os.open(dir, os.O_TMPFILE) raises an\n    # IsADirectoryError exception\n    _O_TMPFILE_WORKS = hasattr(_os, 'O_TMPFILE')\n\n    def TemporaryFile(mode='w+b', buffering=-1, encoding=None,\n                      newline=None, suffix=None, prefix=None,\n                      dir=None, *, errors=None):\n        \"\"\"Create and return a temporary file.\n        Arguments:\n        'prefix', 'suffix', 'dir' -- as for mkstemp.\n        'mode' -- the mode argument to io.open (default \"w+b\").\n        'buffering' -- the buffer size argument to io.open (default -1).\n        'encoding' -- the encoding argument to io.open (default None)\n        'newline' -- the newline argument to io.open (default None)\n        'errors' -- the errors argument to io.open (default None)\n        The file is created as mkstemp() would do it.\n\n        Returns an object with a file-like interface.  The file has no\n        name, and will cease to exist when it is closed.\n        \"\"\"\n        global _O_TMPFILE_WORKS\n\n        prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n\n        flags = _bin_openflags\n        if _O_TMPFILE_WORKS:\n            try:\n                flags2 = (flags | _os.O_TMPFILE) & ~_os.O_CREAT\n                fd = _os.open(dir, flags2, 0o600)\n            except IsADirectoryError:\n                # Linux kernel older than 3.11 ignores the O_TMPFILE flag:\n                # O_TMPFILE is read as O_DIRECTORY. Trying to open a directory\n                # with O_RDWR|O_DIRECTORY fails with IsADirectoryError, a\n                # directory cannot be open to write. Set flag to False to not\n                # try again.\n                _O_TMPFILE_WORKS = False\n            except OSError:\n                # The filesystem of the directory does not support O_TMPFILE.\n                # For example, OSError(95, 'Operation not supported').\n                #\n                # On Linux kernel older than 3.11, trying to open a regular\n                # file (or a symbolic link to a regular file) with O_TMPFILE\n                # fails with NotADirectoryError, because O_TMPFILE is read as\n                # O_DIRECTORY.\n                pass\n            else:\n                try:\n                    return _io.open(fd, mode, buffering=buffering,\n                                    newline=newline, encoding=encoding,\n                                    errors=errors)\n                except:\n                    _os.close(fd)\n                    raise\n            # Fallback to _mkstemp_inner().\n\n        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n        try:\n            _os.unlink(name)\n            return _io.open(fd, mode, buffering=buffering,\n                            newline=newline, encoding=encoding, errors=errors)\n        except:\n            _os.close(fd)\n            raise",
        "name_type": "stdlib"
    },
    "tempfile._exists": {
        "API_name": "tempfile._exists",
        "loc_name": "tempfile._exists",
        "args": "fn",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 76,
        "namespace": "*",
        "body": "def _exists(fn):\n    try:\n        _os.lstat(fn)\n    except OSError:\n        return False\n    else:\n        return True",
        "name_type": "stdlib"
    },
    "tempfile._infer_return_type": {
        "API_name": "tempfile._infer_return_type",
        "loc_name": "tempfile._infer_return_type",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 85,
        "namespace": "*",
        "body": "def _infer_return_type(*args):\n    \"\"\"Look at the type of all args and divine their implied return type.\"\"\"\n    return_type = None\n    for arg in args:\n        if arg is None:\n            continue\n\n        if isinstance(arg, _os.PathLike):\n            arg = _os.fspath(arg)\n\n        if isinstance(arg, bytes):\n            if return_type is str:\n                raise TypeError(\"Can't mix bytes and non-bytes in \"\n                                \"path components.\")\n            return_type = bytes\n        else:\n            if return_type is bytes:\n                raise TypeError(\"Can't mix bytes and non-bytes in \"\n                                \"path components.\")\n            return_type = str\n    if return_type is None:\n        return str  # tempfile APIs return a str by default.\n    return return_type",
        "name_type": "stdlib"
    },
    "tempfile._sanitize_params": {
        "API_name": "tempfile._sanitize_params",
        "loc_name": "tempfile._sanitize_params",
        "args": "prefix;suffix;dir",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 110,
        "namespace": "*",
        "body": "def _sanitize_params(prefix, suffix, dir):\n    \"\"\"Common parameter processing for most APIs in this module.\"\"\"\n    output_type = _infer_return_type(prefix, suffix, dir)\n    if suffix is None:\n        suffix = output_type()\n    if prefix is None:\n        if output_type is str:\n            prefix = template\n        else:\n            prefix = _os.fsencode(template)\n    if dir is None:\n        if output_type is str:\n            dir = gettempdir()\n        else:\n            dir = gettempdirb()\n    return prefix, suffix, dir, output_type",
        "name_type": "stdlib"
    },
    "tempfile._RandomNameSequence.rng": {
        "API_name": "tempfile._RandomNameSequence.rng",
        "loc_name": "tempfile._RandomNameSequence.rng",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 139,
        "namespace": "_RandomNameSequence",
        "body": "    def rng(self):\n        cur_pid = _os.getpid()\n        if cur_pid != getattr(self, '_rng_pid', None):\n            self._rng = _Random()\n            self._rng_pid = cur_pid\n        return self._rng",
        "name_type": "stdlib"
    },
    "tempfile._RandomNameSequence.__iter__": {
        "API_name": "tempfile._RandomNameSequence.__iter__",
        "loc_name": "tempfile._RandomNameSequence.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 146,
        "namespace": "_RandomNameSequence",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "tempfile._RandomNameSequence.__next__": {
        "API_name": "tempfile._RandomNameSequence.__next__",
        "loc_name": "tempfile._RandomNameSequence.__next__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 149,
        "namespace": "_RandomNameSequence",
        "body": "    def __next__(self):\n        c = self.characters\n        choose = self.rng.choice\n        letters = [choose(c) for dummy in range(8)]\n        return ''.join(letters)",
        "name_type": "stdlib"
    },
    "tempfile._RandomNameSequence": {
        "API_name": "tempfile._RandomNameSequence",
        "loc_name": "tempfile._RandomNameSequence",
        "args": "*",
        "args_default": "*",
        "filepath": "tempfile",
        "lineno": 128,
        "namespace": "_RandomNameSequence",
        "body": "",
        "name_type": "stdlib"
    },
    "tempfile._candidate_tempdir_list": {
        "API_name": "tempfile._candidate_tempdir_list",
        "loc_name": "tempfile._candidate_tempdir_list",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 155,
        "namespace": "*",
        "body": "def _candidate_tempdir_list():\n    \"\"\"Generate a list of candidate temporary directories which\n    _get_default_tempdir will try.\"\"\"\n\n    dirlist = []\n\n    # First, try the environment.\n    for envname in 'TMPDIR', 'TEMP', 'TMP':\n        dirname = _os.getenv(envname)\n        if dirname: dirlist.append(dirname)\n\n    # Failing that, try OS-specific locations.\n    if _os.name == 'nt':\n        dirlist.extend([ _os.path.expanduser(r'~\\AppData\\Local\\Temp'),\n                         _os.path.expandvars(r'%SYSTEMROOT%\\Temp'),\n                         r'c:\\temp', r'c:\\tmp', r'\\temp', r'\\tmp' ])\n    else:\n        dirlist.extend([ '/tmp', '/var/tmp', '/usr/tmp' ])\n\n    # As a last resort, the current directory.\n    try:\n        dirlist.append(_os.getcwd())\n    except (AttributeError, OSError):\n        dirlist.append(_os.curdir)\n\n    return dirlist",
        "name_type": "stdlib"
    },
    "tempfile._get_default_tempdir": {
        "API_name": "tempfile._get_default_tempdir",
        "loc_name": "tempfile._get_default_tempdir",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 182,
        "namespace": "*",
        "body": "def _get_default_tempdir():\n    \"\"\"Calculate the default directory to use for temporary files.\n    This routine should be called exactly once.\n\n    We determine whether or not a candidate temp dir is usable by\n    trying to create and write to a file in that directory.  If this\n    is successful, the test file is deleted.  To prevent denial of\n    service, the name of the test file must be randomized.\"\"\"\n\n    namer = _RandomNameSequence()\n    dirlist = _candidate_tempdir_list()\n\n    for dir in dirlist:\n        if dir != _os.curdir:\n            dir = _os.path.abspath(dir)\n        # Try only a few names per directory.\n        for seq in range(100):\n            name = next(namer)\n            filename = _os.path.join(dir, name)\n            try:\n                fd = _os.open(filename, _bin_openflags, 0o600)\n                try:\n                    try:\n                        with _io.open(fd, 'wb', closefd=False) as fp:\n                            fp.write(b'blat')\n                    finally:\n                        _os.close(fd)\n                finally:\n                    _os.unlink(filename)\n                return dir\n            except FileExistsError:\n                pass\n            except PermissionError:\n                # This exception is thrown when a directory with the chosen name\n                # already exists on windows.\n                if (_os.name == 'nt' and _os.path.isdir(dir) and\n                    _os.access(dir, _os.W_OK)):\n                    continue\n                break   # no point trying more names in this directory\n            except OSError:\n                break   # no point trying more names in this directory\n    raise FileNotFoundError(_errno.ENOENT,\n                            \"No usable temporary directory found in %s\" %\n                            dirlist)",
        "name_type": "stdlib"
    },
    "tempfile._get_candidate_names": {
        "API_name": "tempfile._get_candidate_names",
        "loc_name": "tempfile._get_candidate_names",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 229,
        "namespace": "*",
        "body": "def _get_candidate_names():\n    \"\"\"Common setup sequence for all user-callable interfaces.\"\"\"\n\n    global _name_sequence\n    if _name_sequence is None:\n        _once_lock.acquire()\n        try:\n            if _name_sequence is None:\n                _name_sequence = _RandomNameSequence()\n        finally:\n            _once_lock.release()\n    return _name_sequence",
        "name_type": "stdlib"
    },
    "tempfile._mkstemp_inner": {
        "API_name": "tempfile._mkstemp_inner",
        "loc_name": "tempfile._mkstemp_inner",
        "args": "dir;pre;suf;flags;output_type",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 243,
        "namespace": "*",
        "body": "def _mkstemp_inner(dir, pre, suf, flags, output_type):\n    \"\"\"Code common to mkstemp, TemporaryFile, and NamedTemporaryFile.\"\"\"\n\n    names = _get_candidate_names()\n    if output_type is bytes:\n        names = map(_os.fsencode, names)\n\n    for seq in range(TMP_MAX):\n        name = next(names)\n        file = _os.path.join(dir, pre + name + suf)\n        _sys.audit(\"tempfile.mkstemp\", file)\n        try:\n            fd = _os.open(file, flags, 0o600)\n        except FileExistsError:\n            continue    # try again\n        except PermissionError:\n            # This exception is thrown when a directory with the chosen name\n            # already exists on windows.\n            if (_os.name == 'nt' and _os.path.isdir(dir) and\n                _os.access(dir, _os.W_OK)):\n                continue\n            else:\n                raise\n        return (fd, _os.path.abspath(file))\n\n    raise FileExistsError(_errno.EEXIST,\n                          \"No usable temporary file name found\")",
        "name_type": "stdlib"
    },
    "tempfile.gettempprefix": {
        "API_name": "tempfile.gettempprefix",
        "loc_name": "tempfile.gettempprefix",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 274,
        "namespace": "*",
        "body": "def gettempprefix():\n    \"\"\"The default prefix for temporary directories.\"\"\"\n    return template",
        "name_type": "stdlib"
    },
    "tempfile.gettempprefixb": {
        "API_name": "tempfile.gettempprefixb",
        "loc_name": "tempfile.gettempprefixb",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 278,
        "namespace": "*",
        "body": "def gettempprefixb():\n    \"\"\"The default prefix for temporary directories as bytes.\"\"\"\n    return _os.fsencode(gettempprefix())",
        "name_type": "stdlib"
    },
    "tempfile.gettempdir": {
        "API_name": "tempfile.gettempdir",
        "loc_name": "tempfile.gettempdir",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 284,
        "namespace": "*",
        "body": "def gettempdir():\n    \"\"\"Accessor for tempfile.tempdir.\"\"\"\n    global tempdir\n    if tempdir is None:\n        _once_lock.acquire()\n        try:\n            if tempdir is None:\n                tempdir = _get_default_tempdir()\n        finally:\n            _once_lock.release()\n    return tempdir",
        "name_type": "stdlib"
    },
    "tempfile.gettempdirb": {
        "API_name": "tempfile.gettempdirb",
        "loc_name": "tempfile.gettempdirb",
        "args": "",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 296,
        "namespace": "*",
        "body": "def gettempdirb():\n    \"\"\"A bytes version of tempfile.gettempdir().\"\"\"\n    return _os.fsencode(gettempdir())",
        "name_type": "stdlib"
    },
    "tempfile.mkstemp": {
        "API_name": "tempfile.mkstemp",
        "loc_name": "tempfile.mkstemp",
        "args": "suffix;prefix;dir;text",
        "args_default": 4,
        "filepath": "tempfile",
        "lineno": 300,
        "namespace": "*",
        "body": "def mkstemp(suffix=None, prefix=None, dir=None, text=False):\n    \"\"\"User-callable function to create and return a unique temporary\n    file.  The return value is a pair (fd, name) where fd is the\n    file descriptor returned by os.open, and name is the filename.\n\n    If 'suffix' is not None, the file name will end with that suffix,\n    otherwise there will be no suffix.\n\n    If 'prefix' is not None, the file name will begin with that prefix,\n    otherwise a default prefix is used.\n\n    If 'dir' is not None, the file will be created in that directory,\n    otherwise a default directory is used.\n\n    If 'text' is specified and true, the file is opened in text\n    mode.  Else (the default) the file is opened in binary mode.\n\n    If any of 'suffix', 'prefix' and 'dir' are not None, they must be the\n    same type.  If they are bytes, the returned name will be bytes; str\n    otherwise.\n\n    The file is readable and writable only by the creating user ID.\n    If the operating system uses permission bits to indicate whether a\n    file is executable, the file is executable by no one. The file\n    descriptor is not inherited by children of this process.\n\n    Caller is responsible for deleting the file when done with it.\n    \"\"\"\n\n    prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n\n    if text:\n        flags = _text_openflags\n    else:\n        flags = _bin_openflags\n\n    return _mkstemp_inner(dir, prefix, suffix, flags, output_type)",
        "name_type": "stdlib"
    },
    "tempfile.mkdtemp": {
        "API_name": "tempfile.mkdtemp",
        "loc_name": "tempfile.mkdtemp",
        "args": "suffix;prefix;dir",
        "args_default": 3,
        "filepath": "tempfile",
        "lineno": 339,
        "namespace": "*",
        "body": "def mkdtemp(suffix=None, prefix=None, dir=None):\n    \"\"\"User-callable function to create and return a unique temporary\n    directory.  The return value is the pathname of the directory.\n\n    Arguments are as for mkstemp, except that the 'text' argument is\n    not accepted.\n\n    The directory is readable, writable, and searchable only by the\n    creating user.\n\n    Caller is responsible for deleting the directory when done with it.\n    \"\"\"\n\n    prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n\n    names = _get_candidate_names()\n    if output_type is bytes:\n        names = map(_os.fsencode, names)\n\n    for seq in range(TMP_MAX):\n        name = next(names)\n        file = _os.path.join(dir, prefix + name + suffix)\n        _sys.audit(\"tempfile.mkdtemp\", file)\n        try:\n            _os.mkdir(file, 0o700)\n        except FileExistsError:\n            continue    # try again\n        except PermissionError:\n            # This exception is thrown when a directory with the chosen name\n            # already exists on windows.\n            if (_os.name == 'nt' and _os.path.isdir(dir) and\n                _os.access(dir, _os.W_OK)):\n                continue\n            else:\n                raise\n        return file\n\n    raise FileExistsError(_errno.EEXIST,\n                          \"No usable temporary directory name found\")",
        "name_type": "stdlib"
    },
    "tempfile.mktemp": {
        "API_name": "tempfile.mktemp",
        "loc_name": "tempfile.mktemp",
        "args": "suffix;prefix;dir",
        "args_default": 3,
        "filepath": "tempfile",
        "lineno": 379,
        "namespace": "*",
        "body": "def mktemp(suffix=\"\", prefix=template, dir=None):\n    \"\"\"User-callable function to return a unique temporary file name.  The\n    file is not created.\n\n    Arguments are similar to mkstemp, except that the 'text' argument is\n    not accepted, and suffix=None, prefix=None and bytes file names are not\n    supported.\n\n    THIS FUNCTION IS UNSAFE AND SHOULD NOT BE USED.  The file name may\n    refer to a file that did not exist at some point, but by the time\n    you get around to creating it, someone else may have beaten you to\n    the punch.\n    \"\"\"\n\n##    from warnings import warn as _warn\n##    _warn(\"mktemp is a potential security risk to your program\",\n##          RuntimeWarning, stacklevel=2)\n\n    if dir is None:\n        dir = gettempdir()\n\n    names = _get_candidate_names()\n    for seq in range(TMP_MAX):\n        name = next(names)\n        file = _os.path.join(dir, prefix + name + suffix)\n        if not _exists(file):\n            return file\n\n    raise FileExistsError(_errno.EEXIST,\n                          \"No usable temporary filename found\")",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileCloser": {
        "API_name": "tempfile._TemporaryFileCloser",
        "loc_name": "tempfile._TemporaryFileCloser",
        "args": "*",
        "args_default": "*",
        "filepath": "tempfile",
        "lineno": 411,
        "namespace": "_TemporaryFileCloser",
        "body": "",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileCloser.__init__": {
        "API_name": "tempfile._TemporaryFileCloser.__init__",
        "loc_name": "tempfile._TemporaryFileCloser.__init__",
        "args": "self;file;name;delete",
        "args_default": 1,
        "filepath": "tempfile",
        "lineno": 419,
        "namespace": "_TemporaryFileCloser",
        "body": "    def __init__(self, file, name, delete=True):\n        self.file = file\n        self.name = name\n        self.delete = delete",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper": {
        "API_name": "tempfile._TemporaryFileWrapper",
        "loc_name": "tempfile._TemporaryFileWrapper",
        "args": "*",
        "args_default": "*",
        "filepath": "tempfile",
        "lineno": 454,
        "namespace": "_TemporaryFileWrapper",
        "body": "",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper.__init__": {
        "API_name": "tempfile._TemporaryFileWrapper.__init__",
        "loc_name": "tempfile._TemporaryFileWrapper.__init__",
        "args": "self;file;name;delete",
        "args_default": 1,
        "filepath": "tempfile",
        "lineno": 462,
        "namespace": "_TemporaryFileWrapper",
        "body": "    def __init__(self, file, name, delete=True):\n        self.file = file\n        self.name = name\n        self.delete = delete\n        self._closer = _TemporaryFileCloser(file, name, delete)",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper.__getattr__": {
        "API_name": "tempfile._TemporaryFileWrapper.__getattr__",
        "loc_name": "tempfile._TemporaryFileWrapper.__getattr__",
        "args": "self;name",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 468,
        "namespace": "_TemporaryFileWrapper",
        "body": "    def __getattr__(self, name):\n        # Attribute lookups are delegated to the underlying file\n        # and cached for non-numeric results\n        # (i.e. methods are cached, closed and friends are not)\n        file = self.__dict__['file']\n        a = getattr(file, name)\n        if hasattr(a, '__call__'):\n            func = a\n            @_functools.wraps(func)\n            def func_wrapper(*args, **kwargs):\n                return func(*args, **kwargs)\n            # Avoid closing the file as long as the wrapper is alive,\n            # see issue #18879.\n            func_wrapper._closer = self._closer\n            a = func_wrapper\n        if not isinstance(a, int):\n            setattr(self, name, a)\n        return a",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper.__enter__": {
        "API_name": "tempfile._TemporaryFileWrapper.__enter__",
        "loc_name": "tempfile._TemporaryFileWrapper.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 489,
        "namespace": "_TemporaryFileWrapper",
        "body": "    def __enter__(self):\n        self.file.__enter__()\n        return self",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper.__exit__": {
        "API_name": "tempfile._TemporaryFileWrapper.__exit__",
        "loc_name": "tempfile._TemporaryFileWrapper.__exit__",
        "args": "self;exc;value;tb",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 495,
        "namespace": "_TemporaryFileWrapper",
        "body": "    def __exit__(self, exc, value, tb):\n        result = self.file.__exit__(exc, value, tb)\n        self.close()\n        return result",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper.close": {
        "API_name": "tempfile._TemporaryFileWrapper.close",
        "loc_name": "tempfile._TemporaryFileWrapper.close",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 500,
        "namespace": "_TemporaryFileWrapper",
        "body": "    def close(self):\n        \"\"\"\n        Close the temporary file, possibly deleting it.\n        \"\"\"\n        self._closer.close()",
        "name_type": "stdlib"
    },
    "tempfile._TemporaryFileWrapper.__iter__": {
        "API_name": "tempfile._TemporaryFileWrapper.__iter__",
        "loc_name": "tempfile._TemporaryFileWrapper.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 507,
        "namespace": "_TemporaryFileWrapper",
        "body": "    def __iter__(self):\n        # Don't return iter(self.file), but yield from it to avoid closing\n        # file as long as it's being used as iterator (see issue #23700).  We\n        # can't use 'yield from' here because iter(file) returns the file\n        # object itself, which has a close method, and thus the file would get\n        # closed when the generator is finalized, due to PEP380 semantics.\n        for line in self.file:\n            yield line",
        "name_type": "stdlib"
    },
    "tempfile.NamedTemporaryFile": {
        "API_name": "tempfile.NamedTemporaryFile",
        "loc_name": "tempfile.NamedTemporaryFile",
        "args": "mode;buffering;encoding;newline;suffix;prefix;dir;delete",
        "args_default": 8,
        "filepath": "tempfile",
        "lineno": 517,
        "namespace": "*",
        "body": "def NamedTemporaryFile(mode='w+b', buffering=-1, encoding=None,\n                       newline=None, suffix=None, prefix=None,\n                       dir=None, delete=True, *, errors=None):\n    \"\"\"Create and return a temporary file.\n    Arguments:\n    'prefix', 'suffix', 'dir' -- as for mkstemp.\n    'mode' -- the mode argument to io.open (default \"w+b\").\n    'buffering' -- the buffer size argument to io.open (default -1).\n    'encoding' -- the encoding argument to io.open (default None)\n    'newline' -- the newline argument to io.open (default None)\n    'delete' -- whether the file is deleted on close (default True).\n    'errors' -- the errors argument to io.open (default None)\n    The file is created as mkstemp() would do it.\n\n    Returns an object with a file-like interface; the name of the file\n    is accessible as its 'name' attribute.  The file will be automatically\n    deleted when it is closed unless the 'delete' argument is set to False.\n    \"\"\"\n\n    prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n\n    flags = _bin_openflags\n\n    # Setting O_TEMPORARY in the flags causes the OS to delete\n    # the file when it is closed.  This is only supported by Windows.\n    if _os.name == 'nt' and delete:\n        flags |= _os.O_TEMPORARY\n\n    (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n    try:\n        file = _io.open(fd, mode, buffering=buffering,\n                        newline=newline, encoding=encoding, errors=errors)\n\n        return _TemporaryFileWrapper(file, name, delete)\n    except BaseException:\n        _os.unlink(name)\n        _os.close(fd)\n        raise",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryFile": {
        "API_name": "tempfile.TemporaryFile",
        "loc_name": "tempfile.TemporaryFile",
        "args": "mode;buffering;encoding;newline;suffix;prefix;dir",
        "args_default": 7,
        "filepath": "tempfile",
        "lineno": 567,
        "namespace": "*",
        "body": "    def TemporaryFile(mode='w+b', buffering=-1, encoding=None,\n                      newline=None, suffix=None, prefix=None,\n                      dir=None, *, errors=None):\n        \"\"\"Create and return a temporary file.\n        Arguments:\n        'prefix', 'suffix', 'dir' -- as for mkstemp.\n        'mode' -- the mode argument to io.open (default \"w+b\").\n        'buffering' -- the buffer size argument to io.open (default -1).\n        'encoding' -- the encoding argument to io.open (default None)\n        'newline' -- the newline argument to io.open (default None)\n        'errors' -- the errors argument to io.open (default None)\n        The file is created as mkstemp() would do it.\n\n        Returns an object with a file-like interface.  The file has no\n        name, and will cease to exist when it is closed.\n        \"\"\"\n        global _O_TMPFILE_WORKS\n\n        prefix, suffix, dir, output_type = _sanitize_params(prefix, suffix, dir)\n\n        flags = _bin_openflags\n        if _O_TMPFILE_WORKS:\n            try:\n                flags2 = (flags | _os.O_TMPFILE) & ~_os.O_CREAT\n                fd = _os.open(dir, flags2, 0o600)\n            except IsADirectoryError:\n                # Linux kernel older than 3.11 ignores the O_TMPFILE flag:\n                # O_TMPFILE is read as O_DIRECTORY. Trying to open a directory\n                # with O_RDWR|O_DIRECTORY fails with IsADirectoryError, a\n                # directory cannot be open to write. Set flag to False to not\n                # try again.\n                _O_TMPFILE_WORKS = False\n            except OSError:\n                # The filesystem of the directory does not support O_TMPFILE.\n                # For example, OSError(95, 'Operation not supported').\n                #\n                # On Linux kernel older than 3.11, trying to open a regular\n                # file (or a symbolic link to a regular file) with O_TMPFILE\n                # fails with NotADirectoryError, because O_TMPFILE is read as\n                # O_DIRECTORY.\n                pass\n            else:\n                try:\n                    return _io.open(fd, mode, buffering=buffering,\n                                    newline=newline, encoding=encoding,\n                                    errors=errors)\n                except:\n                    _os.close(fd)\n                    raise\n            # Fallback to _mkstemp_inner().\n\n        (fd, name) = _mkstemp_inner(dir, prefix, suffix, flags, output_type)\n        try:\n            _os.unlink(name)\n            return _io.open(fd, mode, buffering=buffering,\n                            newline=newline, encoding=encoding, errors=errors)\n        except:\n            _os.close(fd)\n            raise",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile": {
        "API_name": "tempfile.SpooledTemporaryFile",
        "loc_name": "tempfile.SpooledTemporaryFile",
        "args": "*",
        "args_default": "*",
        "filepath": "tempfile",
        "lineno": 627,
        "namespace": "SpooledTemporaryFile",
        "body": "",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.__init__": {
        "API_name": "tempfile.SpooledTemporaryFile.__init__",
        "loc_name": "tempfile.SpooledTemporaryFile.__init__",
        "args": "self;max_size;mode;buffering;encoding;newline;suffix;prefix;dir",
        "args_default": 8,
        "filepath": "tempfile",
        "lineno": 634,
        "namespace": "SpooledTemporaryFile",
        "body": "    def __init__(self, max_size=0, mode='w+b', buffering=-1,\n                 encoding=None, newline=None,\n                 suffix=None, prefix=None, dir=None, *, errors=None):\n        if 'b' in mode:\n            self._file = _io.BytesIO()\n        else:\n            self._file = _io.TextIOWrapper(_io.BytesIO(),\n                            encoding=encoding, errors=errors,\n                            newline=newline)\n        self._max_size = max_size\n        self._rolled = False\n        self._TemporaryFileArgs = {'mode': mode, 'buffering': buffering,\n                                   'suffix': suffix, 'prefix': prefix,\n                                   'encoding': encoding, 'newline': newline,\n                                   'dir': dir, 'errors': errors}",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile._check": {
        "API_name": "tempfile.SpooledTemporaryFile._check",
        "loc_name": "tempfile.SpooledTemporaryFile._check",
        "args": "self;file",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 652,
        "namespace": "SpooledTemporaryFile",
        "body": "    def _check(self, file):\n        if self._rolled: return\n        max_size = self._max_size\n        if max_size and file.tell() > max_size:\n            self.rollover()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.rollover": {
        "API_name": "tempfile.SpooledTemporaryFile.rollover",
        "loc_name": "tempfile.SpooledTemporaryFile.rollover",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 658,
        "namespace": "SpooledTemporaryFile",
        "body": "    def rollover(self):\n        if self._rolled: return\n        file = self._file\n        newfile = self._file = TemporaryFile(**self._TemporaryFileArgs)\n        del self._TemporaryFileArgs\n\n        pos = file.tell()\n        if hasattr(newfile, 'buffer'):\n            newfile.buffer.write(file.detach().getvalue())\n        else:\n            newfile.write(file.getvalue())\n        newfile.seek(pos, 0)\n\n        self._rolled = True",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.__enter__": {
        "API_name": "tempfile.SpooledTemporaryFile.__enter__",
        "loc_name": "tempfile.SpooledTemporaryFile.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 679,
        "namespace": "SpooledTemporaryFile",
        "body": "    def __enter__(self):\n        if self._file.closed:\n            raise ValueError(\"Cannot enter context with closed file\")\n        return self",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.__exit__": {
        "API_name": "tempfile.SpooledTemporaryFile.__exit__",
        "loc_name": "tempfile.SpooledTemporaryFile.__exit__",
        "args": "self;exc;value;tb",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 684,
        "namespace": "SpooledTemporaryFile",
        "body": "    def __exit__(self, exc, value, tb):\n        self._file.close()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.__iter__": {
        "API_name": "tempfile.SpooledTemporaryFile.__iter__",
        "loc_name": "tempfile.SpooledTemporaryFile.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 688,
        "namespace": "SpooledTemporaryFile",
        "body": "    def __iter__(self):\n        return self._file.__iter__()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.close": {
        "API_name": "tempfile.SpooledTemporaryFile.close",
        "loc_name": "tempfile.SpooledTemporaryFile.close",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 691,
        "namespace": "SpooledTemporaryFile",
        "body": "    def close(self):\n        self._file.close()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.closed": {
        "API_name": "tempfile.SpooledTemporaryFile.closed",
        "loc_name": "tempfile.SpooledTemporaryFile.closed",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 695,
        "namespace": "SpooledTemporaryFile",
        "body": "    def closed(self):\n        return self._file.closed",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.encoding": {
        "API_name": "tempfile.SpooledTemporaryFile.encoding",
        "loc_name": "tempfile.SpooledTemporaryFile.encoding",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 699,
        "namespace": "SpooledTemporaryFile",
        "body": "    def encoding(self):\n        return self._file.encoding",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.errors": {
        "API_name": "tempfile.SpooledTemporaryFile.errors",
        "loc_name": "tempfile.SpooledTemporaryFile.errors",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 703,
        "namespace": "SpooledTemporaryFile",
        "body": "    def errors(self):\n        return self._file.errors",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.fileno": {
        "API_name": "tempfile.SpooledTemporaryFile.fileno",
        "loc_name": "tempfile.SpooledTemporaryFile.fileno",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 706,
        "namespace": "SpooledTemporaryFile",
        "body": "    def fileno(self):\n        self.rollover()\n        return self._file.fileno()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.flush": {
        "API_name": "tempfile.SpooledTemporaryFile.flush",
        "loc_name": "tempfile.SpooledTemporaryFile.flush",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 710,
        "namespace": "SpooledTemporaryFile",
        "body": "    def flush(self):\n        self._file.flush()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.isatty": {
        "API_name": "tempfile.SpooledTemporaryFile.isatty",
        "loc_name": "tempfile.SpooledTemporaryFile.isatty",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 713,
        "namespace": "SpooledTemporaryFile",
        "body": "    def isatty(self):\n        return self._file.isatty()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.mode": {
        "API_name": "tempfile.SpooledTemporaryFile.mode",
        "loc_name": "tempfile.SpooledTemporaryFile.mode",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 717,
        "namespace": "SpooledTemporaryFile",
        "body": "    def mode(self):\n        try:\n            return self._file.mode\n        except AttributeError:\n            return self._TemporaryFileArgs['mode']",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.name": {
        "API_name": "tempfile.SpooledTemporaryFile.name",
        "loc_name": "tempfile.SpooledTemporaryFile.name",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 724,
        "namespace": "SpooledTemporaryFile",
        "body": "    def name(self):\n        try:\n            return self._file.name\n        except AttributeError:\n            return None",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.newlines": {
        "API_name": "tempfile.SpooledTemporaryFile.newlines",
        "loc_name": "tempfile.SpooledTemporaryFile.newlines",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 731,
        "namespace": "SpooledTemporaryFile",
        "body": "    def newlines(self):\n        return self._file.newlines",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.read": {
        "API_name": "tempfile.SpooledTemporaryFile.read",
        "loc_name": "tempfile.SpooledTemporaryFile.read",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 734,
        "namespace": "SpooledTemporaryFile",
        "body": "    def read(self, *args):\n        return self._file.read(*args)",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.readline": {
        "API_name": "tempfile.SpooledTemporaryFile.readline",
        "loc_name": "tempfile.SpooledTemporaryFile.readline",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 737,
        "namespace": "SpooledTemporaryFile",
        "body": "    def readline(self, *args):\n        return self._file.readline(*args)",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.readlines": {
        "API_name": "tempfile.SpooledTemporaryFile.readlines",
        "loc_name": "tempfile.SpooledTemporaryFile.readlines",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 740,
        "namespace": "SpooledTemporaryFile",
        "body": "    def readlines(self, *args):\n        return self._file.readlines(*args)",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.seek": {
        "API_name": "tempfile.SpooledTemporaryFile.seek",
        "loc_name": "tempfile.SpooledTemporaryFile.seek",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 743,
        "namespace": "SpooledTemporaryFile",
        "body": "    def seek(self, *args):\n        return self._file.seek(*args)",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.tell": {
        "API_name": "tempfile.SpooledTemporaryFile.tell",
        "loc_name": "tempfile.SpooledTemporaryFile.tell",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 746,
        "namespace": "SpooledTemporaryFile",
        "body": "    def tell(self):\n        return self._file.tell()",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.truncate": {
        "API_name": "tempfile.SpooledTemporaryFile.truncate",
        "loc_name": "tempfile.SpooledTemporaryFile.truncate",
        "args": "self;size",
        "args_default": 1,
        "filepath": "tempfile",
        "lineno": 749,
        "namespace": "SpooledTemporaryFile",
        "body": "    def truncate(self, size=None):\n        if size is None:\n            self._file.truncate()\n        else:\n            if size > self._max_size:\n                self.rollover()\n            self._file.truncate(size)",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.write": {
        "API_name": "tempfile.SpooledTemporaryFile.write",
        "loc_name": "tempfile.SpooledTemporaryFile.write",
        "args": "self;s",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 757,
        "namespace": "SpooledTemporaryFile",
        "body": "    def write(self, s):\n        file = self._file\n        rv = file.write(s)\n        self._check(file)\n        return rv",
        "name_type": "stdlib"
    },
    "tempfile.SpooledTemporaryFile.writelines": {
        "API_name": "tempfile.SpooledTemporaryFile.writelines",
        "loc_name": "tempfile.SpooledTemporaryFile.writelines",
        "args": "self;iterable",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 763,
        "namespace": "SpooledTemporaryFile",
        "body": "    def writelines(self, iterable):\n        file = self._file\n        rv = file.writelines(iterable)\n        self._check(file)\n        return rv",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory": {
        "API_name": "tempfile.TemporaryDirectory",
        "loc_name": "tempfile.TemporaryDirectory",
        "args": "*",
        "args_default": "*",
        "filepath": "tempfile",
        "lineno": 770,
        "namespace": "TemporaryDirectory",
        "body": "",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory.__init__": {
        "API_name": "tempfile.TemporaryDirectory.__init__",
        "loc_name": "tempfile.TemporaryDirectory.__init__",
        "args": "self;suffix;prefix;dir",
        "args_default": 3,
        "filepath": "tempfile",
        "lineno": 782,
        "namespace": "TemporaryDirectory",
        "body": "    def __init__(self, suffix=None, prefix=None, dir=None):\n        self.name = mkdtemp(suffix, prefix, dir)\n        self._finalizer = _weakref.finalize(\n            self, self._cleanup, self.name,\n            warn_message=\"Implicitly cleaning up {!r}\".format(self))",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory._rmtree": {
        "API_name": "tempfile.TemporaryDirectory._rmtree",
        "loc_name": "tempfile.TemporaryDirectory._rmtree",
        "args": "cls;name",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 789,
        "namespace": "TemporaryDirectory",
        "body": "    def _rmtree(cls, name):\n        def onerror(func, path, exc_info):\n            if issubclass(exc_info[0], PermissionError):\n                def resetperms(path):\n                    try:\n                        _os.chflags(path, 0)\n                    except AttributeError:\n                        pass\n                    _os.chmod(path, 0o700)\n\n                try:\n                    if path != name:\n                        resetperms(_os.path.dirname(path))\n                    resetperms(path)\n\n                    try:\n                        _os.unlink(path)\n                    # PermissionError is raised on FreeBSD for directories\n                    except (IsADirectoryError, PermissionError):\n                        cls._rmtree(path)\n                except FileNotFoundError:\n                    pass\n            elif issubclass(exc_info[0], FileNotFoundError):\n                pass\n            else:\n                raise\n\n        _shutil.rmtree(name, onerror=onerror)",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory._rmtree.onerror": {
        "API_name": "tempfile.TemporaryDirectory._rmtree.onerror",
        "loc_name": "tempfile.TemporaryDirectory._rmtree.onerror",
        "args": "func;path;exc_info",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 790,
        "namespace": "TemporaryDirectory",
        "body": "        def onerror(func, path, exc_info):\n            if issubclass(exc_info[0], PermissionError):\n                def resetperms(path):\n                    try:\n                        _os.chflags(path, 0)\n                    except AttributeError:\n                        pass\n                    _os.chmod(path, 0o700)\n\n                try:\n                    if path != name:\n                        resetperms(_os.path.dirname(path))\n                    resetperms(path)\n\n                    try:\n                        _os.unlink(path)\n                    # PermissionError is raised on FreeBSD for directories\n                    except (IsADirectoryError, PermissionError):\n                        cls._rmtree(path)\n                except FileNotFoundError:\n                    pass\n            elif issubclass(exc_info[0], FileNotFoundError):\n                pass\n            else:\n                raise",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory._cleanup": {
        "API_name": "tempfile.TemporaryDirectory._cleanup",
        "loc_name": "tempfile.TemporaryDirectory._cleanup",
        "args": "cls;name;warn_message",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 819,
        "namespace": "TemporaryDirectory",
        "body": "    def _cleanup(cls, name, warn_message):\n        cls._rmtree(name)\n        _warnings.warn(warn_message, ResourceWarning)",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory.__repr__": {
        "API_name": "tempfile.TemporaryDirectory.__repr__",
        "loc_name": "tempfile.TemporaryDirectory.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 823,
        "namespace": "TemporaryDirectory",
        "body": "    def __repr__(self):\n        return \"<{} {!r}>\".format(self.__class__.__name__, self.name)",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory.__enter__": {
        "API_name": "tempfile.TemporaryDirectory.__enter__",
        "loc_name": "tempfile.TemporaryDirectory.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 826,
        "namespace": "TemporaryDirectory",
        "body": "    def __enter__(self):\n        return self.name",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory.__exit__": {
        "API_name": "tempfile.TemporaryDirectory.__exit__",
        "loc_name": "tempfile.TemporaryDirectory.__exit__",
        "args": "self;exc;value;tb",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 829,
        "namespace": "TemporaryDirectory",
        "body": "    def __exit__(self, exc, value, tb):\n        self.cleanup()",
        "name_type": "stdlib"
    },
    "tempfile.TemporaryDirectory.cleanup": {
        "API_name": "tempfile.TemporaryDirectory.cleanup",
        "loc_name": "tempfile.TemporaryDirectory.cleanup",
        "args": "self",
        "args_default": 0,
        "filepath": "tempfile",
        "lineno": 832,
        "namespace": "TemporaryDirectory",
        "body": "    def cleanup(self):\n        if self._finalizer.detach():\n            self._rmtree(self.name)",
        "name_type": "stdlib"
    },
    "threading": {
        "API_name": "threading",
        "loc_name": "threading",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Thread module emulating a subset of Java's threading model.\"\"\"\ntry:\n    from _collections import deque as _deque\nexcept ImportError:\n    from collections import deque as _deque\n__all__ = ['get_ident', 'active_count', 'Condition', 'current_thread',\n           'enumerate', 'main_thread', 'TIMEOUT_MAX',\n           'Event', 'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Thread',\n           'Barrier', 'BrokenBarrierError', 'Timer', 'ThreadError',\n           'setprofile', 'settrace', 'local', 'stack_size',\n           'excepthook', 'ExceptHookArgs']\n_start_new_thread = _thread.start_new_thread\n_allocate_lock = _thread.allocate_lock\n_set_sentinel = _thread._set_sentinel\nget_ident = _thread.get_ident\ntry:\n    get_native_id = _thread.get_native_id\n    _HAVE_THREAD_NATIVE_ID = True\n    __all__.append('get_native_id')\nexcept AttributeError:\n    _HAVE_THREAD_NATIVE_ID = False\nThreadError = _thread.error\ntry:\n    _CRLock = _thread.RLock\nexcept AttributeError:\n    _CRLock = None\nTIMEOUT_MAX = _thread.TIMEOUT_MAX\ndel _thread\n_profile_hook = None\n_trace_hook = None\nLock = _allocate_lock\n_PyRLock = _RLock\n_counter = _count().__next__\n_counter() # Consume 0 so first non-main thread has id 1.\n_active_limbo_lock = RLock()\n_active = {}    # maps thread id to Thread object\n_limbo = {}\n_dangling = WeakSet()\n_shutdown_locks_lock = _allocate_lock()\n_shutdown_locks = set()\ntry:\n    from _thread import (_excepthook as excepthook,\n                         _ExceptHookArgs as ExceptHookArgs)\nexcept ImportError:\n    # Simple Python implementation if _thread._excepthook() is not available\n    from traceback import print_exception as _print_exception\n    from collections import namedtuple\n\n    _ExceptHookArgs = namedtuple(\n        'ExceptHookArgs',\n        'exc_type exc_value exc_traceback thread')\n\n    def ExceptHookArgs(args):\n        return _ExceptHookArgs(*args)\n\n    def excepthook(args, /):\n        \"\"\"\n        Handle uncaught Thread.run() exception.\n        \"\"\"\n        if args.exc_type == SystemExit:\n            # silently ignore SystemExit\n            return\n\n        if _sys is not None and _sys.stderr is not None:\n            stderr = _sys.stderr\n        elif args.thread is not None:\n            stderr = args.thread._stderr\n            if stderr is None:\n                # do nothing if sys.stderr is None and sys.stderr was None\n                # when the thread was created\n                return\n        else:\n            # do nothing if sys.stderr is None and args.thread is None\n            return\n\n        if args.thread is not None:\n            name = args.thread.name\n        else:\n            name = get_ident()\n        print(f\"Exception in thread {name}:\",\n              file=stderr, flush=True)\n        _print_exception(args.exc_type, args.exc_value, args.exc_traceback,\n                         file=stderr)\n        stderr.flush()\ncurrentThread = current_thread\nactiveCount = active_count\n_threading_atexits = []\n_SHUTTING_DOWN = False\n_main_thread = _MainThread()\ntry:\n    from _thread import _local as local\nexcept ImportError:\n    from _threading_local import local\nif hasattr(_os, \"register_at_fork\"):\n    _os.register_at_fork(after_in_child=_after_fork)",
        "name_type": "stdlib"
    },
    "threading.setprofile": {
        "API_name": "threading.setprofile",
        "loc_name": "threading.setprofile",
        "args": "func",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 58,
        "namespace": "*",
        "body": "def setprofile(func):\n    \"\"\"Set a profile function for all threads started from the threading module.\n\n    The func will be passed to sys.setprofile() for each thread, before its\n    run() method is called.\n\n    \"\"\"\n    global _profile_hook\n    _profile_hook = func",
        "name_type": "stdlib"
    },
    "threading.settrace": {
        "API_name": "threading.settrace",
        "loc_name": "threading.settrace",
        "args": "func",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 68,
        "namespace": "*",
        "body": "def settrace(func):\n    \"\"\"Set a trace function for all threads started from the threading module.\n\n    The func will be passed to sys.settrace() for each thread, before its run()\n    method is called.\n\n    \"\"\"\n    global _trace_hook\n    _trace_hook = func",
        "name_type": "stdlib"
    },
    "threading.RLock": {
        "API_name": "threading.RLock",
        "loc_name": "threading.RLock",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 82,
        "namespace": "*",
        "body": "def RLock(*args, **kwargs):\n    \"\"\"Factory function that returns a new reentrant lock.\n\n    A reentrant lock must be released by the thread that acquired it. Once a\n    thread has acquired a reentrant lock, the same thread may acquire it again\n    without blocking; the thread must release it once for each time it has\n    acquired it.\n\n    \"\"\"\n    if _CRLock is None:\n        return _PyRLock(*args, **kwargs)\n    return _CRLock(*args, **kwargs)",
        "name_type": "stdlib"
    },
    "threading._RLock": {
        "API_name": "threading._RLock",
        "loc_name": "threading._RLock",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 95,
        "namespace": "_RLock",
        "body": "",
        "name_type": "stdlib"
    },
    "threading._RLock.__init__": {
        "API_name": "threading._RLock.__init__",
        "loc_name": "threading._RLock.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 105,
        "namespace": "_RLock",
        "body": "    def __init__(self):\n        self._block = _allocate_lock()\n        self._owner = None\n        self._count = 0",
        "name_type": "stdlib"
    },
    "threading._RLock.__repr__": {
        "API_name": "threading._RLock.__repr__",
        "loc_name": "threading._RLock.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 110,
        "namespace": "_RLock",
        "body": "    def __repr__(self):\n        owner = self._owner\n        try:\n            owner = _active[owner].name\n        except KeyError:\n            pass\n        return \"<%s %s.%s object owner=%r count=%d at %s>\" % (\n            \"locked\" if self._block.locked() else \"unlocked\",\n            self.__class__.__module__,\n            self.__class__.__qualname__,\n            owner,\n            self._count,\n            hex(id(self))\n        )",
        "name_type": "stdlib"
    },
    "threading._RLock._at_fork_reinit": {
        "API_name": "threading._RLock._at_fork_reinit",
        "loc_name": "threading._RLock._at_fork_reinit",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 125,
        "namespace": "_RLock",
        "body": "    def _at_fork_reinit(self):\n        self._block._at_fork_reinit()\n        self._owner = None\n        self._count = 0",
        "name_type": "stdlib"
    },
    "threading._RLock.acquire": {
        "API_name": "threading._RLock.acquire",
        "loc_name": "threading._RLock.acquire",
        "args": "self;blocking;timeout",
        "args_default": 2,
        "filepath": "threading",
        "lineno": 130,
        "namespace": "_RLock",
        "body": "    def acquire(self, blocking=True, timeout=-1):\n        \"\"\"Acquire a lock, blocking or non-blocking.\n\n        When invoked without arguments: if this thread already owns the lock,\n        increment the recursion level by one, and return immediately. Otherwise,\n        if another thread owns the lock, block until the lock is unlocked. Once\n        the lock is unlocked (not owned by any thread), then grab ownership, set\n        the recursion level to one, and return. If more than one thread is\n        blocked waiting until the lock is unlocked, only one at a time will be\n        able to grab ownership of the lock. There is no return value in this\n        case.\n\n        When invoked with the blocking argument set to true, do the same thing\n        as when called without arguments, and return true.\n\n        When invoked with the blocking argument set to false, do not block. If a\n        call without an argument would block, return false immediately;\n        otherwise, do the same thing as when called without arguments, and\n        return true.\n\n        When invoked with the floating-point timeout argument set to a positive\n        value, block for at most the number of seconds specified by timeout\n        and as long as the lock cannot be acquired.  Return true if the lock has\n        been acquired, false if the timeout has elapsed.\n\n        \"\"\"\n        me = get_ident()\n        if self._owner == me:\n            self._count += 1\n            return 1\n        rc = self._block.acquire(blocking, timeout)\n        if rc:\n            self._owner = me\n            self._count = 1\n        return rc",
        "name_type": "stdlib"
    },
    "threading._RLock.release": {
        "API_name": "threading._RLock.release",
        "loc_name": "threading._RLock.release",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 168,
        "namespace": "_RLock",
        "body": "    def release(self):\n        \"\"\"Release a lock, decrementing the recursion level.\n\n        If after the decrement it is zero, reset the lock to unlocked (not owned\n        by any thread), and if any other threads are blocked waiting for the\n        lock to become unlocked, allow exactly one of them to proceed. If after\n        the decrement the recursion level is still nonzero, the lock remains\n        locked and owned by the calling thread.\n\n        Only call this method when the calling thread owns the lock. A\n        RuntimeError is raised if this method is called when the lock is\n        unlocked.\n\n        There is no return value.\n\n        \"\"\"\n        if self._owner != get_ident():\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        self._count = count = self._count - 1\n        if not count:\n            self._owner = None\n            self._block.release()",
        "name_type": "stdlib"
    },
    "threading._RLock.__exit__": {
        "API_name": "threading._RLock.__exit__",
        "loc_name": "threading._RLock.__exit__",
        "args": "self;t;v;tb",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 191,
        "namespace": "_RLock",
        "body": "    def __exit__(self, t, v, tb):\n        self.release()",
        "name_type": "stdlib"
    },
    "threading._RLock._acquire_restore": {
        "API_name": "threading._RLock._acquire_restore",
        "loc_name": "threading._RLock._acquire_restore",
        "args": "self;state",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 196,
        "namespace": "_RLock",
        "body": "    def _acquire_restore(self, state):\n        self._block.acquire()\n        self._count, self._owner = state",
        "name_type": "stdlib"
    },
    "threading._RLock._release_save": {
        "API_name": "threading._RLock._release_save",
        "loc_name": "threading._RLock._release_save",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 200,
        "namespace": "_RLock",
        "body": "    def _release_save(self):\n        if self._count == 0:\n            raise RuntimeError(\"cannot release un-acquired lock\")\n        count = self._count\n        self._count = 0\n        owner = self._owner\n        self._owner = None\n        self._block.release()\n        return (count, owner)",
        "name_type": "stdlib"
    },
    "threading._RLock._is_owned": {
        "API_name": "threading._RLock._is_owned",
        "loc_name": "threading._RLock._is_owned",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 210,
        "namespace": "_RLock",
        "body": "    def _is_owned(self):\n        return self._owner == get_ident()",
        "name_type": "stdlib"
    },
    "threading.Condition": {
        "API_name": "threading.Condition",
        "loc_name": "threading.Condition",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 216,
        "namespace": "Condition",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.Condition.__init__": {
        "API_name": "threading.Condition.__init__",
        "loc_name": "threading.Condition.__init__",
        "args": "self;lock",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 228,
        "namespace": "Condition",
        "body": "    def __init__(self, lock=None):\n        if lock is None:\n            lock = RLock()\n        self._lock = lock\n        # Export the lock's acquire() and release() methods\n        self.acquire = lock.acquire\n        self.release = lock.release\n        # If the lock defines _release_save() and/or _acquire_restore(),\n        # these override the default implementations (which just call\n        # release() and acquire() on the lock).  Ditto for _is_owned().\n        try:\n            self._release_save = lock._release_save\n        except AttributeError:\n            pass\n        try:\n            self._acquire_restore = lock._acquire_restore\n        except AttributeError:\n            pass\n        try:\n            self._is_owned = lock._is_owned\n        except AttributeError:\n            pass\n        self._waiters = _deque()",
        "name_type": "stdlib"
    },
    "threading.Condition._at_fork_reinit": {
        "API_name": "threading.Condition._at_fork_reinit",
        "loc_name": "threading.Condition._at_fork_reinit",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 252,
        "namespace": "Condition",
        "body": "    def _at_fork_reinit(self):\n        self._lock._at_fork_reinit()\n        self._waiters.clear()",
        "name_type": "stdlib"
    },
    "threading.Condition.__enter__": {
        "API_name": "threading.Condition.__enter__",
        "loc_name": "threading.Condition.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 256,
        "namespace": "Condition",
        "body": "    def __enter__(self):\n        return self._lock.__enter__()",
        "name_type": "stdlib"
    },
    "threading.Condition.__exit__": {
        "API_name": "threading.Condition.__exit__",
        "loc_name": "threading.Condition.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 259,
        "namespace": "Condition",
        "body": "    def __exit__(self, *args):\n        return self._lock.__exit__(*args)",
        "name_type": "stdlib"
    },
    "threading.Condition.__repr__": {
        "API_name": "threading.Condition.__repr__",
        "loc_name": "threading.Condition.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 262,
        "namespace": "Condition",
        "body": "    def __repr__(self):\n        return \"<Condition(%s, %d)>\" % (self._lock, len(self._waiters))",
        "name_type": "stdlib"
    },
    "threading.Condition._release_save": {
        "API_name": "threading.Condition._release_save",
        "loc_name": "threading.Condition._release_save",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 265,
        "namespace": "Condition",
        "body": "    def _release_save(self):\n        self._lock.release()           # No state to save",
        "name_type": "stdlib"
    },
    "threading.Condition._acquire_restore": {
        "API_name": "threading.Condition._acquire_restore",
        "loc_name": "threading.Condition._acquire_restore",
        "args": "self;x",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 268,
        "namespace": "Condition",
        "body": "    def _acquire_restore(self, x):\n        self._lock.acquire()           # Ignore saved state",
        "name_type": "stdlib"
    },
    "threading.Condition._is_owned": {
        "API_name": "threading.Condition._is_owned",
        "loc_name": "threading.Condition._is_owned",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 271,
        "namespace": "Condition",
        "body": "    def _is_owned(self):\n        # Return True if lock is owned by current_thread.\n        # This method is called only if _lock doesn't have _is_owned().\n        if self._lock.acquire(False):\n            self._lock.release()\n            return False\n        else:\n            return True",
        "name_type": "stdlib"
    },
    "threading.Condition.wait": {
        "API_name": "threading.Condition.wait",
        "loc_name": "threading.Condition.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 280,
        "namespace": "Condition",
        "body": "    def wait(self, timeout=None):\n        \"\"\"Wait until notified or until a timeout occurs.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method releases the underlying lock, and then blocks until it is\n        awakened by a notify() or notify_all() call for the same condition\n        variable in another thread, or until the optional timeout occurs. Once\n        awakened or timed out, it re-acquires the lock and returns.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        When the underlying lock is an RLock, it is not released using its\n        release() method, since this may not actually unlock the lock when it\n        was acquired multiple times recursively. Instead, an internal interface\n        of the RLock class is used, which really unlocks it even when it has\n        been recursively acquired several times. Another internal interface is\n        then used to restore the recursion level when the lock is reacquired.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot wait on un-acquired lock\")\n        waiter = _allocate_lock()\n        waiter.acquire()\n        self._waiters.append(waiter)\n        saved_state = self._release_save()\n        gotit = False\n        try:    # restore state no matter what (e.g., KeyboardInterrupt)\n            if timeout is None:\n                waiter.acquire()\n                gotit = True\n            else:\n                if timeout > 0:\n                    gotit = waiter.acquire(True, timeout)\n                else:\n                    gotit = waiter.acquire(False)\n            return gotit\n        finally:\n            self._acquire_restore(saved_state)\n            if not gotit:\n                try:\n                    self._waiters.remove(waiter)\n                except ValueError:\n                    pass",
        "name_type": "stdlib"
    },
    "threading.Condition.wait_for": {
        "API_name": "threading.Condition.wait_for",
        "loc_name": "threading.Condition.wait_for",
        "args": "self;predicate;timeout",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 328,
        "namespace": "Condition",
        "body": "    def wait_for(self, predicate, timeout=None):\n        \"\"\"Wait until a condition evaluates to True.\n\n        predicate should be a callable which result will be interpreted as a\n        boolean value.  A timeout may be provided giving the maximum time to\n        wait.\n\n        \"\"\"\n        endtime = None\n        waittime = timeout\n        result = predicate()\n        while not result:\n            if waittime is not None:\n                if endtime is None:\n                    endtime = _time() + waittime\n                else:\n                    waittime = endtime - _time()\n                    if waittime <= 0:\n                        break\n            self.wait(waittime)\n            result = predicate()\n        return result",
        "name_type": "stdlib"
    },
    "threading.Condition.notify": {
        "API_name": "threading.Condition.notify",
        "loc_name": "threading.Condition.notify",
        "args": "self;n",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 351,
        "namespace": "Condition",
        "body": "    def notify(self, n=1):\n        \"\"\"Wake up one or more threads waiting on this condition, if any.\n\n        If the calling thread has not acquired the lock when this method is\n        called, a RuntimeError is raised.\n\n        This method wakes up at most n of the threads waiting for the condition\n        variable; it is a no-op if no threads are waiting.\n\n        \"\"\"\n        if not self._is_owned():\n            raise RuntimeError(\"cannot notify on un-acquired lock\")\n        waiters = self._waiters\n        while waiters and n > 0:\n            waiter = waiters[0]\n            try:\n                waiter.release()\n            except RuntimeError:\n                # gh-92530: The previous call of notify() released the lock,\n                # but was interrupted before removing it from the queue.\n                # It can happen if a signal handler raises an exception,\n                # like CTRL+C which raises KeyboardInterrupt.\n                pass\n            else:\n                n -= 1\n            try:\n                waiters.remove(waiter)\n            except ValueError:\n                pass",
        "name_type": "stdlib"
    },
    "threading.Condition.notify_all": {
        "API_name": "threading.Condition.notify_all",
        "loc_name": "threading.Condition.notify_all",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 381,
        "namespace": "Condition",
        "body": "    def notify_all(self):\n        \"\"\"Wake up all threads waiting on this condition.\n\n        If the calling thread has not acquired the lock when this method\n        is called, a RuntimeError is raised.\n\n        \"\"\"\n        self.notify(len(self._waiters))",
        "name_type": "stdlib"
    },
    "threading.Semaphore": {
        "API_name": "threading.Semaphore",
        "loc_name": "threading.Semaphore",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 393,
        "namespace": "Semaphore",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.Semaphore.__init__": {
        "API_name": "threading.Semaphore.__init__",
        "loc_name": "threading.Semaphore.__init__",
        "args": "self;value",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 405,
        "namespace": "Semaphore",
        "body": "    def __init__(self, value=1):\n        if value < 0:\n            raise ValueError(\"semaphore initial value must be >= 0\")\n        self._cond = Condition(Lock())\n        self._value = value",
        "name_type": "stdlib"
    },
    "threading.Semaphore.acquire": {
        "API_name": "threading.Semaphore.acquire",
        "loc_name": "threading.Semaphore.acquire",
        "args": "self;blocking;timeout",
        "args_default": 2,
        "filepath": "threading",
        "lineno": 411,
        "namespace": "Semaphore",
        "body": "    def acquire(self, blocking=True, timeout=None):\n        \"\"\"Acquire a semaphore, decrementing the internal counter by one.\n\n        When invoked without arguments: if the internal counter is larger than\n        zero on entry, decrement it by one and return immediately. If it is zero\n        on entry, block, waiting until some other thread has called release() to\n        make it larger than zero. This is done with proper interlocking so that\n        if multiple acquire() calls are blocked, release() will wake exactly one\n        of them up. The implementation may pick one at random, so the order in\n        which blocked threads are awakened should not be relied on. There is no\n        return value in this case.\n\n        When invoked with blocking set to true, do the same thing as when called\n        without arguments, and return true.\n\n        When invoked with blocking set to false, do not block. If a call without\n        an argument would block, return false immediately; otherwise, do the\n        same thing as when called without arguments, and return true.\n\n        When invoked with a timeout other than None, it will block for at\n        most timeout seconds.  If acquire does not complete successfully in\n        that interval, return false.  Return true otherwise.\n\n        \"\"\"\n        if not blocking and timeout is not None:\n            raise ValueError(\"can't specify timeout for non-blocking acquire\")\n        rc = False\n        endtime = None\n        with self._cond:\n            while self._value == 0:\n                if not blocking:\n                    break\n                if timeout is not None:\n                    if endtime is None:\n                        endtime = _time() + timeout\n                    else:\n                        timeout = endtime - _time()\n                        if timeout <= 0:\n                            break\n                self._cond.wait(timeout)\n            else:\n                self._value -= 1\n                rc = True\n        return rc",
        "name_type": "stdlib"
    },
    "threading.Semaphore.release": {
        "API_name": "threading.Semaphore.release",
        "loc_name": "threading.Semaphore.release",
        "args": "self;n",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 458,
        "namespace": "Semaphore",
        "body": "    def release(self, n=1):\n        \"\"\"Release a semaphore, incrementing the internal counter by one or more.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        \"\"\"\n        if n < 1:\n            raise ValueError('n must be one or more')\n        with self._cond:\n            self._value += n\n            for i in range(n):\n                self._cond.notify()",
        "name_type": "stdlib"
    },
    "threading.Semaphore.__exit__": {
        "API_name": "threading.Semaphore.__exit__",
        "loc_name": "threading.Semaphore.__exit__",
        "args": "self;t;v;tb",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 472,
        "namespace": "Semaphore",
        "body": "    def __exit__(self, t, v, tb):\n        self.release()",
        "name_type": "stdlib"
    },
    "threading.BoundedSemaphore": {
        "API_name": "threading.BoundedSemaphore",
        "loc_name": "threading.BoundedSemaphore",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 476,
        "namespace": "BoundedSemaphore",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.BoundedSemaphore.__init__": {
        "API_name": "threading.BoundedSemaphore.__init__",
        "loc_name": "threading.BoundedSemaphore.__init__",
        "args": "self;value",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 493,
        "namespace": "BoundedSemaphore",
        "body": "    def __init__(self, value=1):\n        Semaphore.__init__(self, value)\n        self._initial_value = value",
        "name_type": "stdlib"
    },
    "threading.BoundedSemaphore.release": {
        "API_name": "threading.BoundedSemaphore.release",
        "loc_name": "threading.BoundedSemaphore.release",
        "args": "self;n",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 497,
        "namespace": "BoundedSemaphore",
        "body": "    def release(self, n=1):\n        \"\"\"Release a semaphore, incrementing the internal counter by one or more.\n\n        When the counter is zero on entry and another thread is waiting for it\n        to become larger than zero again, wake up that thread.\n\n        If the number of releases exceeds the number of acquires,\n        raise a ValueError.\n\n        \"\"\"\n        if n < 1:\n            raise ValueError('n must be one or more')\n        with self._cond:\n            if self._value + n > self._initial_value:\n                raise ValueError(\"Semaphore released too many times\")\n            self._value += n\n            for i in range(n):\n                self._cond.notify()",
        "name_type": "stdlib"
    },
    "threading.Event": {
        "API_name": "threading.Event",
        "loc_name": "threading.Event",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 517,
        "namespace": "Event",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.Event.__init__": {
        "API_name": "threading.Event.__init__",
        "loc_name": "threading.Event.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 528,
        "namespace": "Event",
        "body": "    def __init__(self):\n        self._cond = Condition(Lock())\n        self._flag = False",
        "name_type": "stdlib"
    },
    "threading.Event._at_fork_reinit": {
        "API_name": "threading.Event._at_fork_reinit",
        "loc_name": "threading.Event._at_fork_reinit",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 532,
        "namespace": "Event",
        "body": "    def _at_fork_reinit(self):\n        # Private method called by Thread._reset_internal_locks()\n        self._cond._at_fork_reinit()",
        "name_type": "stdlib"
    },
    "threading.Event.is_set": {
        "API_name": "threading.Event.is_set",
        "loc_name": "threading.Event.is_set",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 536,
        "namespace": "Event",
        "body": "    def is_set(self):\n        \"\"\"Return true if and only if the internal flag is true.\"\"\"\n        return self._flag",
        "name_type": "stdlib"
    },
    "threading.Event.set": {
        "API_name": "threading.Event.set",
        "loc_name": "threading.Event.set",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 542,
        "namespace": "Event",
        "body": "    def set(self):\n        \"\"\"Set the internal flag to true.\n\n        All threads waiting for it to become true are awakened. Threads\n        that call wait() once the flag is true will not block at all.\n\n        \"\"\"\n        with self._cond:\n            self._flag = True\n            self._cond.notify_all()",
        "name_type": "stdlib"
    },
    "threading.Event.clear": {
        "API_name": "threading.Event.clear",
        "loc_name": "threading.Event.clear",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 553,
        "namespace": "Event",
        "body": "    def clear(self):\n        \"\"\"Reset the internal flag to false.\n\n        Subsequently, threads calling wait() will block until set() is called to\n        set the internal flag to true again.\n\n        \"\"\"\n        with self._cond:\n            self._flag = False",
        "name_type": "stdlib"
    },
    "threading.Event.wait": {
        "API_name": "threading.Event.wait",
        "loc_name": "threading.Event.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 563,
        "namespace": "Event",
        "body": "    def wait(self, timeout=None):\n        \"\"\"Block until the internal flag is true.\n\n        If the internal flag is true on entry, return immediately. Otherwise,\n        block until another thread calls set() to set the flag to true, or until\n        the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof).\n\n        This method returns the internal flag on exit, so it will always return\n        True except if a timeout is given and the operation times out.\n\n        \"\"\"\n        with self._cond:\n            signaled = self._flag\n            if not signaled:\n                signaled = self._cond.wait(timeout)\n            return signaled",
        "name_type": "stdlib"
    },
    "threading.Barrier": {
        "API_name": "threading.Barrier",
        "loc_name": "threading.Barrier",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 596,
        "namespace": "Barrier",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.Barrier.__init__": {
        "API_name": "threading.Barrier.__init__",
        "loc_name": "threading.Barrier.__init__",
        "args": "self;parties;action;timeout",
        "args_default": 2,
        "filepath": "threading",
        "lineno": 605,
        "namespace": "Barrier",
        "body": "    def __init__(self, parties, action=None, timeout=None):\n        \"\"\"Create a barrier, initialised to 'parties' threads.\n\n        'action' is a callable which, when supplied, will be called by one of\n        the threads after they have all entered the barrier and just prior to\n        releasing them all. If a 'timeout' is provided, it is used as the\n        default for all subsequent 'wait()' calls.\n\n        \"\"\"\n        self._cond = Condition(Lock())\n        self._action = action\n        self._timeout = timeout\n        self._parties = parties\n        self._state = 0  # 0 filling, 1 draining, -1 resetting, -2 broken\n        self._count = 0",
        "name_type": "stdlib"
    },
    "threading.Barrier.wait": {
        "API_name": "threading.Barrier.wait",
        "loc_name": "threading.Barrier.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 621,
        "namespace": "Barrier",
        "body": "    def wait(self, timeout=None):\n        \"\"\"Wait for the barrier.\n\n        When the specified number of threads have started waiting, they are all\n        simultaneously awoken. If an 'action' was provided for the barrier, one\n        of the threads will have executed that callback prior to returning.\n        Returns an individual index number from 0 to 'parties-1'.\n\n        \"\"\"\n        if timeout is None:\n            timeout = self._timeout\n        with self._cond:\n            self._enter() # Block while the barrier drains.\n            index = self._count\n            self._count += 1\n            try:\n                if index + 1 == self._parties:\n                    # We release the barrier\n                    self._release()\n                else:\n                    # We wait until someone releases us\n                    self._wait(timeout)\n                return index\n            finally:\n                self._count -= 1\n                # Wake up any threads waiting for barrier to drain.\n                self._exit()",
        "name_type": "stdlib"
    },
    "threading.Barrier._enter": {
        "API_name": "threading.Barrier._enter",
        "loc_name": "threading.Barrier._enter",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 651,
        "namespace": "Barrier",
        "body": "    def _enter(self):\n        while self._state in (-1, 1):\n            # It is draining or resetting, wait until done\n            self._cond.wait()\n        #see if the barrier is in a broken state\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 0",
        "name_type": "stdlib"
    },
    "threading.Barrier._release": {
        "API_name": "threading.Barrier._release",
        "loc_name": "threading.Barrier._release",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 662,
        "namespace": "Barrier",
        "body": "    def _release(self):\n        try:\n            if self._action:\n                self._action()\n            # enter draining state\n            self._state = 1\n            self._cond.notify_all()\n        except:\n            #an exception during the _action handler.  Break and reraise\n            self._break()\n            raise",
        "name_type": "stdlib"
    },
    "threading.Barrier._wait": {
        "API_name": "threading.Barrier._wait",
        "loc_name": "threading.Barrier._wait",
        "args": "self;timeout",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 676,
        "namespace": "Barrier",
        "body": "    def _wait(self, timeout):\n        if not self._cond.wait_for(lambda : self._state != 0, timeout):\n            #timed out.  Break the barrier\n            self._break()\n            raise BrokenBarrierError\n        if self._state < 0:\n            raise BrokenBarrierError\n        assert self._state == 1",
        "name_type": "stdlib"
    },
    "threading.Barrier._exit": {
        "API_name": "threading.Barrier._exit",
        "loc_name": "threading.Barrier._exit",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 687,
        "namespace": "Barrier",
        "body": "    def _exit(self):\n        if self._count == 0:\n            if self._state in (-1, 1):\n                #resetting or draining\n                self._state = 0\n                self._cond.notify_all()",
        "name_type": "stdlib"
    },
    "threading.Barrier.reset": {
        "API_name": "threading.Barrier.reset",
        "loc_name": "threading.Barrier.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 694,
        "namespace": "Barrier",
        "body": "    def reset(self):\n        \"\"\"Reset the barrier to the initial state.\n\n        Any threads currently waiting will get the BrokenBarrier exception\n        raised.\n\n        \"\"\"\n        with self._cond:\n            if self._count > 0:\n                if self._state == 0:\n                    #reset the barrier, waking up threads\n                    self._state = -1\n                elif self._state == -2:\n                    #was broken, set it to reset state\n                    #which clears when the last thread exits\n                    self._state = -1\n            else:\n                self._state = 0\n            self._cond.notify_all()",
        "name_type": "stdlib"
    },
    "threading.Barrier.abort": {
        "API_name": "threading.Barrier.abort",
        "loc_name": "threading.Barrier.abort",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 714,
        "namespace": "Barrier",
        "body": "    def abort(self):\n        \"\"\"Place the barrier into a 'broken' state.\n\n        Useful in case of error.  Any currently waiting threads and threads\n        attempting to 'wait()' will have BrokenBarrierError raised.\n\n        \"\"\"\n        with self._cond:\n            self._break()",
        "name_type": "stdlib"
    },
    "threading.Barrier._break": {
        "API_name": "threading.Barrier._break",
        "loc_name": "threading.Barrier._break",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 724,
        "namespace": "Barrier",
        "body": "    def _break(self):\n        # An internal error was detected.  The barrier is set to\n        # a broken state all parties awakened.\n        self._state = -2\n        self._cond.notify_all()",
        "name_type": "stdlib"
    },
    "threading.Barrier.parties": {
        "API_name": "threading.Barrier.parties",
        "loc_name": "threading.Barrier.parties",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 731,
        "namespace": "Barrier",
        "body": "    def parties(self):\n        \"\"\"Return the number of threads required to trip the barrier.\"\"\"\n        return self._parties",
        "name_type": "stdlib"
    },
    "threading.Barrier.n_waiting": {
        "API_name": "threading.Barrier.n_waiting",
        "loc_name": "threading.Barrier.n_waiting",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 736,
        "namespace": "Barrier",
        "body": "    def n_waiting(self):\n        \"\"\"Return the number of threads currently waiting at the barrier.\"\"\"\n        # We don't need synchronization here since this is an ephemeral result\n        # anyway.  It returns the correct value in the steady state.\n        if self._state == 0:\n            return self._count\n        return 0",
        "name_type": "stdlib"
    },
    "threading.Barrier.broken": {
        "API_name": "threading.Barrier.broken",
        "loc_name": "threading.Barrier.broken",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 745,
        "namespace": "Barrier",
        "body": "    def broken(self):\n        \"\"\"Return True if the barrier is in a broken state.\"\"\"\n        return self._state == -2",
        "name_type": "stdlib"
    },
    "threading.BrokenBarrierError": {
        "API_name": "threading.BrokenBarrierError",
        "loc_name": "threading.BrokenBarrierError",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 750,
        "namespace": "BrokenBarrierError",
        "body": "",
        "name_type": "stdlib"
    },
    "threading._newname": {
        "API_name": "threading._newname",
        "loc_name": "threading._newname",
        "args": "template",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 757,
        "namespace": "*",
        "body": "def _newname(template=\"Thread-%d\"):\n    return template % _counter()",
        "name_type": "stdlib"
    },
    "threading._maintain_shutdown_locks": {
        "API_name": "threading._maintain_shutdown_locks",
        "loc_name": "threading._maintain_shutdown_locks",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 775,
        "namespace": "*",
        "body": "def _maintain_shutdown_locks():\n    \"\"\"\n    Drop any shutdown locks that don't correspond to running threads anymore.\n\n    Calling this from time to time avoids an ever-growing _shutdown_locks\n    set when Thread objects are not joined explicitly. See bpo-37788.\n\n    This must be called with _shutdown_locks_lock acquired.\n    \"\"\"\n    # If a lock was released, the corresponding thread has exited\n    to_remove = [lock for lock in _shutdown_locks if not lock.locked()]\n    _shutdown_locks.difference_update(to_remove)",
        "name_type": "stdlib"
    },
    "threading.Thread": {
        "API_name": "threading.Thread",
        "loc_name": "threading.Thread",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 791,
        "namespace": "Thread",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.Thread.__init__": {
        "API_name": "threading.Thread.__init__",
        "loc_name": "threading.Thread.__init__",
        "args": "self;group;target;name;args;kwargs",
        "args_default": 5,
        "filepath": "threading",
        "lineno": 802,
        "namespace": "Thread",
        "body": "    def __init__(self, group=None, target=None, name=None,\n                 args=(), kwargs=None, *, daemon=None):\n        \"\"\"This constructor should always be called with keyword arguments. Arguments are:\n\n        *group* should be None; reserved for future extension when a ThreadGroup\n        class is implemented.\n\n        *target* is the callable object to be invoked by the run()\n        method. Defaults to None, meaning nothing is called.\n\n        *name* is the thread name. By default, a unique name is constructed of\n        the form \"Thread-N\" where N is a small decimal number.\n\n        *args* is the argument tuple for the target invocation. Defaults to ().\n\n        *kwargs* is a dictionary of keyword arguments for the target\n        invocation. Defaults to {}.\n\n        If a subclass overrides the constructor, it must make sure to invoke\n        the base class constructor (Thread.__init__()) before doing anything\n        else to the thread.\n\n        \"\"\"\n        assert group is None, \"group argument must be None for now\"\n        if kwargs is None:\n            kwargs = {}\n        self._target = target\n        self._name = str(name or _newname())\n        self._args = args\n        self._kwargs = kwargs\n        if daemon is not None:\n            self._daemonic = daemon\n        else:\n            self._daemonic = current_thread().daemon\n        self._ident = None\n        if _HAVE_THREAD_NATIVE_ID:\n            self._native_id = None\n        self._tstate_lock = None\n        self._started = Event()\n        self._is_stopped = False\n        self._initialized = True\n        # Copy of sys.stderr used by self._invoke_excepthook()\n        self._stderr = _sys.stderr\n        self._invoke_excepthook = _make_invoke_excepthook()\n        # For debugging and _after_fork()\n        _dangling.add(self)",
        "name_type": "stdlib"
    },
    "threading.Thread._reset_internal_locks": {
        "API_name": "threading.Thread._reset_internal_locks",
        "loc_name": "threading.Thread._reset_internal_locks",
        "args": "self;is_alive",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 849,
        "namespace": "Thread",
        "body": "    def _reset_internal_locks(self, is_alive):\n        # private!  Called by _after_fork() to reset our internal locks as\n        # they may be in an invalid state leading to a deadlock or crash.\n        self._started._at_fork_reinit()\n        if is_alive:\n            # bpo-42350: If the fork happens when the thread is already stopped\n            # (ex: after threading._shutdown() has been called), _tstate_lock\n            # is None. Do nothing in this case.\n            if self._tstate_lock is not None:\n                self._tstate_lock._at_fork_reinit()\n                self._tstate_lock.acquire()\n        else:\n            # The thread isn't alive after fork: it doesn't have a tstate\n            # anymore.\n            self._is_stopped = True\n            self._tstate_lock = None",
        "name_type": "stdlib"
    },
    "threading.Thread.__repr__": {
        "API_name": "threading.Thread.__repr__",
        "loc_name": "threading.Thread.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 866,
        "namespace": "Thread",
        "body": "    def __repr__(self):\n        assert self._initialized, \"Thread.__init__() was not called\"\n        status = \"initial\"\n        if self._started.is_set():\n            status = \"started\"\n        self.is_alive() # easy way to get ._is_stopped set when appropriate\n        if self._is_stopped:\n            status = \"stopped\"\n        if self._daemonic:\n            status += \" daemon\"\n        if self._ident is not None:\n            status += \" %s\" % self._ident\n        return \"<%s(%s, %s)>\" % (self.__class__.__name__, self._name, status)",
        "name_type": "stdlib"
    },
    "threading.Thread.start": {
        "API_name": "threading.Thread.start",
        "loc_name": "threading.Thread.start",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 880,
        "namespace": "Thread",
        "body": "    def start(self):\n        \"\"\"Start the thread's activity.\n\n        It must be called at most once per thread object. It arranges for the\n        object's run() method to be invoked in a separate thread of control.\n\n        This method will raise a RuntimeError if called more than once on the\n        same thread object.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"thread.__init__() not called\")\n\n        if self._started.is_set():\n            raise RuntimeError(\"threads can only be started once\")\n\n        with _active_limbo_lock:\n            _limbo[self] = self\n        try:\n            _start_new_thread(self._bootstrap, ())\n        except Exception:\n            with _active_limbo_lock:\n                del _limbo[self]\n            raise\n        self._started.wait()",
        "name_type": "stdlib"
    },
    "threading.Thread.run": {
        "API_name": "threading.Thread.run",
        "loc_name": "threading.Thread.run",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 906,
        "namespace": "Thread",
        "body": "    def run(self):\n        \"\"\"Method representing the thread's activity.\n\n        You may override this method in a subclass. The standard run() method\n        invokes the callable object passed to the object's constructor as the\n        target argument, if any, with sequential and keyword arguments taken\n        from the args and kwargs arguments, respectively.\n\n        \"\"\"\n        try:\n            if self._target:\n                self._target(*self._args, **self._kwargs)\n        finally:\n            # Avoid a refcycle if the thread is running a function with\n            # an argument that has a member that points to the thread.\n            del self._target, self._args, self._kwargs",
        "name_type": "stdlib"
    },
    "threading.Thread._bootstrap": {
        "API_name": "threading.Thread._bootstrap",
        "loc_name": "threading.Thread._bootstrap",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 923,
        "namespace": "Thread",
        "body": "    def _bootstrap(self):\n        # Wrapper around the real bootstrap code that ignores\n        # exceptions during interpreter cleanup.  Those typically\n        # happen when a daemon thread wakes up at an unfortunate\n        # moment, finds the world around it destroyed, and raises some\n        # random exception *** while trying to report the exception in\n        # _bootstrap_inner() below ***.  Those random exceptions\n        # don't help anybody, and they confuse users, so we suppress\n        # them.  We suppress them only when it appears that the world\n        # indeed has already been destroyed, so that exceptions in\n        # _bootstrap_inner() during normal business hours are properly\n        # reported.  Also, we only suppress them for daemonic threads;\n        # if a non-daemonic encounters this, something else is wrong.\n        try:\n            self._bootstrap_inner()\n        except:\n            if self._daemonic and _sys is None:\n                return\n            raise",
        "name_type": "stdlib"
    },
    "threading.Thread._set_ident": {
        "API_name": "threading.Thread._set_ident",
        "loc_name": "threading.Thread._set_ident",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 943,
        "namespace": "Thread",
        "body": "    def _set_ident(self):\n        self._ident = get_ident()",
        "name_type": "stdlib"
    },
    "threading.Thread._set_tstate_lock": {
        "API_name": "threading.Thread._set_tstate_lock",
        "loc_name": "threading.Thread._set_tstate_lock",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 950,
        "namespace": "Thread",
        "body": "    def _set_tstate_lock(self):\n        \"\"\"\n        Set a lock object which will be released by the interpreter when\n        the underlying thread state (see pystate.h) gets deleted.\n        \"\"\"\n        self._tstate_lock = _set_sentinel()\n        self._tstate_lock.acquire()\n\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                _maintain_shutdown_locks()\n                _shutdown_locks.add(self._tstate_lock)",
        "name_type": "stdlib"
    },
    "threading.Thread._bootstrap_inner": {
        "API_name": "threading.Thread._bootstrap_inner",
        "loc_name": "threading.Thread._bootstrap_inner",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 963,
        "namespace": "Thread",
        "body": "    def _bootstrap_inner(self):\n        try:\n            self._set_ident()\n            self._set_tstate_lock()\n            if _HAVE_THREAD_NATIVE_ID:\n                self._set_native_id()\n            self._started.set()\n            with _active_limbo_lock:\n                _active[self._ident] = self\n                del _limbo[self]\n\n            if _trace_hook:\n                _sys.settrace(_trace_hook)\n            if _profile_hook:\n                _sys.setprofile(_profile_hook)\n\n            try:\n                self.run()\n            except:\n                self._invoke_excepthook(self)\n        finally:\n            with _active_limbo_lock:\n                try:\n                    # We don't call self._delete() because it also\n                    # grabs _active_limbo_lock.\n                    del _active[get_ident()]\n                except:\n                    pass",
        "name_type": "stdlib"
    },
    "threading.Thread._stop": {
        "API_name": "threading.Thread._stop",
        "loc_name": "threading.Thread._stop",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 992,
        "namespace": "Thread",
        "body": "    def _stop(self):\n        # After calling ._stop(), .is_alive() returns False and .join() returns\n        # immediately.  ._tstate_lock must be released before calling ._stop().\n        #\n        # Normal case:  C code at the end of the thread's life\n        # (release_sentinel in _threadmodule.c) releases ._tstate_lock, and\n        # that's detected by our ._wait_for_tstate_lock(), called by .join()\n        # and .is_alive().  Any number of threads _may_ call ._stop()\n        # simultaneously (for example, if multiple threads are blocked in\n        # .join() calls), and they're not serialized.  That's harmless -\n        # they'll just make redundant rebindings of ._is_stopped and\n        # ._tstate_lock.  Obscure:  we rebind ._tstate_lock last so that the\n        # \"assert self._is_stopped\" in ._wait_for_tstate_lock() always works\n        # (the assert is executed only if ._tstate_lock is None).\n        #\n        # Special case:  _main_thread releases ._tstate_lock via this\n        # module's _shutdown() function.\n        lock = self._tstate_lock\n        if lock is not None:\n            assert not lock.locked()\n        self._is_stopped = True\n        self._tstate_lock = None\n        if not self.daemon:\n            with _shutdown_locks_lock:\n                # Remove our lock and other released locks from _shutdown_locks\n                _maintain_shutdown_locks()",
        "name_type": "stdlib"
    },
    "threading.Thread._delete": {
        "API_name": "threading.Thread._delete",
        "loc_name": "threading.Thread._delete",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1019,
        "namespace": "Thread",
        "body": "    def _delete(self):\n        \"Remove current thread from the dict of currently running threads.\"\n        with _active_limbo_lock:\n            del _active[get_ident()]",
        "name_type": "stdlib"
    },
    "threading.Thread.join": {
        "API_name": "threading.Thread.join",
        "loc_name": "threading.Thread.join",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 1028,
        "namespace": "Thread",
        "body": "    def join(self, timeout=None):\n        \"\"\"Wait until the thread terminates.\n\n        This blocks the calling thread until the thread whose join() method is\n        called terminates -- either normally or through an unhandled exception\n        or until the optional timeout occurs.\n\n        When the timeout argument is present and not None, it should be a\n        floating point number specifying a timeout for the operation in seconds\n        (or fractions thereof). As join() always returns None, you must call\n        is_alive() after join() to decide whether a timeout happened -- if the\n        thread is still alive, the join() call timed out.\n\n        When the timeout argument is not present or None, the operation will\n        block until the thread terminates.\n\n        A thread can be join()ed many times.\n\n        join() raises a RuntimeError if an attempt is made to join the current\n        thread as that would cause a deadlock. It is also an error to join() a\n        thread before it has been started and attempts to do so raises the same\n        exception.\n\n        \"\"\"\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if not self._started.is_set():\n            raise RuntimeError(\"cannot join thread before it is started\")\n        if self is current_thread():\n            raise RuntimeError(\"cannot join current thread\")\n\n        if timeout is None:\n            self._wait_for_tstate_lock()\n        else:\n            # the behavior of a negative timeout isn't documented, but\n            # historically .join(timeout=x) for x<0 has acted as if timeout=0\n            self._wait_for_tstate_lock(timeout=max(timeout, 0))",
        "name_type": "stdlib"
    },
    "threading.Thread._wait_for_tstate_lock": {
        "API_name": "threading.Thread._wait_for_tstate_lock",
        "loc_name": "threading.Thread._wait_for_tstate_lock",
        "args": "self;block;timeout",
        "args_default": 2,
        "filepath": "threading",
        "lineno": 1066,
        "namespace": "Thread",
        "body": "    def _wait_for_tstate_lock(self, block=True, timeout=-1):\n        # Issue #18808: wait for the thread state to be gone.\n        # At the end of the thread's life, after all knowledge of the thread\n        # is removed from C data structures, C code releases our _tstate_lock.\n        # This method passes its arguments to _tstate_lock.acquire().\n        # If the lock is acquired, the C code is done, and self._stop() is\n        # called.  That sets ._is_stopped to True, and ._tstate_lock to None.\n        lock = self._tstate_lock\n        if lock is None:\n            # already determined that the C code is done\n            assert self._is_stopped\n            return\n\n        try:\n            if lock.acquire(block, timeout):\n                lock.release()\n                self._stop()\n        except:\n            if lock.locked():\n                # bpo-45274: lock.acquire() acquired the lock, but the function\n                # was interrupted with an exception before reaching the\n                # lock.release(). It can happen if a signal handler raises an\n                # exception, like CTRL+C which raises KeyboardInterrupt.\n                lock.release()\n                self._stop()\n            raise",
        "name_type": "stdlib"
    },
    "threading.Thread.name": {
        "API_name": "threading.Thread.name",
        "loc_name": "threading.Thread.name",
        "args": "self;name",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1105,
        "namespace": "Thread",
        "body": "    def name(self, name):\n        assert self._initialized, \"Thread.__init__() not called\"\n        self._name = str(name)",
        "name_type": "stdlib"
    },
    "threading.Thread.ident": {
        "API_name": "threading.Thread.ident",
        "loc_name": "threading.Thread.ident",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1110,
        "namespace": "Thread",
        "body": "    def ident(self):\n        \"\"\"Thread identifier of this thread or None if it has not been started.\n\n        This is a nonzero integer. See the get_ident() function. Thread\n        identifiers may be recycled when a thread exits and another thread is\n        created. The identifier is available even after the thread has exited.\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        return self._ident",
        "name_type": "stdlib"
    },
    "threading.Thread.is_alive": {
        "API_name": "threading.Thread.is_alive",
        "loc_name": "threading.Thread.is_alive",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1133,
        "namespace": "Thread",
        "body": "    def is_alive(self):\n        \"\"\"Return whether the thread is alive.\n\n        This method returns True just before the run() method starts until just\n        after the run() method terminates. See also the module function\n        enumerate().\n\n        \"\"\"\n        assert self._initialized, \"Thread.__init__() not called\"\n        if self._is_stopped or not self._started.is_set():\n            return False\n        self._wait_for_tstate_lock(False)\n        return not self._is_stopped",
        "name_type": "stdlib"
    },
    "threading.Thread.daemon": {
        "API_name": "threading.Thread.daemon",
        "loc_name": "threading.Thread.daemon",
        "args": "self;daemonic",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1163,
        "namespace": "Thread",
        "body": "    def daemon(self, daemonic):\n        if not self._initialized:\n            raise RuntimeError(\"Thread.__init__() not called\")\n        if self._started.is_set():\n            raise RuntimeError(\"cannot set daemon status of active thread\")\n        self._daemonic = daemonic",
        "name_type": "stdlib"
    },
    "threading.Thread.isDaemon": {
        "API_name": "threading.Thread.isDaemon",
        "loc_name": "threading.Thread.isDaemon",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1170,
        "namespace": "Thread",
        "body": "    def isDaemon(self):\n        return self.daemon",
        "name_type": "stdlib"
    },
    "threading.Thread.setDaemon": {
        "API_name": "threading.Thread.setDaemon",
        "loc_name": "threading.Thread.setDaemon",
        "args": "self;daemonic",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1173,
        "namespace": "Thread",
        "body": "    def setDaemon(self, daemonic):\n        self.daemon = daemonic",
        "name_type": "stdlib"
    },
    "threading.Thread.getName": {
        "API_name": "threading.Thread.getName",
        "loc_name": "threading.Thread.getName",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1176,
        "namespace": "Thread",
        "body": "    def getName(self):\n        return self.name",
        "name_type": "stdlib"
    },
    "threading.Thread.setName": {
        "API_name": "threading.Thread.setName",
        "loc_name": "threading.Thread.setName",
        "args": "self;name",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1179,
        "namespace": "Thread",
        "body": "    def setName(self, name):\n        self.name = name",
        "name_type": "stdlib"
    },
    "threading.ExceptHookArgs": {
        "API_name": "threading.ExceptHookArgs",
        "loc_name": "threading.ExceptHookArgs",
        "args": "args",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1195,
        "namespace": "*",
        "body": "    def ExceptHookArgs(args):\n        return _ExceptHookArgs(*args)",
        "name_type": "stdlib"
    },
    "threading.excepthook": {
        "API_name": "threading.excepthook",
        "loc_name": "threading.excepthook",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1198,
        "namespace": "*",
        "body": "    def excepthook(args, /):\n        \"\"\"\n        Handle uncaught Thread.run() exception.\n        \"\"\"\n        if args.exc_type == SystemExit:\n            # silently ignore SystemExit\n            return\n\n        if _sys is not None and _sys.stderr is not None:\n            stderr = _sys.stderr\n        elif args.thread is not None:\n            stderr = args.thread._stderr\n            if stderr is None:\n                # do nothing if sys.stderr is None and sys.stderr was None\n                # when the thread was created\n                return\n        else:\n            # do nothing if sys.stderr is None and args.thread is None\n            return\n\n        if args.thread is not None:\n            name = args.thread.name\n        else:\n            name = get_ident()\n        print(f\"Exception in thread {name}:\",\n              file=stderr, flush=True)\n        _print_exception(args.exc_type, args.exc_value, args.exc_traceback,\n                         file=stderr)\n        stderr.flush()",
        "name_type": "stdlib"
    },
    "threading._make_invoke_excepthook": {
        "API_name": "threading._make_invoke_excepthook",
        "loc_name": "threading._make_invoke_excepthook",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1229,
        "namespace": "*",
        "body": "def _make_invoke_excepthook():\n    # Create a local namespace to ensure that variables remain alive\n    # when _invoke_excepthook() is called, even if it is called late during\n    # Python shutdown. It is mostly needed for daemon threads.\n\n    old_excepthook = excepthook\n    old_sys_excepthook = _sys.excepthook\n    if old_excepthook is None:\n        raise RuntimeError(\"threading.excepthook is None\")\n    if old_sys_excepthook is None:\n        raise RuntimeError(\"sys.excepthook is None\")\n\n    sys_exc_info = _sys.exc_info\n    local_print = print\n    local_sys = _sys\n\n    def invoke_excepthook(thread):\n        global excepthook\n        try:\n            hook = excepthook\n            if hook is None:\n                hook = old_excepthook\n\n            args = ExceptHookArgs([*sys_exc_info(), thread])\n\n            hook(args)\n        except Exception as exc:\n            exc.__suppress_context__ = True\n            del exc\n\n            if local_sys is not None and local_sys.stderr is not None:\n                stderr = local_sys.stderr\n            else:\n                stderr = thread._stderr\n\n            local_print(\"Exception in threading.excepthook:\",\n                        file=stderr, flush=True)\n\n            if local_sys is not None and local_sys.excepthook is not None:\n                sys_excepthook = local_sys.excepthook\n            else:\n                sys_excepthook = old_sys_excepthook\n\n            sys_excepthook(*sys_exc_info())\n        finally:\n            # Break reference cycle (exception stored in a variable)\n            args = None\n\n    return invoke_excepthook",
        "name_type": "stdlib"
    },
    "threading._make_invoke_excepthook.invoke_excepthook": {
        "API_name": "threading._make_invoke_excepthook.invoke_excepthook",
        "loc_name": "threading._make_invoke_excepthook.invoke_excepthook",
        "args": "thread",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1245,
        "namespace": "*",
        "body": "    def invoke_excepthook(thread):\n        global excepthook\n        try:\n            hook = excepthook\n            if hook is None:\n                hook = old_excepthook\n\n            args = ExceptHookArgs([*sys_exc_info(), thread])\n\n            hook(args)\n        except Exception as exc:\n            exc.__suppress_context__ = True\n            del exc\n\n            if local_sys is not None and local_sys.stderr is not None:\n                stderr = local_sys.stderr\n            else:\n                stderr = thread._stderr\n\n            local_print(\"Exception in threading.excepthook:\",\n                        file=stderr, flush=True)\n\n            if local_sys is not None and local_sys.excepthook is not None:\n                sys_excepthook = local_sys.excepthook\n            else:\n                sys_excepthook = old_sys_excepthook\n\n            sys_excepthook(*sys_exc_info())\n        finally:\n            # Break reference cycle (exception stored in a variable)\n            args = None",
        "name_type": "stdlib"
    },
    "threading.Timer": {
        "API_name": "threading.Timer",
        "loc_name": "threading.Timer",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 1282,
        "namespace": "Timer",
        "body": "",
        "name_type": "stdlib"
    },
    "threading.Timer.__init__": {
        "API_name": "threading.Timer.__init__",
        "loc_name": "threading.Timer.__init__",
        "args": "self;interval;function;args;kwargs",
        "args_default": 2,
        "filepath": "threading",
        "lineno": 1291,
        "namespace": "Timer",
        "body": "    def __init__(self, interval, function, args=None, kwargs=None):\n        Thread.__init__(self)\n        self.interval = interval\n        self.function = function\n        self.args = args if args is not None else []\n        self.kwargs = kwargs if kwargs is not None else {}\n        self.finished = Event()",
        "name_type": "stdlib"
    },
    "threading.Timer.cancel": {
        "API_name": "threading.Timer.cancel",
        "loc_name": "threading.Timer.cancel",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1299,
        "namespace": "Timer",
        "body": "    def cancel(self):\n        \"\"\"Stop the timer if it hasn't finished yet.\"\"\"\n        self.finished.set()",
        "name_type": "stdlib"
    },
    "threading.Timer.run": {
        "API_name": "threading.Timer.run",
        "loc_name": "threading.Timer.run",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1303,
        "namespace": "Timer",
        "body": "    def run(self):\n        self.finished.wait(self.interval)\n        if not self.finished.is_set():\n            self.function(*self.args, **self.kwargs)\n        self.finished.set()",
        "name_type": "stdlib"
    },
    "threading._MainThread": {
        "API_name": "threading._MainThread",
        "loc_name": "threading._MainThread",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 1312,
        "namespace": "_MainThread",
        "body": "",
        "name_type": "stdlib"
    },
    "threading._MainThread.__init__": {
        "API_name": "threading._MainThread.__init__",
        "loc_name": "threading._MainThread.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1314,
        "namespace": "_MainThread",
        "body": "    def __init__(self):\n        Thread.__init__(self, name=\"MainThread\", daemon=False)\n        self._set_tstate_lock()\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self",
        "name_type": "stdlib"
    },
    "threading._DummyThread": {
        "API_name": "threading._DummyThread",
        "loc_name": "threading._DummyThread",
        "args": "*",
        "args_default": "*",
        "filepath": "threading",
        "lineno": 1333,
        "namespace": "_DummyThread",
        "body": "",
        "name_type": "stdlib"
    },
    "threading._DummyThread.__init__": {
        "API_name": "threading._DummyThread.__init__",
        "loc_name": "threading._DummyThread.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1335,
        "namespace": "_DummyThread",
        "body": "    def __init__(self):\n        Thread.__init__(self, name=_newname(\"Dummy-%d\"), daemon=True)\n\n        self._started.set()\n        self._set_ident()\n        if _HAVE_THREAD_NATIVE_ID:\n            self._set_native_id()\n        with _active_limbo_lock:\n            _active[self._ident] = self",
        "name_type": "stdlib"
    },
    "threading._DummyThread._stop": {
        "API_name": "threading._DummyThread._stop",
        "loc_name": "threading._DummyThread._stop",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1345,
        "namespace": "_DummyThread",
        "body": "    def _stop(self):\n        pass",
        "name_type": "stdlib"
    },
    "threading._DummyThread.is_alive": {
        "API_name": "threading._DummyThread.is_alive",
        "loc_name": "threading._DummyThread.is_alive",
        "args": "self",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1348,
        "namespace": "_DummyThread",
        "body": "    def is_alive(self):\n        assert not self._is_stopped and self._started.is_set()\n        return True",
        "name_type": "stdlib"
    },
    "threading._DummyThread.join": {
        "API_name": "threading._DummyThread.join",
        "loc_name": "threading._DummyThread.join",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "threading",
        "lineno": 1352,
        "namespace": "_DummyThread",
        "body": "    def join(self, timeout=None):\n        assert False, \"cannot join a dummy thread\"",
        "name_type": "stdlib"
    },
    "threading.current_thread": {
        "API_name": "threading.current_thread",
        "loc_name": "threading.current_thread",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1358,
        "namespace": "*",
        "body": "def current_thread():\n    \"\"\"Return the current Thread object, corresponding to the caller's thread of control.\n\n    If the caller's thread of control was not created through the threading\n    module, a dummy thread object with limited functionality is returned.\n\n    \"\"\"\n    try:\n        return _active[get_ident()]\n    except KeyError:\n        return _DummyThread()",
        "name_type": "stdlib"
    },
    "threading.active_count": {
        "API_name": "threading.active_count",
        "loc_name": "threading.active_count",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1372,
        "namespace": "*",
        "body": "def active_count():\n    \"\"\"Return the number of Thread objects currently alive.\n\n    The returned count is equal to the length of the list returned by\n    enumerate().\n\n    \"\"\"\n    with _active_limbo_lock:\n        return len(_active) + len(_limbo)",
        "name_type": "stdlib"
    },
    "threading._enumerate": {
        "API_name": "threading._enumerate",
        "loc_name": "threading._enumerate",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1384,
        "namespace": "*",
        "body": "def _enumerate():\n    # Same as enumerate(), but without the lock. Internal use only.\n    return list(_active.values()) + list(_limbo.values())",
        "name_type": "stdlib"
    },
    "threading.enumerate": {
        "API_name": "threading.enumerate",
        "loc_name": "threading.enumerate",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1388,
        "namespace": "*",
        "body": "def enumerate():\n    \"\"\"Return a list of all Thread objects currently alive.\n\n    The list includes daemonic threads, dummy thread objects created by\n    current_thread(), and the main thread. It excludes terminated threads and\n    threads that have not yet been started.\n\n    \"\"\"\n    with _active_limbo_lock:\n        return list(_active.values()) + list(_limbo.values())",
        "name_type": "stdlib"
    },
    "threading._register_atexit": {
        "API_name": "threading._register_atexit",
        "loc_name": "threading._register_atexit",
        "args": "func",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1403,
        "namespace": "*",
        "body": "def _register_atexit(func, *arg, **kwargs):\n    \"\"\"CPython internal: register *func* to be called before joining threads.\n\n    The registered *func* is called with its arguments just before all\n    non-daemon threads are joined in `_shutdown()`. It provides a similar\n    purpose to `atexit.register()`, but its functions are called prior to\n    threading shutdown instead of interpreter shutdown.\n\n    For similarity to atexit, the registered functions are called in reverse.\n    \"\"\"\n    if _SHUTTING_DOWN:\n        raise RuntimeError(\"can't register atexit after shutdown\")\n\n    call = functools.partial(func, *arg, **kwargs)\n    _threading_atexits.append(call)",
        "name_type": "stdlib"
    },
    "threading._shutdown": {
        "API_name": "threading._shutdown",
        "loc_name": "threading._shutdown",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1428,
        "namespace": "*",
        "body": "def _shutdown():\n    \"\"\"\n    Wait until the Python thread state of all non-daemon threads get deleted.\n    \"\"\"\n    # Obscure:  other threads may be waiting to join _main_thread.  That's\n    # dubious, but some code does it.  We can't wait for C code to release\n    # the main thread's tstate_lock - that won't happen until the interpreter\n    # is nearly dead.  So we release it here.  Note that just calling _stop()\n    # isn't enough:  other threads may already be waiting on _tstate_lock.\n    if _main_thread._is_stopped:\n        # _shutdown() was already called\n        return\n\n    global _SHUTTING_DOWN\n    _SHUTTING_DOWN = True\n\n    # Call registered threading atexit functions before threads are joined.\n    # Order is reversed, similar to atexit.\n    for atexit_call in reversed(_threading_atexits):\n        atexit_call()\n\n    # Main thread\n    if _main_thread.ident == get_ident():\n        tlock = _main_thread._tstate_lock\n        # The main thread isn't finished yet, so its thread state lock can't\n        # have been released.\n        assert tlock is not None\n        assert tlock.locked()\n        tlock.release()\n        _main_thread._stop()\n    else:\n        # bpo-1596321: _shutdown() must be called in the main thread.\n        # If the threading module was not imported by the main thread,\n        # _main_thread is the thread which imported the threading module.\n        # In this case, ignore _main_thread, similar behavior than for threads\n        # spawned by C libraries or using _thread.start_new_thread().\n        pass\n\n    # Join all non-deamon threads\n    while True:\n        with _shutdown_locks_lock:\n            locks = list(_shutdown_locks)\n            _shutdown_locks.clear()\n\n        if not locks:\n            break\n\n        for lock in locks:\n            # mimic Thread.join()\n            lock.acquire()\n            lock.release()",
        "name_type": "stdlib"
    },
    "threading.main_thread": {
        "API_name": "threading.main_thread",
        "loc_name": "threading.main_thread",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1484,
        "namespace": "*",
        "body": "def main_thread():\n    \"\"\"Return the main thread object.\n\n    In normal conditions, the main thread is the thread from which the\n    Python interpreter was started.\n    \"\"\"\n    return _main_thread",
        "name_type": "stdlib"
    },
    "threading._after_fork": {
        "API_name": "threading._after_fork",
        "loc_name": "threading._after_fork",
        "args": "",
        "args_default": 0,
        "filepath": "threading",
        "lineno": 1501,
        "namespace": "*",
        "body": "def _after_fork():\n    \"\"\"\n    Cleanup threading module state that should not exist after a fork.\n    \"\"\"\n    # Reset _active_limbo_lock, in case we forked while the lock was held\n    # by another (non-forked) thread.  http://bugs.python.org/issue874900\n    global _active_limbo_lock, _main_thread\n    global _shutdown_locks_lock, _shutdown_locks\n    _active_limbo_lock = RLock()\n\n    # fork() only copied the current thread; clear references to others.\n    new_active = {}\n\n    try:\n        current = _active[get_ident()]\n    except KeyError:\n        # fork() was called in a thread which was not spawned\n        # by threading.Thread. For example, a thread spawned\n        # by thread.start_new_thread().\n        current = _MainThread()\n\n    _main_thread = current\n\n    # reset _shutdown() locks: threads re-register their _tstate_lock below\n    _shutdown_locks_lock = _allocate_lock()\n    _shutdown_locks = set()\n\n    with _active_limbo_lock:\n        # Dangling thread instances must still have their locks reset,\n        # because someone may join() them.\n        threads = set(_enumerate())\n        threads.update(_dangling)\n        for thread in threads:\n            # Any lock/condition variable may be currently locked or in an\n            # invalid state, so we reinitialize them.\n            if thread is current:\n                # There is only one active thread. We reset the ident to\n                # its new value since it can have changed.\n                thread._reset_internal_locks(True)\n                ident = get_ident()\n                thread._ident = ident\n                new_active[ident] = thread\n            else:\n                # All the others are already stopped.\n                thread._reset_internal_locks(False)\n                thread._stop()\n\n        _limbo.clear()\n        _active.clear()\n        _active.update(new_active)\n        assert len(_active) == 1",
        "name_type": "stdlib"
    },
    "uuid": {
        "API_name": "uuid",
        "loc_name": "uuid",
        "args": "*",
        "args_default": "*",
        "filepath": "uuid",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"UUID objects (universally unique identifiers) according to RFC 4122.\n\nThis module provides immutable UUID objects (class UUID) and the functions\nuuid1(), uuid3(), uuid4(), uuid5() for generating version 1, 3, 4, and 5\nUUIDs as specified in RFC 4122.\n\nIf all you want is a unique ID, you should probably call uuid1() or uuid4().\nNote that uuid1() may compromise privacy since it creates a UUID containing\nthe computer's network address.  uuid4() creates a random UUID.\n\nTypical usage:\n\n    >>> import uuid\n\n    # make a UUID based on the host ID and current time\n    >>> uuid.uuid1()    # doctest: +SKIP\n    UUID('a8098c1a-f86e-11da-bd1a-00112444be1e')\n\n    # make a UUID using an MD5 hash of a namespace UUID and a name\n    >>> uuid.uuid3(uuid.NAMESPACE_DNS, 'python.org')\n    UUID('6fa459ea-ee8a-3ca4-894e-db77e160355e')\n\n    # make a random UUID\n    >>> uuid.uuid4()    # doctest: +SKIP\n    UUID('16fd2706-8baf-433b-82eb-8c7fada847da')\n\n    # make a UUID using a SHA-1 hash of a namespace UUID and a name\n    >>> uuid.uuid5(uuid.NAMESPACE_DNS, 'python.org')\n    UUID('886313e1-3b8a-5372-9b90-0c9aee199e5d')\n\n    # make a UUID from a string of hex digits (braces and hyphens ignored)\n    >>> x = uuid.UUID('{00010203-0405-0607-0809-0a0b0c0d0e0f}')\n\n    # convert a UUID to a string of hex digits in standard form\n    >>> str(x)\n    '00010203-0405-0607-0809-0a0b0c0d0e0f'\n\n    # get the raw 16 bytes of the UUID\n    >>> x.bytes\n    b'\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\t\\n\\x0b\\x0c\\r\\x0e\\x0f'\n\n    # make a UUID from a 16-byte string\n    >>> uuid.UUID(bytes=x.bytes)\n    UUID('00010203-0405-0607-0809-0a0b0c0d0e0f')\n\"\"\"\n__author__ = 'Ka-Ping Yee <ping@zesty.ca>'\nif sys.platform in ('win32', 'darwin'):\n    _AIX = _LINUX = False\nelse:\n    import platform\n    _platform_system = platform.system()\n    _AIX     = _platform_system == 'AIX'\n    _LINUX   = _platform_system == 'Linux'\n_MAC_DELIM = b':'\n_MAC_OMITS_LEADING_ZEROES = False\nif _AIX:\n    _MAC_DELIM = b'.'\n    _MAC_OMITS_LEADING_ZEROES = True\nRESERVED_NCS, RFC_4122, RESERVED_MICROSOFT, RESERVED_FUTURE = [\n    'reserved for NCS compatibility', 'specified in RFC 4122',\n    'reserved for Microsoft compatibility', 'reserved for future definition']\nint_ = int      # The built-in int type\nbytes_ = bytes  # The built-in bytes type\ntry:\n    import _uuid\n    _generate_time_safe = getattr(_uuid, \"generate_time_safe\", None)\n    _UuidCreate = getattr(_uuid, \"UuidCreate\", None)\n    _has_uuid_generate_time_safe = _uuid.has_uuid_generate_time_safe\nexcept ImportError:\n    _uuid = None\n    _generate_time_safe = None\n    _UuidCreate = None\n    _has_uuid_generate_time_safe = None\nif _LINUX:\n    _OS_GETTERS = [_ip_getnode, _ifconfig_getnode]\nelif sys.platform == 'darwin':\n    _OS_GETTERS = [_ifconfig_getnode, _arp_getnode, _netstat_getnode]\nelif sys.platform == 'win32':\n    # bpo-40201: _windll_getnode will always succeed, so these are not needed\n    _OS_GETTERS = []\nelif _AIX:\n    _OS_GETTERS = [_netstat_getnode]\nelse:\n    _OS_GETTERS = [_ifconfig_getnode, _ip_getnode, _arp_getnode,\n                   _netstat_getnode, _lanscan_getnode]\nif os.name == 'posix':\n    _GETTERS = [_unix_getnode] + _OS_GETTERS\nelif os.name == 'nt':\n    _GETTERS = [_windll_getnode] + _OS_GETTERS\nelse:\n    _GETTERS = _OS_GETTERS\n_node = None\n_last_timestamp = None\nNAMESPACE_DNS = UUID('6ba7b810-9dad-11d1-80b4-00c04fd430c8')\nNAMESPACE_URL = UUID('6ba7b811-9dad-11d1-80b4-00c04fd430c8')\nNAMESPACE_OID = UUID('6ba7b812-9dad-11d1-80b4-00c04fd430c8')\nNAMESPACE_X500 = UUID('6ba7b814-9dad-11d1-80b4-00c04fd430c8')",
        "name_type": "stdlib"
    },
    "uuid.SafeUUID": {
        "API_name": "uuid.SafeUUID",
        "loc_name": "uuid.SafeUUID",
        "args": "*",
        "args_default": "*",
        "filepath": "uuid",
        "lineno": 78,
        "namespace": "SafeUUID",
        "body": "",
        "name_type": "stdlib"
    },
    "uuid.UUID": {
        "API_name": "uuid.UUID",
        "loc_name": "uuid.UUID",
        "args": "*",
        "args_default": "*",
        "filepath": "uuid",
        "lineno": 84,
        "namespace": "UUID",
        "body": "",
        "name_type": "stdlib"
    },
    "uuid.UUID.__init__": {
        "API_name": "uuid.UUID.__init__",
        "loc_name": "uuid.UUID.__init__",
        "args": "self;hex;bytes;bytes_le;fields;int;version",
        "args_default": 6,
        "filepath": "uuid",
        "lineno": 138,
        "namespace": "UUID",
        "body": "    def __init__(self, hex=None, bytes=None, bytes_le=None, fields=None,\n                       int=None, version=None,\n                       *, is_safe=SafeUUID.unknown):\n        r\"\"\"Create a UUID from either a string of 32 hexadecimal digits,\n        a string of 16 bytes as the 'bytes' argument, a string of 16 bytes\n        in little-endian order as the 'bytes_le' argument, a tuple of six\n        integers (32-bit time_low, 16-bit time_mid, 16-bit time_hi_version,\n        8-bit clock_seq_hi_variant, 8-bit clock_seq_low, 48-bit node) as\n        the 'fields' argument, or a single 128-bit integer as the 'int'\n        argument.  When a string of hex digits is given, curly braces,\n        hyphens, and a URN prefix are all optional.  For example, these\n        expressions all yield the same UUID:\n\n        UUID('{12345678-1234-5678-1234-567812345678}')\n        UUID('12345678123456781234567812345678')\n        UUID('urn:uuid:12345678-1234-5678-1234-567812345678')\n        UUID(bytes='\\x12\\x34\\x56\\x78'*4)\n        UUID(bytes_le='\\x78\\x56\\x34\\x12\\x34\\x12\\x78\\x56' +\n                      '\\x12\\x34\\x56\\x78\\x12\\x34\\x56\\x78')\n        UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))\n        UUID(int=0x12345678123456781234567812345678)\n\n        Exactly one of 'hex', 'bytes', 'bytes_le', 'fields', or 'int' must\n        be given.  The 'version' argument is optional; if given, the resulting\n        UUID will have its variant and version set according to RFC 4122,\n        overriding the given 'hex', 'bytes', 'bytes_le', 'fields', or 'int'.\n\n        is_safe is an enum exposed as an attribute on the instance.  It\n        indicates whether the UUID has been generated in a way that is safe\n        for multiprocessing applications, via uuid_generate_time_safe(3).\n        \"\"\"\n\n        if [hex, bytes, bytes_le, fields, int].count(None) != 4:\n            raise TypeError('one of the hex, bytes, bytes_le, fields, '\n                            'or int arguments must be given')\n        if hex is not None:\n            hex = hex.replace('urn:', '').replace('uuid:', '')\n            hex = hex.strip('{}').replace('-', '')\n            if len(hex) != 32:\n                raise ValueError('badly formed hexadecimal UUID string')\n            int = int_(hex, 16)\n        if bytes_le is not None:\n            if len(bytes_le) != 16:\n                raise ValueError('bytes_le is not a 16-char string')\n            bytes = (bytes_le[4-1::-1] + bytes_le[6-1:4-1:-1] +\n                     bytes_le[8-1:6-1:-1] + bytes_le[8:])\n        if bytes is not None:\n            if len(bytes) != 16:\n                raise ValueError('bytes is not a 16-char string')\n            assert isinstance(bytes, bytes_), repr(bytes)\n            int = int_.from_bytes(bytes, byteorder='big')\n        if fields is not None:\n            if len(fields) != 6:\n                raise ValueError('fields is not a 6-tuple')\n            (time_low, time_mid, time_hi_version,\n             clock_seq_hi_variant, clock_seq_low, node) = fields\n            if not 0 <= time_low < 1<<32:\n                raise ValueError('field 1 out of range (need a 32-bit value)')\n            if not 0 <= time_mid < 1<<16:\n                raise ValueError('field 2 out of range (need a 16-bit value)')\n            if not 0 <= time_hi_version < 1<<16:\n                raise ValueError('field 3 out of range (need a 16-bit value)')\n            if not 0 <= clock_seq_hi_variant < 1<<8:\n                raise ValueError('field 4 out of range (need an 8-bit value)')\n            if not 0 <= clock_seq_low < 1<<8:\n                raise ValueError('field 5 out of range (need an 8-bit value)')\n            if not 0 <= node < 1<<48:\n                raise ValueError('field 6 out of range (need a 48-bit value)')\n            clock_seq = (clock_seq_hi_variant << 8) | clock_seq_low\n            int = ((time_low << 96) | (time_mid << 80) |\n                   (time_hi_version << 64) | (clock_seq << 48) | node)\n        if int is not None:\n            if not 0 <= int < 1<<128:\n                raise ValueError('int is out of range (need a 128-bit value)')\n        if version is not None:\n            if not 1 <= version <= 5:\n                raise ValueError('illegal version number')\n            # Set the variant to RFC 4122.\n            int &= ~(0xc000 << 48)\n            int |= 0x8000 << 48\n            # Set the version number.\n            int &= ~(0xf000 << 64)\n            int |= version << 76\n        object.__setattr__(self, 'int', int)\n        object.__setattr__(self, 'is_safe', is_safe)",
        "name_type": "stdlib"
    },
    "uuid.UUID.__getstate__": {
        "API_name": "uuid.UUID.__getstate__",
        "loc_name": "uuid.UUID.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 224,
        "namespace": "UUID",
        "body": "    def __getstate__(self):\n        d = {'int': self.int}\n        if self.is_safe != SafeUUID.unknown:\n            # is_safe is a SafeUUID instance.  Return just its value, so that\n            # it can be un-pickled in older Python versions without SafeUUID.\n            d['is_safe'] = self.is_safe.value\n        return d",
        "name_type": "stdlib"
    },
    "uuid.UUID.__setstate__": {
        "API_name": "uuid.UUID.__setstate__",
        "loc_name": "uuid.UUID.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 232,
        "namespace": "UUID",
        "body": "    def __setstate__(self, state):\n        object.__setattr__(self, 'int', state['int'])\n        # is_safe was added in 3.7; it is also omitted when it is \"unknown\"\n        object.__setattr__(self, 'is_safe',\n                           SafeUUID(state['is_safe'])\n                           if 'is_safe' in state else SafeUUID.unknown)",
        "name_type": "stdlib"
    },
    "uuid.UUID.__eq__": {
        "API_name": "uuid.UUID.__eq__",
        "loc_name": "uuid.UUID.__eq__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 239,
        "namespace": "UUID",
        "body": "    def __eq__(self, other):\n        if isinstance(other, UUID):\n            return self.int == other.int\n        return NotImplemented",
        "name_type": "stdlib"
    },
    "uuid.UUID.__lt__": {
        "API_name": "uuid.UUID.__lt__",
        "loc_name": "uuid.UUID.__lt__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 247,
        "namespace": "UUID",
        "body": "    def __lt__(self, other):\n        if isinstance(other, UUID):\n            return self.int < other.int\n        return NotImplemented",
        "name_type": "stdlib"
    },
    "uuid.UUID.__gt__": {
        "API_name": "uuid.UUID.__gt__",
        "loc_name": "uuid.UUID.__gt__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 252,
        "namespace": "UUID",
        "body": "    def __gt__(self, other):\n        if isinstance(other, UUID):\n            return self.int > other.int\n        return NotImplemented",
        "name_type": "stdlib"
    },
    "uuid.UUID.__le__": {
        "API_name": "uuid.UUID.__le__",
        "loc_name": "uuid.UUID.__le__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 257,
        "namespace": "UUID",
        "body": "    def __le__(self, other):\n        if isinstance(other, UUID):\n            return self.int <= other.int\n        return NotImplemented",
        "name_type": "stdlib"
    },
    "uuid.UUID.__ge__": {
        "API_name": "uuid.UUID.__ge__",
        "loc_name": "uuid.UUID.__ge__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 262,
        "namespace": "UUID",
        "body": "    def __ge__(self, other):\n        if isinstance(other, UUID):\n            return self.int >= other.int\n        return NotImplemented",
        "name_type": "stdlib"
    },
    "uuid.UUID.__hash__": {
        "API_name": "uuid.UUID.__hash__",
        "loc_name": "uuid.UUID.__hash__",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 267,
        "namespace": "UUID",
        "body": "    def __hash__(self):\n        return hash(self.int)",
        "name_type": "stdlib"
    },
    "uuid.UUID.__int__": {
        "API_name": "uuid.UUID.__int__",
        "loc_name": "uuid.UUID.__int__",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 270,
        "namespace": "UUID",
        "body": "    def __int__(self):\n        return self.int",
        "name_type": "stdlib"
    },
    "uuid.UUID.__repr__": {
        "API_name": "uuid.UUID.__repr__",
        "loc_name": "uuid.UUID.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 273,
        "namespace": "UUID",
        "body": "    def __repr__(self):\n        return '%s(%r)' % (self.__class__.__name__, str(self))",
        "name_type": "stdlib"
    },
    "uuid.UUID.__setattr__": {
        "API_name": "uuid.UUID.__setattr__",
        "loc_name": "uuid.UUID.__setattr__",
        "args": "self;name;value",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 276,
        "namespace": "UUID",
        "body": "    def __setattr__(self, name, value):\n        raise TypeError('UUID objects are immutable')",
        "name_type": "stdlib"
    },
    "uuid.UUID.__str__": {
        "API_name": "uuid.UUID.__str__",
        "loc_name": "uuid.UUID.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 279,
        "namespace": "UUID",
        "body": "    def __str__(self):\n        hex = '%032x' % self.int\n        return '%s-%s-%s-%s-%s' % (\n            hex[:8], hex[8:12], hex[12:16], hex[16:20], hex[20:])",
        "name_type": "stdlib"
    },
    "uuid.UUID.bytes": {
        "API_name": "uuid.UUID.bytes",
        "loc_name": "uuid.UUID.bytes",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 285,
        "namespace": "UUID",
        "body": "    def bytes(self):\n        return self.int.to_bytes(16, 'big')",
        "name_type": "stdlib"
    },
    "uuid.UUID.bytes_le": {
        "API_name": "uuid.UUID.bytes_le",
        "loc_name": "uuid.UUID.bytes_le",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 289,
        "namespace": "UUID",
        "body": "    def bytes_le(self):\n        bytes = self.bytes\n        return (bytes[4-1::-1] + bytes[6-1:4-1:-1] + bytes[8-1:6-1:-1] +\n                bytes[8:])",
        "name_type": "stdlib"
    },
    "uuid.UUID.fields": {
        "API_name": "uuid.UUID.fields",
        "loc_name": "uuid.UUID.fields",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 295,
        "namespace": "UUID",
        "body": "    def fields(self):\n        return (self.time_low, self.time_mid, self.time_hi_version,\n                self.clock_seq_hi_variant, self.clock_seq_low, self.node)",
        "name_type": "stdlib"
    },
    "uuid.UUID.time_low": {
        "API_name": "uuid.UUID.time_low",
        "loc_name": "uuid.UUID.time_low",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 300,
        "namespace": "UUID",
        "body": "    def time_low(self):\n        return self.int >> 96",
        "name_type": "stdlib"
    },
    "uuid.UUID.time_mid": {
        "API_name": "uuid.UUID.time_mid",
        "loc_name": "uuid.UUID.time_mid",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 304,
        "namespace": "UUID",
        "body": "    def time_mid(self):\n        return (self.int >> 80) & 0xffff",
        "name_type": "stdlib"
    },
    "uuid.UUID.time_hi_version": {
        "API_name": "uuid.UUID.time_hi_version",
        "loc_name": "uuid.UUID.time_hi_version",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 308,
        "namespace": "UUID",
        "body": "    def time_hi_version(self):\n        return (self.int >> 64) & 0xffff",
        "name_type": "stdlib"
    },
    "uuid.UUID.clock_seq_hi_variant": {
        "API_name": "uuid.UUID.clock_seq_hi_variant",
        "loc_name": "uuid.UUID.clock_seq_hi_variant",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 312,
        "namespace": "UUID",
        "body": "    def clock_seq_hi_variant(self):\n        return (self.int >> 56) & 0xff",
        "name_type": "stdlib"
    },
    "uuid.UUID.clock_seq_low": {
        "API_name": "uuid.UUID.clock_seq_low",
        "loc_name": "uuid.UUID.clock_seq_low",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 316,
        "namespace": "UUID",
        "body": "    def clock_seq_low(self):\n        return (self.int >> 48) & 0xff",
        "name_type": "stdlib"
    },
    "uuid.UUID.time": {
        "API_name": "uuid.UUID.time",
        "loc_name": "uuid.UUID.time",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 320,
        "namespace": "UUID",
        "body": "    def time(self):\n        return (((self.time_hi_version & 0x0fff) << 48) |\n                (self.time_mid << 32) | self.time_low)",
        "name_type": "stdlib"
    },
    "uuid.UUID.clock_seq": {
        "API_name": "uuid.UUID.clock_seq",
        "loc_name": "uuid.UUID.clock_seq",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 325,
        "namespace": "UUID",
        "body": "    def clock_seq(self):\n        return (((self.clock_seq_hi_variant & 0x3f) << 8) |\n                self.clock_seq_low)",
        "name_type": "stdlib"
    },
    "uuid.UUID.node": {
        "API_name": "uuid.UUID.node",
        "loc_name": "uuid.UUID.node",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 330,
        "namespace": "UUID",
        "body": "    def node(self):\n        return self.int & 0xffffffffffff",
        "name_type": "stdlib"
    },
    "uuid.UUID.hex": {
        "API_name": "uuid.UUID.hex",
        "loc_name": "uuid.UUID.hex",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 334,
        "namespace": "UUID",
        "body": "    def hex(self):\n        return '%032x' % self.int",
        "name_type": "stdlib"
    },
    "uuid.UUID.urn": {
        "API_name": "uuid.UUID.urn",
        "loc_name": "uuid.UUID.urn",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 338,
        "namespace": "UUID",
        "body": "    def urn(self):\n        return 'urn:uuid:' + str(self)",
        "name_type": "stdlib"
    },
    "uuid.UUID.variant": {
        "API_name": "uuid.UUID.variant",
        "loc_name": "uuid.UUID.variant",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 342,
        "namespace": "UUID",
        "body": "    def variant(self):\n        if not self.int & (0x8000 << 48):\n            return RESERVED_NCS\n        elif not self.int & (0x4000 << 48):\n            return RFC_4122\n        elif not self.int & (0x2000 << 48):\n            return RESERVED_MICROSOFT\n        else:\n            return RESERVED_FUTURE",
        "name_type": "stdlib"
    },
    "uuid.UUID.version": {
        "API_name": "uuid.UUID.version",
        "loc_name": "uuid.UUID.version",
        "args": "self",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 353,
        "namespace": "UUID",
        "body": "    def version(self):\n        # The version bits are only meaningful for RFC 4122 UUIDs.\n        if self.variant == RFC_4122:\n            return int((self.int >> 76) & 0xf)",
        "name_type": "stdlib"
    },
    "uuid._get_command_stdout": {
        "API_name": "uuid._get_command_stdout",
        "loc_name": "uuid._get_command_stdout",
        "args": "command",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 359,
        "namespace": "*",
        "body": "def _get_command_stdout(command, *args):\n    import io, os, shutil, subprocess\n\n    try:\n        path_dirs = os.environ.get('PATH', os.defpath).split(os.pathsep)\n        path_dirs.extend(['/sbin', '/usr/sbin'])\n        executable = shutil.which(command, path=os.pathsep.join(path_dirs))\n        if executable is None:\n            return None\n        # LC_ALL=C to ensure English output, stderr=DEVNULL to prevent output\n        # on stderr (Note: we don't have an example where the words we search\n        # for are actually localized, but in theory some system could do so.)\n        env = dict(os.environ)\n        env['LC_ALL'] = 'C'\n        proc = subprocess.Popen((executable,) + args,\n                                stdout=subprocess.PIPE,\n                                stderr=subprocess.DEVNULL,\n                                env=env)\n        if not proc:\n            return None\n        stdout, stderr = proc.communicate()\n        return io.BytesIO(stdout)\n    except (OSError, subprocess.SubprocessError):\n        return None",
        "name_type": "stdlib"
    },
    "uuid._is_universal": {
        "API_name": "uuid._is_universal",
        "loc_name": "uuid._is_universal",
        "args": "mac",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 400,
        "namespace": "*",
        "body": "def _is_universal(mac):\n    return not (mac & (1 << 41))",
        "name_type": "stdlib"
    },
    "uuid._find_mac_near_keyword": {
        "API_name": "uuid._find_mac_near_keyword",
        "loc_name": "uuid._find_mac_near_keyword",
        "args": "command;args;keywords;get_word_index",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 404,
        "namespace": "*",
        "body": "def _find_mac_near_keyword(command, args, keywords, get_word_index):\n    \"\"\"Searches a command's output for a MAC address near a keyword.\n\n    Each line of words in the output is case-insensitively searched for\n    any of the given keywords.  Upon a match, get_word_index is invoked\n    to pick a word from the line, given the index of the match.  For\n    example, lambda i: 0 would get the first word on the line, while\n    lambda i: i - 1 would get the word preceding the keyword.\n    \"\"\"\n    stdout = _get_command_stdout(command, args)\n    if stdout is None:\n        return None\n\n    first_local_mac = None\n    for line in stdout:\n        words = line.lower().rstrip().split()\n        for i in range(len(words)):\n            if words[i] in keywords:\n                try:\n                    word = words[get_word_index(i)]\n                    mac = int(word.replace(_MAC_DELIM, b''), 16)\n                except (ValueError, IndexError):\n                    # Virtual interfaces, such as those provided by\n                    # VPNs, do not have a colon-delimited MAC address\n                    # as expected, but a 16-byte HWAddr separated by\n                    # dashes. These should be ignored in favor of a\n                    # real MAC address\n                    pass\n                else:\n                    if _is_universal(mac):\n                        return mac\n                    first_local_mac = first_local_mac or mac\n    return first_local_mac or None",
        "name_type": "stdlib"
    },
    "uuid._parse_mac": {
        "API_name": "uuid._parse_mac",
        "loc_name": "uuid._parse_mac",
        "args": "word",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 439,
        "namespace": "*",
        "body": "def _parse_mac(word):\n    # Accept 'HH:HH:HH:HH:HH:HH' MAC address (ex: '52:54:00:9d:0e:67'),\n    # but reject IPv6 address (ex: 'fe80::5054:ff:fe9' or '123:2:3:4:5:6:7:8').\n    #\n    # Virtual interfaces, such as those provided by VPNs, do not have a\n    # colon-delimited MAC address as expected, but a 16-byte HWAddr separated\n    # by dashes. These should be ignored in favor of a real MAC address\n    parts = word.split(_MAC_DELIM)\n    if len(parts) != 6:\n        return\n    if _MAC_OMITS_LEADING_ZEROES:\n        # (Only) on AIX the macaddr value given is not prefixed by 0, e.g.\n        # en0   1500  link#2      fa.bc.de.f7.62.4 110854824     0 160133733     0     0\n        # not\n        # en0   1500  link#2      fa.bc.de.f7.62.04 110854824     0 160133733     0     0\n        if not all(1 <= len(part) <= 2 for part in parts):\n            return\n        hexstr = b''.join(part.rjust(2, b'0') for part in parts)\n    else:\n        if not all(len(part) == 2 for part in parts):\n            return\n        hexstr = b''.join(parts)\n    try:\n        return int(hexstr, 16)\n    except ValueError:\n        return",
        "name_type": "stdlib"
    },
    "uuid._find_mac_under_heading": {
        "API_name": "uuid._find_mac_under_heading",
        "loc_name": "uuid._find_mac_under_heading",
        "args": "command;args;heading",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 467,
        "namespace": "*",
        "body": "def _find_mac_under_heading(command, args, heading):\n    \"\"\"Looks for a MAC address under a heading in a command's output.\n\n    The first line of words in the output is searched for the given\n    heading. Words at the same word index as the heading in subsequent\n    lines are then examined to see if they look like MAC addresses.\n    \"\"\"\n    stdout = _get_command_stdout(command, args)\n    if stdout is None:\n        return None\n\n    keywords = stdout.readline().rstrip().split()\n    try:\n        column_index = keywords.index(heading)\n    except ValueError:\n        return None\n\n    first_local_mac = None\n    for line in stdout:\n        words = line.rstrip().split()\n        try:\n            word = words[column_index]\n        except IndexError:\n            continue\n\n        mac = _parse_mac(word)\n        if mac is None:\n            continue\n        if _is_universal(mac):\n            return mac\n        if first_local_mac is None:\n            first_local_mac = mac\n\n    return first_local_mac",
        "name_type": "stdlib"
    },
    "uuid._ifconfig_getnode": {
        "API_name": "uuid._ifconfig_getnode",
        "loc_name": "uuid._ifconfig_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 505,
        "namespace": "*",
        "body": "def _ifconfig_getnode():\n    \"\"\"Get the hardware address on Unix by running ifconfig.\"\"\"\n    # This works on Linux ('' or '-a'), Tru64 ('-av'), but not all Unixes.\n    keywords = (b'hwaddr', b'ether', b'address:', b'lladdr')\n    for args in ('', '-a', '-av'):\n        mac = _find_mac_near_keyword('ifconfig', args, keywords, lambda i: i+1)\n        if mac:\n            return mac\n        return None",
        "name_type": "stdlib"
    },
    "uuid._ip_getnode": {
        "API_name": "uuid._ip_getnode",
        "loc_name": "uuid._ip_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 515,
        "namespace": "*",
        "body": "def _ip_getnode():\n    \"\"\"Get the hardware address on Unix by running ip.\"\"\"\n    # This works on Linux with iproute2.\n    mac = _find_mac_near_keyword('ip', 'link', [b'link/ether'], lambda i: i+1)\n    if mac:\n        return mac\n    return None",
        "name_type": "stdlib"
    },
    "uuid._arp_getnode": {
        "API_name": "uuid._arp_getnode",
        "loc_name": "uuid._arp_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 523,
        "namespace": "*",
        "body": "def _arp_getnode():\n    \"\"\"Get the hardware address on Unix by running arp.\"\"\"\n    import os, socket\n    try:\n        ip_addr = socket.gethostbyname(socket.gethostname())\n    except OSError:\n        return None\n\n    # Try getting the MAC addr from arp based on our IP address (Solaris).\n    mac = _find_mac_near_keyword('arp', '-an', [os.fsencode(ip_addr)], lambda i: -1)\n    if mac:\n        return mac\n\n    # This works on OpenBSD\n    mac = _find_mac_near_keyword('arp', '-an', [os.fsencode(ip_addr)], lambda i: i+1)\n    if mac:\n        return mac\n\n    # This works on Linux, FreeBSD and NetBSD\n    mac = _find_mac_near_keyword('arp', '-an', [os.fsencode('(%s)' % ip_addr)],\n                    lambda i: i+2)\n    # Return None instead of 0.\n    if mac:\n        return mac\n    return None",
        "name_type": "stdlib"
    },
    "uuid._lanscan_getnode": {
        "API_name": "uuid._lanscan_getnode",
        "loc_name": "uuid._lanscan_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 549,
        "namespace": "*",
        "body": "def _lanscan_getnode():\n    \"\"\"Get the hardware address on Unix by running lanscan.\"\"\"\n    # This might work on HP-UX.\n    return _find_mac_near_keyword('lanscan', '-ai', [b'lan0'], lambda i: 0)",
        "name_type": "stdlib"
    },
    "uuid._netstat_getnode": {
        "API_name": "uuid._netstat_getnode",
        "loc_name": "uuid._netstat_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 554,
        "namespace": "*",
        "body": "def _netstat_getnode():\n    \"\"\"Get the hardware address on Unix by running netstat.\"\"\"\n    # This works on AIX and might work on Tru64 UNIX.\n    return _find_mac_under_heading('netstat', '-ian', b'Address')",
        "name_type": "stdlib"
    },
    "uuid._ipconfig_getnode": {
        "API_name": "uuid._ipconfig_getnode",
        "loc_name": "uuid._ipconfig_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 559,
        "namespace": "*",
        "body": "def _ipconfig_getnode():\n    \"\"\"[DEPRECATED] Get the hardware address on Windows.\"\"\"\n    # bpo-40501: UuidCreateSequential() is now the only supported approach\n    return _windll_getnode()",
        "name_type": "stdlib"
    },
    "uuid._netbios_getnode": {
        "API_name": "uuid._netbios_getnode",
        "loc_name": "uuid._netbios_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 564,
        "namespace": "*",
        "body": "def _netbios_getnode():\n    \"\"\"[DEPRECATED] Get the hardware address on Windows.\"\"\"\n    # bpo-40501: UuidCreateSequential() is now the only supported approach\n    return _windll_getnode()",
        "name_type": "stdlib"
    },
    "uuid._load_system_functions": {
        "API_name": "uuid._load_system_functions",
        "loc_name": "uuid._load_system_functions",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 583,
        "namespace": "*",
        "body": "def _load_system_functions():\n    \"\"\"[DEPRECATED] Platform-specific functions loaded at import time\"\"\"",
        "name_type": "stdlib"
    },
    "uuid._unix_getnode": {
        "API_name": "uuid._unix_getnode",
        "loc_name": "uuid._unix_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 587,
        "namespace": "*",
        "body": "def _unix_getnode():\n    \"\"\"Get the hardware address on Unix using the _uuid extension module.\"\"\"\n    if _generate_time_safe:\n        uuid_time, _ = _generate_time_safe()\n        return UUID(bytes=uuid_time).node",
        "name_type": "stdlib"
    },
    "uuid._windll_getnode": {
        "API_name": "uuid._windll_getnode",
        "loc_name": "uuid._windll_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 593,
        "namespace": "*",
        "body": "def _windll_getnode():\n    \"\"\"Get the hardware address on Windows using the _uuid extension module.\"\"\"\n    if _UuidCreate:\n        uuid_bytes = _UuidCreate()\n        return UUID(bytes_le=uuid_bytes).node",
        "name_type": "stdlib"
    },
    "uuid._random_getnode": {
        "API_name": "uuid._random_getnode",
        "loc_name": "uuid._random_getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 599,
        "namespace": "*",
        "body": "def _random_getnode():\n    \"\"\"Get a random node ID.\"\"\"\n    # RFC 4122, $4.1.6 says \"For systems with no IEEE address, a randomly or\n    # pseudo-randomly generated value may be used; see Section 4.5.  The\n    # multicast bit must be set in such addresses, in order that they will\n    # never conflict with addresses obtained from network cards.\"\n    #\n    # The \"multicast bit\" of a MAC address is defined to be \"the least\n    # significant bit of the first octet\".  This works out to be the 41st bit\n    # counting from 1 being the least significant bit, or 1<<40.\n    #\n    # See https://en.wikipedia.org/wiki/MAC_address#Unicast_vs._multicast\n    import random\n    return random.getrandbits(48) | (1 << 40)",
        "name_type": "stdlib"
    },
    "uuid.getnode": {
        "API_name": "uuid.getnode",
        "loc_name": "uuid.getnode",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 642,
        "namespace": "*",
        "body": "def getnode():\n    \"\"\"Get the hardware address as a 48-bit positive integer.\n\n    The first time this runs, it may launch a separate program, which could\n    be quite slow.  If all attempts to obtain the hardware address fail, we\n    choose a random 48-bit number with its eighth bit set to 1 as recommended\n    in RFC 4122.\n    \"\"\"\n    global _node\n    if _node is not None:\n        return _node\n\n    for getter in _GETTERS + [_random_getnode]:\n        try:\n            _node = getter()\n        except:\n            continue\n        if (_node is not None) and (0 <= _node < (1 << 48)):\n            return _node\n    assert False, '_random_getnode() returned invalid value: {}'.format(_node)",
        "name_type": "stdlib"
    },
    "uuid.uuid1": {
        "API_name": "uuid.uuid1",
        "loc_name": "uuid.uuid1",
        "args": "node;clock_seq",
        "args_default": 2,
        "filepath": "uuid",
        "lineno": 666,
        "namespace": "*",
        "body": "def uuid1(node=None, clock_seq=None):\n    \"\"\"Generate a UUID from a host ID, sequence number, and the current time.\n    If 'node' is not given, getnode() is used to obtain the hardware\n    address.  If 'clock_seq' is given, it is used as the sequence number;\n    otherwise a random 14-bit sequence number is chosen.\"\"\"\n\n    # When the system provides a version-1 UUID generator, use it (but don't\n    # use UuidCreate here because its UUIDs don't conform to RFC 4122).\n    if _generate_time_safe is not None and node is clock_seq is None:\n        uuid_time, safely_generated = _generate_time_safe()\n        try:\n            is_safe = SafeUUID(safely_generated)\n        except ValueError:\n            is_safe = SafeUUID.unknown\n        return UUID(bytes=uuid_time, is_safe=is_safe)\n\n    global _last_timestamp\n    import time\n    nanoseconds = time.time_ns()\n    # 0x01b21dd213814000 is the number of 100-ns intervals between the\n    # UUID epoch 1582-10-15 00:00:00 and the Unix epoch 1970-01-01 00:00:00.\n    timestamp = nanoseconds // 100 + 0x01b21dd213814000\n    if _last_timestamp is not None and timestamp <= _last_timestamp:\n        timestamp = _last_timestamp + 1\n    _last_timestamp = timestamp\n    if clock_seq is None:\n        import random\n        clock_seq = random.getrandbits(14) # instead of stable storage\n    time_low = timestamp & 0xffffffff\n    time_mid = (timestamp >> 32) & 0xffff\n    time_hi_version = (timestamp >> 48) & 0x0fff\n    clock_seq_low = clock_seq & 0xff\n    clock_seq_hi_variant = (clock_seq >> 8) & 0x3f\n    if node is None:\n        node = getnode()\n    return UUID(fields=(time_low, time_mid, time_hi_version,\n                        clock_seq_hi_variant, clock_seq_low, node), version=1)",
        "name_type": "stdlib"
    },
    "uuid.uuid3": {
        "API_name": "uuid.uuid3",
        "loc_name": "uuid.uuid3",
        "args": "namespace;name",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 704,
        "namespace": "*",
        "body": "def uuid3(namespace, name):\n    \"\"\"Generate a UUID from the MD5 hash of a namespace UUID and a name.\"\"\"\n    from hashlib import md5\n    digest = md5(\n        namespace.bytes + bytes(name, \"utf-8\"),\n        usedforsecurity=False\n    ).digest()\n    return UUID(bytes=digest[:16], version=3)",
        "name_type": "stdlib"
    },
    "uuid.uuid4": {
        "API_name": "uuid.uuid4",
        "loc_name": "uuid.uuid4",
        "args": "",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 713,
        "namespace": "*",
        "body": "def uuid4():\n    \"\"\"Generate a random UUID.\"\"\"\n    return UUID(bytes=os.urandom(16), version=4)",
        "name_type": "stdlib"
    },
    "uuid.uuid5": {
        "API_name": "uuid.uuid5",
        "loc_name": "uuid.uuid5",
        "args": "namespace;name",
        "args_default": 0,
        "filepath": "uuid",
        "lineno": 717,
        "namespace": "*",
        "body": "def uuid5(namespace, name):\n    \"\"\"Generate a UUID from the SHA-1 hash of a namespace UUID and a name.\"\"\"\n    from hashlib import sha1\n    hash = sha1(namespace.bytes + bytes(name, \"utf-8\")).digest()\n    return UUID(bytes=hash[:16], version=5)",
        "name_type": "stdlib"
    },
    "html.entities": {
        "API_name": "html.entities",
        "loc_name": "html.entities",
        "args": "*",
        "args_default": "*",
        "filepath": "html.entities",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"HTML character entity references.\"\"\"\n__all__ = ['html5', 'name2codepoint', 'codepoint2name', 'entitydefs']\nname2codepoint = {\n    'AElig':    0x00c6, # latin capital letter AE = latin capital ligature AE, U+00C6 ISOlat1\n    'Aacute':   0x00c1, # latin capital letter A with acute, U+00C1 ISOlat1\n    'Acirc':    0x00c2, # latin capital letter A with circumflex, U+00C2 ISOlat1\n    'Agrave':   0x00c0, # latin capital letter A with grave = latin capital letter A grave, U+00C0 ISOlat1\n    'Alpha':    0x0391, # greek capital letter alpha, U+0391\n    'Aring':    0x00c5, # latin capital letter A with ring above = latin capital letter A ring, U+00C5 ISOlat1\n    'Atilde':   0x00c3, # latin capital letter A with tilde, U+00C3 ISOlat1\n    'Auml':     0x00c4, # latin capital letter A with diaeresis, U+00C4 ISOlat1\n    'Beta':     0x0392, # greek capital letter beta, U+0392\n    'Ccedil':   0x00c7, # latin capital letter C with cedilla, U+00C7 ISOlat1\n    'Chi':      0x03a7, # greek capital letter chi, U+03A7\n    'Dagger':   0x2021, # double dagger, U+2021 ISOpub\n    'Delta':    0x0394, # greek capital letter delta, U+0394 ISOgrk3\n    'ETH':      0x00d0, # latin capital letter ETH, U+00D0 ISOlat1\n    'Eacute':   0x00c9, # latin capital letter E with acute, U+00C9 ISOlat1\n    'Ecirc':    0x00ca, # latin capital letter E with circumflex, U+00CA ISOlat1\n    'Egrave':   0x00c8, # latin capital letter E with grave, U+00C8 ISOlat1\n    'Epsilon':  0x0395, # greek capital letter epsilon, U+0395\n    'Eta':      0x0397, # greek capital letter eta, U+0397\n    'Euml':     0x00cb, # latin capital letter E with diaeresis, U+00CB ISOlat1\n    'Gamma':    0x0393, # greek capital letter gamma, U+0393 ISOgrk3\n    'Iacute':   0x00cd, # latin capital letter I with acute, U+00CD ISOlat1\n    'Icirc':    0x00ce, # latin capital letter I with circumflex, U+00CE ISOlat1\n    'Igrave':   0x00cc, # latin capital letter I with grave, U+00CC ISOlat1\n    'Iota':     0x0399, # greek capital letter iota, U+0399\n    'Iuml':     0x00cf, # latin capital letter I with diaeresis, U+00CF ISOlat1\n    'Kappa':    0x039a, # greek capital letter kappa, U+039A\n    'Lambda':   0x039b, # greek capital letter lambda, U+039B ISOgrk3\n    'Mu':       0x039c, # greek capital letter mu, U+039C\n    'Ntilde':   0x00d1, # latin capital letter N with tilde, U+00D1 ISOlat1\n    'Nu':       0x039d, # greek capital letter nu, U+039D\n    'OElig':    0x0152, # latin capital ligature OE, U+0152 ISOlat2\n    'Oacute':   0x00d3, # latin capital letter O with acute, U+00D3 ISOlat1\n    'Ocirc':    0x00d4, # latin capital letter O with circumflex, U+00D4 ISOlat1\n    'Ograve':   0x00d2, # latin capital letter O with grave, U+00D2 ISOlat1\n    'Omega':    0x03a9, # greek capital letter omega, U+03A9 ISOgrk3\n    'Omicron':  0x039f, # greek capital letter omicron, U+039F\n    'Oslash':   0x00d8, # latin capital letter O with stroke = latin capital letter O slash, U+00D8 ISOlat1\n    'Otilde':   0x00d5, # latin capital letter O with tilde, U+00D5 ISOlat1\n    'Ouml':     0x00d6, # latin capital letter O with diaeresis, U+00D6 ISOlat1\n    'Phi':      0x03a6, # greek capital letter phi, U+03A6 ISOgrk3\n    'Pi':       0x03a0, # greek capital letter pi, U+03A0 ISOgrk3\n    'Prime':    0x2033, # double prime = seconds = inches, U+2033 ISOtech\n    'Psi':      0x03a8, # greek capital letter psi, U+03A8 ISOgrk3\n    'Rho':      0x03a1, # greek capital letter rho, U+03A1\n    'Scaron':   0x0160, # latin capital letter S with caron, U+0160 ISOlat2\n    'Sigma':    0x03a3, # greek capital letter sigma, U+03A3 ISOgrk3\n    'THORN':    0x00de, # latin capital letter THORN, U+00DE ISOlat1\n    'Tau':      0x03a4, # greek capital letter tau, U+03A4\n    'Theta':    0x0398, # greek capital letter theta, U+0398 ISOgrk3\n    'Uacute':   0x00da, # latin capital letter U with acute, U+00DA ISOlat1\n    'Ucirc':    0x00db, # latin capital letter U with circumflex, U+00DB ISOlat1\n    'Ugrave':   0x00d9, # latin capital letter U with grave, U+00D9 ISOlat1\n    'Upsilon':  0x03a5, # greek capital letter upsilon, U+03A5 ISOgrk3\n    'Uuml':     0x00dc, # latin capital letter U with diaeresis, U+00DC ISOlat1\n    'Xi':       0x039e, # greek capital letter xi, U+039E ISOgrk3\n    'Yacute':   0x00dd, # latin capital letter Y with acute, U+00DD ISOlat1\n    'Yuml':     0x0178, # latin capital letter Y with diaeresis, U+0178 ISOlat2\n    'Zeta':     0x0396, # greek capital letter zeta, U+0396\n    'aacute':   0x00e1, # latin small letter a with acute, U+00E1 ISOlat1\n    'acirc':    0x00e2, # latin small letter a with circumflex, U+00E2 ISOlat1\n    'acute':    0x00b4, # acute accent = spacing acute, U+00B4 ISOdia\n    'aelig':    0x00e6, # latin small letter ae = latin small ligature ae, U+00E6 ISOlat1\n    'agrave':   0x00e0, # latin small letter a with grave = latin small letter a grave, U+00E0 ISOlat1\n    'alefsym':  0x2135, # alef symbol = first transfinite cardinal, U+2135 NEW\n    'alpha':    0x03b1, # greek small letter alpha, U+03B1 ISOgrk3\n    'amp':      0x0026, # ampersand, U+0026 ISOnum\n    'and':      0x2227, # logical and = wedge, U+2227 ISOtech\n    'ang':      0x2220, # angle, U+2220 ISOamso\n    'aring':    0x00e5, # latin small letter a with ring above = latin small letter a ring, U+00E5 ISOlat1\n    'asymp':    0x2248, # almost equal to = asymptotic to, U+2248 ISOamsr\n    'atilde':   0x00e3, # latin small letter a with tilde, U+00E3 ISOlat1\n    'auml':     0x00e4, # latin small letter a with diaeresis, U+00E4 ISOlat1\n    'bdquo':    0x201e, # double low-9 quotation mark, U+201E NEW\n    'beta':     0x03b2, # greek small letter beta, U+03B2 ISOgrk3\n    'brvbar':   0x00a6, # broken bar = broken vertical bar, U+00A6 ISOnum\n    'bull':     0x2022, # bullet = black small circle, U+2022 ISOpub\n    'cap':      0x2229, # intersection = cap, U+2229 ISOtech\n    'ccedil':   0x00e7, # latin small letter c with cedilla, U+00E7 ISOlat1\n    'cedil':    0x00b8, # cedilla = spacing cedilla, U+00B8 ISOdia\n    'cent':     0x00a2, # cent sign, U+00A2 ISOnum\n    'chi':      0x03c7, # greek small letter chi, U+03C7 ISOgrk3\n    'circ':     0x02c6, # modifier letter circumflex accent, U+02C6 ISOpub\n    'clubs':    0x2663, # black club suit = shamrock, U+2663 ISOpub\n    'cong':     0x2245, # approximately equal to, U+2245 ISOtech\n    'copy':     0x00a9, # copyright sign, U+00A9 ISOnum\n    'crarr':    0x21b5, # downwards arrow with corner leftwards = carriage return, U+21B5 NEW\n    'cup':      0x222a, # union = cup, U+222A ISOtech\n    'curren':   0x00a4, # currency sign, U+00A4 ISOnum\n    'dArr':     0x21d3, # downwards double arrow, U+21D3 ISOamsa\n    'dagger':   0x2020, # dagger, U+2020 ISOpub\n    'darr':     0x2193, # downwards arrow, U+2193 ISOnum\n    'deg':      0x00b0, # degree sign, U+00B0 ISOnum\n    'delta':    0x03b4, # greek small letter delta, U+03B4 ISOgrk3\n    'diams':    0x2666, # black diamond suit, U+2666 ISOpub\n    'divide':   0x00f7, # division sign, U+00F7 ISOnum\n    'eacute':   0x00e9, # latin small letter e with acute, U+00E9 ISOlat1\n    'ecirc':    0x00ea, # latin small letter e with circumflex, U+00EA ISOlat1\n    'egrave':   0x00e8, # latin small letter e with grave, U+00E8 ISOlat1\n    'empty':    0x2205, # empty set = null set = diameter, U+2205 ISOamso\n    'emsp':     0x2003, # em space, U+2003 ISOpub\n    'ensp':     0x2002, # en space, U+2002 ISOpub\n    'epsilon':  0x03b5, # greek small letter epsilon, U+03B5 ISOgrk3\n    'equiv':    0x2261, # identical to, U+2261 ISOtech\n    'eta':      0x03b7, # greek small letter eta, U+03B7 ISOgrk3\n    'eth':      0x00f0, # latin small letter eth, U+00F0 ISOlat1\n    'euml':     0x00eb, # latin small letter e with diaeresis, U+00EB ISOlat1\n    'euro':     0x20ac, # euro sign, U+20AC NEW\n    'exist':    0x2203, # there exists, U+2203 ISOtech\n    'fnof':     0x0192, # latin small f with hook = function = florin, U+0192 ISOtech\n    'forall':   0x2200, # for all, U+2200 ISOtech\n    'frac12':   0x00bd, # vulgar fraction one half = fraction one half, U+00BD ISOnum\n    'frac14':   0x00bc, # vulgar fraction one quarter = fraction one quarter, U+00BC ISOnum\n    'frac34':   0x00be, # vulgar fraction three quarters = fraction three quarters, U+00BE ISOnum\n    'frasl':    0x2044, # fraction slash, U+2044 NEW\n    'gamma':    0x03b3, # greek small letter gamma, U+03B3 ISOgrk3\n    'ge':       0x2265, # greater-than or equal to, U+2265 ISOtech\n    'gt':       0x003e, # greater-than sign, U+003E ISOnum\n    'hArr':     0x21d4, # left right double arrow, U+21D4 ISOamsa\n    'harr':     0x2194, # left right arrow, U+2194 ISOamsa\n    'hearts':   0x2665, # black heart suit = valentine, U+2665 ISOpub\n    'hellip':   0x2026, # horizontal ellipsis = three dot leader, U+2026 ISOpub\n    'iacute':   0x00ed, # latin small letter i with acute, U+00ED ISOlat1\n    'icirc':    0x00ee, # latin small letter i with circumflex, U+00EE ISOlat1\n    'iexcl':    0x00a1, # inverted exclamation mark, U+00A1 ISOnum\n    'igrave':   0x00ec, # latin small letter i with grave, U+00EC ISOlat1\n    'image':    0x2111, # blackletter capital I = imaginary part, U+2111 ISOamso\n    'infin':    0x221e, # infinity, U+221E ISOtech\n    'int':      0x222b, # integral, U+222B ISOtech\n    'iota':     0x03b9, # greek small letter iota, U+03B9 ISOgrk3\n    'iquest':   0x00bf, # inverted question mark = turned question mark, U+00BF ISOnum\n    'isin':     0x2208, # element of, U+2208 ISOtech\n    'iuml':     0x00ef, # latin small letter i with diaeresis, U+00EF ISOlat1\n    'kappa':    0x03ba, # greek small letter kappa, U+03BA ISOgrk3\n    'lArr':     0x21d0, # leftwards double arrow, U+21D0 ISOtech\n    'lambda':   0x03bb, # greek small letter lambda, U+03BB ISOgrk3\n    'lang':     0x2329, # left-pointing angle bracket = bra, U+2329 ISOtech\n    'laquo':    0x00ab, # left-pointing double angle quotation mark = left pointing guillemet, U+00AB ISOnum\n    'larr':     0x2190, # leftwards arrow, U+2190 ISOnum\n    'lceil':    0x2308, # left ceiling = apl upstile, U+2308 ISOamsc\n    'ldquo':    0x201c, # left double quotation mark, U+201C ISOnum\n    'le':       0x2264, # less-than or equal to, U+2264 ISOtech\n    'lfloor':   0x230a, # left floor = apl downstile, U+230A ISOamsc\n    'lowast':   0x2217, # asterisk operator, U+2217 ISOtech\n    'loz':      0x25ca, # lozenge, U+25CA ISOpub\n    'lrm':      0x200e, # left-to-right mark, U+200E NEW RFC 2070\n    'lsaquo':   0x2039, # single left-pointing angle quotation mark, U+2039 ISO proposed\n    'lsquo':    0x2018, # left single quotation mark, U+2018 ISOnum\n    'lt':       0x003c, # less-than sign, U+003C ISOnum\n    'macr':     0x00af, # macron = spacing macron = overline = APL overbar, U+00AF ISOdia\n    'mdash':    0x2014, # em dash, U+2014 ISOpub\n    'micro':    0x00b5, # micro sign, U+00B5 ISOnum\n    'middot':   0x00b7, # middle dot = Georgian comma = Greek middle dot, U+00B7 ISOnum\n    'minus':    0x2212, # minus sign, U+2212 ISOtech\n    'mu':       0x03bc, # greek small letter mu, U+03BC ISOgrk3\n    'nabla':    0x2207, # nabla = backward difference, U+2207 ISOtech\n    'nbsp':     0x00a0, # no-break space = non-breaking space, U+00A0 ISOnum\n    'ndash':    0x2013, # en dash, U+2013 ISOpub\n    'ne':       0x2260, # not equal to, U+2260 ISOtech\n    'ni':       0x220b, # contains as member, U+220B ISOtech\n    'not':      0x00ac, # not sign, U+00AC ISOnum\n    'notin':    0x2209, # not an element of, U+2209 ISOtech\n    'nsub':     0x2284, # not a subset of, U+2284 ISOamsn\n    'ntilde':   0x00f1, # latin small letter n with tilde, U+00F1 ISOlat1\n    'nu':       0x03bd, # greek small letter nu, U+03BD ISOgrk3\n    'oacute':   0x00f3, # latin small letter o with acute, U+00F3 ISOlat1\n    'ocirc':    0x00f4, # latin small letter o with circumflex, U+00F4 ISOlat1\n    'oelig':    0x0153, # latin small ligature oe, U+0153 ISOlat2\n    'ograve':   0x00f2, # latin small letter o with grave, U+00F2 ISOlat1\n    'oline':    0x203e, # overline = spacing overscore, U+203E NEW\n    'omega':    0x03c9, # greek small letter omega, U+03C9 ISOgrk3\n    'omicron':  0x03bf, # greek small letter omicron, U+03BF NEW\n    'oplus':    0x2295, # circled plus = direct sum, U+2295 ISOamsb\n    'or':       0x2228, # logical or = vee, U+2228 ISOtech\n    'ordf':     0x00aa, # feminine ordinal indicator, U+00AA ISOnum\n    'ordm':     0x00ba, # masculine ordinal indicator, U+00BA ISOnum\n    'oslash':   0x00f8, # latin small letter o with stroke, = latin small letter o slash, U+00F8 ISOlat1\n    'otilde':   0x00f5, # latin small letter o with tilde, U+00F5 ISOlat1\n    'otimes':   0x2297, # circled times = vector product, U+2297 ISOamsb\n    'ouml':     0x00f6, # latin small letter o with diaeresis, U+00F6 ISOlat1\n    'para':     0x00b6, # pilcrow sign = paragraph sign, U+00B6 ISOnum\n    'part':     0x2202, # partial differential, U+2202 ISOtech\n    'permil':   0x2030, # per mille sign, U+2030 ISOtech\n    'perp':     0x22a5, # up tack = orthogonal to = perpendicular, U+22A5 ISOtech\n    'phi':      0x03c6, # greek small letter phi, U+03C6 ISOgrk3\n    'pi':       0x03c0, # greek small letter pi, U+03C0 ISOgrk3\n    'piv':      0x03d6, # greek pi symbol, U+03D6 ISOgrk3\n    'plusmn':   0x00b1, # plus-minus sign = plus-or-minus sign, U+00B1 ISOnum\n    'pound':    0x00a3, # pound sign, U+00A3 ISOnum\n    'prime':    0x2032, # prime = minutes = feet, U+2032 ISOtech\n    'prod':     0x220f, # n-ary product = product sign, U+220F ISOamsb\n    'prop':     0x221d, # proportional to, U+221D ISOtech\n    'psi':      0x03c8, # greek small letter psi, U+03C8 ISOgrk3\n    'quot':     0x0022, # quotation mark = APL quote, U+0022 ISOnum\n    'rArr':     0x21d2, # rightwards double arrow, U+21D2 ISOtech\n    'radic':    0x221a, # square root = radical sign, U+221A ISOtech\n    'rang':     0x232a, # right-pointing angle bracket = ket, U+232A ISOtech\n    'raquo':    0x00bb, # right-pointing double angle quotation mark = right pointing guillemet, U+00BB ISOnum\n    'rarr':     0x2192, # rightwards arrow, U+2192 ISOnum\n    'rceil':    0x2309, # right ceiling, U+2309 ISOamsc\n    'rdquo':    0x201d, # right double quotation mark, U+201D ISOnum\n    'real':     0x211c, # blackletter capital R = real part symbol, U+211C ISOamso\n    'reg':      0x00ae, # registered sign = registered trade mark sign, U+00AE ISOnum\n    'rfloor':   0x230b, # right floor, U+230B ISOamsc\n    'rho':      0x03c1, # greek small letter rho, U+03C1 ISOgrk3\n    'rlm':      0x200f, # right-to-left mark, U+200F NEW RFC 2070\n    'rsaquo':   0x203a, # single right-pointing angle quotation mark, U+203A ISO proposed\n    'rsquo':    0x2019, # right single quotation mark, U+2019 ISOnum\n    'sbquo':    0x201a, # single low-9 quotation mark, U+201A NEW\n    'scaron':   0x0161, # latin small letter s with caron, U+0161 ISOlat2\n    'sdot':     0x22c5, # dot operator, U+22C5 ISOamsb\n    'sect':     0x00a7, # section sign, U+00A7 ISOnum\n    'shy':      0x00ad, # soft hyphen = discretionary hyphen, U+00AD ISOnum\n    'sigma':    0x03c3, # greek small letter sigma, U+03C3 ISOgrk3\n    'sigmaf':   0x03c2, # greek small letter final sigma, U+03C2 ISOgrk3\n    'sim':      0x223c, # tilde operator = varies with = similar to, U+223C ISOtech\n    'spades':   0x2660, # black spade suit, U+2660 ISOpub\n    'sub':      0x2282, # subset of, U+2282 ISOtech\n    'sube':     0x2286, # subset of or equal to, U+2286 ISOtech\n    'sum':      0x2211, # n-ary summation, U+2211 ISOamsb\n    'sup':      0x2283, # superset of, U+2283 ISOtech\n    'sup1':     0x00b9, # superscript one = superscript digit one, U+00B9 ISOnum\n    'sup2':     0x00b2, # superscript two = superscript digit two = squared, U+00B2 ISOnum\n    'sup3':     0x00b3, # superscript three = superscript digit three = cubed, U+00B3 ISOnum\n    'supe':     0x2287, # superset of or equal to, U+2287 ISOtech\n    'szlig':    0x00df, # latin small letter sharp s = ess-zed, U+00DF ISOlat1\n    'tau':      0x03c4, # greek small letter tau, U+03C4 ISOgrk3\n    'there4':   0x2234, # therefore, U+2234 ISOtech\n    'theta':    0x03b8, # greek small letter theta, U+03B8 ISOgrk3\n    'thetasym': 0x03d1, # greek small letter theta symbol, U+03D1 NEW\n    'thinsp':   0x2009, # thin space, U+2009 ISOpub\n    'thorn':    0x00fe, # latin small letter thorn with, U+00FE ISOlat1\n    'tilde':    0x02dc, # small tilde, U+02DC ISOdia\n    'times':    0x00d7, # multiplication sign, U+00D7 ISOnum\n    'trade':    0x2122, # trade mark sign, U+2122 ISOnum\n    'uArr':     0x21d1, # upwards double arrow, U+21D1 ISOamsa\n    'uacute':   0x00fa, # latin small letter u with acute, U+00FA ISOlat1\n    'uarr':     0x2191, # upwards arrow, U+2191 ISOnum\n    'ucirc':    0x00fb, # latin small letter u with circumflex, U+00FB ISOlat1\n    'ugrave':   0x00f9, # latin small letter u with grave, U+00F9 ISOlat1\n    'uml':      0x00a8, # diaeresis = spacing diaeresis, U+00A8 ISOdia\n    'upsih':    0x03d2, # greek upsilon with hook symbol, U+03D2 NEW\n    'upsilon':  0x03c5, # greek small letter upsilon, U+03C5 ISOgrk3\n    'uuml':     0x00fc, # latin small letter u with diaeresis, U+00FC ISOlat1\n    'weierp':   0x2118, # script capital P = power set = Weierstrass p, U+2118 ISOamso\n    'xi':       0x03be, # greek small letter xi, U+03BE ISOgrk3\n    'yacute':   0x00fd, # latin small letter y with acute, U+00FD ISOlat1\n    'yen':      0x00a5, # yen sign = yuan sign, U+00A5 ISOnum\n    'yuml':     0x00ff, # latin small letter y with diaeresis, U+00FF ISOlat1\n    'zeta':     0x03b6, # greek small letter zeta, U+03B6 ISOgrk3\n    'zwj':      0x200d, # zero width joiner, U+200D NEW RFC 2070\n    'zwnj':     0x200c, # zero width non-joiner, U+200C NEW RFC 2070\n}\nhtml5 = {\n    'Aacute': '\\xc1',\n    'aacute': '\\xe1',\n    'Aacute;': '\\xc1',\n    'aacute;': '\\xe1',\n    'Abreve;': '\\u0102',\n    'abreve;': '\\u0103',\n    'ac;': '\\u223e',\n    'acd;': '\\u223f',\n    'acE;': '\\u223e\\u0333',\n    'Acirc': '\\xc2',\n    'acirc': '\\xe2',\n    'Acirc;': '\\xc2',\n    'acirc;': '\\xe2',\n    'acute': '\\xb4',\n    'acute;': '\\xb4',\n    'Acy;': '\\u0410',\n    'acy;': '\\u0430',\n    'AElig': '\\xc6',\n    'aelig': '\\xe6',\n    'AElig;': '\\xc6',\n    'aelig;': '\\xe6',\n    'af;': '\\u2061',\n    'Afr;': '\\U0001d504',\n    'afr;': '\\U0001d51e',\n    'Agrave': '\\xc0',\n    'agrave': '\\xe0',\n    'Agrave;': '\\xc0',\n    'agrave;': '\\xe0',\n    'alefsym;': '\\u2135',\n    'aleph;': '\\u2135',\n    'Alpha;': '\\u0391',\n    'alpha;': '\\u03b1',\n    'Amacr;': '\\u0100',\n    'amacr;': '\\u0101',\n    'amalg;': '\\u2a3f',\n    'AMP': '&',\n    'amp': '&',\n    'AMP;': '&',\n    'amp;': '&',\n    'And;': '\\u2a53',\n    'and;': '\\u2227',\n    'andand;': '\\u2a55',\n    'andd;': '\\u2a5c',\n    'andslope;': '\\u2a58',\n    'andv;': '\\u2a5a',\n    'ang;': '\\u2220',\n    'ange;': '\\u29a4',\n    'angle;': '\\u2220',\n    'angmsd;': '\\u2221',\n    'angmsdaa;': '\\u29a8',\n    'angmsdab;': '\\u29a9',\n    'angmsdac;': '\\u29aa',\n    'angmsdad;': '\\u29ab',\n    'angmsdae;': '\\u29ac',\n    'angmsdaf;': '\\u29ad',\n    'angmsdag;': '\\u29ae',\n    'angmsdah;': '\\u29af',\n    'angrt;': '\\u221f',\n    'angrtvb;': '\\u22be',\n    'angrtvbd;': '\\u299d',\n    'angsph;': '\\u2222',\n    'angst;': '\\xc5',\n    'angzarr;': '\\u237c',\n    'Aogon;': '\\u0104',\n    'aogon;': '\\u0105',\n    'Aopf;': '\\U0001d538',\n    'aopf;': '\\U0001d552',\n    'ap;': '\\u2248',\n    'apacir;': '\\u2a6f',\n    'apE;': '\\u2a70',\n    'ape;': '\\u224a',\n    'apid;': '\\u224b',\n    'apos;': \"'\",\n    'ApplyFunction;': '\\u2061',\n    'approx;': '\\u2248',\n    'approxeq;': '\\u224a',\n    'Aring': '\\xc5',\n    'aring': '\\xe5',\n    'Aring;': '\\xc5',\n    'aring;': '\\xe5',\n    'Ascr;': '\\U0001d49c',\n    'ascr;': '\\U0001d4b6',\n    'Assign;': '\\u2254',\n    'ast;': '*',\n    'asymp;': '\\u2248',\n    'asympeq;': '\\u224d',\n    'Atilde': '\\xc3',\n    'atilde': '\\xe3',\n    'Atilde;': '\\xc3',\n    'atilde;': '\\xe3',\n    'Auml': '\\xc4',\n    'auml': '\\xe4',\n    'Auml;': '\\xc4',\n    'auml;': '\\xe4',\n    'awconint;': '\\u2233',\n    'awint;': '\\u2a11',\n    'backcong;': '\\u224c',\n    'backepsilon;': '\\u03f6',\n    'backprime;': '\\u2035',\n    'backsim;': '\\u223d',\n    'backsimeq;': '\\u22cd',\n    'Backslash;': '\\u2216',\n    'Barv;': '\\u2ae7',\n    'barvee;': '\\u22bd',\n    'Barwed;': '\\u2306',\n    'barwed;': '\\u2305',\n    'barwedge;': '\\u2305',\n    'bbrk;': '\\u23b5',\n    'bbrktbrk;': '\\u23b6',\n    'bcong;': '\\u224c',\n    'Bcy;': '\\u0411',\n    'bcy;': '\\u0431',\n    'bdquo;': '\\u201e',\n    'becaus;': '\\u2235',\n    'Because;': '\\u2235',\n    'because;': '\\u2235',\n    'bemptyv;': '\\u29b0',\n    'bepsi;': '\\u03f6',\n    'bernou;': '\\u212c',\n    'Bernoullis;': '\\u212c',\n    'Beta;': '\\u0392',\n    'beta;': '\\u03b2',\n    'beth;': '\\u2136',\n    'between;': '\\u226c',\n    'Bfr;': '\\U0001d505',\n    'bfr;': '\\U0001d51f',\n    'bigcap;': '\\u22c2',\n    'bigcirc;': '\\u25ef',\n    'bigcup;': '\\u22c3',\n    'bigodot;': '\\u2a00',\n    'bigoplus;': '\\u2a01',\n    'bigotimes;': '\\u2a02',\n    'bigsqcup;': '\\u2a06',\n    'bigstar;': '\\u2605',\n    'bigtriangledown;': '\\u25bd',\n    'bigtriangleup;': '\\u25b3',\n    'biguplus;': '\\u2a04',\n    'bigvee;': '\\u22c1',\n    'bigwedge;': '\\u22c0',\n    'bkarow;': '\\u290d',\n    'blacklozenge;': '\\u29eb',\n    'blacksquare;': '\\u25aa',\n    'blacktriangle;': '\\u25b4',\n    'blacktriangledown;': '\\u25be',\n    'blacktriangleleft;': '\\u25c2',\n    'blacktriangleright;': '\\u25b8',\n    'blank;': '\\u2423',\n    'blk12;': '\\u2592',\n    'blk14;': '\\u2591',\n    'blk34;': '\\u2593',\n    'block;': '\\u2588',\n    'bne;': '=\\u20e5',\n    'bnequiv;': '\\u2261\\u20e5',\n    'bNot;': '\\u2aed',\n    'bnot;': '\\u2310',\n    'Bopf;': '\\U0001d539',\n    'bopf;': '\\U0001d553',\n    'bot;': '\\u22a5',\n    'bottom;': '\\u22a5',\n    'bowtie;': '\\u22c8',\n    'boxbox;': '\\u29c9',\n    'boxDL;': '\\u2557',\n    'boxDl;': '\\u2556',\n    'boxdL;': '\\u2555',\n    'boxdl;': '\\u2510',\n    'boxDR;': '\\u2554',\n    'boxDr;': '\\u2553',\n    'boxdR;': '\\u2552',\n    'boxdr;': '\\u250c',\n    'boxH;': '\\u2550',\n    'boxh;': '\\u2500',\n    'boxHD;': '\\u2566',\n    'boxHd;': '\\u2564',\n    'boxhD;': '\\u2565',\n    'boxhd;': '\\u252c',\n    'boxHU;': '\\u2569',\n    'boxHu;': '\\u2567',\n    'boxhU;': '\\u2568',\n    'boxhu;': '\\u2534',\n    'boxminus;': '\\u229f',\n    'boxplus;': '\\u229e',\n    'boxtimes;': '\\u22a0',\n    'boxUL;': '\\u255d',\n    'boxUl;': '\\u255c',\n    'boxuL;': '\\u255b',\n    'boxul;': '\\u2518',\n    'boxUR;': '\\u255a',\n    'boxUr;': '\\u2559',\n    'boxuR;': '\\u2558',\n    'boxur;': '\\u2514',\n    'boxV;': '\\u2551',\n    'boxv;': '\\u2502',\n    'boxVH;': '\\u256c',\n    'boxVh;': '\\u256b',\n    'boxvH;': '\\u256a',\n    'boxvh;': '\\u253c',\n    'boxVL;': '\\u2563',\n    'boxVl;': '\\u2562',\n    'boxvL;': '\\u2561',\n    'boxvl;': '\\u2524',\n    'boxVR;': '\\u2560',\n    'boxVr;': '\\u255f',\n    'boxvR;': '\\u255e',\n    'boxvr;': '\\u251c',\n    'bprime;': '\\u2035',\n    'Breve;': '\\u02d8',\n    'breve;': '\\u02d8',\n    'brvbar': '\\xa6',\n    'brvbar;': '\\xa6',\n    'Bscr;': '\\u212c',\n    'bscr;': '\\U0001d4b7',\n    'bsemi;': '\\u204f',\n    'bsim;': '\\u223d',\n    'bsime;': '\\u22cd',\n    'bsol;': '\\\\',\n    'bsolb;': '\\u29c5',\n    'bsolhsub;': '\\u27c8',\n    'bull;': '\\u2022',\n    'bullet;': '\\u2022',\n    'bump;': '\\u224e',\n    'bumpE;': '\\u2aae',\n    'bumpe;': '\\u224f',\n    'Bumpeq;': '\\u224e',\n    'bumpeq;': '\\u224f',\n    'Cacute;': '\\u0106',\n    'cacute;': '\\u0107',\n    'Cap;': '\\u22d2',\n    'cap;': '\\u2229',\n    'capand;': '\\u2a44',\n    'capbrcup;': '\\u2a49',\n    'capcap;': '\\u2a4b',\n    'capcup;': '\\u2a47',\n    'capdot;': '\\u2a40',\n    'CapitalDifferentialD;': '\\u2145',\n    'caps;': '\\u2229\\ufe00',\n    'caret;': '\\u2041',\n    'caron;': '\\u02c7',\n    'Cayleys;': '\\u212d',\n    'ccaps;': '\\u2a4d',\n    'Ccaron;': '\\u010c',\n    'ccaron;': '\\u010d',\n    'Ccedil': '\\xc7',\n    'ccedil': '\\xe7',\n    'Ccedil;': '\\xc7',\n    'ccedil;': '\\xe7',\n    'Ccirc;': '\\u0108',\n    'ccirc;': '\\u0109',\n    'Cconint;': '\\u2230',\n    'ccups;': '\\u2a4c',\n    'ccupssm;': '\\u2a50',\n    'Cdot;': '\\u010a',\n    'cdot;': '\\u010b',\n    'cedil': '\\xb8',\n    'cedil;': '\\xb8',\n    'Cedilla;': '\\xb8',\n    'cemptyv;': '\\u29b2',\n    'cent': '\\xa2',\n    'cent;': '\\xa2',\n    'CenterDot;': '\\xb7',\n    'centerdot;': '\\xb7',\n    'Cfr;': '\\u212d',\n    'cfr;': '\\U0001d520',\n    'CHcy;': '\\u0427',\n    'chcy;': '\\u0447',\n    'check;': '\\u2713',\n    'checkmark;': '\\u2713',\n    'Chi;': '\\u03a7',\n    'chi;': '\\u03c7',\n    'cir;': '\\u25cb',\n    'circ;': '\\u02c6',\n    'circeq;': '\\u2257',\n    'circlearrowleft;': '\\u21ba',\n    'circlearrowright;': '\\u21bb',\n    'circledast;': '\\u229b',\n    'circledcirc;': '\\u229a',\n    'circleddash;': '\\u229d',\n    'CircleDot;': '\\u2299',\n    'circledR;': '\\xae',\n    'circledS;': '\\u24c8',\n    'CircleMinus;': '\\u2296',\n    'CirclePlus;': '\\u2295',\n    'CircleTimes;': '\\u2297',\n    'cirE;': '\\u29c3',\n    'cire;': '\\u2257',\n    'cirfnint;': '\\u2a10',\n    'cirmid;': '\\u2aef',\n    'cirscir;': '\\u29c2',\n    'ClockwiseContourIntegral;': '\\u2232',\n    'CloseCurlyDoubleQuote;': '\\u201d',\n    'CloseCurlyQuote;': '\\u2019',\n    'clubs;': '\\u2663',\n    'clubsuit;': '\\u2663',\n    'Colon;': '\\u2237',\n    'colon;': ':',\n    'Colone;': '\\u2a74',\n    'colone;': '\\u2254',\n    'coloneq;': '\\u2254',\n    'comma;': ',',\n    'commat;': '@',\n    'comp;': '\\u2201',\n    'compfn;': '\\u2218',\n    'complement;': '\\u2201',\n    'complexes;': '\\u2102',\n    'cong;': '\\u2245',\n    'congdot;': '\\u2a6d',\n    'Congruent;': '\\u2261',\n    'Conint;': '\\u222f',\n    'conint;': '\\u222e',\n    'ContourIntegral;': '\\u222e',\n    'Copf;': '\\u2102',\n    'copf;': '\\U0001d554',\n    'coprod;': '\\u2210',\n    'Coproduct;': '\\u2210',\n    'COPY': '\\xa9',\n    'copy': '\\xa9',\n    'COPY;': '\\xa9',\n    'copy;': '\\xa9',\n    'copysr;': '\\u2117',\n    'CounterClockwiseContourIntegral;': '\\u2233',\n    'crarr;': '\\u21b5',\n    'Cross;': '\\u2a2f',\n    'cross;': '\\u2717',\n    'Cscr;': '\\U0001d49e',\n    'cscr;': '\\U0001d4b8',\n    'csub;': '\\u2acf',\n    'csube;': '\\u2ad1',\n    'csup;': '\\u2ad0',\n    'csupe;': '\\u2ad2',\n    'ctdot;': '\\u22ef',\n    'cudarrl;': '\\u2938',\n    'cudarrr;': '\\u2935',\n    'cuepr;': '\\u22de',\n    'cuesc;': '\\u22df',\n    'cularr;': '\\u21b6',\n    'cularrp;': '\\u293d',\n    'Cup;': '\\u22d3',\n    'cup;': '\\u222a',\n    'cupbrcap;': '\\u2a48',\n    'CupCap;': '\\u224d',\n    'cupcap;': '\\u2a46',\n    'cupcup;': '\\u2a4a',\n    'cupdot;': '\\u228d',\n    'cupor;': '\\u2a45',\n    'cups;': '\\u222a\\ufe00',\n    'curarr;': '\\u21b7',\n    'curarrm;': '\\u293c',\n    'curlyeqprec;': '\\u22de',\n    'curlyeqsucc;': '\\u22df',\n    'curlyvee;': '\\u22ce',\n    'curlywedge;': '\\u22cf',\n    'curren': '\\xa4',\n    'curren;': '\\xa4',\n    'curvearrowleft;': '\\u21b6',\n    'curvearrowright;': '\\u21b7',\n    'cuvee;': '\\u22ce',\n    'cuwed;': '\\u22cf',\n    'cwconint;': '\\u2232',\n    'cwint;': '\\u2231',\n    'cylcty;': '\\u232d',\n    'Dagger;': '\\u2021',\n    'dagger;': '\\u2020',\n    'daleth;': '\\u2138',\n    'Darr;': '\\u21a1',\n    'dArr;': '\\u21d3',\n    'darr;': '\\u2193',\n    'dash;': '\\u2010',\n    'Dashv;': '\\u2ae4',\n    'dashv;': '\\u22a3',\n    'dbkarow;': '\\u290f',\n    'dblac;': '\\u02dd',\n    'Dcaron;': '\\u010e',\n    'dcaron;': '\\u010f',\n    'Dcy;': '\\u0414',\n    'dcy;': '\\u0434',\n    'DD;': '\\u2145',\n    'dd;': '\\u2146',\n    'ddagger;': '\\u2021',\n    'ddarr;': '\\u21ca',\n    'DDotrahd;': '\\u2911',\n    'ddotseq;': '\\u2a77',\n    'deg': '\\xb0',\n    'deg;': '\\xb0',\n    'Del;': '\\u2207',\n    'Delta;': '\\u0394',\n    'delta;': '\\u03b4',\n    'demptyv;': '\\u29b1',\n    'dfisht;': '\\u297f',\n    'Dfr;': '\\U0001d507',\n    'dfr;': '\\U0001d521',\n    'dHar;': '\\u2965',\n    'dharl;': '\\u21c3',\n    'dharr;': '\\u21c2',\n    'DiacriticalAcute;': '\\xb4',\n    'DiacriticalDot;': '\\u02d9',\n    'DiacriticalDoubleAcute;': '\\u02dd',\n    'DiacriticalGrave;': '`',\n    'DiacriticalTilde;': '\\u02dc',\n    'diam;': '\\u22c4',\n    'Diamond;': '\\u22c4',\n    'diamond;': '\\u22c4',\n    'diamondsuit;': '\\u2666',\n    'diams;': '\\u2666',\n    'die;': '\\xa8',\n    'DifferentialD;': '\\u2146',\n    'digamma;': '\\u03dd',\n    'disin;': '\\u22f2',\n    'div;': '\\xf7',\n    'divide': '\\xf7',\n    'divide;': '\\xf7',\n    'divideontimes;': '\\u22c7',\n    'divonx;': '\\u22c7',\n    'DJcy;': '\\u0402',\n    'djcy;': '\\u0452',\n    'dlcorn;': '\\u231e',\n    'dlcrop;': '\\u230d',\n    'dollar;': '$',\n    'Dopf;': '\\U0001d53b',\n    'dopf;': '\\U0001d555',\n    'Dot;': '\\xa8',\n    'dot;': '\\u02d9',\n    'DotDot;': '\\u20dc',\n    'doteq;': '\\u2250',\n    'doteqdot;': '\\u2251',\n    'DotEqual;': '\\u2250',\n    'dotminus;': '\\u2238',\n    'dotplus;': '\\u2214',\n    'dotsquare;': '\\u22a1',\n    'doublebarwedge;': '\\u2306',\n    'DoubleContourIntegral;': '\\u222f',\n    'DoubleDot;': '\\xa8',\n    'DoubleDownArrow;': '\\u21d3',\n    'DoubleLeftArrow;': '\\u21d0',\n    'DoubleLeftRightArrow;': '\\u21d4',\n    'DoubleLeftTee;': '\\u2ae4',\n    'DoubleLongLeftArrow;': '\\u27f8',\n    'DoubleLongLeftRightArrow;': '\\u27fa',\n    'DoubleLongRightArrow;': '\\u27f9',\n    'DoubleRightArrow;': '\\u21d2',\n    'DoubleRightTee;': '\\u22a8',\n    'DoubleUpArrow;': '\\u21d1',\n    'DoubleUpDownArrow;': '\\u21d5',\n    'DoubleVerticalBar;': '\\u2225',\n    'DownArrow;': '\\u2193',\n    'Downarrow;': '\\u21d3',\n    'downarrow;': '\\u2193',\n    'DownArrowBar;': '\\u2913',\n    'DownArrowUpArrow;': '\\u21f5',\n    'DownBreve;': '\\u0311',\n    'downdownarrows;': '\\u21ca',\n    'downharpoonleft;': '\\u21c3',\n    'downharpoonright;': '\\u21c2',\n    'DownLeftRightVector;': '\\u2950',\n    'DownLeftTeeVector;': '\\u295e',\n    'DownLeftVector;': '\\u21bd',\n    'DownLeftVectorBar;': '\\u2956',\n    'DownRightTeeVector;': '\\u295f',\n    'DownRightVector;': '\\u21c1',\n    'DownRightVectorBar;': '\\u2957',\n    'DownTee;': '\\u22a4',\n    'DownTeeArrow;': '\\u21a7',\n    'drbkarow;': '\\u2910',\n    'drcorn;': '\\u231f',\n    'drcrop;': '\\u230c',\n    'Dscr;': '\\U0001d49f',\n    'dscr;': '\\U0001d4b9',\n    'DScy;': '\\u0405',\n    'dscy;': '\\u0455',\n    'dsol;': '\\u29f6',\n    'Dstrok;': '\\u0110',\n    'dstrok;': '\\u0111',\n    'dtdot;': '\\u22f1',\n    'dtri;': '\\u25bf',\n    'dtrif;': '\\u25be',\n    'duarr;': '\\u21f5',\n    'duhar;': '\\u296f',\n    'dwangle;': '\\u29a6',\n    'DZcy;': '\\u040f',\n    'dzcy;': '\\u045f',\n    'dzigrarr;': '\\u27ff',\n    'Eacute': '\\xc9',\n    'eacute': '\\xe9',\n    'Eacute;': '\\xc9',\n    'eacute;': '\\xe9',\n    'easter;': '\\u2a6e',\n    'Ecaron;': '\\u011a',\n    'ecaron;': '\\u011b',\n    'ecir;': '\\u2256',\n    'Ecirc': '\\xca',\n    'ecirc': '\\xea',\n    'Ecirc;': '\\xca',\n    'ecirc;': '\\xea',\n    'ecolon;': '\\u2255',\n    'Ecy;': '\\u042d',\n    'ecy;': '\\u044d',\n    'eDDot;': '\\u2a77',\n    'Edot;': '\\u0116',\n    'eDot;': '\\u2251',\n    'edot;': '\\u0117',\n    'ee;': '\\u2147',\n    'efDot;': '\\u2252',\n    'Efr;': '\\U0001d508',\n    'efr;': '\\U0001d522',\n    'eg;': '\\u2a9a',\n    'Egrave': '\\xc8',\n    'egrave': '\\xe8',\n    'Egrave;': '\\xc8',\n    'egrave;': '\\xe8',\n    'egs;': '\\u2a96',\n    'egsdot;': '\\u2a98',\n    'el;': '\\u2a99',\n    'Element;': '\\u2208',\n    'elinters;': '\\u23e7',\n    'ell;': '\\u2113',\n    'els;': '\\u2a95',\n    'elsdot;': '\\u2a97',\n    'Emacr;': '\\u0112',\n    'emacr;': '\\u0113',\n    'empty;': '\\u2205',\n    'emptyset;': '\\u2205',\n    'EmptySmallSquare;': '\\u25fb',\n    'emptyv;': '\\u2205',\n    'EmptyVerySmallSquare;': '\\u25ab',\n    'emsp13;': '\\u2004',\n    'emsp14;': '\\u2005',\n    'emsp;': '\\u2003',\n    'ENG;': '\\u014a',\n    'eng;': '\\u014b',\n    'ensp;': '\\u2002',\n    'Eogon;': '\\u0118',\n    'eogon;': '\\u0119',\n    'Eopf;': '\\U0001d53c',\n    'eopf;': '\\U0001d556',\n    'epar;': '\\u22d5',\n    'eparsl;': '\\u29e3',\n    'eplus;': '\\u2a71',\n    'epsi;': '\\u03b5',\n    'Epsilon;': '\\u0395',\n    'epsilon;': '\\u03b5',\n    'epsiv;': '\\u03f5',\n    'eqcirc;': '\\u2256',\n    'eqcolon;': '\\u2255',\n    'eqsim;': '\\u2242',\n    'eqslantgtr;': '\\u2a96',\n    'eqslantless;': '\\u2a95',\n    'Equal;': '\\u2a75',\n    'equals;': '=',\n    'EqualTilde;': '\\u2242',\n    'equest;': '\\u225f',\n    'Equilibrium;': '\\u21cc',\n    'equiv;': '\\u2261',\n    'equivDD;': '\\u2a78',\n    'eqvparsl;': '\\u29e5',\n    'erarr;': '\\u2971',\n    'erDot;': '\\u2253',\n    'Escr;': '\\u2130',\n    'escr;': '\\u212f',\n    'esdot;': '\\u2250',\n    'Esim;': '\\u2a73',\n    'esim;': '\\u2242',\n    'Eta;': '\\u0397',\n    'eta;': '\\u03b7',\n    'ETH': '\\xd0',\n    'eth': '\\xf0',\n    'ETH;': '\\xd0',\n    'eth;': '\\xf0',\n    'Euml': '\\xcb',\n    'euml': '\\xeb',\n    'Euml;': '\\xcb',\n    'euml;': '\\xeb',\n    'euro;': '\\u20ac',\n    'excl;': '!',\n    'exist;': '\\u2203',\n    'Exists;': '\\u2203',\n    'expectation;': '\\u2130',\n    'ExponentialE;': '\\u2147',\n    'exponentiale;': '\\u2147',\n    'fallingdotseq;': '\\u2252',\n    'Fcy;': '\\u0424',\n    'fcy;': '\\u0444',\n    'female;': '\\u2640',\n    'ffilig;': '\\ufb03',\n    'fflig;': '\\ufb00',\n    'ffllig;': '\\ufb04',\n    'Ffr;': '\\U0001d509',\n    'ffr;': '\\U0001d523',\n    'filig;': '\\ufb01',\n    'FilledSmallSquare;': '\\u25fc',\n    'FilledVerySmallSquare;': '\\u25aa',\n    'fjlig;': 'fj',\n    'flat;': '\\u266d',\n    'fllig;': '\\ufb02',\n    'fltns;': '\\u25b1',\n    'fnof;': '\\u0192',\n    'Fopf;': '\\U0001d53d',\n    'fopf;': '\\U0001d557',\n    'ForAll;': '\\u2200',\n    'forall;': '\\u2200',\n    'fork;': '\\u22d4',\n    'forkv;': '\\u2ad9',\n    'Fouriertrf;': '\\u2131',\n    'fpartint;': '\\u2a0d',\n    'frac12': '\\xbd',\n    'frac12;': '\\xbd',\n    'frac13;': '\\u2153',\n    'frac14': '\\xbc',\n    'frac14;': '\\xbc',\n    'frac15;': '\\u2155',\n    'frac16;': '\\u2159',\n    'frac18;': '\\u215b',\n    'frac23;': '\\u2154',\n    'frac25;': '\\u2156',\n    'frac34': '\\xbe',\n    'frac34;': '\\xbe',\n    'frac35;': '\\u2157',\n    'frac38;': '\\u215c',\n    'frac45;': '\\u2158',\n    'frac56;': '\\u215a',\n    'frac58;': '\\u215d',\n    'frac78;': '\\u215e',\n    'frasl;': '\\u2044',\n    'frown;': '\\u2322',\n    'Fscr;': '\\u2131',\n    'fscr;': '\\U0001d4bb',\n    'gacute;': '\\u01f5',\n    'Gamma;': '\\u0393',\n    'gamma;': '\\u03b3',\n    'Gammad;': '\\u03dc',\n    'gammad;': '\\u03dd',\n    'gap;': '\\u2a86',\n    'Gbreve;': '\\u011e',\n    'gbreve;': '\\u011f',\n    'Gcedil;': '\\u0122',\n    'Gcirc;': '\\u011c',\n    'gcirc;': '\\u011d',\n    'Gcy;': '\\u0413',\n    'gcy;': '\\u0433',\n    'Gdot;': '\\u0120',\n    'gdot;': '\\u0121',\n    'gE;': '\\u2267',\n    'ge;': '\\u2265',\n    'gEl;': '\\u2a8c',\n    'gel;': '\\u22db',\n    'geq;': '\\u2265',\n    'geqq;': '\\u2267',\n    'geqslant;': '\\u2a7e',\n    'ges;': '\\u2a7e',\n    'gescc;': '\\u2aa9',\n    'gesdot;': '\\u2a80',\n    'gesdoto;': '\\u2a82',\n    'gesdotol;': '\\u2a84',\n    'gesl;': '\\u22db\\ufe00',\n    'gesles;': '\\u2a94',\n    'Gfr;': '\\U0001d50a',\n    'gfr;': '\\U0001d524',\n    'Gg;': '\\u22d9',\n    'gg;': '\\u226b',\n    'ggg;': '\\u22d9',\n    'gimel;': '\\u2137',\n    'GJcy;': '\\u0403',\n    'gjcy;': '\\u0453',\n    'gl;': '\\u2277',\n    'gla;': '\\u2aa5',\n    'glE;': '\\u2a92',\n    'glj;': '\\u2aa4',\n    'gnap;': '\\u2a8a',\n    'gnapprox;': '\\u2a8a',\n    'gnE;': '\\u2269',\n    'gne;': '\\u2a88',\n    'gneq;': '\\u2a88',\n    'gneqq;': '\\u2269',\n    'gnsim;': '\\u22e7',\n    'Gopf;': '\\U0001d53e',\n    'gopf;': '\\U0001d558',\n    'grave;': '`',\n    'GreaterEqual;': '\\u2265',\n    'GreaterEqualLess;': '\\u22db',\n    'GreaterFullEqual;': '\\u2267',\n    'GreaterGreater;': '\\u2aa2',\n    'GreaterLess;': '\\u2277',\n    'GreaterSlantEqual;': '\\u2a7e',\n    'GreaterTilde;': '\\u2273',\n    'Gscr;': '\\U0001d4a2',\n    'gscr;': '\\u210a',\n    'gsim;': '\\u2273',\n    'gsime;': '\\u2a8e',\n    'gsiml;': '\\u2a90',\n    'GT': '>',\n    'gt': '>',\n    'GT;': '>',\n    'Gt;': '\\u226b',\n    'gt;': '>',\n    'gtcc;': '\\u2aa7',\n    'gtcir;': '\\u2a7a',\n    'gtdot;': '\\u22d7',\n    'gtlPar;': '\\u2995',\n    'gtquest;': '\\u2a7c',\n    'gtrapprox;': '\\u2a86',\n    'gtrarr;': '\\u2978',\n    'gtrdot;': '\\u22d7',\n    'gtreqless;': '\\u22db',\n    'gtreqqless;': '\\u2a8c',\n    'gtrless;': '\\u2277',\n    'gtrsim;': '\\u2273',\n    'gvertneqq;': '\\u2269\\ufe00',\n    'gvnE;': '\\u2269\\ufe00',\n    'Hacek;': '\\u02c7',\n    'hairsp;': '\\u200a',\n    'half;': '\\xbd',\n    'hamilt;': '\\u210b',\n    'HARDcy;': '\\u042a',\n    'hardcy;': '\\u044a',\n    'hArr;': '\\u21d4',\n    'harr;': '\\u2194',\n    'harrcir;': '\\u2948',\n    'harrw;': '\\u21ad',\n    'Hat;': '^',\n    'hbar;': '\\u210f',\n    'Hcirc;': '\\u0124',\n    'hcirc;': '\\u0125',\n    'hearts;': '\\u2665',\n    'heartsuit;': '\\u2665',\n    'hellip;': '\\u2026',\n    'hercon;': '\\u22b9',\n    'Hfr;': '\\u210c',\n    'hfr;': '\\U0001d525',\n    'HilbertSpace;': '\\u210b',\n    'hksearow;': '\\u2925',\n    'hkswarow;': '\\u2926',\n    'hoarr;': '\\u21ff',\n    'homtht;': '\\u223b',\n    'hookleftarrow;': '\\u21a9',\n    'hookrightarrow;': '\\u21aa',\n    'Hopf;': '\\u210d',\n    'hopf;': '\\U0001d559',\n    'horbar;': '\\u2015',\n    'HorizontalLine;': '\\u2500',\n    'Hscr;': '\\u210b',\n    'hscr;': '\\U0001d4bd',\n    'hslash;': '\\u210f',\n    'Hstrok;': '\\u0126',\n    'hstrok;': '\\u0127',\n    'HumpDownHump;': '\\u224e',\n    'HumpEqual;': '\\u224f',\n    'hybull;': '\\u2043',\n    'hyphen;': '\\u2010',\n    'Iacute': '\\xcd',\n    'iacute': '\\xed',\n    'Iacute;': '\\xcd',\n    'iacute;': '\\xed',\n    'ic;': '\\u2063',\n    'Icirc': '\\xce',\n    'icirc': '\\xee',\n    'Icirc;': '\\xce',\n    'icirc;': '\\xee',\n    'Icy;': '\\u0418',\n    'icy;': '\\u0438',\n    'Idot;': '\\u0130',\n    'IEcy;': '\\u0415',\n    'iecy;': '\\u0435',\n    'iexcl': '\\xa1',\n    'iexcl;': '\\xa1',\n    'iff;': '\\u21d4',\n    'Ifr;': '\\u2111',\n    'ifr;': '\\U0001d526',\n    'Igrave': '\\xcc',\n    'igrave': '\\xec',\n    'Igrave;': '\\xcc',\n    'igrave;': '\\xec',\n    'ii;': '\\u2148',\n    'iiiint;': '\\u2a0c',\n    'iiint;': '\\u222d',\n    'iinfin;': '\\u29dc',\n    'iiota;': '\\u2129',\n    'IJlig;': '\\u0132',\n    'ijlig;': '\\u0133',\n    'Im;': '\\u2111',\n    'Imacr;': '\\u012a',\n    'imacr;': '\\u012b',\n    'image;': '\\u2111',\n    'ImaginaryI;': '\\u2148',\n    'imagline;': '\\u2110',\n    'imagpart;': '\\u2111',\n    'imath;': '\\u0131',\n    'imof;': '\\u22b7',\n    'imped;': '\\u01b5',\n    'Implies;': '\\u21d2',\n    'in;': '\\u2208',\n    'incare;': '\\u2105',\n    'infin;': '\\u221e',\n    'infintie;': '\\u29dd',\n    'inodot;': '\\u0131',\n    'Int;': '\\u222c',\n    'int;': '\\u222b',\n    'intcal;': '\\u22ba',\n    'integers;': '\\u2124',\n    'Integral;': '\\u222b',\n    'intercal;': '\\u22ba',\n    'Intersection;': '\\u22c2',\n    'intlarhk;': '\\u2a17',\n    'intprod;': '\\u2a3c',\n    'InvisibleComma;': '\\u2063',\n    'InvisibleTimes;': '\\u2062',\n    'IOcy;': '\\u0401',\n    'iocy;': '\\u0451',\n    'Iogon;': '\\u012e',\n    'iogon;': '\\u012f',\n    'Iopf;': '\\U0001d540',\n    'iopf;': '\\U0001d55a',\n    'Iota;': '\\u0399',\n    'iota;': '\\u03b9',\n    'iprod;': '\\u2a3c',\n    'iquest': '\\xbf',\n    'iquest;': '\\xbf',\n    'Iscr;': '\\u2110',\n    'iscr;': '\\U0001d4be',\n    'isin;': '\\u2208',\n    'isindot;': '\\u22f5',\n    'isinE;': '\\u22f9',\n    'isins;': '\\u22f4',\n    'isinsv;': '\\u22f3',\n    'isinv;': '\\u2208',\n    'it;': '\\u2062',\n    'Itilde;': '\\u0128',\n    'itilde;': '\\u0129',\n    'Iukcy;': '\\u0406',\n    'iukcy;': '\\u0456',\n    'Iuml': '\\xcf',\n    'iuml': '\\xef',\n    'Iuml;': '\\xcf',\n    'iuml;': '\\xef',\n    'Jcirc;': '\\u0134',\n    'jcirc;': '\\u0135',\n    'Jcy;': '\\u0419',\n    'jcy;': '\\u0439',\n    'Jfr;': '\\U0001d50d',\n    'jfr;': '\\U0001d527',\n    'jmath;': '\\u0237',\n    'Jopf;': '\\U0001d541',\n    'jopf;': '\\U0001d55b',\n    'Jscr;': '\\U0001d4a5',\n    'jscr;': '\\U0001d4bf',\n    'Jsercy;': '\\u0408',\n    'jsercy;': '\\u0458',\n    'Jukcy;': '\\u0404',\n    'jukcy;': '\\u0454',\n    'Kappa;': '\\u039a',\n    'kappa;': '\\u03ba',\n    'kappav;': '\\u03f0',\n    'Kcedil;': '\\u0136',\n    'kcedil;': '\\u0137',\n    'Kcy;': '\\u041a',\n    'kcy;': '\\u043a',\n    'Kfr;': '\\U0001d50e',\n    'kfr;': '\\U0001d528',\n    'kgreen;': '\\u0138',\n    'KHcy;': '\\u0425',\n    'khcy;': '\\u0445',\n    'KJcy;': '\\u040c',\n    'kjcy;': '\\u045c',\n    'Kopf;': '\\U0001d542',\n    'kopf;': '\\U0001d55c',\n    'Kscr;': '\\U0001d4a6',\n    'kscr;': '\\U0001d4c0',\n    'lAarr;': '\\u21da',\n    'Lacute;': '\\u0139',\n    'lacute;': '\\u013a',\n    'laemptyv;': '\\u29b4',\n    'lagran;': '\\u2112',\n    'Lambda;': '\\u039b',\n    'lambda;': '\\u03bb',\n    'Lang;': '\\u27ea',\n    'lang;': '\\u27e8',\n    'langd;': '\\u2991',\n    'langle;': '\\u27e8',\n    'lap;': '\\u2a85',\n    'Laplacetrf;': '\\u2112',\n    'laquo': '\\xab',\n    'laquo;': '\\xab',\n    'Larr;': '\\u219e',\n    'lArr;': '\\u21d0',\n    'larr;': '\\u2190',\n    'larrb;': '\\u21e4',\n    'larrbfs;': '\\u291f',\n    'larrfs;': '\\u291d',\n    'larrhk;': '\\u21a9',\n    'larrlp;': '\\u21ab',\n    'larrpl;': '\\u2939',\n    'larrsim;': '\\u2973',\n    'larrtl;': '\\u21a2',\n    'lat;': '\\u2aab',\n    'lAtail;': '\\u291b',\n    'latail;': '\\u2919',\n    'late;': '\\u2aad',\n    'lates;': '\\u2aad\\ufe00',\n    'lBarr;': '\\u290e',\n    'lbarr;': '\\u290c',\n    'lbbrk;': '\\u2772',\n    'lbrace;': '{',\n    'lbrack;': '[',\n    'lbrke;': '\\u298b',\n    'lbrksld;': '\\u298f',\n    'lbrkslu;': '\\u298d',\n    'Lcaron;': '\\u013d',\n    'lcaron;': '\\u013e',\n    'Lcedil;': '\\u013b',\n    'lcedil;': '\\u013c',\n    'lceil;': '\\u2308',\n    'lcub;': '{',\n    'Lcy;': '\\u041b',\n    'lcy;': '\\u043b',\n    'ldca;': '\\u2936',\n    'ldquo;': '\\u201c',\n    'ldquor;': '\\u201e',\n    'ldrdhar;': '\\u2967',\n    'ldrushar;': '\\u294b',\n    'ldsh;': '\\u21b2',\n    'lE;': '\\u2266',\n    'le;': '\\u2264',\n    'LeftAngleBracket;': '\\u27e8',\n    'LeftArrow;': '\\u2190',\n    'Leftarrow;': '\\u21d0',\n    'leftarrow;': '\\u2190',\n    'LeftArrowBar;': '\\u21e4',\n    'LeftArrowRightArrow;': '\\u21c6',\n    'leftarrowtail;': '\\u21a2',\n    'LeftCeiling;': '\\u2308',\n    'LeftDoubleBracket;': '\\u27e6',\n    'LeftDownTeeVector;': '\\u2961',\n    'LeftDownVector;': '\\u21c3',\n    'LeftDownVectorBar;': '\\u2959',\n    'LeftFloor;': '\\u230a',\n    'leftharpoondown;': '\\u21bd',\n    'leftharpoonup;': '\\u21bc',\n    'leftleftarrows;': '\\u21c7',\n    'LeftRightArrow;': '\\u2194',\n    'Leftrightarrow;': '\\u21d4',\n    'leftrightarrow;': '\\u2194',\n    'leftrightarrows;': '\\u21c6',\n    'leftrightharpoons;': '\\u21cb',\n    'leftrightsquigarrow;': '\\u21ad',\n    'LeftRightVector;': '\\u294e',\n    'LeftTee;': '\\u22a3',\n    'LeftTeeArrow;': '\\u21a4',\n    'LeftTeeVector;': '\\u295a',\n    'leftthreetimes;': '\\u22cb',\n    'LeftTriangle;': '\\u22b2',\n    'LeftTriangleBar;': '\\u29cf',\n    'LeftTriangleEqual;': '\\u22b4',\n    'LeftUpDownVector;': '\\u2951',\n    'LeftUpTeeVector;': '\\u2960',\n    'LeftUpVector;': '\\u21bf',\n    'LeftUpVectorBar;': '\\u2958',\n    'LeftVector;': '\\u21bc',\n    'LeftVectorBar;': '\\u2952',\n    'lEg;': '\\u2a8b',\n    'leg;': '\\u22da',\n    'leq;': '\\u2264',\n    'leqq;': '\\u2266',\n    'leqslant;': '\\u2a7d',\n    'les;': '\\u2a7d',\n    'lescc;': '\\u2aa8',\n    'lesdot;': '\\u2a7f',\n    'lesdoto;': '\\u2a81',\n    'lesdotor;': '\\u2a83',\n    'lesg;': '\\u22da\\ufe00',\n    'lesges;': '\\u2a93',\n    'lessapprox;': '\\u2a85',\n    'lessdot;': '\\u22d6',\n    'lesseqgtr;': '\\u22da',\n    'lesseqqgtr;': '\\u2a8b',\n    'LessEqualGreater;': '\\u22da',\n    'LessFullEqual;': '\\u2266',\n    'LessGreater;': '\\u2276',\n    'lessgtr;': '\\u2276',\n    'LessLess;': '\\u2aa1',\n    'lesssim;': '\\u2272',\n    'LessSlantEqual;': '\\u2a7d',\n    'LessTilde;': '\\u2272',\n    'lfisht;': '\\u297c',\n    'lfloor;': '\\u230a',\n    'Lfr;': '\\U0001d50f',\n    'lfr;': '\\U0001d529',\n    'lg;': '\\u2276',\n    'lgE;': '\\u2a91',\n    'lHar;': '\\u2962',\n    'lhard;': '\\u21bd',\n    'lharu;': '\\u21bc',\n    'lharul;': '\\u296a',\n    'lhblk;': '\\u2584',\n    'LJcy;': '\\u0409',\n    'ljcy;': '\\u0459',\n    'Ll;': '\\u22d8',\n    'll;': '\\u226a',\n    'llarr;': '\\u21c7',\n    'llcorner;': '\\u231e',\n    'Lleftarrow;': '\\u21da',\n    'llhard;': '\\u296b',\n    'lltri;': '\\u25fa',\n    'Lmidot;': '\\u013f',\n    'lmidot;': '\\u0140',\n    'lmoust;': '\\u23b0',\n    'lmoustache;': '\\u23b0',\n    'lnap;': '\\u2a89',\n    'lnapprox;': '\\u2a89',\n    'lnE;': '\\u2268',\n    'lne;': '\\u2a87',\n    'lneq;': '\\u2a87',\n    'lneqq;': '\\u2268',\n    'lnsim;': '\\u22e6',\n    'loang;': '\\u27ec',\n    'loarr;': '\\u21fd',\n    'lobrk;': '\\u27e6',\n    'LongLeftArrow;': '\\u27f5',\n    'Longleftarrow;': '\\u27f8',\n    'longleftarrow;': '\\u27f5',\n    'LongLeftRightArrow;': '\\u27f7',\n    'Longleftrightarrow;': '\\u27fa',\n    'longleftrightarrow;': '\\u27f7',\n    'longmapsto;': '\\u27fc',\n    'LongRightArrow;': '\\u27f6',\n    'Longrightarrow;': '\\u27f9',\n    'longrightarrow;': '\\u27f6',\n    'looparrowleft;': '\\u21ab',\n    'looparrowright;': '\\u21ac',\n    'lopar;': '\\u2985',\n    'Lopf;': '\\U0001d543',\n    'lopf;': '\\U0001d55d',\n    'loplus;': '\\u2a2d',\n    'lotimes;': '\\u2a34',\n    'lowast;': '\\u2217',\n    'lowbar;': '_',\n    'LowerLeftArrow;': '\\u2199',\n    'LowerRightArrow;': '\\u2198',\n    'loz;': '\\u25ca',\n    'lozenge;': '\\u25ca',\n    'lozf;': '\\u29eb',\n    'lpar;': '(',\n    'lparlt;': '\\u2993',\n    'lrarr;': '\\u21c6',\n    'lrcorner;': '\\u231f',\n    'lrhar;': '\\u21cb',\n    'lrhard;': '\\u296d',\n    'lrm;': '\\u200e',\n    'lrtri;': '\\u22bf',\n    'lsaquo;': '\\u2039',\n    'Lscr;': '\\u2112',\n    'lscr;': '\\U0001d4c1',\n    'Lsh;': '\\u21b0',\n    'lsh;': '\\u21b0',\n    'lsim;': '\\u2272',\n    'lsime;': '\\u2a8d',\n    'lsimg;': '\\u2a8f',\n    'lsqb;': '[',\n    'lsquo;': '\\u2018',\n    'lsquor;': '\\u201a',\n    'Lstrok;': '\\u0141',\n    'lstrok;': '\\u0142',\n    'LT': '<',\n    'lt': '<',\n    'LT;': '<',\n    'Lt;': '\\u226a',\n    'lt;': '<',\n    'ltcc;': '\\u2aa6',\n    'ltcir;': '\\u2a79',\n    'ltdot;': '\\u22d6',\n    'lthree;': '\\u22cb',\n    'ltimes;': '\\u22c9',\n    'ltlarr;': '\\u2976',\n    'ltquest;': '\\u2a7b',\n    'ltri;': '\\u25c3',\n    'ltrie;': '\\u22b4',\n    'ltrif;': '\\u25c2',\n    'ltrPar;': '\\u2996',\n    'lurdshar;': '\\u294a',\n    'luruhar;': '\\u2966',\n    'lvertneqq;': '\\u2268\\ufe00',\n    'lvnE;': '\\u2268\\ufe00',\n    'macr': '\\xaf',\n    'macr;': '\\xaf',\n    'male;': '\\u2642',\n    'malt;': '\\u2720',\n    'maltese;': '\\u2720',\n    'Map;': '\\u2905',\n    'map;': '\\u21a6',\n    'mapsto;': '\\u21a6',\n    'mapstodown;': '\\u21a7',\n    'mapstoleft;': '\\u21a4',\n    'mapstoup;': '\\u21a5',\n    'marker;': '\\u25ae',\n    'mcomma;': '\\u2a29',\n    'Mcy;': '\\u041c',\n    'mcy;': '\\u043c',\n    'mdash;': '\\u2014',\n    'mDDot;': '\\u223a',\n    'measuredangle;': '\\u2221',\n    'MediumSpace;': '\\u205f',\n    'Mellintrf;': '\\u2133',\n    'Mfr;': '\\U0001d510',\n    'mfr;': '\\U0001d52a',\n    'mho;': '\\u2127',\n    'micro': '\\xb5',\n    'micro;': '\\xb5',\n    'mid;': '\\u2223',\n    'midast;': '*',\n    'midcir;': '\\u2af0',\n    'middot': '\\xb7',\n    'middot;': '\\xb7',\n    'minus;': '\\u2212',\n    'minusb;': '\\u229f',\n    'minusd;': '\\u2238',\n    'minusdu;': '\\u2a2a',\n    'MinusPlus;': '\\u2213',\n    'mlcp;': '\\u2adb',\n    'mldr;': '\\u2026',\n    'mnplus;': '\\u2213',\n    'models;': '\\u22a7',\n    'Mopf;': '\\U0001d544',\n    'mopf;': '\\U0001d55e',\n    'mp;': '\\u2213',\n    'Mscr;': '\\u2133',\n    'mscr;': '\\U0001d4c2',\n    'mstpos;': '\\u223e',\n    'Mu;': '\\u039c',\n    'mu;': '\\u03bc',\n    'multimap;': '\\u22b8',\n    'mumap;': '\\u22b8',\n    'nabla;': '\\u2207',\n    'Nacute;': '\\u0143',\n    'nacute;': '\\u0144',\n    'nang;': '\\u2220\\u20d2',\n    'nap;': '\\u2249',\n    'napE;': '\\u2a70\\u0338',\n    'napid;': '\\u224b\\u0338',\n    'napos;': '\\u0149',\n    'napprox;': '\\u2249',\n    'natur;': '\\u266e',\n    'natural;': '\\u266e',\n    'naturals;': '\\u2115',\n    'nbsp': '\\xa0',\n    'nbsp;': '\\xa0',\n    'nbump;': '\\u224e\\u0338',\n    'nbumpe;': '\\u224f\\u0338',\n    'ncap;': '\\u2a43',\n    'Ncaron;': '\\u0147',\n    'ncaron;': '\\u0148',\n    'Ncedil;': '\\u0145',\n    'ncedil;': '\\u0146',\n    'ncong;': '\\u2247',\n    'ncongdot;': '\\u2a6d\\u0338',\n    'ncup;': '\\u2a42',\n    'Ncy;': '\\u041d',\n    'ncy;': '\\u043d',\n    'ndash;': '\\u2013',\n    'ne;': '\\u2260',\n    'nearhk;': '\\u2924',\n    'neArr;': '\\u21d7',\n    'nearr;': '\\u2197',\n    'nearrow;': '\\u2197',\n    'nedot;': '\\u2250\\u0338',\n    'NegativeMediumSpace;': '\\u200b',\n    'NegativeThickSpace;': '\\u200b',\n    'NegativeThinSpace;': '\\u200b',\n    'NegativeVeryThinSpace;': '\\u200b',\n    'nequiv;': '\\u2262',\n    'nesear;': '\\u2928',\n    'nesim;': '\\u2242\\u0338',\n    'NestedGreaterGreater;': '\\u226b',\n    'NestedLessLess;': '\\u226a',\n    'NewLine;': '\\n',\n    'nexist;': '\\u2204',\n    'nexists;': '\\u2204',\n    'Nfr;': '\\U0001d511',\n    'nfr;': '\\U0001d52b',\n    'ngE;': '\\u2267\\u0338',\n    'nge;': '\\u2271',\n    'ngeq;': '\\u2271',\n    'ngeqq;': '\\u2267\\u0338',\n    'ngeqslant;': '\\u2a7e\\u0338',\n    'nges;': '\\u2a7e\\u0338',\n    'nGg;': '\\u22d9\\u0338',\n    'ngsim;': '\\u2275',\n    'nGt;': '\\u226b\\u20d2',\n    'ngt;': '\\u226f',\n    'ngtr;': '\\u226f',\n    'nGtv;': '\\u226b\\u0338',\n    'nhArr;': '\\u21ce',\n    'nharr;': '\\u21ae',\n    'nhpar;': '\\u2af2',\n    'ni;': '\\u220b',\n    'nis;': '\\u22fc',\n    'nisd;': '\\u22fa',\n    'niv;': '\\u220b',\n    'NJcy;': '\\u040a',\n    'njcy;': '\\u045a',\n    'nlArr;': '\\u21cd',\n    'nlarr;': '\\u219a',\n    'nldr;': '\\u2025',\n    'nlE;': '\\u2266\\u0338',\n    'nle;': '\\u2270',\n    'nLeftarrow;': '\\u21cd',\n    'nleftarrow;': '\\u219a',\n    'nLeftrightarrow;': '\\u21ce',\n    'nleftrightarrow;': '\\u21ae',\n    'nleq;': '\\u2270',\n    'nleqq;': '\\u2266\\u0338',\n    'nleqslant;': '\\u2a7d\\u0338',\n    'nles;': '\\u2a7d\\u0338',\n    'nless;': '\\u226e',\n    'nLl;': '\\u22d8\\u0338',\n    'nlsim;': '\\u2274',\n    'nLt;': '\\u226a\\u20d2',\n    'nlt;': '\\u226e',\n    'nltri;': '\\u22ea',\n    'nltrie;': '\\u22ec',\n    'nLtv;': '\\u226a\\u0338',\n    'nmid;': '\\u2224',\n    'NoBreak;': '\\u2060',\n    'NonBreakingSpace;': '\\xa0',\n    'Nopf;': '\\u2115',\n    'nopf;': '\\U0001d55f',\n    'not': '\\xac',\n    'Not;': '\\u2aec',\n    'not;': '\\xac',\n    'NotCongruent;': '\\u2262',\n    'NotCupCap;': '\\u226d',\n    'NotDoubleVerticalBar;': '\\u2226',\n    'NotElement;': '\\u2209',\n    'NotEqual;': '\\u2260',\n    'NotEqualTilde;': '\\u2242\\u0338',\n    'NotExists;': '\\u2204',\n    'NotGreater;': '\\u226f',\n    'NotGreaterEqual;': '\\u2271',\n    'NotGreaterFullEqual;': '\\u2267\\u0338',\n    'NotGreaterGreater;': '\\u226b\\u0338',\n    'NotGreaterLess;': '\\u2279',\n    'NotGreaterSlantEqual;': '\\u2a7e\\u0338',\n    'NotGreaterTilde;': '\\u2275',\n    'NotHumpDownHump;': '\\u224e\\u0338',\n    'NotHumpEqual;': '\\u224f\\u0338',\n    'notin;': '\\u2209',\n    'notindot;': '\\u22f5\\u0338',\n    'notinE;': '\\u22f9\\u0338',\n    'notinva;': '\\u2209',\n    'notinvb;': '\\u22f7',\n    'notinvc;': '\\u22f6',\n    'NotLeftTriangle;': '\\u22ea',\n    'NotLeftTriangleBar;': '\\u29cf\\u0338',\n    'NotLeftTriangleEqual;': '\\u22ec',\n    'NotLess;': '\\u226e',\n    'NotLessEqual;': '\\u2270',\n    'NotLessGreater;': '\\u2278',\n    'NotLessLess;': '\\u226a\\u0338',\n    'NotLessSlantEqual;': '\\u2a7d\\u0338',\n    'NotLessTilde;': '\\u2274',\n    'NotNestedGreaterGreater;': '\\u2aa2\\u0338',\n    'NotNestedLessLess;': '\\u2aa1\\u0338',\n    'notni;': '\\u220c',\n    'notniva;': '\\u220c',\n    'notnivb;': '\\u22fe',\n    'notnivc;': '\\u22fd',\n    'NotPrecedes;': '\\u2280',\n    'NotPrecedesEqual;': '\\u2aaf\\u0338',\n    'NotPrecedesSlantEqual;': '\\u22e0',\n    'NotReverseElement;': '\\u220c',\n    'NotRightTriangle;': '\\u22eb',\n    'NotRightTriangleBar;': '\\u29d0\\u0338',\n    'NotRightTriangleEqual;': '\\u22ed',\n    'NotSquareSubset;': '\\u228f\\u0338',\n    'NotSquareSubsetEqual;': '\\u22e2',\n    'NotSquareSuperset;': '\\u2290\\u0338',\n    'NotSquareSupersetEqual;': '\\u22e3',\n    'NotSubset;': '\\u2282\\u20d2',\n    'NotSubsetEqual;': '\\u2288',\n    'NotSucceeds;': '\\u2281',\n    'NotSucceedsEqual;': '\\u2ab0\\u0338',\n    'NotSucceedsSlantEqual;': '\\u22e1',\n    'NotSucceedsTilde;': '\\u227f\\u0338',\n    'NotSuperset;': '\\u2283\\u20d2',\n    'NotSupersetEqual;': '\\u2289',\n    'NotTilde;': '\\u2241',\n    'NotTildeEqual;': '\\u2244',\n    'NotTildeFullEqual;': '\\u2247',\n    'NotTildeTilde;': '\\u2249',\n    'NotVerticalBar;': '\\u2224',\n    'npar;': '\\u2226',\n    'nparallel;': '\\u2226',\n    'nparsl;': '\\u2afd\\u20e5',\n    'npart;': '\\u2202\\u0338',\n    'npolint;': '\\u2a14',\n    'npr;': '\\u2280',\n    'nprcue;': '\\u22e0',\n    'npre;': '\\u2aaf\\u0338',\n    'nprec;': '\\u2280',\n    'npreceq;': '\\u2aaf\\u0338',\n    'nrArr;': '\\u21cf',\n    'nrarr;': '\\u219b',\n    'nrarrc;': '\\u2933\\u0338',\n    'nrarrw;': '\\u219d\\u0338',\n    'nRightarrow;': '\\u21cf',\n    'nrightarrow;': '\\u219b',\n    'nrtri;': '\\u22eb',\n    'nrtrie;': '\\u22ed',\n    'nsc;': '\\u2281',\n    'nsccue;': '\\u22e1',\n    'nsce;': '\\u2ab0\\u0338',\n    'Nscr;': '\\U0001d4a9',\n    'nscr;': '\\U0001d4c3',\n    'nshortmid;': '\\u2224',\n    'nshortparallel;': '\\u2226',\n    'nsim;': '\\u2241',\n    'nsime;': '\\u2244',\n    'nsimeq;': '\\u2244',\n    'nsmid;': '\\u2224',\n    'nspar;': '\\u2226',\n    'nsqsube;': '\\u22e2',\n    'nsqsupe;': '\\u22e3',\n    'nsub;': '\\u2284',\n    'nsubE;': '\\u2ac5\\u0338',\n    'nsube;': '\\u2288',\n    'nsubset;': '\\u2282\\u20d2',\n    'nsubseteq;': '\\u2288',\n    'nsubseteqq;': '\\u2ac5\\u0338',\n    'nsucc;': '\\u2281',\n    'nsucceq;': '\\u2ab0\\u0338',\n    'nsup;': '\\u2285',\n    'nsupE;': '\\u2ac6\\u0338',\n    'nsupe;': '\\u2289',\n    'nsupset;': '\\u2283\\u20d2',\n    'nsupseteq;': '\\u2289',\n    'nsupseteqq;': '\\u2ac6\\u0338',\n    'ntgl;': '\\u2279',\n    'Ntilde': '\\xd1',\n    'ntilde': '\\xf1',\n    'Ntilde;': '\\xd1',\n    'ntilde;': '\\xf1',\n    'ntlg;': '\\u2278',\n    'ntriangleleft;': '\\u22ea',\n    'ntrianglelefteq;': '\\u22ec',\n    'ntriangleright;': '\\u22eb',\n    'ntrianglerighteq;': '\\u22ed',\n    'Nu;': '\\u039d',\n    'nu;': '\\u03bd',\n    'num;': '#',\n    'numero;': '\\u2116',\n    'numsp;': '\\u2007',\n    'nvap;': '\\u224d\\u20d2',\n    'nVDash;': '\\u22af',\n    'nVdash;': '\\u22ae',\n    'nvDash;': '\\u22ad',\n    'nvdash;': '\\u22ac',\n    'nvge;': '\\u2265\\u20d2',\n    'nvgt;': '>\\u20d2',\n    'nvHarr;': '\\u2904',\n    'nvinfin;': '\\u29de',\n    'nvlArr;': '\\u2902',\n    'nvle;': '\\u2264\\u20d2',\n    'nvlt;': '<\\u20d2',\n    'nvltrie;': '\\u22b4\\u20d2',\n    'nvrArr;': '\\u2903',\n    'nvrtrie;': '\\u22b5\\u20d2',\n    'nvsim;': '\\u223c\\u20d2',\n    'nwarhk;': '\\u2923',\n    'nwArr;': '\\u21d6',\n    'nwarr;': '\\u2196',\n    'nwarrow;': '\\u2196',\n    'nwnear;': '\\u2927',\n    'Oacute': '\\xd3',\n    'oacute': '\\xf3',\n    'Oacute;': '\\xd3',\n    'oacute;': '\\xf3',\n    'oast;': '\\u229b',\n    'ocir;': '\\u229a',\n    'Ocirc': '\\xd4',\n    'ocirc': '\\xf4',\n    'Ocirc;': '\\xd4',\n    'ocirc;': '\\xf4',\n    'Ocy;': '\\u041e',\n    'ocy;': '\\u043e',\n    'odash;': '\\u229d',\n    'Odblac;': '\\u0150',\n    'odblac;': '\\u0151',\n    'odiv;': '\\u2a38',\n    'odot;': '\\u2299',\n    'odsold;': '\\u29bc',\n    'OElig;': '\\u0152',\n    'oelig;': '\\u0153',\n    'ofcir;': '\\u29bf',\n    'Ofr;': '\\U0001d512',\n    'ofr;': '\\U0001d52c',\n    'ogon;': '\\u02db',\n    'Ograve': '\\xd2',\n    'ograve': '\\xf2',\n    'Ograve;': '\\xd2',\n    'ograve;': '\\xf2',\n    'ogt;': '\\u29c1',\n    'ohbar;': '\\u29b5',\n    'ohm;': '\\u03a9',\n    'oint;': '\\u222e',\n    'olarr;': '\\u21ba',\n    'olcir;': '\\u29be',\n    'olcross;': '\\u29bb',\n    'oline;': '\\u203e',\n    'olt;': '\\u29c0',\n    'Omacr;': '\\u014c',\n    'omacr;': '\\u014d',\n    'Omega;': '\\u03a9',\n    'omega;': '\\u03c9',\n    'Omicron;': '\\u039f',\n    'omicron;': '\\u03bf',\n    'omid;': '\\u29b6',\n    'ominus;': '\\u2296',\n    'Oopf;': '\\U0001d546',\n    'oopf;': '\\U0001d560',\n    'opar;': '\\u29b7',\n    'OpenCurlyDoubleQuote;': '\\u201c',\n    'OpenCurlyQuote;': '\\u2018',\n    'operp;': '\\u29b9',\n    'oplus;': '\\u2295',\n    'Or;': '\\u2a54',\n    'or;': '\\u2228',\n    'orarr;': '\\u21bb',\n    'ord;': '\\u2a5d',\n    'order;': '\\u2134',\n    'orderof;': '\\u2134',\n    'ordf': '\\xaa',\n    'ordf;': '\\xaa',\n    'ordm': '\\xba',\n    'ordm;': '\\xba',\n    'origof;': '\\u22b6',\n    'oror;': '\\u2a56',\n    'orslope;': '\\u2a57',\n    'orv;': '\\u2a5b',\n    'oS;': '\\u24c8',\n    'Oscr;': '\\U0001d4aa',\n    'oscr;': '\\u2134',\n    'Oslash': '\\xd8',\n    'oslash': '\\xf8',\n    'Oslash;': '\\xd8',\n    'oslash;': '\\xf8',\n    'osol;': '\\u2298',\n    'Otilde': '\\xd5',\n    'otilde': '\\xf5',\n    'Otilde;': '\\xd5',\n    'otilde;': '\\xf5',\n    'Otimes;': '\\u2a37',\n    'otimes;': '\\u2297',\n    'otimesas;': '\\u2a36',\n    'Ouml': '\\xd6',\n    'ouml': '\\xf6',\n    'Ouml;': '\\xd6',\n    'ouml;': '\\xf6',\n    'ovbar;': '\\u233d',\n    'OverBar;': '\\u203e',\n    'OverBrace;': '\\u23de',\n    'OverBracket;': '\\u23b4',\n    'OverParenthesis;': '\\u23dc',\n    'par;': '\\u2225',\n    'para': '\\xb6',\n    'para;': '\\xb6',\n    'parallel;': '\\u2225',\n    'parsim;': '\\u2af3',\n    'parsl;': '\\u2afd',\n    'part;': '\\u2202',\n    'PartialD;': '\\u2202',\n    'Pcy;': '\\u041f',\n    'pcy;': '\\u043f',\n    'percnt;': '%',\n    'period;': '.',\n    'permil;': '\\u2030',\n    'perp;': '\\u22a5',\n    'pertenk;': '\\u2031',\n    'Pfr;': '\\U0001d513',\n    'pfr;': '\\U0001d52d',\n    'Phi;': '\\u03a6',\n    'phi;': '\\u03c6',\n    'phiv;': '\\u03d5',\n    'phmmat;': '\\u2133',\n    'phone;': '\\u260e',\n    'Pi;': '\\u03a0',\n    'pi;': '\\u03c0',\n    'pitchfork;': '\\u22d4',\n    'piv;': '\\u03d6',\n    'planck;': '\\u210f',\n    'planckh;': '\\u210e',\n    'plankv;': '\\u210f',\n    'plus;': '+',\n    'plusacir;': '\\u2a23',\n    'plusb;': '\\u229e',\n    'pluscir;': '\\u2a22',\n    'plusdo;': '\\u2214',\n    'plusdu;': '\\u2a25',\n    'pluse;': '\\u2a72',\n    'PlusMinus;': '\\xb1',\n    'plusmn': '\\xb1',\n    'plusmn;': '\\xb1',\n    'plussim;': '\\u2a26',\n    'plustwo;': '\\u2a27',\n    'pm;': '\\xb1',\n    'Poincareplane;': '\\u210c',\n    'pointint;': '\\u2a15',\n    'Popf;': '\\u2119',\n    'popf;': '\\U0001d561',\n    'pound': '\\xa3',\n    'pound;': '\\xa3',\n    'Pr;': '\\u2abb',\n    'pr;': '\\u227a',\n    'prap;': '\\u2ab7',\n    'prcue;': '\\u227c',\n    'prE;': '\\u2ab3',\n    'pre;': '\\u2aaf',\n    'prec;': '\\u227a',\n    'precapprox;': '\\u2ab7',\n    'preccurlyeq;': '\\u227c',\n    'Precedes;': '\\u227a',\n    'PrecedesEqual;': '\\u2aaf',\n    'PrecedesSlantEqual;': '\\u227c',\n    'PrecedesTilde;': '\\u227e',\n    'preceq;': '\\u2aaf',\n    'precnapprox;': '\\u2ab9',\n    'precneqq;': '\\u2ab5',\n    'precnsim;': '\\u22e8',\n    'precsim;': '\\u227e',\n    'Prime;': '\\u2033',\n    'prime;': '\\u2032',\n    'primes;': '\\u2119',\n    'prnap;': '\\u2ab9',\n    'prnE;': '\\u2ab5',\n    'prnsim;': '\\u22e8',\n    'prod;': '\\u220f',\n    'Product;': '\\u220f',\n    'profalar;': '\\u232e',\n    'profline;': '\\u2312',\n    'profsurf;': '\\u2313',\n    'prop;': '\\u221d',\n    'Proportion;': '\\u2237',\n    'Proportional;': '\\u221d',\n    'propto;': '\\u221d',\n    'prsim;': '\\u227e',\n    'prurel;': '\\u22b0',\n    'Pscr;': '\\U0001d4ab',\n    'pscr;': '\\U0001d4c5',\n    'Psi;': '\\u03a8',\n    'psi;': '\\u03c8',\n    'puncsp;': '\\u2008',\n    'Qfr;': '\\U0001d514',\n    'qfr;': '\\U0001d52e',\n    'qint;': '\\u2a0c',\n    'Qopf;': '\\u211a',\n    'qopf;': '\\U0001d562',\n    'qprime;': '\\u2057',\n    'Qscr;': '\\U0001d4ac',\n    'qscr;': '\\U0001d4c6',\n    'quaternions;': '\\u210d',\n    'quatint;': '\\u2a16',\n    'quest;': '?',\n    'questeq;': '\\u225f',\n    'QUOT': '\"',\n    'quot': '\"',\n    'QUOT;': '\"',\n    'quot;': '\"',\n    'rAarr;': '\\u21db',\n    'race;': '\\u223d\\u0331',\n    'Racute;': '\\u0154',\n    'racute;': '\\u0155',\n    'radic;': '\\u221a',\n    'raemptyv;': '\\u29b3',\n    'Rang;': '\\u27eb',\n    'rang;': '\\u27e9',\n    'rangd;': '\\u2992',\n    'range;': '\\u29a5',\n    'rangle;': '\\u27e9',\n    'raquo': '\\xbb',\n    'raquo;': '\\xbb',\n    'Rarr;': '\\u21a0',\n    'rArr;': '\\u21d2',\n    'rarr;': '\\u2192',\n    'rarrap;': '\\u2975',\n    'rarrb;': '\\u21e5',\n    'rarrbfs;': '\\u2920',\n    'rarrc;': '\\u2933',\n    'rarrfs;': '\\u291e',\n    'rarrhk;': '\\u21aa',\n    'rarrlp;': '\\u21ac',\n    'rarrpl;': '\\u2945',\n    'rarrsim;': '\\u2974',\n    'Rarrtl;': '\\u2916',\n    'rarrtl;': '\\u21a3',\n    'rarrw;': '\\u219d',\n    'rAtail;': '\\u291c',\n    'ratail;': '\\u291a',\n    'ratio;': '\\u2236',\n    'rationals;': '\\u211a',\n    'RBarr;': '\\u2910',\n    'rBarr;': '\\u290f',\n    'rbarr;': '\\u290d',\n    'rbbrk;': '\\u2773',\n    'rbrace;': '}',\n    'rbrack;': ']',\n    'rbrke;': '\\u298c',\n    'rbrksld;': '\\u298e',\n    'rbrkslu;': '\\u2990',\n    'Rcaron;': '\\u0158',\n    'rcaron;': '\\u0159',\n    'Rcedil;': '\\u0156',\n    'rcedil;': '\\u0157',\n    'rceil;': '\\u2309',\n    'rcub;': '}',\n    'Rcy;': '\\u0420',\n    'rcy;': '\\u0440',\n    'rdca;': '\\u2937',\n    'rdldhar;': '\\u2969',\n    'rdquo;': '\\u201d',\n    'rdquor;': '\\u201d',\n    'rdsh;': '\\u21b3',\n    'Re;': '\\u211c',\n    'real;': '\\u211c',\n    'realine;': '\\u211b',\n    'realpart;': '\\u211c',\n    'reals;': '\\u211d',\n    'rect;': '\\u25ad',\n    'REG': '\\xae',\n    'reg': '\\xae',\n    'REG;': '\\xae',\n    'reg;': '\\xae',\n    'ReverseElement;': '\\u220b',\n    'ReverseEquilibrium;': '\\u21cb',\n    'ReverseUpEquilibrium;': '\\u296f',\n    'rfisht;': '\\u297d',\n    'rfloor;': '\\u230b',\n    'Rfr;': '\\u211c',\n    'rfr;': '\\U0001d52f',\n    'rHar;': '\\u2964',\n    'rhard;': '\\u21c1',\n    'rharu;': '\\u21c0',\n    'rharul;': '\\u296c',\n    'Rho;': '\\u03a1',\n    'rho;': '\\u03c1',\n    'rhov;': '\\u03f1',\n    'RightAngleBracket;': '\\u27e9',\n    'RightArrow;': '\\u2192',\n    'Rightarrow;': '\\u21d2',\n    'rightarrow;': '\\u2192',\n    'RightArrowBar;': '\\u21e5',\n    'RightArrowLeftArrow;': '\\u21c4',\n    'rightarrowtail;': '\\u21a3',\n    'RightCeiling;': '\\u2309',\n    'RightDoubleBracket;': '\\u27e7',\n    'RightDownTeeVector;': '\\u295d',\n    'RightDownVector;': '\\u21c2',\n    'RightDownVectorBar;': '\\u2955',\n    'RightFloor;': '\\u230b',\n    'rightharpoondown;': '\\u21c1',\n    'rightharpoonup;': '\\u21c0',\n    'rightleftarrows;': '\\u21c4',\n    'rightleftharpoons;': '\\u21cc',\n    'rightrightarrows;': '\\u21c9',\n    'rightsquigarrow;': '\\u219d',\n    'RightTee;': '\\u22a2',\n    'RightTeeArrow;': '\\u21a6',\n    'RightTeeVector;': '\\u295b',\n    'rightthreetimes;': '\\u22cc',\n    'RightTriangle;': '\\u22b3',\n    'RightTriangleBar;': '\\u29d0',\n    'RightTriangleEqual;': '\\u22b5',\n    'RightUpDownVector;': '\\u294f',\n    'RightUpTeeVector;': '\\u295c',\n    'RightUpVector;': '\\u21be',\n    'RightUpVectorBar;': '\\u2954',\n    'RightVector;': '\\u21c0',\n    'RightVectorBar;': '\\u2953',\n    'ring;': '\\u02da',\n    'risingdotseq;': '\\u2253',\n    'rlarr;': '\\u21c4',\n    'rlhar;': '\\u21cc',\n    'rlm;': '\\u200f',\n    'rmoust;': '\\u23b1',\n    'rmoustache;': '\\u23b1',\n    'rnmid;': '\\u2aee',\n    'roang;': '\\u27ed',\n    'roarr;': '\\u21fe',\n    'robrk;': '\\u27e7',\n    'ropar;': '\\u2986',\n    'Ropf;': '\\u211d',\n    'ropf;': '\\U0001d563',\n    'roplus;': '\\u2a2e',\n    'rotimes;': '\\u2a35',\n    'RoundImplies;': '\\u2970',\n    'rpar;': ')',\n    'rpargt;': '\\u2994',\n    'rppolint;': '\\u2a12',\n    'rrarr;': '\\u21c9',\n    'Rrightarrow;': '\\u21db',\n    'rsaquo;': '\\u203a',\n    'Rscr;': '\\u211b',\n    'rscr;': '\\U0001d4c7',\n    'Rsh;': '\\u21b1',\n    'rsh;': '\\u21b1',\n    'rsqb;': ']',\n    'rsquo;': '\\u2019',\n    'rsquor;': '\\u2019',\n    'rthree;': '\\u22cc',\n    'rtimes;': '\\u22ca',\n    'rtri;': '\\u25b9',\n    'rtrie;': '\\u22b5',\n    'rtrif;': '\\u25b8',\n    'rtriltri;': '\\u29ce',\n    'RuleDelayed;': '\\u29f4',\n    'ruluhar;': '\\u2968',\n    'rx;': '\\u211e',\n    'Sacute;': '\\u015a',\n    'sacute;': '\\u015b',\n    'sbquo;': '\\u201a',\n    'Sc;': '\\u2abc',\n    'sc;': '\\u227b',\n    'scap;': '\\u2ab8',\n    'Scaron;': '\\u0160',\n    'scaron;': '\\u0161',\n    'sccue;': '\\u227d',\n    'scE;': '\\u2ab4',\n    'sce;': '\\u2ab0',\n    'Scedil;': '\\u015e',\n    'scedil;': '\\u015f',\n    'Scirc;': '\\u015c',\n    'scirc;': '\\u015d',\n    'scnap;': '\\u2aba',\n    'scnE;': '\\u2ab6',\n    'scnsim;': '\\u22e9',\n    'scpolint;': '\\u2a13',\n    'scsim;': '\\u227f',\n    'Scy;': '\\u0421',\n    'scy;': '\\u0441',\n    'sdot;': '\\u22c5',\n    'sdotb;': '\\u22a1',\n    'sdote;': '\\u2a66',\n    'searhk;': '\\u2925',\n    'seArr;': '\\u21d8',\n    'searr;': '\\u2198',\n    'searrow;': '\\u2198',\n    'sect': '\\xa7',\n    'sect;': '\\xa7',\n    'semi;': ';',\n    'seswar;': '\\u2929',\n    'setminus;': '\\u2216',\n    'setmn;': '\\u2216',\n    'sext;': '\\u2736',\n    'Sfr;': '\\U0001d516',\n    'sfr;': '\\U0001d530',\n    'sfrown;': '\\u2322',\n    'sharp;': '\\u266f',\n    'SHCHcy;': '\\u0429',\n    'shchcy;': '\\u0449',\n    'SHcy;': '\\u0428',\n    'shcy;': '\\u0448',\n    'ShortDownArrow;': '\\u2193',\n    'ShortLeftArrow;': '\\u2190',\n    'shortmid;': '\\u2223',\n    'shortparallel;': '\\u2225',\n    'ShortRightArrow;': '\\u2192',\n    'ShortUpArrow;': '\\u2191',\n    'shy': '\\xad',\n    'shy;': '\\xad',\n    'Sigma;': '\\u03a3',\n    'sigma;': '\\u03c3',\n    'sigmaf;': '\\u03c2',\n    'sigmav;': '\\u03c2',\n    'sim;': '\\u223c',\n    'simdot;': '\\u2a6a',\n    'sime;': '\\u2243',\n    'simeq;': '\\u2243',\n    'simg;': '\\u2a9e',\n    'simgE;': '\\u2aa0',\n    'siml;': '\\u2a9d',\n    'simlE;': '\\u2a9f',\n    'simne;': '\\u2246',\n    'simplus;': '\\u2a24',\n    'simrarr;': '\\u2972',\n    'slarr;': '\\u2190',\n    'SmallCircle;': '\\u2218',\n    'smallsetminus;': '\\u2216',\n    'smashp;': '\\u2a33',\n    'smeparsl;': '\\u29e4',\n    'smid;': '\\u2223',\n    'smile;': '\\u2323',\n    'smt;': '\\u2aaa',\n    'smte;': '\\u2aac',\n    'smtes;': '\\u2aac\\ufe00',\n    'SOFTcy;': '\\u042c',\n    'softcy;': '\\u044c',\n    'sol;': '/',\n    'solb;': '\\u29c4',\n    'solbar;': '\\u233f',\n    'Sopf;': '\\U0001d54a',\n    'sopf;': '\\U0001d564',\n    'spades;': '\\u2660',\n    'spadesuit;': '\\u2660',\n    'spar;': '\\u2225',\n    'sqcap;': '\\u2293',\n    'sqcaps;': '\\u2293\\ufe00',\n    'sqcup;': '\\u2294',\n    'sqcups;': '\\u2294\\ufe00',\n    'Sqrt;': '\\u221a',\n    'sqsub;': '\\u228f',\n    'sqsube;': '\\u2291',\n    'sqsubset;': '\\u228f',\n    'sqsubseteq;': '\\u2291',\n    'sqsup;': '\\u2290',\n    'sqsupe;': '\\u2292',\n    'sqsupset;': '\\u2290',\n    'sqsupseteq;': '\\u2292',\n    'squ;': '\\u25a1',\n    'Square;': '\\u25a1',\n    'square;': '\\u25a1',\n    'SquareIntersection;': '\\u2293',\n    'SquareSubset;': '\\u228f',\n    'SquareSubsetEqual;': '\\u2291',\n    'SquareSuperset;': '\\u2290',\n    'SquareSupersetEqual;': '\\u2292',\n    'SquareUnion;': '\\u2294',\n    'squarf;': '\\u25aa',\n    'squf;': '\\u25aa',\n    'srarr;': '\\u2192',\n    'Sscr;': '\\U0001d4ae',\n    'sscr;': '\\U0001d4c8',\n    'ssetmn;': '\\u2216',\n    'ssmile;': '\\u2323',\n    'sstarf;': '\\u22c6',\n    'Star;': '\\u22c6',\n    'star;': '\\u2606',\n    'starf;': '\\u2605',\n    'straightepsilon;': '\\u03f5',\n    'straightphi;': '\\u03d5',\n    'strns;': '\\xaf',\n    'Sub;': '\\u22d0',\n    'sub;': '\\u2282',\n    'subdot;': '\\u2abd',\n    'subE;': '\\u2ac5',\n    'sube;': '\\u2286',\n    'subedot;': '\\u2ac3',\n    'submult;': '\\u2ac1',\n    'subnE;': '\\u2acb',\n    'subne;': '\\u228a',\n    'subplus;': '\\u2abf',\n    'subrarr;': '\\u2979',\n    'Subset;': '\\u22d0',\n    'subset;': '\\u2282',\n    'subseteq;': '\\u2286',\n    'subseteqq;': '\\u2ac5',\n    'SubsetEqual;': '\\u2286',\n    'subsetneq;': '\\u228a',\n    'subsetneqq;': '\\u2acb',\n    'subsim;': '\\u2ac7',\n    'subsub;': '\\u2ad5',\n    'subsup;': '\\u2ad3',\n    'succ;': '\\u227b',\n    'succapprox;': '\\u2ab8',\n    'succcurlyeq;': '\\u227d',\n    'Succeeds;': '\\u227b',\n    'SucceedsEqual;': '\\u2ab0',\n    'SucceedsSlantEqual;': '\\u227d',\n    'SucceedsTilde;': '\\u227f',\n    'succeq;': '\\u2ab0',\n    'succnapprox;': '\\u2aba',\n    'succneqq;': '\\u2ab6',\n    'succnsim;': '\\u22e9',\n    'succsim;': '\\u227f',\n    'SuchThat;': '\\u220b',\n    'Sum;': '\\u2211',\n    'sum;': '\\u2211',\n    'sung;': '\\u266a',\n    'sup1': '\\xb9',\n    'sup1;': '\\xb9',\n    'sup2': '\\xb2',\n    'sup2;': '\\xb2',\n    'sup3': '\\xb3',\n    'sup3;': '\\xb3',\n    'Sup;': '\\u22d1',\n    'sup;': '\\u2283',\n    'supdot;': '\\u2abe',\n    'supdsub;': '\\u2ad8',\n    'supE;': '\\u2ac6',\n    'supe;': '\\u2287',\n    'supedot;': '\\u2ac4',\n    'Superset;': '\\u2283',\n    'SupersetEqual;': '\\u2287',\n    'suphsol;': '\\u27c9',\n    'suphsub;': '\\u2ad7',\n    'suplarr;': '\\u297b',\n    'supmult;': '\\u2ac2',\n    'supnE;': '\\u2acc',\n    'supne;': '\\u228b',\n    'supplus;': '\\u2ac0',\n    'Supset;': '\\u22d1',\n    'supset;': '\\u2283',\n    'supseteq;': '\\u2287',\n    'supseteqq;': '\\u2ac6',\n    'supsetneq;': '\\u228b',\n    'supsetneqq;': '\\u2acc',\n    'supsim;': '\\u2ac8',\n    'supsub;': '\\u2ad4',\n    'supsup;': '\\u2ad6',\n    'swarhk;': '\\u2926',\n    'swArr;': '\\u21d9',\n    'swarr;': '\\u2199',\n    'swarrow;': '\\u2199',\n    'swnwar;': '\\u292a',\n    'szlig': '\\xdf',\n    'szlig;': '\\xdf',\n    'Tab;': '\\t',\n    'target;': '\\u2316',\n    'Tau;': '\\u03a4',\n    'tau;': '\\u03c4',\n    'tbrk;': '\\u23b4',\n    'Tcaron;': '\\u0164',\n    'tcaron;': '\\u0165',\n    'Tcedil;': '\\u0162',\n    'tcedil;': '\\u0163',\n    'Tcy;': '\\u0422',\n    'tcy;': '\\u0442',\n    'tdot;': '\\u20db',\n    'telrec;': '\\u2315',\n    'Tfr;': '\\U0001d517',\n    'tfr;': '\\U0001d531',\n    'there4;': '\\u2234',\n    'Therefore;': '\\u2234',\n    'therefore;': '\\u2234',\n    'Theta;': '\\u0398',\n    'theta;': '\\u03b8',\n    'thetasym;': '\\u03d1',\n    'thetav;': '\\u03d1',\n    'thickapprox;': '\\u2248',\n    'thicksim;': '\\u223c',\n    'ThickSpace;': '\\u205f\\u200a',\n    'thinsp;': '\\u2009',\n    'ThinSpace;': '\\u2009',\n    'thkap;': '\\u2248',\n    'thksim;': '\\u223c',\n    'THORN': '\\xde',\n    'thorn': '\\xfe',\n    'THORN;': '\\xde',\n    'thorn;': '\\xfe',\n    'Tilde;': '\\u223c',\n    'tilde;': '\\u02dc',\n    'TildeEqual;': '\\u2243',\n    'TildeFullEqual;': '\\u2245',\n    'TildeTilde;': '\\u2248',\n    'times': '\\xd7',\n    'times;': '\\xd7',\n    'timesb;': '\\u22a0',\n    'timesbar;': '\\u2a31',\n    'timesd;': '\\u2a30',\n    'tint;': '\\u222d',\n    'toea;': '\\u2928',\n    'top;': '\\u22a4',\n    'topbot;': '\\u2336',\n    'topcir;': '\\u2af1',\n    'Topf;': '\\U0001d54b',\n    'topf;': '\\U0001d565',\n    'topfork;': '\\u2ada',\n    'tosa;': '\\u2929',\n    'tprime;': '\\u2034',\n    'TRADE;': '\\u2122',\n    'trade;': '\\u2122',\n    'triangle;': '\\u25b5',\n    'triangledown;': '\\u25bf',\n    'triangleleft;': '\\u25c3',\n    'trianglelefteq;': '\\u22b4',\n    'triangleq;': '\\u225c',\n    'triangleright;': '\\u25b9',\n    'trianglerighteq;': '\\u22b5',\n    'tridot;': '\\u25ec',\n    'trie;': '\\u225c',\n    'triminus;': '\\u2a3a',\n    'TripleDot;': '\\u20db',\n    'triplus;': '\\u2a39',\n    'trisb;': '\\u29cd',\n    'tritime;': '\\u2a3b',\n    'trpezium;': '\\u23e2',\n    'Tscr;': '\\U0001d4af',\n    'tscr;': '\\U0001d4c9',\n    'TScy;': '\\u0426',\n    'tscy;': '\\u0446',\n    'TSHcy;': '\\u040b',\n    'tshcy;': '\\u045b',\n    'Tstrok;': '\\u0166',\n    'tstrok;': '\\u0167',\n    'twixt;': '\\u226c',\n    'twoheadleftarrow;': '\\u219e',\n    'twoheadrightarrow;': '\\u21a0',\n    'Uacute': '\\xda',\n    'uacute': '\\xfa',\n    'Uacute;': '\\xda',\n    'uacute;': '\\xfa',\n    'Uarr;': '\\u219f',\n    'uArr;': '\\u21d1',\n    'uarr;': '\\u2191',\n    'Uarrocir;': '\\u2949',\n    'Ubrcy;': '\\u040e',\n    'ubrcy;': '\\u045e',\n    'Ubreve;': '\\u016c',\n    'ubreve;': '\\u016d',\n    'Ucirc': '\\xdb',\n    'ucirc': '\\xfb',\n    'Ucirc;': '\\xdb',\n    'ucirc;': '\\xfb',\n    'Ucy;': '\\u0423',\n    'ucy;': '\\u0443',\n    'udarr;': '\\u21c5',\n    'Udblac;': '\\u0170',\n    'udblac;': '\\u0171',\n    'udhar;': '\\u296e',\n    'ufisht;': '\\u297e',\n    'Ufr;': '\\U0001d518',\n    'ufr;': '\\U0001d532',\n    'Ugrave': '\\xd9',\n    'ugrave': '\\xf9',\n    'Ugrave;': '\\xd9',\n    'ugrave;': '\\xf9',\n    'uHar;': '\\u2963',\n    'uharl;': '\\u21bf',\n    'uharr;': '\\u21be',\n    'uhblk;': '\\u2580',\n    'ulcorn;': '\\u231c',\n    'ulcorner;': '\\u231c',\n    'ulcrop;': '\\u230f',\n    'ultri;': '\\u25f8',\n    'Umacr;': '\\u016a',\n    'umacr;': '\\u016b',\n    'uml': '\\xa8',\n    'uml;': '\\xa8',\n    'UnderBar;': '_',\n    'UnderBrace;': '\\u23df',\n    'UnderBracket;': '\\u23b5',\n    'UnderParenthesis;': '\\u23dd',\n    'Union;': '\\u22c3',\n    'UnionPlus;': '\\u228e',\n    'Uogon;': '\\u0172',\n    'uogon;': '\\u0173',\n    'Uopf;': '\\U0001d54c',\n    'uopf;': '\\U0001d566',\n    'UpArrow;': '\\u2191',\n    'Uparrow;': '\\u21d1',\n    'uparrow;': '\\u2191',\n    'UpArrowBar;': '\\u2912',\n    'UpArrowDownArrow;': '\\u21c5',\n    'UpDownArrow;': '\\u2195',\n    'Updownarrow;': '\\u21d5',\n    'updownarrow;': '\\u2195',\n    'UpEquilibrium;': '\\u296e',\n    'upharpoonleft;': '\\u21bf',\n    'upharpoonright;': '\\u21be',\n    'uplus;': '\\u228e',\n    'UpperLeftArrow;': '\\u2196',\n    'UpperRightArrow;': '\\u2197',\n    'Upsi;': '\\u03d2',\n    'upsi;': '\\u03c5',\n    'upsih;': '\\u03d2',\n    'Upsilon;': '\\u03a5',\n    'upsilon;': '\\u03c5',\n    'UpTee;': '\\u22a5',\n    'UpTeeArrow;': '\\u21a5',\n    'upuparrows;': '\\u21c8',\n    'urcorn;': '\\u231d',\n    'urcorner;': '\\u231d',\n    'urcrop;': '\\u230e',\n    'Uring;': '\\u016e',\n    'uring;': '\\u016f',\n    'urtri;': '\\u25f9',\n    'Uscr;': '\\U0001d4b0',\n    'uscr;': '\\U0001d4ca',\n    'utdot;': '\\u22f0',\n    'Utilde;': '\\u0168',\n    'utilde;': '\\u0169',\n    'utri;': '\\u25b5',\n    'utrif;': '\\u25b4',\n    'uuarr;': '\\u21c8',\n    'Uuml': '\\xdc',\n    'uuml': '\\xfc',\n    'Uuml;': '\\xdc',\n    'uuml;': '\\xfc',\n    'uwangle;': '\\u29a7',\n    'vangrt;': '\\u299c',\n    'varepsilon;': '\\u03f5',\n    'varkappa;': '\\u03f0',\n    'varnothing;': '\\u2205',\n    'varphi;': '\\u03d5',\n    'varpi;': '\\u03d6',\n    'varpropto;': '\\u221d',\n    'vArr;': '\\u21d5',\n    'varr;': '\\u2195',\n    'varrho;': '\\u03f1',\n    'varsigma;': '\\u03c2',\n    'varsubsetneq;': '\\u228a\\ufe00',\n    'varsubsetneqq;': '\\u2acb\\ufe00',\n    'varsupsetneq;': '\\u228b\\ufe00',\n    'varsupsetneqq;': '\\u2acc\\ufe00',\n    'vartheta;': '\\u03d1',\n    'vartriangleleft;': '\\u22b2',\n    'vartriangleright;': '\\u22b3',\n    'Vbar;': '\\u2aeb',\n    'vBar;': '\\u2ae8',\n    'vBarv;': '\\u2ae9',\n    'Vcy;': '\\u0412',\n    'vcy;': '\\u0432',\n    'VDash;': '\\u22ab',\n    'Vdash;': '\\u22a9',\n    'vDash;': '\\u22a8',\n    'vdash;': '\\u22a2',\n    'Vdashl;': '\\u2ae6',\n    'Vee;': '\\u22c1',\n    'vee;': '\\u2228',\n    'veebar;': '\\u22bb',\n    'veeeq;': '\\u225a',\n    'vellip;': '\\u22ee',\n    'Verbar;': '\\u2016',\n    'verbar;': '|',\n    'Vert;': '\\u2016',\n    'vert;': '|',\n    'VerticalBar;': '\\u2223',\n    'VerticalLine;': '|',\n    'VerticalSeparator;': '\\u2758',\n    'VerticalTilde;': '\\u2240',\n    'VeryThinSpace;': '\\u200a',\n    'Vfr;': '\\U0001d519',\n    'vfr;': '\\U0001d533',\n    'vltri;': '\\u22b2',\n    'vnsub;': '\\u2282\\u20d2',\n    'vnsup;': '\\u2283\\u20d2',\n    'Vopf;': '\\U0001d54d',\n    'vopf;': '\\U0001d567',\n    'vprop;': '\\u221d',\n    'vrtri;': '\\u22b3',\n    'Vscr;': '\\U0001d4b1',\n    'vscr;': '\\U0001d4cb',\n    'vsubnE;': '\\u2acb\\ufe00',\n    'vsubne;': '\\u228a\\ufe00',\n    'vsupnE;': '\\u2acc\\ufe00',\n    'vsupne;': '\\u228b\\ufe00',\n    'Vvdash;': '\\u22aa',\n    'vzigzag;': '\\u299a',\n    'Wcirc;': '\\u0174',\n    'wcirc;': '\\u0175',\n    'wedbar;': '\\u2a5f',\n    'Wedge;': '\\u22c0',\n    'wedge;': '\\u2227',\n    'wedgeq;': '\\u2259',\n    'weierp;': '\\u2118',\n    'Wfr;': '\\U0001d51a',\n    'wfr;': '\\U0001d534',\n    'Wopf;': '\\U0001d54e',\n    'wopf;': '\\U0001d568',\n    'wp;': '\\u2118',\n    'wr;': '\\u2240',\n    'wreath;': '\\u2240',\n    'Wscr;': '\\U0001d4b2',\n    'wscr;': '\\U0001d4cc',\n    'xcap;': '\\u22c2',\n    'xcirc;': '\\u25ef',\n    'xcup;': '\\u22c3',\n    'xdtri;': '\\u25bd',\n    'Xfr;': '\\U0001d51b',\n    'xfr;': '\\U0001d535',\n    'xhArr;': '\\u27fa',\n    'xharr;': '\\u27f7',\n    'Xi;': '\\u039e',\n    'xi;': '\\u03be',\n    'xlArr;': '\\u27f8',\n    'xlarr;': '\\u27f5',\n    'xmap;': '\\u27fc',\n    'xnis;': '\\u22fb',\n    'xodot;': '\\u2a00',\n    'Xopf;': '\\U0001d54f',\n    'xopf;': '\\U0001d569',\n    'xoplus;': '\\u2a01',\n    'xotime;': '\\u2a02',\n    'xrArr;': '\\u27f9',\n    'xrarr;': '\\u27f6',\n    'Xscr;': '\\U0001d4b3',\n    'xscr;': '\\U0001d4cd',\n    'xsqcup;': '\\u2a06',\n    'xuplus;': '\\u2a04',\n    'xutri;': '\\u25b3',\n    'xvee;': '\\u22c1',\n    'xwedge;': '\\u22c0',\n    'Yacute': '\\xdd',\n    'yacute': '\\xfd',\n    'Yacute;': '\\xdd',\n    'yacute;': '\\xfd',\n    'YAcy;': '\\u042f',\n    'yacy;': '\\u044f',\n    'Ycirc;': '\\u0176',\n    'ycirc;': '\\u0177',\n    'Ycy;': '\\u042b',\n    'ycy;': '\\u044b',\n    'yen': '\\xa5',\n    'yen;': '\\xa5',\n    'Yfr;': '\\U0001d51c',\n    'yfr;': '\\U0001d536',\n    'YIcy;': '\\u0407',\n    'yicy;': '\\u0457',\n    'Yopf;': '\\U0001d550',\n    'yopf;': '\\U0001d56a',\n    'Yscr;': '\\U0001d4b4',\n    'yscr;': '\\U0001d4ce',\n    'YUcy;': '\\u042e',\n    'yucy;': '\\u044e',\n    'yuml': '\\xff',\n    'Yuml;': '\\u0178',\n    'yuml;': '\\xff',\n    'Zacute;': '\\u0179',\n    'zacute;': '\\u017a',\n    'Zcaron;': '\\u017d',\n    'zcaron;': '\\u017e',\n    'Zcy;': '\\u0417',\n    'zcy;': '\\u0437',\n    'Zdot;': '\\u017b',\n    'zdot;': '\\u017c',\n    'zeetrf;': '\\u2128',\n    'ZeroWidthSpace;': '\\u200b',\n    'Zeta;': '\\u0396',\n    'zeta;': '\\u03b6',\n    'Zfr;': '\\u2128',\n    'zfr;': '\\U0001d537',\n    'ZHcy;': '\\u0416',\n    'zhcy;': '\\u0436',\n    'zigrarr;': '\\u21dd',\n    'Zopf;': '\\u2124',\n    'zopf;': '\\U0001d56b',\n    'Zscr;': '\\U0001d4b5',\n    'zscr;': '\\U0001d4cf',\n    'zwj;': '\\u200d',\n    'zwnj;': '\\u200c',\n}\ncodepoint2name = {}\nentitydefs = {}\nfor (name, codepoint) in name2codepoint.items():\n    codepoint2name[codepoint] = name\n    entitydefs[name] = chr(codepoint)\ndel name, codepoint",
        "name_type": "stdlib"
    },
    "html.parser": {
        "API_name": "html.parser",
        "loc_name": "html.parser",
        "args": "*",
        "args_default": "*",
        "filepath": "html.parser",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"A parser for HTML and XHTML.\"\"\"\n__all__ = ['HTMLParser']\ninteresting_normal = re.compile('[&<]')\nincomplete = re.compile('&[a-zA-Z#]')\nentityref = re.compile('&([a-zA-Z][-.a-zA-Z0-9]*)[^a-zA-Z0-9]')\ncharref = re.compile('&#(?:[0-9]+|[xX][0-9a-fA-F]+)[^0-9a-fA-F]')\nstarttagopen = re.compile('<[a-zA-Z]')\npiclose = re.compile('>')\ncommentclose = re.compile(r'--\\s*>')\ntagfind_tolerant = re.compile(r'([a-zA-Z][^\\t\\n\\r\\f />\\x00]*)(?:\\s|/(?!>))*')\nattrfind_tolerant = re.compile(\n    r'((?<=[\\'\"\\s/])[^\\s/>][^\\s/=>]*)(\\s*=+\\s*'\n    r'(\\'[^\\']*\\'|\"[^\"]*\"|(?![\\'\"])[^>\\s]*))?(?:\\s|/(?!>))*')\nlocatestarttagend_tolerant = re.compile(r\"\"\"\n  <[a-zA-Z][^\\t\\n\\r\\f />\\x00]*       # tag name\n  (?:[\\s/]*                          # optional whitespace before attribute name\n    (?:(?<=['\"\\s/])[^\\s/>][^\\s/=>]*  # attribute name\n      (?:\\s*=+\\s*                    # value indicator\n        (?:'[^']*'                   # LITA-enclosed value\n          |\"[^\"]*\"                   # LIT-enclosed value\n          |(?!['\"])[^>\\s]*           # bare value\n         )\n        \\s*                          # possibly followed by a space\n       )?(?:\\s|/(?!>))*\n     )*\n   )?\n  \\s*                                # trailing whitespace\n\"\"\", re.VERBOSE)\nendendtag = re.compile('>')\nendtagfind = re.compile(r'</\\s*([a-zA-Z][-.a-zA-Z0-9:_]*)\\s*>')",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser": {
        "API_name": "html.parser.HTMLParser",
        "loc_name": "html.parser.HTMLParser",
        "args": "*",
        "args_default": "*",
        "filepath": "html.parser",
        "lineno": 62,
        "namespace": "HTMLParser",
        "body": "",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.__init__": {
        "API_name": "html.parser.HTMLParser.__init__",
        "loc_name": "html.parser.HTMLParser.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 86,
        "namespace": "HTMLParser",
        "body": "    def __init__(self, *, convert_charrefs=True):\n        \"\"\"Initialize and reset this instance.\n\n        If convert_charrefs is True (the default), all character references\n        are automatically converted to the corresponding Unicode characters.\n        \"\"\"\n        self.convert_charrefs = convert_charrefs\n        self.reset()",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.reset": {
        "API_name": "html.parser.HTMLParser.reset",
        "loc_name": "html.parser.HTMLParser.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 95,
        "namespace": "HTMLParser",
        "body": "    def reset(self):\n        \"\"\"Reset this instance.  Loses all unprocessed data.\"\"\"\n        self.rawdata = ''\n        self.lasttag = '???'\n        self.interesting = interesting_normal\n        self.cdata_elem = None\n        _markupbase.ParserBase.reset(self)",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.feed": {
        "API_name": "html.parser.HTMLParser.feed",
        "loc_name": "html.parser.HTMLParser.feed",
        "args": "self;data",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 103,
        "namespace": "HTMLParser",
        "body": "    def feed(self, data):\n        r\"\"\"Feed data to the parser.\n\n        Call this as often as you want, with as little or as much text\n        as you want (may include '\\n').\n        \"\"\"\n        self.rawdata = self.rawdata + data\n        self.goahead(0)",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.close": {
        "API_name": "html.parser.HTMLParser.close",
        "loc_name": "html.parser.HTMLParser.close",
        "args": "self",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 112,
        "namespace": "HTMLParser",
        "body": "    def close(self):\n        \"\"\"Handle any buffered data.\"\"\"\n        self.goahead(1)",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.get_starttag_text": {
        "API_name": "html.parser.HTMLParser.get_starttag_text",
        "loc_name": "html.parser.HTMLParser.get_starttag_text",
        "args": "self",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 118,
        "namespace": "HTMLParser",
        "body": "    def get_starttag_text(self):\n        \"\"\"Return full source of start tag: '<...>'.\"\"\"\n        return self.__starttag_text",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.set_cdata_mode": {
        "API_name": "html.parser.HTMLParser.set_cdata_mode",
        "loc_name": "html.parser.HTMLParser.set_cdata_mode",
        "args": "self;elem",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 122,
        "namespace": "HTMLParser",
        "body": "    def set_cdata_mode(self, elem):\n        self.cdata_elem = elem.lower()\n        self.interesting = re.compile(r'</\\s*%s\\s*>' % self.cdata_elem, re.I)",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.clear_cdata_mode": {
        "API_name": "html.parser.HTMLParser.clear_cdata_mode",
        "loc_name": "html.parser.HTMLParser.clear_cdata_mode",
        "args": "self",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 126,
        "namespace": "HTMLParser",
        "body": "    def clear_cdata_mode(self):\n        self.interesting = interesting_normal\n        self.cdata_elem = None",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.goahead": {
        "API_name": "html.parser.HTMLParser.goahead",
        "loc_name": "html.parser.HTMLParser.goahead",
        "args": "self;end",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 133,
        "namespace": "HTMLParser",
        "body": "    def goahead(self, end):\n        rawdata = self.rawdata\n        i = 0\n        n = len(rawdata)\n        while i < n:\n            if self.convert_charrefs and not self.cdata_elem:\n                j = rawdata.find('<', i)\n                if j < 0:\n                    # if we can't find the next <, either we are at the end\n                    # or there's more text incoming.  If the latter is True,\n                    # we can't pass the text to handle_data in case we have\n                    # a charref cut in half at end.  Try to determine if\n                    # this is the case before proceeding by looking for an\n                    # & near the end and see if it's followed by a space or ;.\n                    amppos = rawdata.rfind('&', max(i, n-34))\n                    if (amppos >= 0 and\n                        not re.compile(r'[\\s;]').search(rawdata, amppos)):\n                        break  # wait till we get all the text\n                    j = n\n            else:\n                match = self.interesting.search(rawdata, i)  # < or &\n                if match:\n                    j = match.start()\n                else:\n                    if self.cdata_elem:\n                        break\n                    j = n\n            if i < j:\n                if self.convert_charrefs and not self.cdata_elem:\n                    self.handle_data(unescape(rawdata[i:j]))\n                else:\n                    self.handle_data(rawdata[i:j])\n            i = self.updatepos(i, j)\n            if i == n: break\n            startswith = rawdata.startswith\n            if startswith('<', i):\n                if starttagopen.match(rawdata, i): # < + letter\n                    k = self.parse_starttag(i)\n                elif startswith(\"</\", i):\n                    k = self.parse_endtag(i)\n                elif startswith(\"<!--\", i):\n                    k = self.parse_comment(i)\n                elif startswith(\"<?\", i):\n                    k = self.parse_pi(i)\n                elif startswith(\"<!\", i):\n                    k = self.parse_html_declaration(i)\n                elif (i + 1) < n:\n                    self.handle_data(\"<\")\n                    k = i + 1\n                else:\n                    break\n                if k < 0:\n                    if not end:\n                        break\n                    k = rawdata.find('>', i + 1)\n                    if k < 0:\n                        k = rawdata.find('<', i + 1)\n                        if k < 0:\n                            k = i + 1\n                    else:\n                        k += 1\n                    if self.convert_charrefs and not self.cdata_elem:\n                        self.handle_data(unescape(rawdata[i:k]))\n                    else:\n                        self.handle_data(rawdata[i:k])\n                i = self.updatepos(i, k)\n            elif startswith(\"&#\", i):\n                match = charref.match(rawdata, i)\n                if match:\n                    name = match.group()[2:-1]\n                    self.handle_charref(name)\n                    k = match.end()\n                    if not startswith(';', k-1):\n                        k = k - 1\n                    i = self.updatepos(i, k)\n                    continue\n                else:\n                    if \";\" in rawdata[i:]:  # bail by consuming &#\n                        self.handle_data(rawdata[i:i+2])\n                        i = self.updatepos(i, i+2)\n                    break\n            elif startswith('&', i):\n                match = entityref.match(rawdata, i)\n                if match:\n                    name = match.group(1)\n                    self.handle_entityref(name)\n                    k = match.end()\n                    if not startswith(';', k-1):\n                        k = k - 1\n                    i = self.updatepos(i, k)\n                    continue\n                match = incomplete.match(rawdata, i)\n                if match:\n                    # match.group() will contain at least 2 chars\n                    if end and match.group() == rawdata[i:]:\n                        k = match.end()\n                        if k <= i:\n                            k = n\n                        i = self.updatepos(i, i + 1)\n                    # incomplete\n                    break\n                elif (i + 1) < n:\n                    # not the end of the buffer, and can't be confused\n                    # with some other construct\n                    self.handle_data(\"&\")\n                    i = self.updatepos(i, i + 1)\n                else:\n                    break\n            else:\n                assert 0, \"interesting.search() lied\"\n        # end while\n        if end and i < n and not self.cdata_elem:\n            if self.convert_charrefs and not self.cdata_elem:\n                self.handle_data(unescape(rawdata[i:n]))\n            else:\n                self.handle_data(rawdata[i:n])\n            i = self.updatepos(i, n)\n        self.rawdata = rawdata[i:]",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.parse_html_declaration": {
        "API_name": "html.parser.HTMLParser.parse_html_declaration",
        "loc_name": "html.parser.HTMLParser.parse_html_declaration",
        "args": "self;i",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 255,
        "namespace": "HTMLParser",
        "body": "    def parse_html_declaration(self, i):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] == '<!', ('unexpected call to '\n                                        'parse_html_declaration()')\n        if rawdata[i:i+4] == '<!--':\n            # this case is actually already handled in goahead()\n            return self.parse_comment(i)\n        elif rawdata[i:i+3] == '<![':\n            return self.parse_marked_section(i)\n        elif rawdata[i:i+9].lower() == '<!doctype':\n            # find the closing >\n            gtpos = rawdata.find('>', i+9)\n            if gtpos == -1:\n                return -1\n            self.handle_decl(rawdata[i+2:gtpos])\n            return gtpos+1\n        else:\n            return self.parse_bogus_comment(i)",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.parse_bogus_comment": {
        "API_name": "html.parser.HTMLParser.parse_bogus_comment",
        "loc_name": "html.parser.HTMLParser.parse_bogus_comment",
        "args": "self;i;report",
        "args_default": 1,
        "filepath": "html.parser",
        "lineno": 276,
        "namespace": "HTMLParser",
        "body": "    def parse_bogus_comment(self, i, report=1):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] in ('<!', '</'), ('unexpected call to '\n                                                'parse_comment()')\n        pos = rawdata.find('>', i+2)\n        if pos == -1:\n            return -1\n        if report:\n            self.handle_comment(rawdata[i+2:pos])\n        return pos + 1",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.parse_pi": {
        "API_name": "html.parser.HTMLParser.parse_pi",
        "loc_name": "html.parser.HTMLParser.parse_pi",
        "args": "self;i",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 288,
        "namespace": "HTMLParser",
        "body": "    def parse_pi(self, i):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] == '<?', 'unexpected call to parse_pi()'\n        match = piclose.search(rawdata, i+2) # >\n        if not match:\n            return -1\n        j = match.start()\n        self.handle_pi(rawdata[i+2: j])\n        j = match.end()\n        return j",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.parse_starttag": {
        "API_name": "html.parser.HTMLParser.parse_starttag",
        "loc_name": "html.parser.HTMLParser.parse_starttag",
        "args": "self;i",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 300,
        "namespace": "HTMLParser",
        "body": "    def parse_starttag(self, i):\n        self.__starttag_text = None\n        endpos = self.check_for_whole_start_tag(i)\n        if endpos < 0:\n            return endpos\n        rawdata = self.rawdata\n        self.__starttag_text = rawdata[i:endpos]\n\n        # Now parse the data between i+1 and j into a tag and attrs\n        attrs = []\n        match = tagfind_tolerant.match(rawdata, i+1)\n        assert match, 'unexpected call to parse_starttag()'\n        k = match.end()\n        self.lasttag = tag = match.group(1).lower()\n        while k < endpos:\n            m = attrfind_tolerant.match(rawdata, k)\n            if not m:\n                break\n            attrname, rest, attrvalue = m.group(1, 2, 3)\n            if not rest:\n                attrvalue = None\n            elif attrvalue[:1] == '\\'' == attrvalue[-1:] or \\\n                 attrvalue[:1] == '\"' == attrvalue[-1:]:\n                attrvalue = attrvalue[1:-1]\n            if attrvalue:\n                attrvalue = unescape(attrvalue)\n            attrs.append((attrname.lower(), attrvalue))\n            k = m.end()\n\n        end = rawdata[k:endpos].strip()\n        if end not in (\">\", \"/>\"):\n            lineno, offset = self.getpos()\n            if \"\\n\" in self.__starttag_text:\n                lineno = lineno + self.__starttag_text.count(\"\\n\")\n                offset = len(self.__starttag_text) \\\n                         - self.__starttag_text.rfind(\"\\n\")\n            else:\n                offset = offset + len(self.__starttag_text)\n            self.handle_data(rawdata[i:endpos])\n            return endpos\n        if end.endswith('/>'):\n            # XHTML-style empty tag: <span attr=\"value\" />\n            self.handle_startendtag(tag, attrs)\n        else:\n            self.handle_starttag(tag, attrs)\n            if tag in self.CDATA_CONTENT_ELEMENTS:\n                self.set_cdata_mode(tag)\n        return endpos",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.check_for_whole_start_tag": {
        "API_name": "html.parser.HTMLParser.check_for_whole_start_tag",
        "loc_name": "html.parser.HTMLParser.check_for_whole_start_tag",
        "args": "self;i",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 351,
        "namespace": "HTMLParser",
        "body": "    def check_for_whole_start_tag(self, i):\n        rawdata = self.rawdata\n        m = locatestarttagend_tolerant.match(rawdata, i)\n        if m:\n            j = m.end()\n            next = rawdata[j:j+1]\n            if next == \">\":\n                return j + 1\n            if next == \"/\":\n                if rawdata.startswith(\"/>\", j):\n                    return j + 2\n                if rawdata.startswith(\"/\", j):\n                    # buffer boundary\n                    return -1\n                # else bogus input\n                if j > i:\n                    return j\n                else:\n                    return i + 1\n            if next == \"\":\n                # end of input\n                return -1\n            if next in (\"abcdefghijklmnopqrstuvwxyz=/\"\n                        \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n                # end of input in or before attribute value, or we have the\n                # '/' from a '/>' ending\n                return -1\n            if j > i:\n                return j\n            else:\n                return i + 1\n        raise AssertionError(\"we should not get here!\")",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.parse_endtag": {
        "API_name": "html.parser.HTMLParser.parse_endtag",
        "loc_name": "html.parser.HTMLParser.parse_endtag",
        "args": "self;i",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 385,
        "namespace": "HTMLParser",
        "body": "    def parse_endtag(self, i):\n        rawdata = self.rawdata\n        assert rawdata[i:i+2] == \"</\", \"unexpected call to parse_endtag\"\n        match = endendtag.search(rawdata, i+1) # >\n        if not match:\n            return -1\n        gtpos = match.end()\n        match = endtagfind.match(rawdata, i) # </ + tag + >\n        if not match:\n            if self.cdata_elem is not None:\n                self.handle_data(rawdata[i:gtpos])\n                return gtpos\n            # find the name: w3.org/TR/html5/tokenization.html#tag-name-state\n            namematch = tagfind_tolerant.match(rawdata, i+2)\n            if not namematch:\n                # w3.org/TR/html5/tokenization.html#end-tag-open-state\n                if rawdata[i:i+3] == '</>':\n                    return i+3\n                else:\n                    return self.parse_bogus_comment(i)\n            tagname = namematch.group(1).lower()\n            # consume and ignore other stuff between the name and the >\n            # Note: this is not 100% correct, since we might have things like\n            # </tag attr=\">\">, but looking for > after the name should cover\n            # most of the cases and is much simpler\n            gtpos = rawdata.find('>', namematch.end())\n            self.handle_endtag(tagname)\n            return gtpos+1\n\n        elem = match.group(1).lower() # script or style\n        if self.cdata_elem is not None:\n            if elem != self.cdata_elem:\n                self.handle_data(rawdata[i:gtpos])\n                return gtpos\n\n        self.handle_endtag(elem)\n        self.clear_cdata_mode()\n        return gtpos",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_startendtag": {
        "API_name": "html.parser.HTMLParser.handle_startendtag",
        "loc_name": "html.parser.HTMLParser.handle_startendtag",
        "args": "self;tag;attrs",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 425,
        "namespace": "HTMLParser",
        "body": "    def handle_startendtag(self, tag, attrs):\n        self.handle_starttag(tag, attrs)\n        self.handle_endtag(tag)",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_starttag": {
        "API_name": "html.parser.HTMLParser.handle_starttag",
        "loc_name": "html.parser.HTMLParser.handle_starttag",
        "args": "self;tag;attrs",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 430,
        "namespace": "HTMLParser",
        "body": "    def handle_starttag(self, tag, attrs):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_endtag": {
        "API_name": "html.parser.HTMLParser.handle_endtag",
        "loc_name": "html.parser.HTMLParser.handle_endtag",
        "args": "self;tag",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 434,
        "namespace": "HTMLParser",
        "body": "    def handle_endtag(self, tag):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_charref": {
        "API_name": "html.parser.HTMLParser.handle_charref",
        "loc_name": "html.parser.HTMLParser.handle_charref",
        "args": "self;name",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 438,
        "namespace": "HTMLParser",
        "body": "    def handle_charref(self, name):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_entityref": {
        "API_name": "html.parser.HTMLParser.handle_entityref",
        "loc_name": "html.parser.HTMLParser.handle_entityref",
        "args": "self;name",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 442,
        "namespace": "HTMLParser",
        "body": "    def handle_entityref(self, name):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_data": {
        "API_name": "html.parser.HTMLParser.handle_data",
        "loc_name": "html.parser.HTMLParser.handle_data",
        "args": "self;data",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 446,
        "namespace": "HTMLParser",
        "body": "    def handle_data(self, data):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_comment": {
        "API_name": "html.parser.HTMLParser.handle_comment",
        "loc_name": "html.parser.HTMLParser.handle_comment",
        "args": "self;data",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 450,
        "namespace": "HTMLParser",
        "body": "    def handle_comment(self, data):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_decl": {
        "API_name": "html.parser.HTMLParser.handle_decl",
        "loc_name": "html.parser.HTMLParser.handle_decl",
        "args": "self;decl",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 454,
        "namespace": "HTMLParser",
        "body": "    def handle_decl(self, decl):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.handle_pi": {
        "API_name": "html.parser.HTMLParser.handle_pi",
        "loc_name": "html.parser.HTMLParser.handle_pi",
        "args": "self;data",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 458,
        "namespace": "HTMLParser",
        "body": "    def handle_pi(self, data):\n        pass",
        "name_type": "stdlib"
    },
    "html.parser.HTMLParser.unknown_decl": {
        "API_name": "html.parser.HTMLParser.unknown_decl",
        "loc_name": "html.parser.HTMLParser.unknown_decl",
        "args": "self;data",
        "args_default": 0,
        "filepath": "html.parser",
        "lineno": 461,
        "namespace": "HTMLParser",
        "body": "    def unknown_decl(self, data):\n        pass",
        "name_type": "stdlib"
    },
    "html": {
        "API_name": "html",
        "loc_name": "html",
        "args": "*",
        "args_default": "*",
        "filepath": "html",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"\nGeneral functions for HTML manipulation.\n\"\"\"\n__all__ = ['escape', 'unescape']\n_invalid_charrefs = {\n    0x00: '\\ufffd',  # REPLACEMENT CHARACTER\n    0x0d: '\\r',      # CARRIAGE RETURN\n    0x80: '\\u20ac',  # EURO SIGN\n    0x81: '\\x81',    # <control>\n    0x82: '\\u201a',  # SINGLE LOW-9 QUOTATION MARK\n    0x83: '\\u0192',  # LATIN SMALL LETTER F WITH HOOK\n    0x84: '\\u201e',  # DOUBLE LOW-9 QUOTATION MARK\n    0x85: '\\u2026',  # HORIZONTAL ELLIPSIS\n    0x86: '\\u2020',  # DAGGER\n    0x87: '\\u2021',  # DOUBLE DAGGER\n    0x88: '\\u02c6',  # MODIFIER LETTER CIRCUMFLEX ACCENT\n    0x89: '\\u2030',  # PER MILLE SIGN\n    0x8a: '\\u0160',  # LATIN CAPITAL LETTER S WITH CARON\n    0x8b: '\\u2039',  # SINGLE LEFT-POINTING ANGLE QUOTATION MARK\n    0x8c: '\\u0152',  # LATIN CAPITAL LIGATURE OE\n    0x8d: '\\x8d',    # <control>\n    0x8e: '\\u017d',  # LATIN CAPITAL LETTER Z WITH CARON\n    0x8f: '\\x8f',    # <control>\n    0x90: '\\x90',    # <control>\n    0x91: '\\u2018',  # LEFT SINGLE QUOTATION MARK\n    0x92: '\\u2019',  # RIGHT SINGLE QUOTATION MARK\n    0x93: '\\u201c',  # LEFT DOUBLE QUOTATION MARK\n    0x94: '\\u201d',  # RIGHT DOUBLE QUOTATION MARK\n    0x95: '\\u2022',  # BULLET\n    0x96: '\\u2013',  # EN DASH\n    0x97: '\\u2014',  # EM DASH\n    0x98: '\\u02dc',  # SMALL TILDE\n    0x99: '\\u2122',  # TRADE MARK SIGN\n    0x9a: '\\u0161',  # LATIN SMALL LETTER S WITH CARON\n    0x9b: '\\u203a',  # SINGLE RIGHT-POINTING ANGLE QUOTATION MARK\n    0x9c: '\\u0153',  # LATIN SMALL LIGATURE OE\n    0x9d: '\\x9d',    # <control>\n    0x9e: '\\u017e',  # LATIN SMALL LETTER Z WITH CARON\n    0x9f: '\\u0178',  # LATIN CAPITAL LETTER Y WITH DIAERESIS\n}\n_invalid_codepoints = {\n    # 0x0001 to 0x0008\n    0x1, 0x2, 0x3, 0x4, 0x5, 0x6, 0x7, 0x8,\n    # 0x000E to 0x001F\n    0xe, 0xf, 0x10, 0x11, 0x12, 0x13, 0x14, 0x15, 0x16, 0x17, 0x18, 0x19,\n    0x1a, 0x1b, 0x1c, 0x1d, 0x1e, 0x1f,\n    # 0x007F to 0x009F\n    0x7f, 0x80, 0x81, 0x82, 0x83, 0x84, 0x85, 0x86, 0x87, 0x88, 0x89, 0x8a,\n    0x8b, 0x8c, 0x8d, 0x8e, 0x8f, 0x90, 0x91, 0x92, 0x93, 0x94, 0x95, 0x96,\n    0x97, 0x98, 0x99, 0x9a, 0x9b, 0x9c, 0x9d, 0x9e, 0x9f,\n    # 0xFDD0 to 0xFDEF\n    0xfdd0, 0xfdd1, 0xfdd2, 0xfdd3, 0xfdd4, 0xfdd5, 0xfdd6, 0xfdd7, 0xfdd8,\n    0xfdd9, 0xfdda, 0xfddb, 0xfddc, 0xfddd, 0xfdde, 0xfddf, 0xfde0, 0xfde1,\n    0xfde2, 0xfde3, 0xfde4, 0xfde5, 0xfde6, 0xfde7, 0xfde8, 0xfde9, 0xfdea,\n    0xfdeb, 0xfdec, 0xfded, 0xfdee, 0xfdef,\n    # others\n    0xb, 0xfffe, 0xffff, 0x1fffe, 0x1ffff, 0x2fffe, 0x2ffff, 0x3fffe, 0x3ffff,\n    0x4fffe, 0x4ffff, 0x5fffe, 0x5ffff, 0x6fffe, 0x6ffff, 0x7fffe, 0x7ffff,\n    0x8fffe, 0x8ffff, 0x9fffe, 0x9ffff, 0xafffe, 0xaffff, 0xbfffe, 0xbffff,\n    0xcfffe, 0xcffff, 0xdfffe, 0xdffff, 0xefffe, 0xeffff, 0xffffe, 0xfffff,\n    0x10fffe, 0x10ffff\n}\n_charref = _re.compile(r'&(#[0-9]+;?'\n                       r'|#[xX][0-9a-fA-F]+;?'\n                       r'|[^\\t\\n\\f <&#;]{1,32};?)')",
        "name_type": "stdlib"
    },
    "html.escape": {
        "API_name": "html.escape",
        "loc_name": "html.escape",
        "args": "s;quote",
        "args_default": 1,
        "filepath": "html",
        "lineno": 12,
        "namespace": "*",
        "body": "def escape(s, quote=True):\n    \"\"\"\n    Replace special characters \"&\", \"<\" and \">\" to HTML-safe sequences.\n    If the optional flag quote is true (the default), the quotation mark\n    characters, both double quote (\") and single quote (') characters are also\n    translated.\n    \"\"\"\n    s = s.replace(\"&\", \"&amp;\") # Must be done first!\n    s = s.replace(\"<\", \"&lt;\")\n    s = s.replace(\">\", \"&gt;\")\n    if quote:\n        s = s.replace('\"', \"&quot;\")\n        s = s.replace('\\'', \"&#x27;\")\n    return s",
        "name_type": "stdlib"
    },
    "html._replace_charref": {
        "API_name": "html._replace_charref",
        "loc_name": "html._replace_charref",
        "args": "s",
        "args_default": 0,
        "filepath": "html",
        "lineno": 91,
        "namespace": "*",
        "body": "def _replace_charref(s):\n    s = s.group(1)\n    if s[0] == '#':\n        # numeric charref\n        if s[1] in 'xX':\n            num = int(s[2:].rstrip(';'), 16)\n        else:\n            num = int(s[1:].rstrip(';'))\n        if num in _invalid_charrefs:\n            return _invalid_charrefs[num]\n        if 0xD800 <= num <= 0xDFFF or num > 0x10FFFF:\n            return '\\uFFFD'\n        if num in _invalid_codepoints:\n            return ''\n        return chr(num)\n    else:\n        # named charref\n        if s in _html5:\n            return _html5[s]\n        # find the longest matching name (as defined by the standard)\n        for x in range(len(s)-1, 1, -1):\n            if s[:x] in _html5:\n                return _html5[s[:x]] + s[x:]\n        else:\n            return '&' + s",
        "name_type": "stdlib"
    },
    "html.unescape": {
        "API_name": "html.unescape",
        "loc_name": "html.unescape",
        "args": "s",
        "args_default": 0,
        "filepath": "html",
        "lineno": 122,
        "namespace": "*",
        "body": "def unescape(s):\n    \"\"\"\n    Convert all named and numeric character references (e.g. &gt;, &#62;,\n    &x3e;) in the string s to the corresponding unicode characters.\n    This function uses the rules defined by the HTML 5 standard\n    for both valid and invalid character references, and the list of\n    HTML 5 named character references defined in html.entities.html5.\n    \"\"\"\n    if '&' not in s:\n        return s\n    return _charref.sub(_replace_charref, s)",
        "name_type": "stdlib"
    },
    "http.client": {
        "API_name": "http.client",
        "loc_name": "http.client",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"HTTP/1.1 client library\n\n<intro stuff goes here>\n<other stuff, too>\n\nHTTPConnection goes through a number of \"states\", which define when a client\nmay legally make another request or fetch the response for a particular\nrequest. This diagram details these state transitions:\n\n    (null)\n      |\n      | HTTPConnection()\n      v\n    Idle\n      |\n      | putrequest()\n      v\n    Request-started\n      |\n      | ( putheader() )*  endheaders()\n      v\n    Request-sent\n      |\\_____________________________\n      |                              | getresponse() raises\n      | response = getresponse()     | ConnectionError\n      v                              v\n    Unread-response                Idle\n    [Response-headers-read]\n      |\\____________________\n      |                     |\n      | response.read()     | putrequest()\n      v                     v\n    Idle                  Req-started-unread-response\n                     ______/|\n                   /        |\n   response.read() |        | ( putheader() )*  endheaders()\n                   v        v\n       Request-started    Req-sent-unread-response\n                            |\n                            | response.read()\n                            v\n                          Request-sent\n\nThis diagram presents the following rules:\n  -- a second request may not be started until {response-headers-read}\n  -- a response [object] cannot be retrieved until {request-sent}\n  -- there is no differentiation between an unread response body and a\n     partially read response body\n\nNote: this enforcement is applied by the HTTPConnection class. The\n      HTTPResponse class does not enforce this state machine, which\n      implies sophisticated clients may accelerate the request/response\n      pipeline. Caution should be taken, though: accelerating the states\n      beyond the above pattern may imply knowledge of the server's\n      connection-close behavior for certain requests. For example, it\n      is impossible to tell whether the server will close the connection\n      UNTIL the response headers have been read; this means that further\n      requests cannot be placed into the pipeline until it is known that\n      the server will NOT be closing the connection.\n\nLogical State                  __state            __response\n-------------                  -------            ----------\nIdle                           _CS_IDLE           None\nRequest-started                _CS_REQ_STARTED    None\nRequest-sent                   _CS_REQ_SENT       None\nUnread-response                _CS_IDLE           <response_class>\nReq-started-unread-response    _CS_REQ_STARTED    <response_class>\nReq-sent-unread-response       _CS_REQ_SENT       <response_class>\n\"\"\"\n__all__ = [\"HTTPResponse\", \"HTTPConnection\",\n           \"HTTPException\", \"NotConnected\", \"UnknownProtocol\",\n           \"UnknownTransferEncoding\", \"UnimplementedFileMode\",\n           \"IncompleteRead\", \"InvalidURL\", \"ImproperConnectionState\",\n           \"CannotSendRequest\", \"CannotSendHeader\", \"ResponseNotReady\",\n           \"BadStatusLine\", \"LineTooLong\", \"RemoteDisconnected\", \"error\",\n           \"responses\"]\nHTTP_PORT = 80\nHTTPS_PORT = 443\n_UNKNOWN = 'UNKNOWN'\n_CS_IDLE = 'Idle'\n_CS_REQ_STARTED = 'Request-started'\n_CS_REQ_SENT = 'Request-sent'\nglobals().update(http.HTTPStatus.__members__)\nresponses = {v: v.phrase for v in http.HTTPStatus.__members__.values()}\nMAXAMOUNT = 1048576\n_MAXLINE = 65536\n_MAXHEADERS = 100\n_is_legal_header_name = re.compile(rb'[^:\\s][^:\\r\\n]*').fullmatch\n_is_illegal_header_value = re.compile(rb'\\n(?![ \\t])|\\r(?![ \\t\\n])').search\n_contains_disallowed_url_pchar_re = re.compile('[\\x00-\\x20\\x7f]')\n_contains_disallowed_method_pchar_re = re.compile('[\\x00-\\x1f]')\n_METHODS_EXPECTING_BODY = {'PATCH', 'POST', 'PUT'}\ntry:\n    import ssl\nexcept ImportError:\n    pass\nelse:\n    class HTTPSConnection(HTTPConnection):\n        \"This class allows communication via SSL.\"\n\n        default_port = HTTPS_PORT\n\n        # XXX Should key_file and cert_file be deprecated in favour of context?\n\n        def __init__(self, host, port=None, key_file=None, cert_file=None,\n                     timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n                     source_address=None, *, context=None,\n                     check_hostname=None, blocksize=8192):\n            super(HTTPSConnection, self).__init__(host, port, timeout,\n                                                  source_address,\n                                                  blocksize=blocksize)\n            if (key_file is not None or cert_file is not None or\n                        check_hostname is not None):\n                import warnings\n                warnings.warn(\"key_file, cert_file and check_hostname are \"\n                              \"deprecated, use a custom context instead.\",\n                              DeprecationWarning, 2)\n            self.key_file = key_file\n            self.cert_file = cert_file\n            if context is None:\n                context = ssl._create_default_https_context()\n                # enable PHA for TLS 1.3 connections if available\n                if context.post_handshake_auth is not None:\n                    context.post_handshake_auth = True\n            will_verify = context.verify_mode != ssl.CERT_NONE\n            if check_hostname is None:\n                check_hostname = context.check_hostname\n            if check_hostname and not will_verify:\n                raise ValueError(\"check_hostname needs a SSL context with \"\n                                 \"either CERT_OPTIONAL or CERT_REQUIRED\")\n            if key_file or cert_file:\n                context.load_cert_chain(cert_file, key_file)\n                # cert and key file means the user wants to authenticate.\n                # enable TLS 1.3 PHA implicitly even for custom contexts.\n                if context.post_handshake_auth is not None:\n                    context.post_handshake_auth = True\n            self._context = context\n            if check_hostname is not None:\n                self._context.check_hostname = check_hostname\n\n        def connect(self):\n            \"Connect to a host on a given (SSL) port.\"\n\n            super().connect()\n\n            if self._tunnel_host:\n                server_hostname = self._tunnel_host\n            else:\n                server_hostname = self.host\n\n            self.sock = self._context.wrap_socket(self.sock,\n                                                  server_hostname=server_hostname)\n\n    __all__.append(\"HTTPSConnection\")\nerror = HTTPException",
        "name_type": "stdlib"
    },
    "http.client._encode": {
        "API_name": "http.client._encode",
        "loc_name": "http.client._encode",
        "args": "data;name",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 163,
        "namespace": "*",
        "body": "def _encode(data, name='data'):\n    \"\"\"Call data.encode(\"latin-1\") but show a better error message.\"\"\"\n    try:\n        return data.encode(\"latin-1\")\n    except UnicodeEncodeError as err:\n        raise UnicodeEncodeError(\n            err.encoding,\n            err.object,\n            err.start,\n            err.end,\n            \"%s (%.20r) is not valid Latin-1. Use %s.encode('utf-8') \"\n            \"if you want to send it encoded in UTF-8.\" %\n            (name.title(), data[err.start:err.end], name)) from None",
        "name_type": "stdlib"
    },
    "http.client.HTTPMessage.getallmatchingheaders": {
        "API_name": "http.client.HTTPMessage.getallmatchingheaders",
        "loc_name": "http.client.HTTPMessage.getallmatchingheaders",
        "args": "self;name",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 185,
        "namespace": "HTTPMessage",
        "body": "    def getallmatchingheaders(self, name):\n        \"\"\"Find all header lines matching a given header name.\n\n        Look through the list of headers and find all lines matching a given\n        header name (and their continuation lines).  A list of the lines is\n        returned, without interpretation.  If the header does not occur, an\n        empty list is returned.  If the header occurs multiple times, all\n        occurrences are returned.  Case is not important in the header name.\n\n        \"\"\"\n        name = name.lower() + ':'\n        n = len(name)\n        lst = []\n        hit = 0\n        for line in self.keys():\n            if line[:n].lower() == name:\n                hit = 1\n            elif not line[:1].isspace():\n                hit = 0\n            if hit:\n                lst.append(line)\n        return lst",
        "name_type": "stdlib"
    },
    "http.client.HTTPMessage": {
        "API_name": "http.client.HTTPMessage",
        "loc_name": "http.client.HTTPMessage",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 178,
        "namespace": "HTTPMessage",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client._read_headers": {
        "API_name": "http.client._read_headers",
        "loc_name": "http.client._read_headers",
        "args": "fp",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 208,
        "namespace": "*",
        "body": "def _read_headers(fp):\n    \"\"\"Reads potential header lines into a list from a file pointer.\n\n    Length of line is limited by _MAXLINE, and number of\n    headers is limited by _MAXHEADERS.\n    \"\"\"\n    headers = []\n    while True:\n        line = fp.readline(_MAXLINE + 1)\n        if len(line) > _MAXLINE:\n            raise LineTooLong(\"header line\")\n        headers.append(line)\n        if len(headers) > _MAXHEADERS:\n            raise HTTPException(\"got more than %d headers\" % _MAXHEADERS)\n        if line in (b'\\r\\n', b'\\n', b''):\n            break\n    return headers",
        "name_type": "stdlib"
    },
    "http.client.parse_headers": {
        "API_name": "http.client.parse_headers",
        "loc_name": "http.client.parse_headers",
        "args": "fp;_class",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 226,
        "namespace": "*",
        "body": "def parse_headers(fp, _class=HTTPMessage):\n    \"\"\"Parses only RFC2822 headers from a file pointer.\n\n    email Parser wants to see strings rather than bytes.\n    But a TextIOWrapper around self.rfile would buffer too many bytes\n    from the stream, bytes which we later need to read as bytes.\n    So we read the correct bytes here, as bytes, for email Parser\n    to parse.\n\n    \"\"\"\n    headers = _read_headers(fp)\n    hstring = b''.join(headers).decode('iso-8859-1')\n    return email.parser.Parser(_class=_class).parsestr(hstring)",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse": {
        "API_name": "http.client.HTTPResponse",
        "loc_name": "http.client.HTTPResponse",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 241,
        "namespace": "HTTPResponse",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.__init__": {
        "API_name": "http.client.HTTPResponse.__init__",
        "loc_name": "http.client.HTTPResponse.__init__",
        "args": "self;sock;debuglevel;method;url",
        "args_default": 3,
        "filepath": "http.client",
        "lineno": 250,
        "namespace": "HTTPResponse",
        "body": "    def __init__(self, sock, debuglevel=0, method=None, url=None):\n        # If the response includes a content-length header, we need to\n        # make sure that the client doesn't read more than the\n        # specified number of bytes.  If it does, it will block until\n        # the server times out and closes the connection.  This will\n        # happen if a self.fp.read() is done (without a size) whether\n        # self.fp is buffered or not.  So, no self.fp.read() by\n        # clients unless they know what they are doing.\n        self.fp = sock.makefile(\"rb\")\n        self.debuglevel = debuglevel\n        self._method = method\n\n        # The HTTPResponse object is returned via urllib.  The clients\n        # of http and urllib expect different attributes for the\n        # headers.  headers is used here and supports urllib.  msg is\n        # provided as a backwards compatibility layer for http\n        # clients.\n\n        self.headers = self.msg = None\n\n        # from the Status-Line of the response\n        self.version = _UNKNOWN # HTTP-Version\n        self.status = _UNKNOWN  # Status-Code\n        self.reason = _UNKNOWN  # Reason-Phrase\n\n        self.chunked = _UNKNOWN         # is \"chunked\" being used?\n        self.chunk_left = _UNKNOWN      # bytes left to read in current chunk\n        self.length = _UNKNOWN          # number of bytes left in response\n        self.will_close = _UNKNOWN      # conn will close at end of response",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._read_status": {
        "API_name": "http.client.HTTPResponse._read_status",
        "loc_name": "http.client.HTTPResponse._read_status",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 280,
        "namespace": "HTTPResponse",
        "body": "    def _read_status(self):\n        line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n        if len(line) > _MAXLINE:\n            raise LineTooLong(\"status line\")\n        if self.debuglevel > 0:\n            print(\"reply:\", repr(line))\n        if not line:\n            # Presumably, the server closed the connection before\n            # sending a valid response.\n            raise RemoteDisconnected(\"Remote end closed connection without\"\n                                     \" response\")\n        try:\n            version, status, reason = line.split(None, 2)\n        except ValueError:\n            try:\n                version, status = line.split(None, 1)\n                reason = \"\"\n            except ValueError:\n                # empty version will cause next test to fail.\n                version = \"\"\n        if not version.startswith(\"HTTP/\"):\n            self._close_conn()\n            raise BadStatusLine(line)\n\n        # The status code is a three-digit number\n        try:\n            status = int(status)\n            if status < 100 or status > 999:\n                raise BadStatusLine(line)\n        except ValueError:\n            raise BadStatusLine(line)\n        return version, status, reason",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.begin": {
        "API_name": "http.client.HTTPResponse.begin",
        "loc_name": "http.client.HTTPResponse.begin",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 313,
        "namespace": "HTTPResponse",
        "body": "    def begin(self):\n        if self.headers is not None:\n            # we've already started reading the response\n            return\n\n        # read until we get a non-100 response\n        while True:\n            version, status, reason = self._read_status()\n            if status != CONTINUE:\n                break\n            # skip the header from the 100 response\n            skipped_headers = _read_headers(self.fp)\n            if self.debuglevel > 0:\n                print(\"headers:\", skipped_headers)\n            del skipped_headers\n\n        self.code = self.status = status\n        self.reason = reason.strip()\n        if version in (\"HTTP/1.0\", \"HTTP/0.9\"):\n            # Some servers might still return \"0.9\", treat it as 1.0 anyway\n            self.version = 10\n        elif version.startswith(\"HTTP/1.\"):\n            self.version = 11   # use HTTP/1.1 code for HTTP/1.x where x>=1\n        else:\n            raise UnknownProtocol(version)\n\n        self.headers = self.msg = parse_headers(self.fp)\n\n        if self.debuglevel > 0:\n            for hdr, val in self.headers.items():\n                print(\"header:\", hdr + \":\", val)\n\n        # are we using the chunked-style of transfer encoding?\n        tr_enc = self.headers.get(\"transfer-encoding\")\n        if tr_enc and tr_enc.lower() == \"chunked\":\n            self.chunked = True\n            self.chunk_left = None\n        else:\n            self.chunked = False\n\n        # will the connection close at the end of the response?\n        self.will_close = self._check_close()\n\n        # do we have a Content-Length?\n        # NOTE: RFC 2616, S4.4, #3 says we ignore this if tr_enc is \"chunked\"\n        self.length = None\n        length = self.headers.get(\"content-length\")\n        if length and not self.chunked:\n            try:\n                self.length = int(length)\n            except ValueError:\n                self.length = None\n            else:\n                if self.length < 0:  # ignore nonsensical negative lengths\n                    self.length = None\n        else:\n            self.length = None\n\n        # does the body have a fixed length? (of zero)\n        if (status == NO_CONTENT or status == NOT_MODIFIED or\n            100 <= status < 200 or      # 1xx codes\n            self._method == \"HEAD\"):\n            self.length = 0\n\n        # if the connection remains open, and we aren't using chunked, and\n        # a content-length was not provided, then assume that the connection\n        # WILL close.\n        if (not self.will_close and\n            not self.chunked and\n            self.length is None):\n            self.will_close = True",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._check_close": {
        "API_name": "http.client.HTTPResponse._check_close",
        "loc_name": "http.client.HTTPResponse._check_close",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 385,
        "namespace": "HTTPResponse",
        "body": "    def _check_close(self):\n        conn = self.headers.get(\"connection\")\n        if self.version == 11:\n            # An HTTP/1.1 proxy is assumed to stay open unless\n            # explicitly closed.\n            if conn and \"close\" in conn.lower():\n                return True\n            return False\n\n        # Some HTTP/1.0 implementations have support for persistent\n        # connections, using rules different than HTTP/1.1.\n\n        # For older HTTP, Keep-Alive indicates persistent connection.\n        if self.headers.get(\"keep-alive\"):\n            return False\n\n        # At least Akamai returns a \"Connection: Keep-Alive\" header,\n        # which was supposed to be sent by the client.\n        if conn and \"keep-alive\" in conn.lower():\n            return False\n\n        # Proxy-Connection is a netscape hack.\n        pconn = self.headers.get(\"proxy-connection\")\n        if pconn and \"keep-alive\" in pconn.lower():\n            return False\n\n        # otherwise, assume it will close\n        return True",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._close_conn": {
        "API_name": "http.client.HTTPResponse._close_conn",
        "loc_name": "http.client.HTTPResponse._close_conn",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 414,
        "namespace": "HTTPResponse",
        "body": "    def _close_conn(self):\n        fp = self.fp\n        self.fp = None\n        fp.close()",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.close": {
        "API_name": "http.client.HTTPResponse.close",
        "loc_name": "http.client.HTTPResponse.close",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 419,
        "namespace": "HTTPResponse",
        "body": "    def close(self):\n        try:\n            super().close() # set \"closed\" flag\n        finally:\n            if self.fp:\n                self._close_conn()",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.flush": {
        "API_name": "http.client.HTTPResponse.flush",
        "loc_name": "http.client.HTTPResponse.flush",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 431,
        "namespace": "HTTPResponse",
        "body": "    def flush(self):\n        super().flush()\n        if self.fp:\n            self.fp.flush()",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.readable": {
        "API_name": "http.client.HTTPResponse.readable",
        "loc_name": "http.client.HTTPResponse.readable",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 436,
        "namespace": "HTTPResponse",
        "body": "    def readable(self):\n        \"\"\"Always returns True\"\"\"\n        return True",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.isclosed": {
        "API_name": "http.client.HTTPResponse.isclosed",
        "loc_name": "http.client.HTTPResponse.isclosed",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 442,
        "namespace": "HTTPResponse",
        "body": "    def isclosed(self):\n        \"\"\"True if the connection is closed.\"\"\"\n        # NOTE: it is possible that we will not ever call self.close(). This\n        #       case occurs when will_close is TRUE, length is None, and we\n        #       read up to the last byte, but NOT past it.\n        #\n        # IMPLIES: if will_close is FALSE, then self.close() will ALWAYS be\n        #          called, meaning self.isclosed() is meaningful.\n        return self.fp is None",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.read": {
        "API_name": "http.client.HTTPResponse.read",
        "loc_name": "http.client.HTTPResponse.read",
        "args": "self;amt",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 452,
        "namespace": "HTTPResponse",
        "body": "    def read(self, amt=None):\n        if self.fp is None:\n            return b\"\"\n\n        if self._method == \"HEAD\":\n            self._close_conn()\n            return b\"\"\n\n        if amt is not None:\n            # Amount is given, implement using readinto\n            b = bytearray(amt)\n            n = self.readinto(b)\n            return memoryview(b)[:n].tobytes()\n        else:\n            # Amount is not given (unbounded read) so we must check self.length\n            # and self.chunked\n\n            if self.chunked:\n                return self._readall_chunked()\n\n            if self.length is None:\n                s = self.fp.read()\n            else:\n                try:\n                    s = self._safe_read(self.length)\n                except IncompleteRead:\n                    self._close_conn()\n                    raise\n                self.length = 0\n            self._close_conn()        # we read everything\n            return s",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.readinto": {
        "API_name": "http.client.HTTPResponse.readinto",
        "loc_name": "http.client.HTTPResponse.readinto",
        "args": "self;b",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 484,
        "namespace": "HTTPResponse",
        "body": "    def readinto(self, b):\n        \"\"\"Read up to len(b) bytes into bytearray b and return the number\n        of bytes read.\n        \"\"\"\n\n        if self.fp is None:\n            return 0\n\n        if self._method == \"HEAD\":\n            self._close_conn()\n            return 0\n\n        if self.chunked:\n            return self._readinto_chunked(b)\n\n        if self.length is not None:\n            if len(b) > self.length:\n                # clip the read to the \"end of response\"\n                b = memoryview(b)[0:self.length]\n\n        # we do not use _safe_read() here because this may be a .will_close\n        # connection, and the user is reading more bytes than will be provided\n        # (for example, reading in 1k chunks)\n        n = self.fp.readinto(b)\n        if not n and b:\n            # Ideally, we would raise IncompleteRead if the content-length\n            # wasn't satisfied, but it might break compatibility.\n            self._close_conn()\n        elif self.length is not None:\n            self.length -= n\n            if not self.length:\n                self._close_conn()\n        return n",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._read_next_chunk_size": {
        "API_name": "http.client.HTTPResponse._read_next_chunk_size",
        "loc_name": "http.client.HTTPResponse._read_next_chunk_size",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 518,
        "namespace": "HTTPResponse",
        "body": "    def _read_next_chunk_size(self):\n        # Read the next chunk size from the file\n        line = self.fp.readline(_MAXLINE + 1)\n        if len(line) > _MAXLINE:\n            raise LineTooLong(\"chunk size\")\n        i = line.find(b\";\")\n        if i >= 0:\n            line = line[:i] # strip chunk-extensions\n        try:\n            return int(line, 16)\n        except ValueError:\n            # close the connection as protocol synchronisation is\n            # probably lost\n            self._close_conn()\n            raise",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._read_and_discard_trailer": {
        "API_name": "http.client.HTTPResponse._read_and_discard_trailer",
        "loc_name": "http.client.HTTPResponse._read_and_discard_trailer",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 534,
        "namespace": "HTTPResponse",
        "body": "    def _read_and_discard_trailer(self):\n        # read and discard trailer up to the CRLF terminator\n        ### note: we shouldn't have any trailers!\n        while True:\n            line = self.fp.readline(_MAXLINE + 1)\n            if len(line) > _MAXLINE:\n                raise LineTooLong(\"trailer line\")\n            if not line:\n                # a vanishingly small number of sites EOF without\n                # sending the trailer\n                break\n            if line in (b'\\r\\n', b'\\n', b''):\n                break",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._get_chunk_left": {
        "API_name": "http.client.HTTPResponse._get_chunk_left",
        "loc_name": "http.client.HTTPResponse._get_chunk_left",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 548,
        "namespace": "HTTPResponse",
        "body": "    def _get_chunk_left(self):\n        # return self.chunk_left, reading a new chunk if necessary.\n        # chunk_left == 0: at the end of the current chunk, need to close it\n        # chunk_left == None: No current chunk, should read next.\n        # This function returns non-zero or None if the last chunk has\n        # been read.\n        chunk_left = self.chunk_left\n        if not chunk_left: # Can be 0 or None\n            if chunk_left is not None:\n                # We are at the end of chunk, discard chunk end\n                self._safe_read(2)  # toss the CRLF at the end of the chunk\n            try:\n                chunk_left = self._read_next_chunk_size()\n            except ValueError:\n                raise IncompleteRead(b'')\n            if chunk_left == 0:\n                # last chunk: 1*(\"0\") [ chunk-extension ] CRLF\n                self._read_and_discard_trailer()\n                # we read everything; close the \"file\"\n                self._close_conn()\n                chunk_left = None\n            self.chunk_left = chunk_left\n        return chunk_left",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._readall_chunked": {
        "API_name": "http.client.HTTPResponse._readall_chunked",
        "loc_name": "http.client.HTTPResponse._readall_chunked",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 572,
        "namespace": "HTTPResponse",
        "body": "    def _readall_chunked(self):\n        assert self.chunked != _UNKNOWN\n        value = []\n        try:\n            while True:\n                chunk_left = self._get_chunk_left()\n                if chunk_left is None:\n                    break\n                value.append(self._safe_read(chunk_left))\n                self.chunk_left = 0\n            return b''.join(value)\n        except IncompleteRead:\n            raise IncompleteRead(b''.join(value))",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._readinto_chunked": {
        "API_name": "http.client.HTTPResponse._readinto_chunked",
        "loc_name": "http.client.HTTPResponse._readinto_chunked",
        "args": "self;b",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 586,
        "namespace": "HTTPResponse",
        "body": "    def _readinto_chunked(self, b):\n        assert self.chunked != _UNKNOWN\n        total_bytes = 0\n        mvb = memoryview(b)\n        try:\n            while True:\n                chunk_left = self._get_chunk_left()\n                if chunk_left is None:\n                    return total_bytes\n\n                if len(mvb) <= chunk_left:\n                    n = self._safe_readinto(mvb)\n                    self.chunk_left = chunk_left - n\n                    return total_bytes + n\n\n                temp_mvb = mvb[:chunk_left]\n                n = self._safe_readinto(temp_mvb)\n                mvb = mvb[n:]\n                total_bytes += n\n                self.chunk_left = 0\n\n        except IncompleteRead:\n            raise IncompleteRead(bytes(b[0:total_bytes]))",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._safe_read": {
        "API_name": "http.client.HTTPResponse._safe_read",
        "loc_name": "http.client.HTTPResponse._safe_read",
        "args": "self;amt",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 610,
        "namespace": "HTTPResponse",
        "body": "    def _safe_read(self, amt):\n        \"\"\"Read the number of bytes requested, compensating for partial reads.\n\n        Normally, we have a blocking socket, but a read() can be interrupted\n        by a signal (resulting in a partial read).\n\n        Note that we cannot distinguish between EOF and an interrupt when zero\n        bytes have been read. IncompleteRead() will be raised in this\n        situation.\n\n        This function should be used when <amt> bytes \"should\" be present for\n        reading. If the bytes are truly not available (due to EOF), then the\n        IncompleteRead exception can be used to detect the problem.\n        \"\"\"\n        s = []\n        while amt > 0:\n            chunk = self.fp.read(min(amt, MAXAMOUNT))\n            if not chunk:\n                raise IncompleteRead(b''.join(s), amt)\n            s.append(chunk)\n            amt -= len(chunk)\n        return b\"\".join(s)",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._safe_readinto": {
        "API_name": "http.client.HTTPResponse._safe_readinto",
        "loc_name": "http.client.HTTPResponse._safe_readinto",
        "args": "self;b",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 633,
        "namespace": "HTTPResponse",
        "body": "    def _safe_readinto(self, b):\n        \"\"\"Same as _safe_read, but for reading into a buffer.\"\"\"\n        total_bytes = 0\n        mvb = memoryview(b)\n        while total_bytes < len(b):\n            if MAXAMOUNT < len(mvb):\n                temp_mvb = mvb[0:MAXAMOUNT]\n                n = self.fp.readinto(temp_mvb)\n            else:\n                n = self.fp.readinto(mvb)\n            if not n:\n                raise IncompleteRead(bytes(mvb[0:total_bytes]), len(b))\n            mvb = mvb[n:]\n            total_bytes += n\n        return total_bytes",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.read1": {
        "API_name": "http.client.HTTPResponse.read1",
        "loc_name": "http.client.HTTPResponse.read1",
        "args": "self;n",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 649,
        "namespace": "HTTPResponse",
        "body": "    def read1(self, n=-1):\n        \"\"\"Read with at most one underlying system call.  If at least one\n        byte is buffered, return that instead.\n        \"\"\"\n        if self.fp is None or self._method == \"HEAD\":\n            return b\"\"\n        if self.chunked:\n            return self._read1_chunked(n)\n        if self.length is not None and (n < 0 or n > self.length):\n            n = self.length\n        result = self.fp.read1(n)\n        if not result and n:\n            self._close_conn()\n        elif self.length is not None:\n            self.length -= len(result)\n        return result",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.peek": {
        "API_name": "http.client.HTTPResponse.peek",
        "loc_name": "http.client.HTTPResponse.peek",
        "args": "self;n",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 666,
        "namespace": "HTTPResponse",
        "body": "    def peek(self, n=-1):\n        # Having this enables IOBase.readline() to read more than one\n        # byte at a time\n        if self.fp is None or self._method == \"HEAD\":\n            return b\"\"\n        if self.chunked:\n            return self._peek_chunked(n)\n        return self.fp.peek(n)",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.readline": {
        "API_name": "http.client.HTTPResponse.readline",
        "loc_name": "http.client.HTTPResponse.readline",
        "args": "self;limit",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 675,
        "namespace": "HTTPResponse",
        "body": "    def readline(self, limit=-1):\n        if self.fp is None or self._method == \"HEAD\":\n            return b\"\"\n        if self.chunked:\n            # Fallback to IOBase readline which uses peek() and read()\n            return super().readline(limit)\n        if self.length is not None and (limit < 0 or limit > self.length):\n            limit = self.length\n        result = self.fp.readline(limit)\n        if not result and limit:\n            self._close_conn()\n        elif self.length is not None:\n            self.length -= len(result)\n        return result",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._read1_chunked": {
        "API_name": "http.client.HTTPResponse._read1_chunked",
        "loc_name": "http.client.HTTPResponse._read1_chunked",
        "args": "self;n",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 690,
        "namespace": "HTTPResponse",
        "body": "    def _read1_chunked(self, n):\n        # Strictly speaking, _get_chunk_left() may cause more than one read,\n        # but that is ok, since that is to satisfy the chunked protocol.\n        chunk_left = self._get_chunk_left()\n        if chunk_left is None or n == 0:\n            return b''\n        if not (0 <= n <= chunk_left):\n            n = chunk_left # if n is negative or larger than chunk_left\n        read = self.fp.read1(n)\n        self.chunk_left -= len(read)\n        if not read:\n            raise IncompleteRead(b\"\")\n        return read",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse._peek_chunked": {
        "API_name": "http.client.HTTPResponse._peek_chunked",
        "loc_name": "http.client.HTTPResponse._peek_chunked",
        "args": "self;n",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 704,
        "namespace": "HTTPResponse",
        "body": "    def _peek_chunked(self, n):\n        # Strictly speaking, _get_chunk_left() may cause more than one read,\n        # but that is ok, since that is to satisfy the chunked protocol.\n        try:\n            chunk_left = self._get_chunk_left()\n        except IncompleteRead:\n            return b'' # peek doesn't worry about protocol\n        if chunk_left is None:\n            return b'' # eof\n        # peek is allowed to return more than requested.  Just request the\n        # entire chunk, and truncate what we get.\n        return self.fp.peek(chunk_left)[:chunk_left]",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.fileno": {
        "API_name": "http.client.HTTPResponse.fileno",
        "loc_name": "http.client.HTTPResponse.fileno",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 717,
        "namespace": "HTTPResponse",
        "body": "    def fileno(self):\n        return self.fp.fileno()",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.getheader": {
        "API_name": "http.client.HTTPResponse.getheader",
        "loc_name": "http.client.HTTPResponse.getheader",
        "args": "self;name;default",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 720,
        "namespace": "HTTPResponse",
        "body": "    def getheader(self, name, default=None):\n        '''Returns the value of the header matching *name*.\n\n        If there are multiple matching headers, the values are\n        combined into a single string separated by commas and spaces.\n\n        If no matching header is found, returns *default* or None if\n        the *default* is not specified.\n\n        If the headers are unknown, raises http.client.ResponseNotReady.\n\n        '''\n        if self.headers is None:\n            raise ResponseNotReady()\n        headers = self.headers.get_all(name) or default\n        if isinstance(headers, str) or not hasattr(headers, '__iter__'):\n            return headers\n        else:\n            return ', '.join(headers)",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.getheaders": {
        "API_name": "http.client.HTTPResponse.getheaders",
        "loc_name": "http.client.HTTPResponse.getheaders",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 740,
        "namespace": "HTTPResponse",
        "body": "    def getheaders(self):\n        \"\"\"Return list of (header, value) tuples.\"\"\"\n        if self.headers is None:\n            raise ResponseNotReady()\n        return list(self.headers.items())",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.__iter__": {
        "API_name": "http.client.HTTPResponse.__iter__",
        "loc_name": "http.client.HTTPResponse.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 748,
        "namespace": "HTTPResponse",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.info": {
        "API_name": "http.client.HTTPResponse.info",
        "loc_name": "http.client.HTTPResponse.info",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 753,
        "namespace": "HTTPResponse",
        "body": "    def info(self):\n        '''Returns an instance of the class mimetools.Message containing\n        meta-information associated with the URL.\n\n        When the method is HTTP, these headers are those returned by\n        the server at the head of the retrieved HTML page (including\n        Content-Length and Content-Type).\n\n        When the method is FTP, a Content-Length header will be\n        present if (as is now usual) the server passed back a file\n        length in response to the FTP retrieval request. A\n        Content-Type header will be present if the MIME type can be\n        guessed.\n\n        When the method is local-file, returned headers will include\n        a Date representing the file's last-modified time, a\n        Content-Length giving file size, and a Content-Type\n        containing a guess at the file's type. See also the\n        description of the mimetools module.\n\n        '''\n        return self.headers",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.geturl": {
        "API_name": "http.client.HTTPResponse.geturl",
        "loc_name": "http.client.HTTPResponse.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 776,
        "namespace": "HTTPResponse",
        "body": "    def geturl(self):\n        '''Return the real URL of the page.\n\n        In some cases, the HTTP server redirects a client to another\n        URL. The urlopen() function handles this transparently, but in\n        some cases the caller needs to know which URL the client was\n        redirected to. The geturl() method can be used to get at this\n        redirected URL.\n\n        '''\n        return self.url",
        "name_type": "stdlib"
    },
    "http.client.HTTPResponse.getcode": {
        "API_name": "http.client.HTTPResponse.getcode",
        "loc_name": "http.client.HTTPResponse.getcode",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 788,
        "namespace": "HTTPResponse",
        "body": "    def getcode(self):\n        '''Return the HTTP status code that was sent with the response,\n        or None if the URL is not an HTTP URL.\n\n        '''\n        return self.status",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection": {
        "API_name": "http.client.HTTPConnection",
        "loc_name": "http.client.HTTPConnection",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 795,
        "namespace": "HTTPConnection",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._is_textIO": {
        "API_name": "http.client.HTTPConnection._is_textIO",
        "loc_name": "http.client.HTTPConnection._is_textIO",
        "args": "stream",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 806,
        "namespace": "HTTPConnection",
        "body": "    def _is_textIO(stream):\n        \"\"\"Test whether a file-like object is a text or a binary stream.\n        \"\"\"\n        return isinstance(stream, io.TextIOBase)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._get_content_length": {
        "API_name": "http.client.HTTPConnection._get_content_length",
        "loc_name": "http.client.HTTPConnection._get_content_length",
        "args": "body;method",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 812,
        "namespace": "HTTPConnection",
        "body": "    def _get_content_length(body, method):\n        \"\"\"Get the content-length based on the body.\n\n        If the body is None, we set Content-Length: 0 for methods that expect\n        a body (RFC 7230, Section 3.3.2). We also set the Content-Length for\n        any method if the body is a str or bytes-like object and not a file.\n        \"\"\"\n        if body is None:\n            # do an explicit check for not None here to distinguish\n            # between unset and set but empty\n            if method.upper() in _METHODS_EXPECTING_BODY:\n                return 0\n            else:\n                return None\n\n        if hasattr(body, 'read'):\n            # file-like object.\n            return None\n\n        try:\n            # does it implement the buffer protocol (bytes, bytearray, array)?\n            mv = memoryview(body)\n            return mv.nbytes\n        except TypeError:\n            pass\n\n        if isinstance(body, str):\n            return len(body)\n\n        return None",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.__init__": {
        "API_name": "http.client.HTTPConnection.__init__",
        "loc_name": "http.client.HTTPConnection.__init__",
        "args": "self;host;port;timeout;source_address;blocksize",
        "args_default": 4,
        "filepath": "http.client",
        "lineno": 843,
        "namespace": "HTTPConnection",
        "body": "    def __init__(self, host, port=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n                 source_address=None, blocksize=8192):\n        self.timeout = timeout\n        self.source_address = source_address\n        self.blocksize = blocksize\n        self.sock = None\n        self._buffer = []\n        self.__response = None\n        self.__state = _CS_IDLE\n        self._method = None\n        self._tunnel_host = None\n        self._tunnel_port = None\n        self._tunnel_headers = {}\n\n        (self.host, self.port) = self._get_hostport(host, port)\n\n        self._validate_host(self.host)\n\n        # This is stored as an instance variable to allow unit\n        # tests to replace it with a suitable mockup\n        self._create_connection = socket.create_connection",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.set_tunnel": {
        "API_name": "http.client.HTTPConnection.set_tunnel",
        "loc_name": "http.client.HTTPConnection.set_tunnel",
        "args": "self;host;port;headers",
        "args_default": 2,
        "filepath": "http.client",
        "lineno": 865,
        "namespace": "HTTPConnection",
        "body": "    def set_tunnel(self, host, port=None, headers=None):\n        \"\"\"Set up host and port for HTTP CONNECT tunnelling.\n\n        In a connection that uses HTTP CONNECT tunneling, the host passed to the\n        constructor is used as a proxy server that relays all communication to\n        the endpoint passed to `set_tunnel`. This done by sending an HTTP\n        CONNECT request to the proxy server when the connection is established.\n\n        This method must be called before the HTTP connection has been\n        established.\n\n        The headers argument should be a mapping of extra HTTP headers to send\n        with the CONNECT request.\n        \"\"\"\n\n        if self.sock:\n            raise RuntimeError(\"Can't set up tunnel for established connection\")\n\n        self._tunnel_host, self._tunnel_port = self._get_hostport(host, port)\n        if headers:\n            self._tunnel_headers = headers\n        else:\n            self._tunnel_headers.clear()",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._get_hostport": {
        "API_name": "http.client.HTTPConnection._get_hostport",
        "loc_name": "http.client.HTTPConnection._get_hostport",
        "args": "self;host;port",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 889,
        "namespace": "HTTPConnection",
        "body": "    def _get_hostport(self, host, port):\n        if port is None:\n            i = host.rfind(':')\n            j = host.rfind(']')         # ipv6 addresses have [...]\n            if i > j:\n                try:\n                    port = int(host[i+1:])\n                except ValueError:\n                    if host[i+1:] == \"\": # http://foo.com:/ == http://foo.com/\n                        port = self.default_port\n                    else:\n                        raise InvalidURL(\"nonnumeric port: '%s'\" % host[i+1:])\n                host = host[:i]\n            else:\n                port = self.default_port\n            if host and host[0] == '[' and host[-1] == ']':\n                host = host[1:-1]\n\n        return (host, port)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.set_debuglevel": {
        "API_name": "http.client.HTTPConnection.set_debuglevel",
        "loc_name": "http.client.HTTPConnection.set_debuglevel",
        "args": "self;level",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 909,
        "namespace": "HTTPConnection",
        "body": "    def set_debuglevel(self, level):\n        self.debuglevel = level",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._tunnel": {
        "API_name": "http.client.HTTPConnection._tunnel",
        "loc_name": "http.client.HTTPConnection._tunnel",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 912,
        "namespace": "HTTPConnection",
        "body": "    def _tunnel(self):\n        connect = b\"CONNECT %s:%d HTTP/1.0\\r\\n\" % (\n            self._tunnel_host.encode(\"ascii\"), self._tunnel_port)\n        headers = [connect]\n        for header, value in self._tunnel_headers.items():\n            headers.append(f\"{header}: {value}\\r\\n\".encode(\"latin-1\"))\n        headers.append(b\"\\r\\n\")\n        # Making a single send() call instead of one per line encourages\n        # the host OS to use a more optimal packet size instead of\n        # potentially emitting a series of small packets.\n        self.send(b\"\".join(headers))\n        del headers\n\n        response = self.response_class(self.sock, method=self._method)\n        (version, code, message) = response._read_status()\n\n        if code != http.HTTPStatus.OK:\n            self.close()\n            raise OSError(f\"Tunnel connection failed: {code} {message.strip()}\")\n        while True:\n            line = response.fp.readline(_MAXLINE + 1)\n            if len(line) > _MAXLINE:\n                raise LineTooLong(\"header line\")\n            if not line:\n                # for sites which EOF without sending a trailer\n                break\n            if line in (b'\\r\\n', b'\\n', b''):\n                break\n\n            if self.debuglevel > 0:\n                print('header:', line.decode())",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.connect": {
        "API_name": "http.client.HTTPConnection.connect",
        "loc_name": "http.client.HTTPConnection.connect",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 944,
        "namespace": "HTTPConnection",
        "body": "    def connect(self):\n        \"\"\"Connect to the host and port specified in __init__.\"\"\"\n        self.sock = self._create_connection(\n            (self.host,self.port), self.timeout, self.source_address)\n        # Might fail in OSs that don't implement TCP_NODELAY\n        try:\n             self.sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)\n        except OSError as e:\n            if e.errno != errno.ENOPROTOOPT:\n                raise\n\n        if self._tunnel_host:\n            self._tunnel()",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.close": {
        "API_name": "http.client.HTTPConnection.close",
        "loc_name": "http.client.HTTPConnection.close",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 958,
        "namespace": "HTTPConnection",
        "body": "    def close(self):\n        \"\"\"Close the connection to the HTTP server.\"\"\"\n        self.__state = _CS_IDLE\n        try:\n            sock = self.sock\n            if sock:\n                self.sock = None\n                sock.close()   # close it manually... there may be other refs\n        finally:\n            response = self.__response\n            if response:\n                self.__response = None\n                response.close()",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.send": {
        "API_name": "http.client.HTTPConnection.send",
        "loc_name": "http.client.HTTPConnection.send",
        "args": "self;data",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 972,
        "namespace": "HTTPConnection",
        "body": "    def send(self, data):\n        \"\"\"Send `data' to the server.\n        ``data`` can be a string object, a bytes object, an array object, a\n        file-like object that supports a .read() method, or an iterable object.\n        \"\"\"\n\n        if self.sock is None:\n            if self.auto_open:\n                self.connect()\n            else:\n                raise NotConnected()\n\n        if self.debuglevel > 0:\n            print(\"send:\", repr(data))\n        if hasattr(data, \"read\") :\n            if self.debuglevel > 0:\n                print(\"sendIng a read()able\")\n            encode = self._is_textIO(data)\n            if encode and self.debuglevel > 0:\n                print(\"encoding file using iso-8859-1\")\n            while 1:\n                datablock = data.read(self.blocksize)\n                if not datablock:\n                    break\n                if encode:\n                    datablock = datablock.encode(\"iso-8859-1\")\n                self.sock.sendall(datablock)\n            return\n        try:\n            self.sock.sendall(data)\n        except TypeError:\n            if isinstance(data, collections.abc.Iterable):\n                for d in data:\n                    self.sock.sendall(d)\n            else:\n                raise TypeError(\"data should be a bytes-like object \"\n                                \"or an iterable, got %r\" % type(data))",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._output": {
        "API_name": "http.client.HTTPConnection._output",
        "loc_name": "http.client.HTTPConnection._output",
        "args": "self;s",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1010,
        "namespace": "HTTPConnection",
        "body": "    def _output(self, s):\n        \"\"\"Add a line of output to the current request buffer.\n\n        Assumes that the line does *not* end with \\\\r\\\\n.\n        \"\"\"\n        self._buffer.append(s)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._read_readable": {
        "API_name": "http.client.HTTPConnection._read_readable",
        "loc_name": "http.client.HTTPConnection._read_readable",
        "args": "self;readable",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1017,
        "namespace": "HTTPConnection",
        "body": "    def _read_readable(self, readable):\n        if self.debuglevel > 0:\n            print(\"sendIng a read()able\")\n        encode = self._is_textIO(readable)\n        if encode and self.debuglevel > 0:\n            print(\"encoding file using iso-8859-1\")\n        while True:\n            datablock = readable.read(self.blocksize)\n            if not datablock:\n                break\n            if encode:\n                datablock = datablock.encode(\"iso-8859-1\")\n            yield datablock",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._send_output": {
        "API_name": "http.client.HTTPConnection._send_output",
        "loc_name": "http.client.HTTPConnection._send_output",
        "args": "self;message_body;encode_chunked",
        "args_default": 2,
        "filepath": "http.client",
        "lineno": 1031,
        "namespace": "HTTPConnection",
        "body": "    def _send_output(self, message_body=None, encode_chunked=False):\n        \"\"\"Send the currently buffered request and clear the buffer.\n\n        Appends an extra \\\\r\\\\n to the buffer.\n        A message_body may be specified, to be appended to the request.\n        \"\"\"\n        self._buffer.extend((b\"\", b\"\"))\n        msg = b\"\\r\\n\".join(self._buffer)\n        del self._buffer[:]\n        self.send(msg)\n\n        if message_body is not None:\n\n            # create a consistent interface to message_body\n            if hasattr(message_body, 'read'):\n                # Let file-like take precedence over byte-like.  This\n                # is needed to allow the current position of mmap'ed\n                # files to be taken into account.\n                chunks = self._read_readable(message_body)\n            else:\n                try:\n                    # this is solely to check to see if message_body\n                    # implements the buffer API.  it /would/ be easier\n                    # to capture if PyObject_CheckBuffer was exposed\n                    # to Python.\n                    memoryview(message_body)\n                except TypeError:\n                    try:\n                        chunks = iter(message_body)\n                    except TypeError:\n                        raise TypeError(\"message_body should be a bytes-like \"\n                                        \"object or an iterable, got %r\"\n                                        % type(message_body))\n                else:\n                    # the object implements the buffer interface and\n                    # can be passed directly into socket methods\n                    chunks = (message_body,)\n\n            for chunk in chunks:\n                if not chunk:\n                    if self.debuglevel > 0:\n                        print('Zero length chunk ignored')\n                    continue\n\n                if encode_chunked and self._http_vsn == 11:\n                    # chunked encoding\n                    chunk = f'{len(chunk):X}\\r\\n'.encode('ascii') + chunk \\\n                        + b'\\r\\n'\n                self.send(chunk)\n\n            if encode_chunked and self._http_vsn == 11:\n                # end chunked transfer\n                self.send(b'0\\r\\n\\r\\n')",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.putrequest": {
        "API_name": "http.client.HTTPConnection.putrequest",
        "loc_name": "http.client.HTTPConnection.putrequest",
        "args": "self;method;url;skip_host;skip_accept_encoding",
        "args_default": 2,
        "filepath": "http.client",
        "lineno": 1085,
        "namespace": "HTTPConnection",
        "body": "    def putrequest(self, method, url, skip_host=False,\n                   skip_accept_encoding=False):\n        \"\"\"Send a request to the server.\n\n        `method' specifies an HTTP request method, e.g. 'GET'.\n        `url' specifies the object being requested, e.g. '/index.html'.\n        `skip_host' if True does not add automatically a 'Host:' header\n        `skip_accept_encoding' if True does not add automatically an\n           'Accept-Encoding:' header\n        \"\"\"\n\n        # if a prior response has been completed, then forget about it.\n        if self.__response and self.__response.isclosed():\n            self.__response = None\n\n\n        # in certain cases, we cannot issue another request on this connection.\n        # this occurs when:\n        #   1) we are in the process of sending a request.   (_CS_REQ_STARTED)\n        #   2) a response to a previous request has signalled that it is going\n        #      to close the connection upon completion.\n        #   3) the headers for the previous response have not been read, thus\n        #      we cannot determine whether point (2) is true.   (_CS_REQ_SENT)\n        #\n        # if there is no prior response, then we can request at will.\n        #\n        # if point (2) is true, then we will have passed the socket to the\n        # response (effectively meaning, \"there is no prior response\"), and\n        # will open a new one when a new request is made.\n        #\n        # Note: if a prior response exists, then we *can* start a new request.\n        #       We are not allowed to begin fetching the response to this new\n        #       request, however, until that prior response is complete.\n        #\n        if self.__state == _CS_IDLE:\n            self.__state = _CS_REQ_STARTED\n        else:\n            raise CannotSendRequest(self.__state)\n\n        self._validate_method(method)\n\n        # Save the method for use later in the response phase\n        self._method = method\n\n        url = url or '/'\n        self._validate_path(url)\n\n        request = '%s %s %s' % (method, url, self._http_vsn_str)\n\n        self._output(self._encode_request(request))\n\n        if self._http_vsn == 11:\n            # Issue some standard headers for better HTTP/1.1 compliance\n\n            if not skip_host:\n                # this header is issued *only* for HTTP/1.1\n                # connections. more specifically, this means it is\n                # only issued when the client uses the new\n                # HTTPConnection() class. backwards-compat clients\n                # will be using HTTP/1.0 and those clients may be\n                # issuing this header themselves. we should NOT issue\n                # it twice; some web servers (such as Apache) barf\n                # when they see two Host: headers\n\n                # If we need a non-standard port,include it in the\n                # header.  If the request is going through a proxy,\n                # but the host of the actual URL, not the host of the\n                # proxy.\n\n                netloc = ''\n                if url.startswith('http'):\n                    nil, netloc, nil, nil, nil = urlsplit(url)\n\n                if netloc:\n                    try:\n                        netloc_enc = netloc.encode(\"ascii\")\n                    except UnicodeEncodeError:\n                        netloc_enc = netloc.encode(\"idna\")\n                    self.putheader('Host', netloc_enc)\n                else:\n                    if self._tunnel_host:\n                        host = self._tunnel_host\n                        port = self._tunnel_port\n                    else:\n                        host = self.host\n                        port = self.port\n\n                    try:\n                        host_enc = host.encode(\"ascii\")\n                    except UnicodeEncodeError:\n                        host_enc = host.encode(\"idna\")\n\n                    # As per RFC 273, IPv6 address should be wrapped with []\n                    # when used as Host header\n\n                    if host.find(':') >= 0:\n                        host_enc = b'[' + host_enc + b']'\n\n                    if port == self.default_port:\n                        self.putheader('Host', host_enc)\n                    else:\n                        host_enc = host_enc.decode(\"ascii\")\n                        self.putheader('Host', \"%s:%s\" % (host_enc, port))\n\n            # note: we are assuming that clients will not attempt to set these\n            #       headers since *this* library must deal with the\n            #       consequences. this also means that when the supporting\n            #       libraries are updated to recognize other forms, then this\n            #       code should be changed (removed or updated).\n\n            # we only want a Content-Encoding of \"identity\" since we don't\n            # support encodings such as x-gzip or x-deflate.\n            if not skip_accept_encoding:\n                self.putheader('Accept-Encoding', 'identity')\n\n            # we can accept \"chunked\" Transfer-Encodings, but no others\n            # NOTE: no TE header implies *only* \"chunked\"\n            #self.putheader('TE', 'chunked')\n\n            # if TE is supplied in the header, then it must appear in a\n            # Connection header.\n            #self.putheader('Connection', 'TE')\n\n        else:\n            # For HTTP/1.0, the server will assume \"not chunked\"\n            pass",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._encode_request": {
        "API_name": "http.client.HTTPConnection._encode_request",
        "loc_name": "http.client.HTTPConnection._encode_request",
        "args": "self;request",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1212,
        "namespace": "HTTPConnection",
        "body": "    def _encode_request(self, request):\n        # ASCII also helps prevent CVE-2019-9740.\n        return request.encode('ascii')",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._validate_method": {
        "API_name": "http.client.HTTPConnection._validate_method",
        "loc_name": "http.client.HTTPConnection._validate_method",
        "args": "self;method",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1216,
        "namespace": "HTTPConnection",
        "body": "    def _validate_method(self, method):\n        \"\"\"Validate a method name for putrequest.\"\"\"\n        # prevent http header injection\n        match = _contains_disallowed_method_pchar_re.search(method)\n        if match:\n            raise ValueError(\n                    f\"method can't contain control characters. {method!r} \"\n                    f\"(found at least {match.group()!r})\")",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._validate_path": {
        "API_name": "http.client.HTTPConnection._validate_path",
        "loc_name": "http.client.HTTPConnection._validate_path",
        "args": "self;url",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1225,
        "namespace": "HTTPConnection",
        "body": "    def _validate_path(self, url):\n        \"\"\"Validate a url for putrequest.\"\"\"\n        # Prevent CVE-2019-9740.\n        match = _contains_disallowed_url_pchar_re.search(url)\n        if match:\n            raise InvalidURL(f\"URL can't contain control characters. {url!r} \"\n                             f\"(found at least {match.group()!r})\")",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._validate_host": {
        "API_name": "http.client.HTTPConnection._validate_host",
        "loc_name": "http.client.HTTPConnection._validate_host",
        "args": "self;host",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1233,
        "namespace": "HTTPConnection",
        "body": "    def _validate_host(self, host):\n        \"\"\"Validate a host so it doesn't contain control characters.\"\"\"\n        # Prevent CVE-2019-18348.\n        match = _contains_disallowed_url_pchar_re.search(host)\n        if match:\n            raise InvalidURL(f\"URL can't contain control characters. {host!r} \"\n                             f\"(found at least {match.group()!r})\")",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.putheader": {
        "API_name": "http.client.HTTPConnection.putheader",
        "loc_name": "http.client.HTTPConnection.putheader",
        "args": "self;header",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1241,
        "namespace": "HTTPConnection",
        "body": "    def putheader(self, header, *values):\n        \"\"\"Send a request header line to the server.\n\n        For example: h.putheader('Accept', 'text/html')\n        \"\"\"\n        if self.__state != _CS_REQ_STARTED:\n            raise CannotSendHeader()\n\n        if hasattr(header, 'encode'):\n            header = header.encode('ascii')\n\n        if not _is_legal_header_name(header):\n            raise ValueError('Invalid header name %r' % (header,))\n\n        values = list(values)\n        for i, one_value in enumerate(values):\n            if hasattr(one_value, 'encode'):\n                values[i] = one_value.encode('latin-1')\n            elif isinstance(one_value, int):\n                values[i] = str(one_value).encode('ascii')\n\n            if _is_illegal_header_value(values[i]):\n                raise ValueError('Invalid header value %r' % (values[i],))\n\n        value = b'\\r\\n\\t'.join(values)\n        header = header + b': ' + value\n        self._output(header)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.endheaders": {
        "API_name": "http.client.HTTPConnection.endheaders",
        "loc_name": "http.client.HTTPConnection.endheaders",
        "args": "self;message_body",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 1269,
        "namespace": "HTTPConnection",
        "body": "    def endheaders(self, message_body=None, *, encode_chunked=False):\n        \"\"\"Indicate that the last header line has been sent to the server.\n\n        This method sends the request to the server.  The optional message_body\n        argument can be used to pass a message body associated with the\n        request.\n        \"\"\"\n        if self.__state == _CS_REQ_STARTED:\n            self.__state = _CS_REQ_SENT\n        else:\n            raise CannotSendHeader()\n        self._send_output(message_body, encode_chunked=encode_chunked)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.request": {
        "API_name": "http.client.HTTPConnection.request",
        "loc_name": "http.client.HTTPConnection.request",
        "args": "self;method;url;body;headers",
        "args_default": 2,
        "filepath": "http.client",
        "lineno": 1282,
        "namespace": "HTTPConnection",
        "body": "    def request(self, method, url, body=None, headers={}, *,\n                encode_chunked=False):\n        \"\"\"Send a complete request to the server.\"\"\"\n        self._send_request(method, url, body, headers, encode_chunked)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection._send_request": {
        "API_name": "http.client.HTTPConnection._send_request",
        "loc_name": "http.client.HTTPConnection._send_request",
        "args": "self;method;url;body;headers;encode_chunked",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1287,
        "namespace": "HTTPConnection",
        "body": "    def _send_request(self, method, url, body, headers, encode_chunked):\n        # Honor explicitly requested Host: and Accept-Encoding: headers.\n        header_names = frozenset(k.lower() for k in headers)\n        skips = {}\n        if 'host' in header_names:\n            skips['skip_host'] = 1\n        if 'accept-encoding' in header_names:\n            skips['skip_accept_encoding'] = 1\n\n        self.putrequest(method, url, **skips)\n\n        # chunked encoding will happen if HTTP/1.1 is used and either\n        # the caller passes encode_chunked=True or the following\n        # conditions hold:\n        # 1. content-length has not been explicitly set\n        # 2. the body is a file or iterable, but not a str or bytes-like\n        # 3. Transfer-Encoding has NOT been explicitly set by the caller\n\n        if 'content-length' not in header_names:\n            # only chunk body if not explicitly set for backwards\n            # compatibility, assuming the client code is already handling the\n            # chunking\n            if 'transfer-encoding' not in header_names:\n                # if content-length cannot be automatically determined, fall\n                # back to chunked encoding\n                encode_chunked = False\n                content_length = self._get_content_length(body, method)\n                if content_length is None:\n                    if body is not None:\n                        if self.debuglevel > 0:\n                            print('Unable to determine size of %r' % body)\n                        encode_chunked = True\n                        self.putheader('Transfer-Encoding', 'chunked')\n                else:\n                    self.putheader('Content-Length', str(content_length))\n        else:\n            encode_chunked = False\n\n        for hdr, value in headers.items():\n            self.putheader(hdr, value)\n        if isinstance(body, str):\n            # RFC 2616 Section 3.7.1 says that text default has a\n            # default charset of iso-8859-1.\n            body = _encode(body, 'body')\n        self.endheaders(body, encode_chunked=encode_chunked)",
        "name_type": "stdlib"
    },
    "http.client.HTTPConnection.getresponse": {
        "API_name": "http.client.HTTPConnection.getresponse",
        "loc_name": "http.client.HTTPConnection.getresponse",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1333,
        "namespace": "HTTPConnection",
        "body": "    def getresponse(self):\n        \"\"\"Get the response from the server.\n\n        If the HTTPConnection is in the correct state, returns an\n        instance of HTTPResponse or of whatever object is returned by\n        the response_class variable.\n\n        If a request has not been sent or if a previous response has\n        not be handled, ResponseNotReady is raised.  If the HTTP\n        response indicates that the connection should be closed, then\n        it will be closed before the response is returned.  When the\n        connection is closed, the underlying socket is closed.\n        \"\"\"\n\n        # if a prior response has been completed, then forget about it.\n        if self.__response and self.__response.isclosed():\n            self.__response = None\n\n        # if a prior response exists, then it must be completed (otherwise, we\n        # cannot read this response's header to determine the connection-close\n        # behavior)\n        #\n        # note: if a prior response existed, but was connection-close, then the\n        # socket and response were made independent of this HTTPConnection\n        # object since a new request requires that we open a whole new\n        # connection\n        #\n        # this means the prior response had one of two states:\n        #   1) will_close: this connection was reset and the prior socket and\n        #                  response operate independently\n        #   2) persistent: the response was retained and we await its\n        #                  isclosed() status to become true.\n        #\n        if self.__state != _CS_REQ_SENT or self.__response:\n            raise ResponseNotReady(self.__state)\n\n        if self.debuglevel > 0:\n            response = self.response_class(self.sock, self.debuglevel,\n                                           method=self._method)\n        else:\n            response = self.response_class(self.sock, method=self._method)\n\n        try:\n            try:\n                response.begin()\n            except ConnectionError:\n                self.close()\n                raise\n            assert response.will_close != _UNKNOWN\n            self.__state = _CS_IDLE\n\n            if response.will_close:\n                # this effectively passes the connection to the response\n                self.close()\n            else:\n                # remember this, so we can tell when it is complete\n                self.__response = response\n\n            return response\n        except:\n            response.close()\n            raise",
        "name_type": "stdlib"
    },
    "http.client.HTTPSConnection": {
        "API_name": "http.client.HTTPSConnection",
        "loc_name": "http.client.HTTPSConnection",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1401,
        "namespace": "HTTPSConnection",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.HTTPSConnection.__init__": {
        "API_name": "http.client.HTTPSConnection.__init__",
        "loc_name": "http.client.HTTPSConnection.__init__",
        "args": "self;host;port;key_file;cert_file;timeout;source_address",
        "args_default": 5,
        "filepath": "http.client",
        "lineno": 1408,
        "namespace": "HTTPSConnection",
        "body": "        def __init__(self, host, port=None, key_file=None, cert_file=None,\n                     timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n                     source_address=None, *, context=None,\n                     check_hostname=None, blocksize=8192):\n            super(HTTPSConnection, self).__init__(host, port, timeout,\n                                                  source_address,\n                                                  blocksize=blocksize)\n            if (key_file is not None or cert_file is not None or\n                        check_hostname is not None):\n                import warnings\n                warnings.warn(\"key_file, cert_file and check_hostname are \"\n                              \"deprecated, use a custom context instead.\",\n                              DeprecationWarning, 2)\n            self.key_file = key_file\n            self.cert_file = cert_file\n            if context is None:\n                context = ssl._create_default_https_context()\n                # enable PHA for TLS 1.3 connections if available\n                if context.post_handshake_auth is not None:\n                    context.post_handshake_auth = True\n            will_verify = context.verify_mode != ssl.CERT_NONE\n            if check_hostname is None:\n                check_hostname = context.check_hostname\n            if check_hostname and not will_verify:\n                raise ValueError(\"check_hostname needs a SSL context with \"\n                                 \"either CERT_OPTIONAL or CERT_REQUIRED\")\n            if key_file or cert_file:\n                context.load_cert_chain(cert_file, key_file)\n                # cert and key file means the user wants to authenticate.\n                # enable TLS 1.3 PHA implicitly even for custom contexts.\n                if context.post_handshake_auth is not None:\n                    context.post_handshake_auth = True\n            self._context = context\n            if check_hostname is not None:\n                self._context.check_hostname = check_hostname",
        "name_type": "stdlib"
    },
    "http.client.HTTPSConnection.connect": {
        "API_name": "http.client.HTTPSConnection.connect",
        "loc_name": "http.client.HTTPSConnection.connect",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1444,
        "namespace": "HTTPSConnection",
        "body": "        def connect(self):\n            \"Connect to a host on a given (SSL) port.\"\n\n            super().connect()\n\n            if self._tunnel_host:\n                server_hostname = self._tunnel_host\n            else:\n                server_hostname = self.host\n\n            self.sock = self._context.wrap_socket(self.sock,\n                                                  server_hostname=server_hostname)",
        "name_type": "stdlib"
    },
    "http.client.HTTPException": {
        "API_name": "http.client.HTTPException",
        "loc_name": "http.client.HTTPException",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1459,
        "namespace": "HTTPException",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.NotConnected": {
        "API_name": "http.client.NotConnected",
        "loc_name": "http.client.NotConnected",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1464,
        "namespace": "NotConnected",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.InvalidURL": {
        "API_name": "http.client.InvalidURL",
        "loc_name": "http.client.InvalidURL",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1467,
        "namespace": "InvalidURL",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.UnknownProtocol": {
        "API_name": "http.client.UnknownProtocol",
        "loc_name": "http.client.UnknownProtocol",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1470,
        "namespace": "UnknownProtocol",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.UnknownProtocol.__init__": {
        "API_name": "http.client.UnknownProtocol.__init__",
        "loc_name": "http.client.UnknownProtocol.__init__",
        "args": "self;version",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1471,
        "namespace": "UnknownProtocol",
        "body": "    def __init__(self, version):\n        self.args = version,\n        self.version = version",
        "name_type": "stdlib"
    },
    "http.client.UnknownTransferEncoding": {
        "API_name": "http.client.UnknownTransferEncoding",
        "loc_name": "http.client.UnknownTransferEncoding",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1475,
        "namespace": "UnknownTransferEncoding",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.UnimplementedFileMode": {
        "API_name": "http.client.UnimplementedFileMode",
        "loc_name": "http.client.UnimplementedFileMode",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1478,
        "namespace": "UnimplementedFileMode",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.IncompleteRead": {
        "API_name": "http.client.IncompleteRead",
        "loc_name": "http.client.IncompleteRead",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1481,
        "namespace": "IncompleteRead",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.IncompleteRead.__init__": {
        "API_name": "http.client.IncompleteRead.__init__",
        "loc_name": "http.client.IncompleteRead.__init__",
        "args": "self;partial;expected",
        "args_default": 1,
        "filepath": "http.client",
        "lineno": 1482,
        "namespace": "IncompleteRead",
        "body": "    def __init__(self, partial, expected=None):\n        self.args = partial,\n        self.partial = partial\n        self.expected = expected",
        "name_type": "stdlib"
    },
    "http.client.IncompleteRead.__repr__": {
        "API_name": "http.client.IncompleteRead.__repr__",
        "loc_name": "http.client.IncompleteRead.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1486,
        "namespace": "IncompleteRead",
        "body": "    def __repr__(self):\n        if self.expected is not None:\n            e = ', %i more expected' % self.expected\n        else:\n            e = ''\n        return '%s(%i bytes read%s)' % (self.__class__.__name__,\n                                        len(self.partial), e)",
        "name_type": "stdlib"
    },
    "http.client.ImproperConnectionState": {
        "API_name": "http.client.ImproperConnectionState",
        "loc_name": "http.client.ImproperConnectionState",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1495,
        "namespace": "ImproperConnectionState",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.CannotSendRequest": {
        "API_name": "http.client.CannotSendRequest",
        "loc_name": "http.client.CannotSendRequest",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1498,
        "namespace": "CannotSendRequest",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.CannotSendHeader": {
        "API_name": "http.client.CannotSendHeader",
        "loc_name": "http.client.CannotSendHeader",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1501,
        "namespace": "CannotSendHeader",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.ResponseNotReady": {
        "API_name": "http.client.ResponseNotReady",
        "loc_name": "http.client.ResponseNotReady",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1504,
        "namespace": "ResponseNotReady",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.BadStatusLine": {
        "API_name": "http.client.BadStatusLine",
        "loc_name": "http.client.BadStatusLine",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1507,
        "namespace": "BadStatusLine",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.BadStatusLine.__init__": {
        "API_name": "http.client.BadStatusLine.__init__",
        "loc_name": "http.client.BadStatusLine.__init__",
        "args": "self;line",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1508,
        "namespace": "BadStatusLine",
        "body": "    def __init__(self, line):\n        if not line:\n            line = repr(line)\n        self.args = line,\n        self.line = line",
        "name_type": "stdlib"
    },
    "http.client.LineTooLong": {
        "API_name": "http.client.LineTooLong",
        "loc_name": "http.client.LineTooLong",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1514,
        "namespace": "LineTooLong",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.LineTooLong.__init__": {
        "API_name": "http.client.LineTooLong.__init__",
        "loc_name": "http.client.LineTooLong.__init__",
        "args": "self;line_type",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1515,
        "namespace": "LineTooLong",
        "body": "    def __init__(self, line_type):\n        HTTPException.__init__(self, \"got more than %d bytes when reading %s\"\n                                     % (_MAXLINE, line_type))",
        "name_type": "stdlib"
    },
    "http.client.RemoteDisconnected": {
        "API_name": "http.client.RemoteDisconnected",
        "loc_name": "http.client.RemoteDisconnected",
        "args": "*",
        "args_default": "*",
        "filepath": "http.client",
        "lineno": 1519,
        "namespace": "RemoteDisconnected",
        "body": "",
        "name_type": "stdlib"
    },
    "http.client.RemoteDisconnected.__init__": {
        "API_name": "http.client.RemoteDisconnected.__init__",
        "loc_name": "http.client.RemoteDisconnected.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.client",
        "lineno": 1520,
        "namespace": "RemoteDisconnected",
        "body": "    def __init__(self, *pos, **kw):\n        BadStatusLine.__init__(self, \"\")\n        ConnectionResetError.__init__(self, *pos, **kw)",
        "name_type": "stdlib"
    },
    "http.cookiejar": {
        "API_name": "http.cookiejar",
        "loc_name": "http.cookiejar",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"HTTP cookie handling for web clients.\n\nThis module has (now fairly distant) origins in Gisle Aas' Perl module\nHTTP::Cookies, from the libwww-perl library.\n\nDocstrings, comments and debug strings in this code refer to the\nattributes of the HTTP cookie system as cookie-attributes, to distinguish\nthem clearly from Python attributes.\n\nClass diagram (note that BSDDBCookieJar and the MSIE* classes are not\ndistributed with the Python standard library, but are available from\nhttp://wwwsearch.sf.net/):\n\n                        CookieJar____\n                        /     \\      \\\n            FileCookieJar      \\      \\\n             /    |   \\         \\      \\\n MozillaCookieJar | LWPCookieJar \\      \\\n                  |               |      \\\n                  |   ---MSIEBase |       \\\n                  |  /      |     |        \\\n                  | /   MSIEDBCookieJar BSDDBCookieJar\n                  |/\n               MSIECookieJar\n\n\"\"\"\n__all__ = ['Cookie', 'CookieJar', 'CookiePolicy', 'DefaultCookiePolicy',\n           'FileCookieJar', 'LWPCookieJar', 'LoadError', 'MozillaCookieJar']\ndebug = False   # set to True to enable debugging via the logging module\nlogger = None\nDEFAULT_HTTP_PORT = str(http.client.HTTP_PORT)\nMISSING_FILENAME_TEXT = (\"a filename was not supplied (nor was the CookieJar \"\n                         \"instance initialised with one)\")\nEPOCH_YEAR = 1970\nDAYS = [\"Mon\", \"Tue\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"]\nMONTHS = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\",\n          \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\nMONTHS_LOWER = []\nfor month in MONTHS: MONTHS_LOWER.append(month.lower())\nUTC_ZONES = {\"GMT\": None, \"UTC\": None, \"UT\": None, \"Z\": None}\nTIMEZONE_RE = re.compile(r\"^([-+])?(\\d\\d?):?(\\d\\d)?$\", re.ASCII)\nSTRICT_DATE_RE = re.compile(\n    r\"^[SMTWF][a-z][a-z], (\\d\\d) ([JFMASOND][a-z][a-z]) \"\n    r\"(\\d\\d\\d\\d) (\\d\\d):(\\d\\d):(\\d\\d) GMT$\", re.ASCII)\nWEEKDAY_RE = re.compile(\n    r\"^(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-z]*,?\\s*\", re.I | re.ASCII)\nLOOSE_HTTP_DATE_RE = re.compile(\n    r\"\"\"^\n    (\\d\\d?)            # day\n       (?:\\s+|[-\\/])\n    (\\w+)              # month\n        (?:\\s+|[-\\/])\n    (\\d+)              # year\n    (?:\n          (?:\\s+|:)    # separator before clock\n       (\\d\\d?):(\\d\\d)  # hour:min\n       (?::(\\d\\d))?    # optional seconds\n    )?                 # optional clock\n       \\s*\n    (?:\n       ([-+]?\\d{2,4}|(?![APap][Mm]\\b)[A-Za-z]+) # timezone\n       \\s*\n    )?\n    (?:\n       \\(\\w+\\)         # ASCII representation of timezone in parens.\n       \\s*\n    )?$\"\"\", re.X | re.ASCII)\nISO_DATE_RE = re.compile(\n    r\"\"\"^\n    (\\d{4})              # year\n       [-\\/]?\n    (\\d\\d?)              # numerical month\n       [-\\/]?\n    (\\d\\d?)              # day\n   (?:\n         (?:\\s+|[-:Tt])  # separator before clock\n      (\\d\\d?):?(\\d\\d)    # hour:min\n      (?::?(\\d\\d(?:\\.\\d*)?))?  # optional seconds (and fractional)\n   )?                    # optional clock\n      \\s*\n   (?:\n      ([-+]?\\d\\d?:?(:?\\d\\d)?\n       |Z|z)             # timezone  (Z is \"zero meridian\", i.e. GMT)\n      \\s*\n   )?$\"\"\", re.X | re. ASCII)\nHEADER_TOKEN_RE =        re.compile(r\"^\\s*([^=\\s;,]+)\")\nHEADER_QUOTED_VALUE_RE = re.compile(r\"^\\s*=\\s*\\\"([^\\\"\\\\]*(?:\\\\.[^\\\"\\\\]*)*)\\\"\")\nHEADER_VALUE_RE =        re.compile(r\"^\\s*=\\s*([^\\s;,]*)\")\nHEADER_ESCAPE_RE = re.compile(r\"\\\\(.)\")\nHEADER_JOIN_ESCAPE_RE = re.compile(r\"([\\\"\\\\])\")\nIPV4_RE = re.compile(r\"\\.\\d+$\", re.ASCII)\ncut_port_re = re.compile(r\":\\d+$\", re.ASCII)\nHTTP_PATH_SAFE = \"%/;:@&=+$,!~*'()\"\nESCAPED_CHAR_RE = re.compile(r\"%([0-9a-fA-F][0-9a-fA-F])\")",
        "name_type": "stdlib"
    },
    "http.cookiejar._debug": {
        "API_name": "http.cookiejar._debug",
        "loc_name": "http.cookiejar._debug",
        "args": "",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 44,
        "namespace": "*",
        "body": "def _debug(*args):\n    if not debug:\n        return\n    global logger\n    if not logger:\n        import logging\n        logger = logging.getLogger(\"http.cookiejar\")\n    return logger.debug(*args)",
        "name_type": "stdlib"
    },
    "http.cookiejar._warn_unhandled_exception": {
        "API_name": "http.cookiejar._warn_unhandled_exception",
        "loc_name": "http.cookiejar._warn_unhandled_exception",
        "args": "",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 58,
        "namespace": "*",
        "body": "def _warn_unhandled_exception():\n    # There are a few catch-all except: statements in this module, for\n    # catching input that's bad in unexpected ways.  Warn if any\n    # exceptions are caught there.\n    import io, warnings, traceback\n    f = io.StringIO()\n    traceback.print_exc(None, f)\n    msg = f.getvalue()\n    warnings.warn(\"http.cookiejar bug!\\n%s\" % msg, stacklevel=2)",
        "name_type": "stdlib"
    },
    "http.cookiejar._timegm": {
        "API_name": "http.cookiejar._timegm",
        "loc_name": "http.cookiejar._timegm",
        "args": "tt",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 73,
        "namespace": "*",
        "body": "def _timegm(tt):\n    year, month, mday, hour, min, sec = tt[:6]\n    if ((year >= EPOCH_YEAR) and (1 <= month <= 12) and (1 <= mday <= 31) and\n        (0 <= hour <= 24) and (0 <= min <= 59) and (0 <= sec <= 61)):\n        return timegm(tt)\n    else:\n        return None",
        "name_type": "stdlib"
    },
    "http.cookiejar.time2isoz": {
        "API_name": "http.cookiejar.time2isoz",
        "loc_name": "http.cookiejar.time2isoz",
        "args": "t",
        "args_default": 1,
        "filepath": "http.cookiejar",
        "lineno": 87,
        "namespace": "*",
        "body": "def time2isoz(t=None):\n    \"\"\"Return a string representing time in seconds since epoch, t.\n\n    If the function is called without an argument, it will use the current\n    time.\n\n    The format of the returned string is like \"YYYY-MM-DD hh:mm:ssZ\",\n    representing Universal Time (UTC, aka GMT).  An example of this format is:\n\n    1994-11-24 08:49:37Z\n\n    \"\"\"\n    if t is None:\n        dt = datetime.datetime.utcnow()\n    else:\n        dt = datetime.datetime.utcfromtimestamp(t)\n    return \"%04d-%02d-%02d %02d:%02d:%02dZ\" % (\n        dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second)",
        "name_type": "stdlib"
    },
    "http.cookiejar.time2netscape": {
        "API_name": "http.cookiejar.time2netscape",
        "loc_name": "http.cookiejar.time2netscape",
        "args": "t",
        "args_default": 1,
        "filepath": "http.cookiejar",
        "lineno": 106,
        "namespace": "*",
        "body": "def time2netscape(t=None):\n    \"\"\"Return a string representing time in seconds since epoch, t.\n\n    If the function is called without an argument, it will use the current\n    time.\n\n    The format of the returned string is like this:\n\n    Wed, DD-Mon-YYYY HH:MM:SS GMT\n\n    \"\"\"\n    if t is None:\n        dt = datetime.datetime.utcnow()\n    else:\n        dt = datetime.datetime.utcfromtimestamp(t)\n    return \"%s, %02d-%s-%04d %02d:%02d:%02d GMT\" % (\n        DAYS[dt.weekday()], dt.day, MONTHS[dt.month-1],\n        dt.year, dt.hour, dt.minute, dt.second)",
        "name_type": "stdlib"
    },
    "http.cookiejar.offset_from_tz_string": {
        "API_name": "http.cookiejar.offset_from_tz_string",
        "loc_name": "http.cookiejar.offset_from_tz_string",
        "args": "tz",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 129,
        "namespace": "*",
        "body": "def offset_from_tz_string(tz):\n    offset = None\n    if tz in UTC_ZONES:\n        offset = 0\n    else:\n        m = TIMEZONE_RE.search(tz)\n        if m:\n            offset = 3600 * int(m.group(2))\n            if m.group(3):\n                offset = offset + 60 * int(m.group(3))\n            if m.group(1) == '-':\n                offset = -offset\n    return offset",
        "name_type": "stdlib"
    },
    "http.cookiejar._str2time": {
        "API_name": "http.cookiejar._str2time",
        "loc_name": "http.cookiejar._str2time",
        "args": "day;mon;yr;hr;min;sec;tz",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 143,
        "namespace": "*",
        "body": "def _str2time(day, mon, yr, hr, min, sec, tz):\n    yr = int(yr)\n    if yr > datetime.MAXYEAR:\n        return None\n\n    # translate month name to number\n    # month numbers start with 1 (January)\n    try:\n        mon = MONTHS_LOWER.index(mon.lower())+1\n    except ValueError:\n        # maybe it's already a number\n        try:\n            imon = int(mon)\n        except ValueError:\n            return None\n        if 1 <= imon <= 12:\n            mon = imon\n        else:\n            return None\n\n    # make sure clock elements are defined\n    if hr is None: hr = 0\n    if min is None: min = 0\n    if sec is None: sec = 0\n\n    day = int(day)\n    hr = int(hr)\n    min = int(min)\n    sec = int(sec)\n\n    if yr < 1000:\n        # find \"obvious\" year\n        cur_yr = time.localtime(time.time())[0]\n        m = cur_yr % 100\n        tmp = yr\n        yr = yr + cur_yr - m\n        m = m - tmp\n        if abs(m) > 50:\n            if m > 0: yr = yr + 100\n            else: yr = yr - 100\n\n    # convert UTC time tuple to seconds since epoch (not timezone-adjusted)\n    t = _timegm((yr, mon, day, hr, min, sec, tz))\n\n    if t is not None:\n        # adjust time using timezone string, to get absolute time since epoch\n        if tz is None:\n            tz = \"UTC\"\n        tz = tz.upper()\n        offset = offset_from_tz_string(tz)\n        if offset is None:\n            return None\n        t = t - offset\n\n    return t",
        "name_type": "stdlib"
    },
    "http.cookiejar.http2time": {
        "API_name": "http.cookiejar.http2time",
        "loc_name": "http.cookiejar.http2time",
        "args": "text",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 225,
        "namespace": "*",
        "body": "def http2time(text):\n    \"\"\"Returns time in seconds since epoch of time represented by a string.\n\n    Return value is an integer.\n\n    None is returned if the format of str is unrecognized, the time is outside\n    the representable range, or the timezone string is not recognized.  If the\n    string contains no timezone, UTC is assumed.\n\n    The timezone in the string may be numerical (like \"-0800\" or \"+0100\") or a\n    string timezone (like \"UTC\", \"GMT\", \"BST\" or \"EST\").  Currently, only the\n    timezone strings equivalent to UTC (zero offset) are known to the function.\n\n    The function loosely parses the following formats:\n\n    Wed, 09 Feb 1994 22:23:32 GMT       -- HTTP format\n    Tuesday, 08-Feb-94 14:15:29 GMT     -- old rfc850 HTTP format\n    Tuesday, 08-Feb-1994 14:15:29 GMT   -- broken rfc850 HTTP format\n    09 Feb 1994 22:23:32 GMT            -- HTTP format (no weekday)\n    08-Feb-94 14:15:29 GMT              -- rfc850 format (no weekday)\n    08-Feb-1994 14:15:29 GMT            -- broken rfc850 format (no weekday)\n\n    The parser ignores leading and trailing whitespace.  The time may be\n    absent.\n\n    If the year is given with only 2 digits, the function will select the\n    century that makes the year closest to the current date.\n\n    \"\"\"\n    # fast exit for strictly conforming string\n    m = STRICT_DATE_RE.search(text)\n    if m:\n        g = m.groups()\n        mon = MONTHS_LOWER.index(g[1].lower()) + 1\n        tt = (int(g[2]), mon, int(g[0]),\n              int(g[3]), int(g[4]), float(g[5]))\n        return _timegm(tt)\n\n    # No, we need some messy parsing...\n\n    # clean up\n    text = text.lstrip()\n    text = WEEKDAY_RE.sub(\"\", text, 1)  # Useless weekday\n\n    # tz is time zone specifier string\n    day, mon, yr, hr, min, sec, tz = [None]*7\n\n    # loose regexp parse\n    m = LOOSE_HTTP_DATE_RE.search(text)\n    if m is not None:\n        day, mon, yr, hr, min, sec, tz = m.groups()\n    else:\n        return None  # bad format\n\n    return _str2time(day, mon, yr, hr, min, sec, tz)",
        "name_type": "stdlib"
    },
    "http.cookiejar.iso2time": {
        "API_name": "http.cookiejar.iso2time",
        "loc_name": "http.cookiejar.iso2time",
        "args": "text",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 299,
        "namespace": "*",
        "body": "def iso2time(text):\n    \"\"\"\n    As for http2time, but parses the ISO 8601 formats:\n\n    1994-02-03 14:15:29 -0100    -- ISO 8601 format\n    1994-02-03 14:15:29          -- zone is optional\n    1994-02-03                   -- only date\n    1994-02-03T14:15:29          -- Use T as separator\n    19940203T141529Z             -- ISO 8601 compact format\n    19940203                     -- only date\n\n    \"\"\"\n    # clean up\n    text = text.lstrip()\n\n    # tz is time zone specifier string\n    day, mon, yr, hr, min, sec, tz = [None]*7\n\n    # loose regexp parse\n    m = ISO_DATE_RE.search(text)\n    if m is not None:\n        # XXX there's an extra bit of the timezone I'm ignoring here: is\n        #   this the right thing to do?\n        yr, mon, day, hr, min, sec, tz, _ = m.groups()\n    else:\n        return None  # bad format\n\n    return _str2time(day, mon, yr, hr, min, sec, tz)",
        "name_type": "stdlib"
    },
    "http.cookiejar.unmatched": {
        "API_name": "http.cookiejar.unmatched",
        "loc_name": "http.cookiejar.unmatched",
        "args": "match",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 332,
        "namespace": "*",
        "body": "def unmatched(match):\n    \"\"\"Return unmatched part of re.Match object.\"\"\"\n    start, end = match.span(0)\n    return match.string[:start]+match.string[end:]",
        "name_type": "stdlib"
    },
    "http.cookiejar.split_header_words": {
        "API_name": "http.cookiejar.split_header_words",
        "loc_name": "http.cookiejar.split_header_words",
        "args": "header_values",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 341,
        "namespace": "*",
        "body": "def split_header_words(header_values):\n    r\"\"\"Parse header values into a list of lists containing key,value pairs.\n\n    The function knows how to deal with \",\", \";\" and \"=\" as well as quoted\n    values after \"=\".  A list of space separated tokens are parsed as if they\n    were separated by \";\".\n\n    If the header_values passed as argument contains multiple values, then they\n    are treated as if they were a single value separated by comma \",\".\n\n    This means that this function is useful for parsing header fields that\n    follow this syntax (BNF as from the HTTP/1.1 specification, but we relax\n    the requirement for tokens).\n\n      headers           = #header\n      header            = (token | parameter) *( [\";\"] (token | parameter))\n\n      token             = 1*<any CHAR except CTLs or separators>\n      separators        = \"(\" | \")\" | \"<\" | \">\" | \"@\"\n                        | \",\" | \";\" | \":\" | \"\\\" | <\">\n                        | \"/\" | \"[\" | \"]\" | \"?\" | \"=\"\n                        | \"{\" | \"}\" | SP | HT\n\n      quoted-string     = ( <\"> *(qdtext | quoted-pair ) <\"> )\n      qdtext            = <any TEXT except <\">>\n      quoted-pair       = \"\\\" CHAR\n\n      parameter         = attribute \"=\" value\n      attribute         = token\n      value             = token | quoted-string\n\n    Each header is represented by a list of key/value pairs.  The value for a\n    simple token (not part of a parameter) is None.  Syntactically incorrect\n    headers will not necessarily be parsed as you would want.\n\n    This is easier to describe with some examples:\n\n    >>> split_header_words(['foo=\"bar\"; port=\"80,81\"; discard, bar=baz'])\n    [[('foo', 'bar'), ('port', '80,81'), ('discard', None)], [('bar', 'baz')]]\n    >>> split_header_words(['text/html; charset=\"iso-8859-1\"'])\n    [[('text/html', None), ('charset', 'iso-8859-1')]]\n    >>> split_header_words([r'Basic realm=\"\\\"foo\\bar\\\"\"'])\n    [[('Basic', None), ('realm', '\"foobar\"')]]\n\n    \"\"\"\n    assert not isinstance(header_values, str)\n    result = []\n    for text in header_values:\n        orig_text = text\n        pairs = []\n        while text:\n            m = HEADER_TOKEN_RE.search(text)\n            if m:\n                text = unmatched(m)\n                name = m.group(1)\n                m = HEADER_QUOTED_VALUE_RE.search(text)\n                if m:  # quoted value\n                    text = unmatched(m)\n                    value = m.group(1)\n                    value = HEADER_ESCAPE_RE.sub(r\"\\1\", value)\n                else:\n                    m = HEADER_VALUE_RE.search(text)\n                    if m:  # unquoted value\n                        text = unmatched(m)\n                        value = m.group(1)\n                        value = value.rstrip()\n                    else:\n                        # no value, a lone token\n                        value = None\n                pairs.append((name, value))\n            elif text.lstrip().startswith(\",\"):\n                # concatenated headers, as per RFC 2616 section 4.2\n                text = text.lstrip()[1:]\n                if pairs: result.append(pairs)\n                pairs = []\n            else:\n                # skip junk\n                non_junk, nr_junk_chars = re.subn(r\"^[=\\s;]*\", \"\", text)\n                assert nr_junk_chars > 0, (\n                    \"split_header_words bug: '%s', '%s', %s\" %\n                    (orig_text, text, pairs))\n                text = non_junk\n        if pairs: result.append(pairs)\n    return result",
        "name_type": "stdlib"
    },
    "http.cookiejar.join_header_words": {
        "API_name": "http.cookiejar.join_header_words",
        "loc_name": "http.cookiejar.join_header_words",
        "args": "lists",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 427,
        "namespace": "*",
        "body": "def join_header_words(lists):\n    \"\"\"Do the inverse (almost) of the conversion done by split_header_words.\n\n    Takes a list of lists of (key, value) pairs and produces a single header\n    value.  Attribute values are quoted if needed.\n\n    >>> join_header_words([[(\"text/plain\", None), (\"charset\", \"iso-8859-1\")]])\n    'text/plain; charset=\"iso-8859-1\"'\n    >>> join_header_words([[(\"text/plain\", None)], [(\"charset\", \"iso-8859-1\")]])\n    'text/plain, charset=\"iso-8859-1\"'\n\n    \"\"\"\n    headers = []\n    for pairs in lists:\n        attr = []\n        for k, v in pairs:\n            if v is not None:\n                if not re.search(r\"^\\w+$\", v):\n                    v = HEADER_JOIN_ESCAPE_RE.sub(r\"\\\\\\1\", v)  # escape \" and \\\n                    v = '\"%s\"' % v\n                k = \"%s=%s\" % (k, v)\n            attr.append(k)\n        if attr: headers.append(\"; \".join(attr))\n    return \", \".join(headers)",
        "name_type": "stdlib"
    },
    "http.cookiejar.strip_quotes": {
        "API_name": "http.cookiejar.strip_quotes",
        "loc_name": "http.cookiejar.strip_quotes",
        "args": "text",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 452,
        "namespace": "*",
        "body": "def strip_quotes(text):\n    if text.startswith('\"'):\n        text = text[1:]\n    if text.endswith('\"'):\n        text = text[:-1]\n    return text",
        "name_type": "stdlib"
    },
    "http.cookiejar.parse_ns_headers": {
        "API_name": "http.cookiejar.parse_ns_headers",
        "loc_name": "http.cookiejar.parse_ns_headers",
        "args": "ns_headers",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 459,
        "namespace": "*",
        "body": "def parse_ns_headers(ns_headers):\n    \"\"\"Ad-hoc parser for Netscape protocol cookie-attributes.\n\n    The old Netscape cookie format for Set-Cookie can for instance contain\n    an unquoted \",\" in the expires field, so we have to use this ad-hoc\n    parser instead of split_header_words.\n\n    XXX This may not make the best possible effort to parse all the crap\n    that Netscape Cookie headers contain.  Ronald Tschalar's HTTPClient\n    parser is probably better, so could do worse than following that if\n    this ever gives any trouble.\n\n    Currently, this is also used for parsing RFC 2109 cookies.\n\n    \"\"\"\n    known_attrs = (\"expires\", \"domain\", \"path\", \"secure\",\n                   # RFC 2109 attrs (may turn up in Netscape cookies, too)\n                   \"version\", \"port\", \"max-age\")\n\n    result = []\n    for ns_header in ns_headers:\n        pairs = []\n        version_set = False\n\n        # XXX: The following does not strictly adhere to RFCs in that empty\n        # names and values are legal (the former will only appear once and will\n        # be overwritten if multiple occurrences are present). This is\n        # mostly to deal with backwards compatibility.\n        for ii, param in enumerate(ns_header.split(';')):\n            param = param.strip()\n\n            key, sep, val = param.partition('=')\n            key = key.strip()\n\n            if not key:\n                if ii == 0:\n                    break\n                else:\n                    continue\n\n            # allow for a distinction between present and empty and missing\n            # altogether\n            val = val.strip() if sep else None\n\n            if ii != 0:\n                lc = key.lower()\n                if lc in known_attrs:\n                    key = lc\n\n                if key == \"version\":\n                    # This is an RFC 2109 cookie.\n                    if val is not None:\n                        val = strip_quotes(val)\n                    version_set = True\n                elif key == \"expires\":\n                    # convert expires date to seconds since epoch\n                    if val is not None:\n                        val = http2time(strip_quotes(val))  # None if invalid\n            pairs.append((key, val))\n\n        if pairs:\n            if not version_set:\n                pairs.append((\"version\", \"0\"))\n            result.append(pairs)\n\n    return result",
        "name_type": "stdlib"
    },
    "http.cookiejar.is_HDN": {
        "API_name": "http.cookiejar.is_HDN",
        "loc_name": "http.cookiejar.is_HDN",
        "args": "text",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 528,
        "namespace": "*",
        "body": "def is_HDN(text):\n    \"\"\"Return True if text is a host domain name.\"\"\"\n    # XXX\n    # This may well be wrong.  Which RFC is HDN defined in, if any (for\n    #  the purposes of RFC 2965)?\n    # For the current implementation, what about IPv6?  Remember to look\n    #  at other uses of IPV4_RE also, if change this.\n    if IPV4_RE.search(text):\n        return False\n    if text == \"\":\n        return False\n    if text[0] == \".\" or text[-1] == \".\":\n        return False\n    return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.domain_match": {
        "API_name": "http.cookiejar.domain_match",
        "loc_name": "http.cookiejar.domain_match",
        "args": "A;B",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 543,
        "namespace": "*",
        "body": "def domain_match(A, B):\n    \"\"\"Return True if domain A domain-matches domain B, according to RFC 2965.\n\n    A and B may be host domain names or IP addresses.\n\n    RFC 2965, section 1:\n\n    Host names can be specified either as an IP address or a HDN string.\n    Sometimes we compare one host name with another.  (Such comparisons SHALL\n    be case-insensitive.)  Host A's name domain-matches host B's if\n\n         *  their host name strings string-compare equal; or\n\n         * A is a HDN string and has the form NB, where N is a non-empty\n            name string, B has the form .B', and B' is a HDN string.  (So,\n            x.y.com domain-matches .Y.com but not Y.com.)\n\n    Note that domain-match is not a commutative operation: a.b.c.com\n    domain-matches .c.com, but not the reverse.\n\n    \"\"\"\n    # Note that, if A or B are IP addresses, the only relevant part of the\n    # definition of the domain-match algorithm is the direct string-compare.\n    A = A.lower()\n    B = B.lower()\n    if A == B:\n        return True\n    if not is_HDN(A):\n        return False\n    i = A.rfind(B)\n    if i == -1 or i == 0:\n        # A does not have form NB, or N is the empty string\n        return False\n    if not B.startswith(\".\"):\n        return False\n    if not is_HDN(B[1:]):\n        return False\n    return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.liberal_is_HDN": {
        "API_name": "http.cookiejar.liberal_is_HDN",
        "loc_name": "http.cookiejar.liberal_is_HDN",
        "args": "text",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 582,
        "namespace": "*",
        "body": "def liberal_is_HDN(text):\n    \"\"\"Return True if text is a sort-of-like a host domain name.\n\n    For accepting/blocking domains.\n\n    \"\"\"\n    if IPV4_RE.search(text):\n        return False\n    return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.user_domain_match": {
        "API_name": "http.cookiejar.user_domain_match",
        "loc_name": "http.cookiejar.user_domain_match",
        "args": "A;B",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 592,
        "namespace": "*",
        "body": "def user_domain_match(A, B):\n    \"\"\"For blocking/accepting domains.\n\n    A and B may be host domain names or IP addresses.\n\n    \"\"\"\n    A = A.lower()\n    B = B.lower()\n    if not (liberal_is_HDN(A) and liberal_is_HDN(B)):\n        if A == B:\n            # equal IP addresses\n            return True\n        return False\n    initial_dot = B.startswith(\".\")\n    if initial_dot and A.endswith(B):\n        return True\n    if not initial_dot and A == B:\n        return True\n    return False",
        "name_type": "stdlib"
    },
    "http.cookiejar.request_host": {
        "API_name": "http.cookiejar.request_host",
        "loc_name": "http.cookiejar.request_host",
        "args": "request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 613,
        "namespace": "*",
        "body": "def request_host(request):\n    \"\"\"Return request-host, as defined by RFC 2965.\n\n    Variation from RFC: returned value is lowercased, for convenient\n    comparison.\n\n    \"\"\"\n    url = request.get_full_url()\n    host = urllib.parse.urlparse(url)[1]\n    if host == \"\":\n        host = request.get_header(\"Host\", \"\")\n\n    # remove port, if present\n    host = cut_port_re.sub(\"\", host, 1)\n    return host.lower()",
        "name_type": "stdlib"
    },
    "http.cookiejar.eff_request_host": {
        "API_name": "http.cookiejar.eff_request_host",
        "loc_name": "http.cookiejar.eff_request_host",
        "args": "request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 629,
        "namespace": "*",
        "body": "def eff_request_host(request):\n    \"\"\"Return a tuple (request-host, effective request-host name).\n\n    As defined by RFC 2965, except both are lowercased.\n\n    \"\"\"\n    erhn = req_host = request_host(request)\n    if req_host.find(\".\") == -1 and not IPV4_RE.search(req_host):\n        erhn = req_host + \".local\"\n    return req_host, erhn",
        "name_type": "stdlib"
    },
    "http.cookiejar.request_path": {
        "API_name": "http.cookiejar.request_path",
        "loc_name": "http.cookiejar.request_path",
        "args": "request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 640,
        "namespace": "*",
        "body": "def request_path(request):\n    \"\"\"Path component of request-URI, as defined by RFC 2965.\"\"\"\n    url = request.get_full_url()\n    parts = urllib.parse.urlsplit(url)\n    path = escape_path(parts.path)\n    if not path.startswith(\"/\"):\n        # fix bad RFC 2396 absoluteURI\n        path = \"/\" + path\n    return path",
        "name_type": "stdlib"
    },
    "http.cookiejar.request_port": {
        "API_name": "http.cookiejar.request_port",
        "loc_name": "http.cookiejar.request_port",
        "args": "request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 650,
        "namespace": "*",
        "body": "def request_port(request):\n    host = request.host\n    i = host.find(':')\n    if i >= 0:\n        port = host[i+1:]\n        try:\n            int(port)\n        except ValueError:\n            _debug(\"nonnumeric port: '%s'\", port)\n            return None\n    else:\n        port = DEFAULT_HTTP_PORT\n    return port",
        "name_type": "stdlib"
    },
    "http.cookiejar.uppercase_escaped_char": {
        "API_name": "http.cookiejar.uppercase_escaped_char",
        "loc_name": "http.cookiejar.uppercase_escaped_char",
        "args": "match",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 668,
        "namespace": "*",
        "body": "def uppercase_escaped_char(match):\n    return \"%%%s\" % match.group(1).upper()",
        "name_type": "stdlib"
    },
    "http.cookiejar.escape_path": {
        "API_name": "http.cookiejar.escape_path",
        "loc_name": "http.cookiejar.escape_path",
        "args": "path",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 670,
        "namespace": "*",
        "body": "def escape_path(path):\n    \"\"\"Escape any invalid characters in HTTP URL, and uppercase all escapes.\"\"\"\n    # There's no knowing what character encoding was used to create URLs\n    # containing %-escapes, but since we have to pick one to escape invalid\n    # path characters, we pick UTF-8, as recommended in the HTML 4.0\n    # specification:\n    # http://www.w3.org/TR/REC-html40/appendix/notes.html#h-B.2.1\n    # And here, kind of: draft-fielding-uri-rfc2396bis-03\n    # (And in draft IRI specification: draft-duerst-iri-05)\n    # (And here, for new URI schemes: RFC 2718)\n    path = urllib.parse.quote(path, HTTP_PATH_SAFE)\n    path = ESCAPED_CHAR_RE.sub(uppercase_escaped_char, path)\n    return path",
        "name_type": "stdlib"
    },
    "http.cookiejar.reach": {
        "API_name": "http.cookiejar.reach",
        "loc_name": "http.cookiejar.reach",
        "args": "h",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 684,
        "namespace": "*",
        "body": "def reach(h):\n    \"\"\"Return reach of host h, as defined by RFC 2965, section 1.\n\n    The reach R of a host name H is defined as follows:\n\n       *  If\n\n          -  H is the host domain name of a host; and,\n\n          -  H has the form A.B; and\n\n          -  A has no embedded (that is, interior) dots; and\n\n          -  B has at least one embedded dot, or B is the string \"local\".\n             then the reach of H is .B.\n\n       *  Otherwise, the reach of H is H.\n\n    >>> reach(\"www.acme.com\")\n    '.acme.com'\n    >>> reach(\"acme.com\")\n    'acme.com'\n    >>> reach(\"acme.local\")\n    '.local'\n\n    \"\"\"\n    i = h.find(\".\")\n    if i >= 0:\n        #a = h[:i]  # this line is only here to show what a is\n        b = h[i+1:]\n        i = b.find(\".\")\n        if is_HDN(h) and (i >= 0 or b == \"local\"):\n            return \".\"+b\n    return h",
        "name_type": "stdlib"
    },
    "http.cookiejar.is_third_party": {
        "API_name": "http.cookiejar.is_third_party",
        "loc_name": "http.cookiejar.is_third_party",
        "args": "request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 719,
        "namespace": "*",
        "body": "def is_third_party(request):\n    \"\"\"\n\n    RFC 2965, section 3.3.6:\n\n        An unverifiable transaction is to a third-party host if its request-\n        host U does not domain-match the reach R of the request-host O in the\n        origin transaction.\n\n    \"\"\"\n    req_host = request_host(request)\n    if not domain_match(req_host, reach(request.origin_req_host)):\n        return True\n    else:\n        return False",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie": {
        "API_name": "http.cookiejar.Cookie",
        "loc_name": "http.cookiejar.Cookie",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 736,
        "namespace": "Cookie",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.__init__": {
        "API_name": "http.cookiejar.Cookie.__init__",
        "loc_name": "http.cookiejar.Cookie.__init__",
        "args": "self;version;name;value;port;port_specified;domain;domain_specified;domain_initial_dot;path;path_specified;secure;expires;discard;comment;comment_url;rest;rfc2109",
        "args_default": 1,
        "filepath": "http.cookiejar",
        "lineno": 754,
        "namespace": "Cookie",
        "body": "    def __init__(self, version, name, value,\n                 port, port_specified,\n                 domain, domain_specified, domain_initial_dot,\n                 path, path_specified,\n                 secure,\n                 expires,\n                 discard,\n                 comment,\n                 comment_url,\n                 rest,\n                 rfc2109=False,\n                 ):\n\n        if version is not None: version = int(version)\n        if expires is not None: expires = int(float(expires))\n        if port is None and port_specified is True:\n            raise ValueError(\"if port is None, port_specified must be false\")\n\n        self.version = version\n        self.name = name\n        self.value = value\n        self.port = port\n        self.port_specified = port_specified\n        # normalise case, as per RFC 2965 section 3.3.3\n        self.domain = domain.lower()\n        self.domain_specified = domain_specified\n        # Sigh.  We need to know whether the domain given in the\n        # cookie-attribute had an initial dot, in order to follow RFC 2965\n        # (as clarified in draft errata).  Needed for the returned $Domain\n        # value.\n        self.domain_initial_dot = domain_initial_dot\n        self.path = path\n        self.path_specified = path_specified\n        self.secure = secure\n        self.expires = expires\n        self.discard = discard\n        self.comment = comment\n        self.comment_url = comment_url\n        self.rfc2109 = rfc2109\n\n        self._rest = copy.copy(rest)",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.has_nonstandard_attr": {
        "API_name": "http.cookiejar.Cookie.has_nonstandard_attr",
        "loc_name": "http.cookiejar.Cookie.has_nonstandard_attr",
        "args": "self;name",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 796,
        "namespace": "Cookie",
        "body": "    def has_nonstandard_attr(self, name):\n        return name in self._rest",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.get_nonstandard_attr": {
        "API_name": "http.cookiejar.Cookie.get_nonstandard_attr",
        "loc_name": "http.cookiejar.Cookie.get_nonstandard_attr",
        "args": "self;name;default",
        "args_default": 1,
        "filepath": "http.cookiejar",
        "lineno": 798,
        "namespace": "Cookie",
        "body": "    def get_nonstandard_attr(self, name, default=None):\n        return self._rest.get(name, default)",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.set_nonstandard_attr": {
        "API_name": "http.cookiejar.Cookie.set_nonstandard_attr",
        "loc_name": "http.cookiejar.Cookie.set_nonstandard_attr",
        "args": "self;name;value",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 800,
        "namespace": "Cookie",
        "body": "    def set_nonstandard_attr(self, name, value):\n        self._rest[name] = value",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.is_expired": {
        "API_name": "http.cookiejar.Cookie.is_expired",
        "loc_name": "http.cookiejar.Cookie.is_expired",
        "args": "self;now",
        "args_default": 1,
        "filepath": "http.cookiejar",
        "lineno": 803,
        "namespace": "Cookie",
        "body": "    def is_expired(self, now=None):\n        if now is None: now = time.time()\n        if (self.expires is not None) and (self.expires <= now):\n            return True\n        return False",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.__str__": {
        "API_name": "http.cookiejar.Cookie.__str__",
        "loc_name": "http.cookiejar.Cookie.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 809,
        "namespace": "Cookie",
        "body": "    def __str__(self):\n        if self.port is None: p = \"\"\n        else: p = \":\"+self.port\n        limit = self.domain + p + self.path\n        if self.value is not None:\n            namevalue = \"%s=%s\" % (self.name, self.value)\n        else:\n            namevalue = self.name\n        return \"<Cookie %s for %s>\" % (namevalue, limit)",
        "name_type": "stdlib"
    },
    "http.cookiejar.Cookie.__repr__": {
        "API_name": "http.cookiejar.Cookie.__repr__",
        "loc_name": "http.cookiejar.Cookie.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 819,
        "namespace": "Cookie",
        "body": "    def __repr__(self):\n        args = []\n        for name in (\"version\", \"name\", \"value\",\n                     \"port\", \"port_specified\",\n                     \"domain\", \"domain_specified\", \"domain_initial_dot\",\n                     \"path\", \"path_specified\",\n                     \"secure\", \"expires\", \"discard\", \"comment\", \"comment_url\",\n                     ):\n            attr = getattr(self, name)\n            args.append(\"%s=%s\" % (name, repr(attr)))\n        args.append(\"rest=%s\" % repr(self._rest))\n        args.append(\"rfc2109=%s\" % repr(self.rfc2109))\n        return \"%s(%s)\" % (self.__class__.__name__, \", \".join(args))",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookiePolicy.set_ok": {
        "API_name": "http.cookiejar.CookiePolicy.set_ok",
        "loc_name": "http.cookiejar.CookiePolicy.set_ok",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 843,
        "namespace": "CookiePolicy",
        "body": "    def set_ok(self, cookie, request):\n        \"\"\"Return true if (and only if) cookie should be accepted from server.\n\n        Currently, pre-expired cookies never get this far -- the CookieJar\n        class deletes such cookies itself.\n\n        \"\"\"\n        raise NotImplementedError()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookiePolicy.return_ok": {
        "API_name": "http.cookiejar.CookiePolicy.return_ok",
        "loc_name": "http.cookiejar.CookiePolicy.return_ok",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 852,
        "namespace": "CookiePolicy",
        "body": "    def return_ok(self, cookie, request):\n        \"\"\"Return true if (and only if) cookie should be returned to server.\"\"\"\n        raise NotImplementedError()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookiePolicy.domain_return_ok": {
        "API_name": "http.cookiejar.CookiePolicy.domain_return_ok",
        "loc_name": "http.cookiejar.CookiePolicy.domain_return_ok",
        "args": "self;domain;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 856,
        "namespace": "CookiePolicy",
        "body": "    def domain_return_ok(self, domain, request):\n        \"\"\"Return false if cookies should not be returned, given cookie domain.\n        \"\"\"\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookiePolicy.path_return_ok": {
        "API_name": "http.cookiejar.CookiePolicy.path_return_ok",
        "loc_name": "http.cookiejar.CookiePolicy.path_return_ok",
        "args": "self;path;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 861,
        "namespace": "CookiePolicy",
        "body": "    def path_return_ok(self, path, request):\n        \"\"\"Return false if cookies should not be returned, given cookie path.\n        \"\"\"\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookiePolicy": {
        "API_name": "http.cookiejar.CookiePolicy",
        "loc_name": "http.cookiejar.CookiePolicy",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 834,
        "namespace": "CookiePolicy",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy": {
        "API_name": "http.cookiejar.DefaultCookiePolicy",
        "loc_name": "http.cookiejar.DefaultCookiePolicy",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 867,
        "namespace": "DefaultCookiePolicy",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.__init__": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.__init__",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.__init__",
        "args": "self;blocked_domains;allowed_domains;netscape;rfc2965;rfc2109_as_netscape;hide_cookie2;strict_domain;strict_rfc2965_unverifiable;strict_ns_unverifiable;strict_ns_domain;strict_ns_set_initial_dollar;strict_ns_set_path;secure_protocols",
        "args_default": 13,
        "filepath": "http.cookiejar",
        "lineno": 877,
        "namespace": "DefaultCookiePolicy",
        "body": "    def __init__(self,\n                 blocked_domains=None, allowed_domains=None,\n                 netscape=True, rfc2965=False,\n                 rfc2109_as_netscape=None,\n                 hide_cookie2=False,\n                 strict_domain=False,\n                 strict_rfc2965_unverifiable=True,\n                 strict_ns_unverifiable=False,\n                 strict_ns_domain=DomainLiberal,\n                 strict_ns_set_initial_dollar=False,\n                 strict_ns_set_path=False,\n                 secure_protocols=(\"https\", \"wss\")\n                 ):\n        \"\"\"Constructor arguments should be passed as keyword arguments only.\"\"\"\n        self.netscape = netscape\n        self.rfc2965 = rfc2965\n        self.rfc2109_as_netscape = rfc2109_as_netscape\n        self.hide_cookie2 = hide_cookie2\n        self.strict_domain = strict_domain\n        self.strict_rfc2965_unverifiable = strict_rfc2965_unverifiable\n        self.strict_ns_unverifiable = strict_ns_unverifiable\n        self.strict_ns_domain = strict_ns_domain\n        self.strict_ns_set_initial_dollar = strict_ns_set_initial_dollar\n        self.strict_ns_set_path = strict_ns_set_path\n        self.secure_protocols = secure_protocols\n\n        if blocked_domains is not None:\n            self._blocked_domains = tuple(blocked_domains)\n        else:\n            self._blocked_domains = ()\n\n        if allowed_domains is not None:\n            allowed_domains = tuple(allowed_domains)\n        self._allowed_domains = allowed_domains",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.blocked_domains": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.blocked_domains",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.blocked_domains",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 912,
        "namespace": "DefaultCookiePolicy",
        "body": "    def blocked_domains(self):\n        \"\"\"Return the sequence of blocked domains (as a tuple).\"\"\"\n        return self._blocked_domains",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_blocked_domains": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_blocked_domains",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_blocked_domains",
        "args": "self;blocked_domains",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 915,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_blocked_domains(self, blocked_domains):\n        \"\"\"Set the sequence of blocked domains.\"\"\"\n        self._blocked_domains = tuple(blocked_domains)",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.is_blocked": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.is_blocked",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.is_blocked",
        "args": "self;domain",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 919,
        "namespace": "DefaultCookiePolicy",
        "body": "    def is_blocked(self, domain):\n        for blocked_domain in self._blocked_domains:\n            if user_domain_match(domain, blocked_domain):\n                return True\n        return False",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.allowed_domains": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.allowed_domains",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.allowed_domains",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 925,
        "namespace": "DefaultCookiePolicy",
        "body": "    def allowed_domains(self):\n        \"\"\"Return None, or the sequence of allowed domains (as a tuple).\"\"\"\n        return self._allowed_domains",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_allowed_domains": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_allowed_domains",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_allowed_domains",
        "args": "self;allowed_domains",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 928,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_allowed_domains(self, allowed_domains):\n        \"\"\"Set the sequence of allowed domains, or None.\"\"\"\n        if allowed_domains is not None:\n            allowed_domains = tuple(allowed_domains)\n        self._allowed_domains = allowed_domains",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.is_not_allowed": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.is_not_allowed",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.is_not_allowed",
        "args": "self;domain",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 934,
        "namespace": "DefaultCookiePolicy",
        "body": "    def is_not_allowed(self, domain):\n        if self._allowed_domains is None:\n            return False\n        for allowed_domain in self._allowed_domains:\n            if user_domain_match(domain, allowed_domain):\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 942,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok(self, cookie, request):\n        \"\"\"\n        If you override .set_ok(), be sure to call this method.  If it returns\n        false, so should your subclass (assuming your subclass wants to be more\n        strict about which cookies to accept).\n\n        \"\"\"\n        _debug(\" - checking cookie %s=%s\", cookie.name, cookie.value)\n\n        assert cookie.name is not None\n\n        for n in \"version\", \"verifiability\", \"name\", \"path\", \"domain\", \"port\":\n            fn_name = \"set_ok_\"+n\n            fn = getattr(self, fn_name)\n            if not fn(cookie, request):\n                return False\n\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok_version": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok_version",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok_version",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 961,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok_version(self, cookie, request):\n        if cookie.version is None:\n            # Version is always set to 0 by parse_ns_headers if it's a Netscape\n            # cookie, so this must be an invalid RFC 2965 cookie.\n            _debug(\"   Set-Cookie2 without version attribute (%s=%s)\",\n                   cookie.name, cookie.value)\n            return False\n        if cookie.version > 0 and not self.rfc2965:\n            _debug(\"   RFC 2965 cookies are switched off\")\n            return False\n        elif cookie.version == 0 and not self.netscape:\n            _debug(\"   Netscape cookies are switched off\")\n            return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok_verifiability": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok_verifiability",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok_verifiability",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 976,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok_verifiability(self, cookie, request):\n        if request.unverifiable and is_third_party(request):\n            if cookie.version > 0 and self.strict_rfc2965_unverifiable:\n                _debug(\"   third-party RFC 2965 cookie during \"\n                             \"unverifiable transaction\")\n                return False\n            elif cookie.version == 0 and self.strict_ns_unverifiable:\n                _debug(\"   third-party Netscape cookie during \"\n                             \"unverifiable transaction\")\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok_name": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok_name",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok_name",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 988,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok_name(self, cookie, request):\n        # Try and stop servers setting V0 cookies designed to hack other\n        # servers that know both V0 and V1 protocols.\n        if (cookie.version == 0 and self.strict_ns_set_initial_dollar and\n            cookie.name.startswith(\"$\")):\n            _debug(\"   illegal name (starts with '$'): '%s'\", cookie.name)\n            return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok_path": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok_path",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok_path",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 997,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok_path(self, cookie, request):\n        if cookie.path_specified:\n            req_path = request_path(request)\n            if ((cookie.version > 0 or\n                 (cookie.version == 0 and self.strict_ns_set_path)) and\n                not self.path_return_ok(cookie.path, request)):\n                _debug(\"   path attribute %s is not a prefix of request \"\n                       \"path %s\", cookie.path, req_path)\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok_domain": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok_domain",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok_domain",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1008,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok_domain(self, cookie, request):\n        if self.is_blocked(cookie.domain):\n            _debug(\"   domain %s is in user block-list\", cookie.domain)\n            return False\n        if self.is_not_allowed(cookie.domain):\n            _debug(\"   domain %s is not in user allow-list\", cookie.domain)\n            return False\n        if cookie.domain_specified:\n            req_host, erhn = eff_request_host(request)\n            domain = cookie.domain\n            if self.strict_domain and (domain.count(\".\") >= 2):\n                # XXX This should probably be compared with the Konqueror\n                # (kcookiejar.cpp) and Mozilla implementations, but it's a\n                # losing battle.\n                i = domain.rfind(\".\")\n                j = domain.rfind(\".\", 0, i)\n                if j == 0:  # domain like .foo.bar\n                    tld = domain[i+1:]\n                    sld = domain[j+1:i]\n                    if sld.lower() in (\"co\", \"ac\", \"com\", \"edu\", \"org\", \"net\",\n                       \"gov\", \"mil\", \"int\", \"aero\", \"biz\", \"cat\", \"coop\",\n                       \"info\", \"jobs\", \"mobi\", \"museum\", \"name\", \"pro\",\n                       \"travel\", \"eu\") and len(tld) == 2:\n                        # domain like .co.uk\n                        _debug(\"   country-code second level domain %s\", domain)\n                        return False\n            if domain.startswith(\".\"):\n                undotted_domain = domain[1:]\n            else:\n                undotted_domain = domain\n            embedded_dots = (undotted_domain.find(\".\") >= 0)\n            if not embedded_dots and domain != \".local\":\n                _debug(\"   non-local domain %s contains no embedded dot\",\n                       domain)\n                return False\n            if cookie.version == 0:\n                if (not erhn.endswith(domain) and\n                    (not erhn.startswith(\".\") and\n                     not (\".\"+erhn).endswith(domain))):\n                    _debug(\"   effective request-host %s (even with added \"\n                           \"initial dot) does not end with %s\",\n                           erhn, domain)\n                    return False\n            if (cookie.version > 0 or\n                (self.strict_ns_domain & self.DomainRFC2965Match)):\n                if not domain_match(erhn, domain):\n                    _debug(\"   effective request-host %s does not domain-match \"\n                           \"%s\", erhn, domain)\n                    return False\n            if (cookie.version > 0 or\n                (self.strict_ns_domain & self.DomainStrictNoDots)):\n                host_prefix = req_host[:-len(domain)]\n                if (host_prefix.find(\".\") >= 0 and\n                    not IPV4_RE.search(req_host)):\n                    _debug(\"   host prefix %s for domain %s contains a dot\",\n                           host_prefix, domain)\n                    return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.set_ok_port": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.set_ok_port",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.set_ok_port",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1067,
        "namespace": "DefaultCookiePolicy",
        "body": "    def set_ok_port(self, cookie, request):\n        if cookie.port_specified:\n            req_port = request_port(request)\n            if req_port is None:\n                req_port = \"80\"\n            else:\n                req_port = str(req_port)\n            for p in cookie.port.split(\",\"):\n                try:\n                    int(p)\n                except ValueError:\n                    _debug(\"   bad port %s (not numeric)\", p)\n                    return False\n                if p == req_port:\n                    break\n            else:\n                _debug(\"   request port (%s) not found in %s\",\n                       req_port, cookie.port)\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1088,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok(self, cookie, request):\n        \"\"\"\n        If you override .return_ok(), be sure to call this method.  If it\n        returns false, so should your subclass (assuming your subclass wants to\n        be more strict about which cookies to return).\n\n        \"\"\"\n        # Path has already been checked by .path_return_ok(), and domain\n        # blocking done by .domain_return_ok().\n        _debug(\" - checking cookie %s=%s\", cookie.name, cookie.value)\n\n        for n in \"version\", \"verifiability\", \"secure\", \"expires\", \"port\", \"domain\":\n            fn_name = \"return_ok_\"+n\n            fn = getattr(self, fn_name)\n            if not fn(cookie, request):\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok_version": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok_version",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok_version",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1106,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok_version(self, cookie, request):\n        if cookie.version > 0 and not self.rfc2965:\n            _debug(\"   RFC 2965 cookies are switched off\")\n            return False\n        elif cookie.version == 0 and not self.netscape:\n            _debug(\"   Netscape cookies are switched off\")\n            return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok_verifiability": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok_verifiability",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok_verifiability",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1115,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok_verifiability(self, cookie, request):\n        if request.unverifiable and is_third_party(request):\n            if cookie.version > 0 and self.strict_rfc2965_unverifiable:\n                _debug(\"   third-party RFC 2965 cookie during unverifiable \"\n                       \"transaction\")\n                return False\n            elif cookie.version == 0 and self.strict_ns_unverifiable:\n                _debug(\"   third-party Netscape cookie during unverifiable \"\n                       \"transaction\")\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok_secure": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok_secure",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok_secure",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1127,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok_secure(self, cookie, request):\n        if cookie.secure and request.type not in self.secure_protocols:\n            _debug(\"   secure cookie with non-secure request\")\n            return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok_expires": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok_expires",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok_expires",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1133,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok_expires(self, cookie, request):\n        if cookie.is_expired(self._now):\n            _debug(\"   cookie expired\")\n            return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok_port": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok_port",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok_port",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1139,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok_port(self, cookie, request):\n        if cookie.port:\n            req_port = request_port(request)\n            if req_port is None:\n                req_port = \"80\"\n            for p in cookie.port.split(\",\"):\n                if p == req_port:\n                    break\n            else:\n                _debug(\"   request port %s does not match cookie port %s\",\n                       req_port, cookie.port)\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.return_ok_domain": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.return_ok_domain",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.return_ok_domain",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1153,
        "namespace": "DefaultCookiePolicy",
        "body": "    def return_ok_domain(self, cookie, request):\n        req_host, erhn = eff_request_host(request)\n        domain = cookie.domain\n\n        if domain and not domain.startswith(\".\"):\n            dotdomain = \".\" + domain\n        else:\n            dotdomain = domain\n\n        # strict check of non-domain cookies: Mozilla does this, MSIE5 doesn't\n        if (cookie.version == 0 and\n            (self.strict_ns_domain & self.DomainStrictNonDomain) and\n            not cookie.domain_specified and domain != erhn):\n            _debug(\"   cookie with unspecified domain does not string-compare \"\n                   \"equal to request domain\")\n            return False\n\n        if cookie.version > 0 and not domain_match(erhn, domain):\n            _debug(\"   effective request-host name %s does not domain-match \"\n                   \"RFC 2965 cookie domain %s\", erhn, domain)\n            return False\n        if cookie.version == 0 and not (\".\"+erhn).endswith(dotdomain):\n            _debug(\"   request-host %s does not match Netscape cookie domain \"\n                   \"%s\", req_host, domain)\n            return False\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.domain_return_ok": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.domain_return_ok",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.domain_return_ok",
        "args": "self;domain;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1180,
        "namespace": "DefaultCookiePolicy",
        "body": "    def domain_return_ok(self, domain, request):\n        # Liberal check of.  This is here as an optimization to avoid\n        # having to load lots of MSIE cookie files unless necessary.\n        req_host, erhn = eff_request_host(request)\n        if not req_host.startswith(\".\"):\n            req_host = \".\"+req_host\n        if not erhn.startswith(\".\"):\n            erhn = \".\"+erhn\n        if domain and not domain.startswith(\".\"):\n            dotdomain = \".\" + domain\n        else:\n            dotdomain = domain\n        if not (req_host.endswith(dotdomain) or erhn.endswith(dotdomain)):\n            #_debug(\"   request domain %s does not match cookie domain %s\",\n            #       req_host, domain)\n            return False\n\n        if self.is_blocked(domain):\n            _debug(\"   domain %s is in user block-list\", domain)\n            return False\n        if self.is_not_allowed(domain):\n            _debug(\"   domain %s is not in user allow-list\", domain)\n            return False\n\n        return True",
        "name_type": "stdlib"
    },
    "http.cookiejar.DefaultCookiePolicy.path_return_ok": {
        "API_name": "http.cookiejar.DefaultCookiePolicy.path_return_ok",
        "loc_name": "http.cookiejar.DefaultCookiePolicy.path_return_ok",
        "args": "self;path;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1206,
        "namespace": "DefaultCookiePolicy",
        "body": "    def path_return_ok(self, path, request):\n        _debug(\"- checking cookie path=%s\", path)\n        req_path = request_path(request)\n        pathlen = len(path)\n        if req_path == path:\n            return True\n        elif (req_path.startswith(path) and\n              (path.endswith(\"/\") or req_path[pathlen:pathlen+1] == \"/\")):\n            return True\n\n        _debug(\"  %s does not path-match %s\", req_path, path)\n        return False",
        "name_type": "stdlib"
    },
    "http.cookiejar.vals_sorted_by_key": {
        "API_name": "http.cookiejar.vals_sorted_by_key",
        "loc_name": "http.cookiejar.vals_sorted_by_key",
        "args": "adict",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1219,
        "namespace": "*",
        "body": "def vals_sorted_by_key(adict):\n    keys = sorted(adict.keys())\n    return map(adict.get, keys)",
        "name_type": "stdlib"
    },
    "http.cookiejar.deepvalues": {
        "API_name": "http.cookiejar.deepvalues",
        "loc_name": "http.cookiejar.deepvalues",
        "args": "mapping",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1223,
        "namespace": "*",
        "body": "def deepvalues(mapping):\n    \"\"\"Iterates over nested mapping, depth-first, in sorted order by key.\"\"\"\n    values = vals_sorted_by_key(mapping)\n    for obj in values:\n        mapping = False\n        try:\n            obj.items\n        except AttributeError:\n            pass\n        else:\n            mapping = True\n            yield from deepvalues(obj)\n        if not mapping:\n            yield obj",
        "name_type": "stdlib"
    },
    "http.cookiejar.Absent": {
        "API_name": "http.cookiejar.Absent",
        "loc_name": "http.cookiejar.Absent",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 1241,
        "namespace": "Absent",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar": {
        "API_name": "http.cookiejar.CookieJar",
        "loc_name": "http.cookiejar.CookieJar",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 1243,
        "namespace": "CookieJar",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.__init__": {
        "API_name": "http.cookiejar.CookieJar.__init__",
        "loc_name": "http.cookiejar.CookieJar.__init__",
        "args": "self;policy",
        "args_default": 1,
        "filepath": "http.cookiejar",
        "lineno": 1258,
        "namespace": "CookieJar",
        "body": "    def __init__(self, policy=None):\n        if policy is None:\n            policy = DefaultCookiePolicy()\n        self._policy = policy\n\n        self._cookies_lock = _threading.RLock()\n        self._cookies = {}",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.set_policy": {
        "API_name": "http.cookiejar.CookieJar.set_policy",
        "loc_name": "http.cookiejar.CookieJar.set_policy",
        "args": "self;policy",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1266,
        "namespace": "CookieJar",
        "body": "    def set_policy(self, policy):\n        self._policy = policy",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._cookies_for_domain": {
        "API_name": "http.cookiejar.CookieJar._cookies_for_domain",
        "loc_name": "http.cookiejar.CookieJar._cookies_for_domain",
        "args": "self;domain;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1269,
        "namespace": "CookieJar",
        "body": "    def _cookies_for_domain(self, domain, request):\n        cookies = []\n        if not self._policy.domain_return_ok(domain, request):\n            return []\n        _debug(\"Checking %s for cookies to return\", domain)\n        cookies_by_path = self._cookies[domain]\n        for path in cookies_by_path.keys():\n            if not self._policy.path_return_ok(path, request):\n                continue\n            cookies_by_name = cookies_by_path[path]\n            for cookie in cookies_by_name.values():\n                if not self._policy.return_ok(cookie, request):\n                    _debug(\"   not returning cookie\")\n                    continue\n                _debug(\"   it's a match\")\n                cookies.append(cookie)\n        return cookies",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._cookies_for_request": {
        "API_name": "http.cookiejar.CookieJar._cookies_for_request",
        "loc_name": "http.cookiejar.CookieJar._cookies_for_request",
        "args": "self;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1287,
        "namespace": "CookieJar",
        "body": "    def _cookies_for_request(self, request):\n        \"\"\"Return a list of cookies to be returned to server.\"\"\"\n        cookies = []\n        for domain in self._cookies.keys():\n            cookies.extend(self._cookies_for_domain(domain, request))\n        return cookies",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._cookie_attrs": {
        "API_name": "http.cookiejar.CookieJar._cookie_attrs",
        "loc_name": "http.cookiejar.CookieJar._cookie_attrs",
        "args": "self;cookies",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1294,
        "namespace": "CookieJar",
        "body": "    def _cookie_attrs(self, cookies):\n        \"\"\"Return a list of cookie-attributes to be returned to server.\n\n        like ['foo=\"bar\"; $Path=\"/\"', ...]\n\n        The $Version attribute is also added when appropriate (currently only\n        once per request).\n\n        \"\"\"\n        # add cookies in order of most specific (ie. longest) path first\n        cookies.sort(key=lambda a: len(a.path), reverse=True)\n\n        version_set = False\n\n        attrs = []\n        for cookie in cookies:\n            # set version of Cookie header\n            # XXX\n            # What should it be if multiple matching Set-Cookie headers have\n            #  different versions themselves?\n            # Answer: there is no answer; was supposed to be settled by\n            #  RFC 2965 errata, but that may never appear...\n            version = cookie.version\n            if not version_set:\n                version_set = True\n                if version > 0:\n                    attrs.append(\"$Version=%s\" % version)\n\n            # quote cookie value if necessary\n            # (not for Netscape protocol, which already has any quotes\n            #  intact, due to the poorly-specified Netscape Cookie: syntax)\n            if ((cookie.value is not None) and\n                self.non_word_re.search(cookie.value) and version > 0):\n                value = self.quote_re.sub(r\"\\\\\\1\", cookie.value)\n            else:\n                value = cookie.value\n\n            # add cookie-attributes to be returned in Cookie header\n            if cookie.value is None:\n                attrs.append(cookie.name)\n            else:\n                attrs.append(\"%s=%s\" % (cookie.name, value))\n            if version > 0:\n                if cookie.path_specified:\n                    attrs.append('$Path=\"%s\"' % cookie.path)\n                if cookie.domain.startswith(\".\"):\n                    domain = cookie.domain\n                    if (not cookie.domain_initial_dot and\n                        domain.startswith(\".\")):\n                        domain = domain[1:]\n                    attrs.append('$Domain=\"%s\"' % domain)\n                if cookie.port is not None:\n                    p = \"$Port\"\n                    if cookie.port_specified:\n                        p = p + ('=\"%s\"' % cookie.port)\n                    attrs.append(p)\n\n        return attrs",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.add_cookie_header": {
        "API_name": "http.cookiejar.CookieJar.add_cookie_header",
        "loc_name": "http.cookiejar.CookieJar.add_cookie_header",
        "args": "self;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1353,
        "namespace": "CookieJar",
        "body": "    def add_cookie_header(self, request):\n        \"\"\"Add correct Cookie: header to request (urllib.request.Request object).\n\n        The Cookie2 header is also added unless policy.hide_cookie2 is true.\n\n        \"\"\"\n        _debug(\"add_cookie_header\")\n        self._cookies_lock.acquire()\n        try:\n\n            self._policy._now = self._now = int(time.time())\n\n            cookies = self._cookies_for_request(request)\n\n            attrs = self._cookie_attrs(cookies)\n            if attrs:\n                if not request.has_header(\"Cookie\"):\n                    request.add_unredirected_header(\n                        \"Cookie\", \"; \".join(attrs))\n\n            # if necessary, advertise that we know RFC 2965\n            if (self._policy.rfc2965 and not self._policy.hide_cookie2 and\n                not request.has_header(\"Cookie2\")):\n                for cookie in cookies:\n                    if cookie.version != 1:\n                        request.add_unredirected_header(\"Cookie2\", '$Version=\"1\"')\n                        break\n\n        finally:\n            self._cookies_lock.release()\n\n        self.clear_expired_cookies()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._normalized_cookie_tuples": {
        "API_name": "http.cookiejar.CookieJar._normalized_cookie_tuples",
        "loc_name": "http.cookiejar.CookieJar._normalized_cookie_tuples",
        "args": "self;attrs_set",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1386,
        "namespace": "CookieJar",
        "body": "    def _normalized_cookie_tuples(self, attrs_set):\n        \"\"\"Return list of tuples containing normalised cookie information.\n\n        attrs_set is the list of lists of key,value pairs extracted from\n        the Set-Cookie or Set-Cookie2 headers.\n\n        Tuples are name, value, standard, rest, where name and value are the\n        cookie name and value, standard is a dictionary containing the standard\n        cookie-attributes (discard, secure, version, expires or max-age,\n        domain, path and port) and rest is a dictionary containing the rest of\n        the cookie-attributes.\n\n        \"\"\"\n        cookie_tuples = []\n\n        boolean_attrs = \"discard\", \"secure\"\n        value_attrs = (\"version\",\n                       \"expires\", \"max-age\",\n                       \"domain\", \"path\", \"port\",\n                       \"comment\", \"commenturl\")\n\n        for cookie_attrs in attrs_set:\n            name, value = cookie_attrs[0]\n\n            # Build dictionary of standard cookie-attributes (standard) and\n            # dictionary of other cookie-attributes (rest).\n\n            # Note: expiry time is normalised to seconds since epoch.  V0\n            # cookies should have the Expires cookie-attribute, and V1 cookies\n            # should have Max-Age, but since V1 includes RFC 2109 cookies (and\n            # since V0 cookies may be a mish-mash of Netscape and RFC 2109), we\n            # accept either (but prefer Max-Age).\n            max_age_set = False\n\n            bad_cookie = False\n\n            standard = {}\n            rest = {}\n            for k, v in cookie_attrs[1:]:\n                lc = k.lower()\n                # don't lose case distinction for unknown fields\n                if lc in value_attrs or lc in boolean_attrs:\n                    k = lc\n                if k in boolean_attrs and v is None:\n                    # boolean cookie-attribute is present, but has no value\n                    # (like \"discard\", rather than \"port=80\")\n                    v = True\n                if k in standard:\n                    # only first value is significant\n                    continue\n                if k == \"domain\":\n                    if v is None:\n                        _debug(\"   missing value for domain attribute\")\n                        bad_cookie = True\n                        break\n                    # RFC 2965 section 3.3.3\n                    v = v.lower()\n                if k == \"expires\":\n                    if max_age_set:\n                        # Prefer max-age to expires (like Mozilla)\n                        continue\n                    if v is None:\n                        _debug(\"   missing or invalid value for expires \"\n                              \"attribute: treating as session cookie\")\n                        continue\n                if k == \"max-age\":\n                    max_age_set = True\n                    try:\n                        v = int(v)\n                    except ValueError:\n                        _debug(\"   missing or invalid (non-numeric) value for \"\n                              \"max-age attribute\")\n                        bad_cookie = True\n                        break\n                    # convert RFC 2965 Max-Age to seconds since epoch\n                    # XXX Strictly you're supposed to follow RFC 2616\n                    #   age-calculation rules.  Remember that zero Max-Age\n                    #   is a request to discard (old and new) cookie, though.\n                    k = \"expires\"\n                    v = self._now + v\n                if (k in value_attrs) or (k in boolean_attrs):\n                    if (v is None and\n                        k not in (\"port\", \"comment\", \"commenturl\")):\n                        _debug(\"   missing value for %s attribute\" % k)\n                        bad_cookie = True\n                        break\n                    standard[k] = v\n                else:\n                    rest[k] = v\n\n            if bad_cookie:\n                continue\n\n            cookie_tuples.append((name, value, standard, rest))\n\n        return cookie_tuples",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._cookie_from_cookie_tuple": {
        "API_name": "http.cookiejar.CookieJar._cookie_from_cookie_tuple",
        "loc_name": "http.cookiejar.CookieJar._cookie_from_cookie_tuple",
        "args": "self;tup;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1483,
        "namespace": "CookieJar",
        "body": "    def _cookie_from_cookie_tuple(self, tup, request):\n        # standard is dict of standard cookie-attributes, rest is dict of the\n        # rest of them\n        name, value, standard, rest = tup\n\n        domain = standard.get(\"domain\", Absent)\n        path = standard.get(\"path\", Absent)\n        port = standard.get(\"port\", Absent)\n        expires = standard.get(\"expires\", Absent)\n\n        # set the easy defaults\n        version = standard.get(\"version\", None)\n        if version is not None:\n            try:\n                version = int(version)\n            except ValueError:\n                return None  # invalid version, ignore cookie\n        secure = standard.get(\"secure\", False)\n        # (discard is also set if expires is Absent)\n        discard = standard.get(\"discard\", False)\n        comment = standard.get(\"comment\", None)\n        comment_url = standard.get(\"commenturl\", None)\n\n        # set default path\n        if path is not Absent and path != \"\":\n            path_specified = True\n            path = escape_path(path)\n        else:\n            path_specified = False\n            path = request_path(request)\n            i = path.rfind(\"/\")\n            if i != -1:\n                if version == 0:\n                    # Netscape spec parts company from reality here\n                    path = path[:i]\n                else:\n                    path = path[:i+1]\n            if len(path) == 0: path = \"/\"\n\n        # set default domain\n        domain_specified = domain is not Absent\n        # but first we have to remember whether it starts with a dot\n        domain_initial_dot = False\n        if domain_specified:\n            domain_initial_dot = bool(domain.startswith(\".\"))\n        if domain is Absent:\n            req_host, erhn = eff_request_host(request)\n            domain = erhn\n        elif not domain.startswith(\".\"):\n            domain = \".\"+domain\n\n        # set default port\n        port_specified = False\n        if port is not Absent:\n            if port is None:\n                # Port attr present, but has no value: default to request port.\n                # Cookie should then only be sent back on that port.\n                port = request_port(request)\n            else:\n                port_specified = True\n                port = re.sub(r\"\\s+\", \"\", port)\n        else:\n            # No port attr present.  Cookie can be sent back on any port.\n            port = None\n\n        # set default expires and discard\n        if expires is Absent:\n            expires = None\n            discard = True\n        elif expires <= self._now:\n            # Expiry date in past is request to delete cookie.  This can't be\n            # in DefaultCookiePolicy, because can't delete cookies there.\n            try:\n                self.clear(domain, path, name)\n            except KeyError:\n                pass\n            _debug(\"Expiring cookie, domain='%s', path='%s', name='%s'\",\n                   domain, path, name)\n            return None\n\n        return Cookie(version,\n                      name, value,\n                      port, port_specified,\n                      domain, domain_specified, domain_initial_dot,\n                      path, path_specified,\n                      secure,\n                      expires,\n                      discard,\n                      comment,\n                      comment_url,\n                      rest)",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._cookies_from_attrs_set": {
        "API_name": "http.cookiejar.CookieJar._cookies_from_attrs_set",
        "loc_name": "http.cookiejar.CookieJar._cookies_from_attrs_set",
        "args": "self;attrs_set;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1575,
        "namespace": "CookieJar",
        "body": "    def _cookies_from_attrs_set(self, attrs_set, request):\n        cookie_tuples = self._normalized_cookie_tuples(attrs_set)\n\n        cookies = []\n        for tup in cookie_tuples:\n            cookie = self._cookie_from_cookie_tuple(tup, request)\n            if cookie: cookies.append(cookie)\n        return cookies",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar._process_rfc2109_cookies": {
        "API_name": "http.cookiejar.CookieJar._process_rfc2109_cookies",
        "loc_name": "http.cookiejar.CookieJar._process_rfc2109_cookies",
        "args": "self;cookies",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1584,
        "namespace": "CookieJar",
        "body": "    def _process_rfc2109_cookies(self, cookies):\n        rfc2109_as_ns = getattr(self._policy, 'rfc2109_as_netscape', None)\n        if rfc2109_as_ns is None:\n            rfc2109_as_ns = not self._policy.rfc2965\n        for cookie in cookies:\n            if cookie.version == 1:\n                cookie.rfc2109 = True\n                if rfc2109_as_ns:\n                    # treat 2109 cookies as Netscape cookies rather than\n                    # as RFC2965 cookies\n                    cookie.version = 0",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.make_cookies": {
        "API_name": "http.cookiejar.CookieJar.make_cookies",
        "loc_name": "http.cookiejar.CookieJar.make_cookies",
        "args": "self;response;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1596,
        "namespace": "CookieJar",
        "body": "    def make_cookies(self, response, request):\n        \"\"\"Return sequence of Cookie objects extracted from response object.\"\"\"\n        # get cookie-attributes for RFC 2965 and Netscape protocols\n        headers = response.info()\n        rfc2965_hdrs = headers.get_all(\"Set-Cookie2\", [])\n        ns_hdrs = headers.get_all(\"Set-Cookie\", [])\n        self._policy._now = self._now = int(time.time())\n\n        rfc2965 = self._policy.rfc2965\n        netscape = self._policy.netscape\n\n        if ((not rfc2965_hdrs and not ns_hdrs) or\n            (not ns_hdrs and not rfc2965) or\n            (not rfc2965_hdrs and not netscape) or\n            (not netscape and not rfc2965)):\n            return []  # no relevant cookie headers: quick exit\n\n        try:\n            cookies = self._cookies_from_attrs_set(\n                split_header_words(rfc2965_hdrs), request)\n        except Exception:\n            _warn_unhandled_exception()\n            cookies = []\n\n        if ns_hdrs and netscape:\n            try:\n                # RFC 2109 and Netscape cookies\n                ns_cookies = self._cookies_from_attrs_set(\n                    parse_ns_headers(ns_hdrs), request)\n            except Exception:\n                _warn_unhandled_exception()\n                ns_cookies = []\n            self._process_rfc2109_cookies(ns_cookies)\n\n            # Look for Netscape cookies (from Set-Cookie headers) that match\n            # corresponding RFC 2965 cookies (from Set-Cookie2 headers).\n            # For each match, keep the RFC 2965 cookie and ignore the Netscape\n            # cookie (RFC 2965 section 9.1).  Actually, RFC 2109 cookies are\n            # bundled in with the Netscape cookies for this purpose, which is\n            # reasonable behaviour.\n            if rfc2965:\n                lookup = {}\n                for cookie in cookies:\n                    lookup[(cookie.domain, cookie.path, cookie.name)] = None\n\n                def no_matching_rfc2965(ns_cookie, lookup=lookup):\n                    key = ns_cookie.domain, ns_cookie.path, ns_cookie.name\n                    return key not in lookup\n                ns_cookies = filter(no_matching_rfc2965, ns_cookies)\n\n            if ns_cookies:\n                cookies.extend(ns_cookies)\n\n        return cookies",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.set_cookie_if_ok": {
        "API_name": "http.cookiejar.CookieJar.set_cookie_if_ok",
        "loc_name": "http.cookiejar.CookieJar.set_cookie_if_ok",
        "args": "self;cookie;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1651,
        "namespace": "CookieJar",
        "body": "    def set_cookie_if_ok(self, cookie, request):\n        \"\"\"Set a cookie if policy says it's OK to do so.\"\"\"\n        self._cookies_lock.acquire()\n        try:\n            self._policy._now = self._now = int(time.time())\n\n            if self._policy.set_ok(cookie, request):\n                self.set_cookie(cookie)\n\n\n        finally:\n            self._cookies_lock.release()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.set_cookie": {
        "API_name": "http.cookiejar.CookieJar.set_cookie",
        "loc_name": "http.cookiejar.CookieJar.set_cookie",
        "args": "self;cookie",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1664,
        "namespace": "CookieJar",
        "body": "    def set_cookie(self, cookie):\n        \"\"\"Set a cookie, without checking whether or not it should be set.\"\"\"\n        c = self._cookies\n        self._cookies_lock.acquire()\n        try:\n            if cookie.domain not in c: c[cookie.domain] = {}\n            c2 = c[cookie.domain]\n            if cookie.path not in c2: c2[cookie.path] = {}\n            c3 = c2[cookie.path]\n            c3[cookie.name] = cookie\n        finally:\n            self._cookies_lock.release()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.extract_cookies": {
        "API_name": "http.cookiejar.CookieJar.extract_cookies",
        "loc_name": "http.cookiejar.CookieJar.extract_cookies",
        "args": "self;response;request",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1677,
        "namespace": "CookieJar",
        "body": "    def extract_cookies(self, response, request):\n        \"\"\"Extract cookies from response, where allowable given the request.\"\"\"\n        _debug(\"extract_cookies: %s\", response.info())\n        self._cookies_lock.acquire()\n        try:\n            for cookie in self.make_cookies(response, request):\n                if self._policy.set_ok(cookie, request):\n                    _debug(\" setting cookie: %s\", cookie)\n                    self.set_cookie(cookie)\n        finally:\n            self._cookies_lock.release()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.clear": {
        "API_name": "http.cookiejar.CookieJar.clear",
        "loc_name": "http.cookiejar.CookieJar.clear",
        "args": "self;domain;path;name",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 1689,
        "namespace": "CookieJar",
        "body": "    def clear(self, domain=None, path=None, name=None):\n        \"\"\"Clear some cookies.\n\n        Invoking this method without arguments will clear all cookies.  If\n        given a single argument, only cookies belonging to that domain will be\n        removed.  If given two arguments, cookies belonging to the specified\n        path within that domain are removed.  If given three arguments, then\n        the cookie with the specified name, path and domain is removed.\n\n        Raises KeyError if no matching cookie exists.\n\n        \"\"\"\n        if name is not None:\n            if (domain is None) or (path is None):\n                raise ValueError(\n                    \"domain and path must be given to remove a cookie by name\")\n            del self._cookies[domain][path][name]\n        elif path is not None:\n            if domain is None:\n                raise ValueError(\n                    \"domain must be given to remove cookies by path\")\n            del self._cookies[domain][path]\n        elif domain is not None:\n            del self._cookies[domain]\n        else:\n            self._cookies = {}",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.clear_session_cookies": {
        "API_name": "http.cookiejar.CookieJar.clear_session_cookies",
        "loc_name": "http.cookiejar.CookieJar.clear_session_cookies",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1716,
        "namespace": "CookieJar",
        "body": "    def clear_session_cookies(self):\n        \"\"\"Discard all session cookies.\n\n        Note that the .save() method won't save session cookies anyway, unless\n        you ask otherwise by passing a true ignore_discard argument.\n\n        \"\"\"\n        self._cookies_lock.acquire()\n        try:\n            for cookie in self:\n                if cookie.discard:\n                    self.clear(cookie.domain, cookie.path, cookie.name)\n        finally:\n            self._cookies_lock.release()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.clear_expired_cookies": {
        "API_name": "http.cookiejar.CookieJar.clear_expired_cookies",
        "loc_name": "http.cookiejar.CookieJar.clear_expired_cookies",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1731,
        "namespace": "CookieJar",
        "body": "    def clear_expired_cookies(self):\n        \"\"\"Discard all expired cookies.\n\n        You probably don't need to call this method: expired cookies are never\n        sent back to the server (provided you're using DefaultCookiePolicy),\n        this method is called by CookieJar itself every so often, and the\n        .save() method won't save expired cookies anyway (unless you ask\n        otherwise by passing a true ignore_expires argument).\n\n        \"\"\"\n        self._cookies_lock.acquire()\n        try:\n            now = time.time()\n            for cookie in self:\n                if cookie.is_expired(now):\n                    self.clear(cookie.domain, cookie.path, cookie.name)\n        finally:\n            self._cookies_lock.release()",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.__iter__": {
        "API_name": "http.cookiejar.CookieJar.__iter__",
        "loc_name": "http.cookiejar.CookieJar.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1750,
        "namespace": "CookieJar",
        "body": "    def __iter__(self):\n        return deepvalues(self._cookies)",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.__len__": {
        "API_name": "http.cookiejar.CookieJar.__len__",
        "loc_name": "http.cookiejar.CookieJar.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1753,
        "namespace": "CookieJar",
        "body": "    def __len__(self):\n        \"\"\"Return number of contained cookies.\"\"\"\n        i = 0\n        for cookie in self: i = i + 1\n        return i",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.__repr__": {
        "API_name": "http.cookiejar.CookieJar.__repr__",
        "loc_name": "http.cookiejar.CookieJar.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1759,
        "namespace": "CookieJar",
        "body": "    def __repr__(self):\n        r = []\n        for cookie in self: r.append(repr(cookie))\n        return \"<%s[%s]>\" % (self.__class__.__name__, \", \".join(r))",
        "name_type": "stdlib"
    },
    "http.cookiejar.CookieJar.__str__": {
        "API_name": "http.cookiejar.CookieJar.__str__",
        "loc_name": "http.cookiejar.CookieJar.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1764,
        "namespace": "CookieJar",
        "body": "    def __str__(self):\n        r = []\n        for cookie in self: r.append(str(cookie))\n        return \"<%s[%s]>\" % (self.__class__.__name__, \", \".join(r))",
        "name_type": "stdlib"
    },
    "http.cookiejar.LoadError": {
        "API_name": "http.cookiejar.LoadError",
        "loc_name": "http.cookiejar.LoadError",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 1771,
        "namespace": "LoadError",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.FileCookieJar": {
        "API_name": "http.cookiejar.FileCookieJar",
        "loc_name": "http.cookiejar.FileCookieJar",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 1773,
        "namespace": "FileCookieJar",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.FileCookieJar.__init__": {
        "API_name": "http.cookiejar.FileCookieJar.__init__",
        "loc_name": "http.cookiejar.FileCookieJar.__init__",
        "args": "self;filename;delayload;policy",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 1776,
        "namespace": "FileCookieJar",
        "body": "    def __init__(self, filename=None, delayload=False, policy=None):\n        \"\"\"\n        Cookies are NOT loaded from the named file until either the .load() or\n        .revert() method is called.\n\n        \"\"\"\n        CookieJar.__init__(self, policy)\n        if filename is not None:\n            filename = os.fspath(filename)\n        self.filename = filename\n        self.delayload = bool(delayload)",
        "name_type": "stdlib"
    },
    "http.cookiejar.FileCookieJar.save": {
        "API_name": "http.cookiejar.FileCookieJar.save",
        "loc_name": "http.cookiejar.FileCookieJar.save",
        "args": "self;filename;ignore_discard;ignore_expires",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 1788,
        "namespace": "FileCookieJar",
        "body": "    def save(self, filename=None, ignore_discard=False, ignore_expires=False):\n        \"\"\"Save cookies to a file.\"\"\"\n        raise NotImplementedError()",
        "name_type": "stdlib"
    },
    "http.cookiejar.FileCookieJar.load": {
        "API_name": "http.cookiejar.FileCookieJar.load",
        "loc_name": "http.cookiejar.FileCookieJar.load",
        "args": "self;filename;ignore_discard;ignore_expires",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 1792,
        "namespace": "FileCookieJar",
        "body": "    def load(self, filename=None, ignore_discard=False, ignore_expires=False):\n        \"\"\"Load cookies from a file.\"\"\"\n        if filename is None:\n            if self.filename is not None: filename = self.filename\n            else: raise ValueError(MISSING_FILENAME_TEXT)\n\n        with open(filename) as f:\n            self._really_load(f, filename, ignore_discard, ignore_expires)",
        "name_type": "stdlib"
    },
    "http.cookiejar.FileCookieJar.revert": {
        "API_name": "http.cookiejar.FileCookieJar.revert",
        "loc_name": "http.cookiejar.FileCookieJar.revert",
        "args": "self;filename;ignore_discard;ignore_expires",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 1801,
        "namespace": "FileCookieJar",
        "body": "    def revert(self, filename=None,\n               ignore_discard=False, ignore_expires=False):\n        \"\"\"Clear all cookies and reload cookies from a saved file.\n\n        Raises LoadError (or OSError) if reversion is not successful; the\n        object's state will not be altered if this happens.\n\n        \"\"\"\n        if filename is None:\n            if self.filename is not None: filename = self.filename\n            else: raise ValueError(MISSING_FILENAME_TEXT)\n\n        self._cookies_lock.acquire()\n        try:\n\n            old_state = copy.deepcopy(self._cookies)\n            self._cookies = {}\n            try:\n                self.load(filename, ignore_discard, ignore_expires)\n            except OSError:\n                self._cookies = old_state\n                raise\n\n        finally:\n            self._cookies_lock.release()",
        "name_type": "stdlib"
    },
    "http.cookiejar.lwp_cookie_str": {
        "API_name": "http.cookiejar.lwp_cookie_str",
        "loc_name": "http.cookiejar.lwp_cookie_str",
        "args": "cookie",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1828,
        "namespace": "*",
        "body": "def lwp_cookie_str(cookie):\n    \"\"\"Return string representation of Cookie in the LWP cookie file format.\n\n    Actually, the format is extended a bit -- see module docstring.\n\n    \"\"\"\n    h = [(cookie.name, cookie.value),\n         (\"path\", cookie.path),\n         (\"domain\", cookie.domain)]\n    if cookie.port is not None: h.append((\"port\", cookie.port))\n    if cookie.path_specified: h.append((\"path_spec\", None))\n    if cookie.port_specified: h.append((\"port_spec\", None))\n    if cookie.domain_initial_dot: h.append((\"domain_dot\", None))\n    if cookie.secure: h.append((\"secure\", None))\n    if cookie.expires: h.append((\"expires\",\n                               time2isoz(float(cookie.expires))))\n    if cookie.discard: h.append((\"discard\", None))\n    if cookie.comment: h.append((\"comment\", cookie.comment))\n    if cookie.comment_url: h.append((\"commenturl\", cookie.comment_url))\n\n    keys = sorted(cookie._rest.keys())\n    for k in keys:\n        h.append((k, str(cookie._rest[k])))\n\n    h.append((\"version\", str(cookie.version)))\n\n    return join_header_words([h])",
        "name_type": "stdlib"
    },
    "http.cookiejar.LWPCookieJar.as_lwp_str": {
        "API_name": "http.cookiejar.LWPCookieJar.as_lwp_str",
        "loc_name": "http.cookiejar.LWPCookieJar.as_lwp_str",
        "args": "self;ignore_discard;ignore_expires",
        "args_default": 2,
        "filepath": "http.cookiejar",
        "lineno": 1869,
        "namespace": "LWPCookieJar",
        "body": "    def as_lwp_str(self, ignore_discard=True, ignore_expires=True):\n        \"\"\"Return cookies as a string of \"\\\\n\"-separated \"Set-Cookie3\" headers.\n\n        ignore_discard and ignore_expires: see docstring for FileCookieJar.save\n\n        \"\"\"\n        now = time.time()\n        r = []\n        for cookie in self:\n            if not ignore_discard and cookie.discard:\n                continue\n            if not ignore_expires and cookie.is_expired(now):\n                continue\n            r.append(\"Set-Cookie3: %s\" % lwp_cookie_str(cookie))\n        return \"\\n\".join(r+[\"\"])",
        "name_type": "stdlib"
    },
    "http.cookiejar.LWPCookieJar.save": {
        "API_name": "http.cookiejar.LWPCookieJar.save",
        "loc_name": "http.cookiejar.LWPCookieJar.save",
        "args": "self;filename;ignore_discard;ignore_expires",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 1885,
        "namespace": "LWPCookieJar",
        "body": "    def save(self, filename=None, ignore_discard=False, ignore_expires=False):\n        if filename is None:\n            if self.filename is not None: filename = self.filename\n            else: raise ValueError(MISSING_FILENAME_TEXT)\n\n        with open(filename, \"w\") as f:\n            # There really isn't an LWP Cookies 2.0 format, but this indicates\n            # that there is extra information in here (domain_dot and\n            # port_spec) while still being compatible with libwww-perl, I hope.\n            f.write(\"#LWP-Cookies-2.0\\n\")\n            f.write(self.as_lwp_str(ignore_discard, ignore_expires))",
        "name_type": "stdlib"
    },
    "http.cookiejar.LWPCookieJar._really_load": {
        "API_name": "http.cookiejar.LWPCookieJar._really_load",
        "loc_name": "http.cookiejar.LWPCookieJar._really_load",
        "args": "self;f;filename;ignore_discard;ignore_expires",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 1897,
        "namespace": "LWPCookieJar",
        "body": "    def _really_load(self, f, filename, ignore_discard, ignore_expires):\n        magic = f.readline()\n        if not self.magic_re.search(magic):\n            msg = (\"%r does not look like a Set-Cookie3 (LWP) format \"\n                   \"file\" % filename)\n            raise LoadError(msg)\n\n        now = time.time()\n\n        header = \"Set-Cookie3:\"\n        boolean_attrs = (\"port_spec\", \"path_spec\", \"domain_dot\",\n                         \"secure\", \"discard\")\n        value_attrs = (\"version\",\n                       \"port\", \"path\", \"domain\",\n                       \"expires\",\n                       \"comment\", \"commenturl\")\n\n        try:\n            while 1:\n                line = f.readline()\n                if line == \"\": break\n                if not line.startswith(header):\n                    continue\n                line = line[len(header):].strip()\n\n                for data in split_header_words([line]):\n                    name, value = data[0]\n                    standard = {}\n                    rest = {}\n                    for k in boolean_attrs:\n                        standard[k] = False\n                    for k, v in data[1:]:\n                        if k is not None:\n                            lc = k.lower()\n                        else:\n                            lc = None\n                        # don't lose case distinction for unknown fields\n                        if (lc in value_attrs) or (lc in boolean_attrs):\n                            k = lc\n                        if k in boolean_attrs:\n                            if v is None: v = True\n                            standard[k] = v\n                        elif k in value_attrs:\n                            standard[k] = v\n                        else:\n                            rest[k] = v\n\n                    h = standard.get\n                    expires = h(\"expires\")\n                    discard = h(\"discard\")\n                    if expires is not None:\n                        expires = iso2time(expires)\n                    if expires is None:\n                        discard = True\n                    domain = h(\"domain\")\n                    domain_specified = domain.startswith(\".\")\n                    c = Cookie(h(\"version\"), name, value,\n                               h(\"port\"), h(\"port_spec\"),\n                               domain, domain_specified, h(\"domain_dot\"),\n                               h(\"path\"), h(\"path_spec\"),\n                               h(\"secure\"),\n                               expires,\n                               discard,\n                               h(\"comment\"),\n                               h(\"commenturl\"),\n                               rest)\n                    if not ignore_discard and c.discard:\n                        continue\n                    if not ignore_expires and c.is_expired(now):\n                        continue\n                    self.set_cookie(c)\n        except OSError:\n            raise\n        except Exception:\n            _warn_unhandled_exception()\n            raise LoadError(\"invalid Set-Cookie3 format file %r: %r\" %\n                            (filename, line))",
        "name_type": "stdlib"
    },
    "http.cookiejar.LWPCookieJar": {
        "API_name": "http.cookiejar.LWPCookieJar",
        "loc_name": "http.cookiejar.LWPCookieJar",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 1856,
        "namespace": "LWPCookieJar",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookiejar.MozillaCookieJar._really_load": {
        "API_name": "http.cookiejar.MozillaCookieJar._really_load",
        "loc_name": "http.cookiejar.MozillaCookieJar._really_load",
        "args": "self;f;filename;ignore_discard;ignore_expires",
        "args_default": 0,
        "filepath": "http.cookiejar",
        "lineno": 2015,
        "namespace": "MozillaCookieJar",
        "body": "    def _really_load(self, f, filename, ignore_discard, ignore_expires):\n        now = time.time()\n\n        magic = f.readline()\n        if not self.magic_re.search(magic):\n            raise LoadError(\n                \"%r does not look like a Netscape format cookies file\" %\n                filename)\n\n        try:\n            while 1:\n                line = f.readline()\n                if line == \"\": break\n\n                # last field may be absent, so keep any trailing tab\n                if line.endswith(\"\\n\"): line = line[:-1]\n\n                # skip comments and blank lines XXX what is $ for?\n                if (line.strip().startswith((\"#\", \"$\")) or\n                    line.strip() == \"\"):\n                    continue\n\n                domain, domain_specified, path, secure, expires, name, value = \\\n                        line.split(\"\\t\")\n                secure = (secure == \"TRUE\")\n                domain_specified = (domain_specified == \"TRUE\")\n                if name == \"\":\n                    # cookies.txt regards 'Set-Cookie: foo' as a cookie\n                    # with no name, whereas http.cookiejar regards it as a\n                    # cookie with no value.\n                    name = value\n                    value = None\n\n                initial_dot = domain.startswith(\".\")\n                assert domain_specified == initial_dot\n\n                discard = False\n                if expires == \"\":\n                    expires = None\n                    discard = True\n\n                # assume path_specified is false\n                c = Cookie(0, name, value,\n                           None, False,\n                           domain, domain_specified, initial_dot,\n                           path, False,\n                           secure,\n                           expires,\n                           discard,\n                           None,\n                           None,\n                           {})\n                if not ignore_discard and c.discard:\n                    continue\n                if not ignore_expires and c.is_expired(now):\n                    continue\n                self.set_cookie(c)\n\n        except OSError:\n            raise\n        except Exception:\n            _warn_unhandled_exception()\n            raise LoadError(\"invalid Netscape format cookies file %r: %r\" %\n                            (filename, line))",
        "name_type": "stdlib"
    },
    "http.cookiejar.MozillaCookieJar.save": {
        "API_name": "http.cookiejar.MozillaCookieJar.save",
        "loc_name": "http.cookiejar.MozillaCookieJar.save",
        "args": "self;filename;ignore_discard;ignore_expires",
        "args_default": 3,
        "filepath": "http.cookiejar",
        "lineno": 2080,
        "namespace": "MozillaCookieJar",
        "body": "    def save(self, filename=None, ignore_discard=False, ignore_expires=False):\n        if filename is None:\n            if self.filename is not None: filename = self.filename\n            else: raise ValueError(MISSING_FILENAME_TEXT)\n\n        with open(filename, \"w\") as f:\n            f.write(self.header)\n            now = time.time()\n            for cookie in self:\n                if not ignore_discard and cookie.discard:\n                    continue\n                if not ignore_expires and cookie.is_expired(now):\n                    continue\n                if cookie.secure: secure = \"TRUE\"\n                else: secure = \"FALSE\"\n                if cookie.domain.startswith(\".\"): initial_dot = \"TRUE\"\n                else: initial_dot = \"FALSE\"\n                if cookie.expires is not None:\n                    expires = str(cookie.expires)\n                else:\n                    expires = \"\"\n                if cookie.value is None:\n                    # cookies.txt regards 'Set-Cookie: foo' as a cookie\n                    # with no name, whereas http.cookiejar regards it as a\n                    # cookie with no value.\n                    name = \"\"\n                    value = cookie.name\n                else:\n                    name = cookie.name\n                    value = cookie.value\n                f.write(\n                    \"\\t\".join([cookie.domain, initial_dot, cookie.path,\n                               secure, expires, name, value])+\n                    \"\\n\")",
        "name_type": "stdlib"
    },
    "http.cookiejar.MozillaCookieJar": {
        "API_name": "http.cookiejar.MozillaCookieJar",
        "loc_name": "http.cookiejar.MozillaCookieJar",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookiejar",
        "lineno": 1976,
        "namespace": "MozillaCookieJar",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookies": {
        "API_name": "http.cookies",
        "loc_name": "http.cookies",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookies",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"\nHere's a sample session to show how to use this module.\nAt the moment, this is the only documentation.\n\nThe Basics\n----------\n\nImporting is easy...\n\n   >>> from http import cookies\n\nMost of the time you start by creating a cookie.\n\n   >>> C = cookies.SimpleCookie()\n\nOnce you've created your Cookie, you can add values just as if it were\na dictionary.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"fig\"] = \"newton\"\n   >>> C[\"sugar\"] = \"wafer\"\n   >>> C.output()\n   'Set-Cookie: fig=newton\\r\\nSet-Cookie: sugar=wafer'\n\nNotice that the printable representation of a Cookie is the\nappropriate format for a Set-Cookie: header.  This is the\ndefault behavior.  You can change the header and printed\nattributes by using the .output() function\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"rocky\"] = \"road\"\n   >>> C[\"rocky\"][\"path\"] = \"/cookie\"\n   >>> print(C.output(header=\"Cookie:\"))\n   Cookie: rocky=road; Path=/cookie\n   >>> print(C.output(attrs=[], header=\"Cookie:\"))\n   Cookie: rocky=road\n\nThe load() method of a Cookie extracts cookies from a string.  In a\nCGI script, you would use this method to extract the cookies from the\nHTTP_COOKIE environment variable.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C.load(\"chips=ahoy; vienna=finger\")\n   >>> C.output()\n   'Set-Cookie: chips=ahoy\\r\\nSet-Cookie: vienna=finger'\n\nThe load() method is darn-tootin smart about identifying cookies\nwithin a string.  Escaped quotation marks, nested semicolons, and other\nsuch trickeries do not confuse it.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C.load('keebler=\"E=everybody; L=\\\\\"Loves\\\\\"; fudge=\\\\012;\";')\n   >>> print(C)\n   Set-Cookie: keebler=\"E=everybody; L=\\\"Loves\\\"; fudge=\\012;\"\n\nEach element of the Cookie also supports all of the RFC 2109\nCookie attributes.  Here's an example which sets the Path\nattribute.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"oreo\"] = \"doublestuff\"\n   >>> C[\"oreo\"][\"path\"] = \"/\"\n   >>> print(C)\n   Set-Cookie: oreo=doublestuff; Path=/\n\nEach dictionary element has a 'value' attribute, which gives you\nback the value associated with the key.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"twix\"] = \"none for you\"\n   >>> C[\"twix\"].value\n   'none for you'\n\nThe SimpleCookie expects that all values should be standard strings.\nJust to be sure, SimpleCookie invokes the str() builtin to convert\nthe value to a string, when the values are set dictionary-style.\n\n   >>> C = cookies.SimpleCookie()\n   >>> C[\"number\"] = 7\n   >>> C[\"string\"] = \"seven\"\n   >>> C[\"number\"].value\n   '7'\n   >>> C[\"string\"].value\n   'seven'\n   >>> C.output()\n   'Set-Cookie: number=7\\r\\nSet-Cookie: string=seven'\n\nFinis.\n\"\"\"\n__all__ = [\"CookieError\", \"BaseCookie\", \"SimpleCookie\"]\n_nulljoin = ''.join\n_semispacejoin = '; '.join\n_spacejoin = ' '.join\n_LegalChars = string.ascii_letters + string.digits + \"!#$%&'*+-.^_`|~:\"\n_UnescapedChars = _LegalChars + ' ()/<=>?@[]{}'\n_Translator = {n: '\\\\%03o' % n\n               for n in set(range(256)) - set(map(ord, _UnescapedChars))}\n_Translator.update({\n    ord('\"'): '\\\\\"',\n    ord('\\\\'): '\\\\\\\\',\n})\n_is_legal_key = re.compile('[%s]+' % re.escape(_LegalChars)).fullmatch\n_OctalPatt = re.compile(r\"\\\\[0-3][0-7][0-7]\")\n_QuotePatt = re.compile(r\"[\\\\].\")\n_weekdayname = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n_monthname = [None,\n              'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',\n              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n_LegalKeyChars  = r\"\\w\\d!#%&'~_`><@,:/\\$\\*\\+\\-\\.\\^\\|\\)\\(\\?\\}\\{\\=\"\n_LegalValueChars = _LegalKeyChars + r'\\[\\]'\n_CookiePattern = re.compile(r\"\"\"\n    \\s*                            # Optional whitespace at start of cookie\n    (?P<key>                       # Start of group 'key'\n    [\"\"\" + _LegalKeyChars + r\"\"\"]+?   # Any word of at least one letter\n    )                              # End of group 'key'\n    (                              # Optional group: there may not be a value.\n    \\s*=\\s*                          # Equal Sign\n    (?P<val>                         # Start of group 'val'\n    \"(?:[^\\\\\"]|\\\\.)*\"                  # Any doublequoted string\n    |                                  # or\n    \\w{3},\\s[\\w\\d\\s-]{9,11}\\s[\\d:]{8}\\sGMT  # Special case for \"expires\" attr\n    |                                  # or\n    [\"\"\" + _LegalValueChars + r\"\"\"]*      # Any word or empty string\n    )                                # End of group 'val'\n    )?                             # End of optional value group\n    \\s*                            # Any number of spaces.\n    (\\s+|;|$)                      # Ending either at space, semicolon, or EOS.\n    \"\"\", re.ASCII | re.VERBOSE)    # re.ASCII may be removed if safe.",
        "name_type": "stdlib"
    },
    "http.cookies.CookieError": {
        "API_name": "http.cookies.CookieError",
        "loc_name": "http.cookies.CookieError",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookies",
        "lineno": 145,
        "namespace": "CookieError",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookies._quote": {
        "API_name": "http.cookies._quote",
        "loc_name": "http.cookies._quote",
        "args": "str",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 174,
        "namespace": "*",
        "body": "def _quote(str):\n    r\"\"\"Quote a string for use in a cookie header.\n\n    If the string does not need to be double-quoted, then just return the\n    string.  Otherwise, surround the string in doublequotes and quote\n    (with a \\) special characters.\n    \"\"\"\n    if str is None or _is_legal_key(str):\n        return str\n    else:\n        return '\"' + str.translate(_Translator) + '\"'",
        "name_type": "stdlib"
    },
    "http.cookies._unquote": {
        "API_name": "http.cookies._unquote",
        "loc_name": "http.cookies._unquote",
        "args": "str",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 190,
        "namespace": "*",
        "body": "def _unquote(str):\n    # If there aren't any doublequotes,\n    # then there can't be any special characters.  See RFC 2109.\n    if str is None or len(str) < 2:\n        return str\n    if str[0] != '\"' or str[-1] != '\"':\n        return str\n\n    # We have to assume that we must decode this string.\n    # Down to work.\n\n    # Remove the \"s\n    str = str[1:-1]\n\n    # Check for special sequences.  Examples:\n    #    \\012 --> \\n\n    #    \\\"   --> \"\n    #\n    i = 0\n    n = len(str)\n    res = []\n    while 0 <= i < n:\n        o_match = _OctalPatt.search(str, i)\n        q_match = _QuotePatt.search(str, i)\n        if not o_match and not q_match:              # Neither matched\n            res.append(str[i:])\n            break\n        # else:\n        j = k = -1\n        if o_match:\n            j = o_match.start(0)\n        if q_match:\n            k = q_match.start(0)\n        if q_match and (not o_match or k < j):     # QuotePatt matched\n            res.append(str[i:k])\n            res.append(str[k+1])\n            i = k + 2\n        else:                                      # OctalPatt matched\n            res.append(str[i:j])\n            res.append(chr(int(str[j+1:j+4], 8)))\n            i = j + 4\n    return _nulljoin(res)",
        "name_type": "stdlib"
    },
    "http.cookies._getdate": {
        "API_name": "http.cookies._getdate",
        "loc_name": "http.cookies._getdate",
        "args": "future;weekdayname;monthname",
        "args_default": 3,
        "filepath": "http.cookies",
        "lineno": 246,
        "namespace": "*",
        "body": "def _getdate(future=0, weekdayname=_weekdayname, monthname=_monthname):\n    from time import gmtime, time\n    now = time()\n    year, month, day, hh, mm, ss, wd, y, z = gmtime(now + future)\n    return \"%s, %02d %3s %4d %02d:%02d:%02d GMT\" % \\\n           (weekdayname[wd], day, monthname[month], year, hh, mm, ss)",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel": {
        "API_name": "http.cookies.Morsel",
        "loc_name": "http.cookies.Morsel",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookies",
        "lineno": 254,
        "namespace": "Morsel",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.__init__": {
        "API_name": "http.cookies.Morsel.__init__",
        "loc_name": "http.cookies.Morsel.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 289,
        "namespace": "Morsel",
        "body": "    def __init__(self):\n        # Set defaults\n        self._key = self._value = self._coded_value = None\n\n        # Set default attributes\n        for key in self._reserved:\n            dict.__setitem__(self, key, \"\")",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.key": {
        "API_name": "http.cookies.Morsel.key",
        "loc_name": "http.cookies.Morsel.key",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 298,
        "namespace": "Morsel",
        "body": "    def key(self):\n        return self._key",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.value": {
        "API_name": "http.cookies.Morsel.value",
        "loc_name": "http.cookies.Morsel.value",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 302,
        "namespace": "Morsel",
        "body": "    def value(self):\n        return self._value",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.coded_value": {
        "API_name": "http.cookies.Morsel.coded_value",
        "loc_name": "http.cookies.Morsel.coded_value",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 306,
        "namespace": "Morsel",
        "body": "    def coded_value(self):\n        return self._coded_value",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.__setitem__": {
        "API_name": "http.cookies.Morsel.__setitem__",
        "loc_name": "http.cookies.Morsel.__setitem__",
        "args": "self;K;V",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 309,
        "namespace": "Morsel",
        "body": "    def __setitem__(self, K, V):\n        K = K.lower()\n        if not K in self._reserved:\n            raise CookieError(\"Invalid attribute %r\" % (K,))\n        dict.__setitem__(self, K, V)",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.setdefault": {
        "API_name": "http.cookies.Morsel.setdefault",
        "loc_name": "http.cookies.Morsel.setdefault",
        "args": "self;key;val",
        "args_default": 1,
        "filepath": "http.cookies",
        "lineno": 315,
        "namespace": "Morsel",
        "body": "    def setdefault(self, key, val=None):\n        key = key.lower()\n        if key not in self._reserved:\n            raise CookieError(\"Invalid attribute %r\" % (key,))\n        return dict.setdefault(self, key, val)",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.__eq__": {
        "API_name": "http.cookies.Morsel.__eq__",
        "loc_name": "http.cookies.Morsel.__eq__",
        "args": "self;morsel",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 321,
        "namespace": "Morsel",
        "body": "    def __eq__(self, morsel):\n        if not isinstance(morsel, Morsel):\n            return NotImplemented\n        return (dict.__eq__(self, morsel) and\n                self._value == morsel._value and\n                self._key == morsel._key and\n                self._coded_value == morsel._coded_value)",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.copy": {
        "API_name": "http.cookies.Morsel.copy",
        "loc_name": "http.cookies.Morsel.copy",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 331,
        "namespace": "Morsel",
        "body": "    def copy(self):\n        morsel = Morsel()\n        dict.update(morsel, self)\n        morsel.__dict__.update(self.__dict__)\n        return morsel",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.update": {
        "API_name": "http.cookies.Morsel.update",
        "loc_name": "http.cookies.Morsel.update",
        "args": "self;values",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 337,
        "namespace": "Morsel",
        "body": "    def update(self, values):\n        data = {}\n        for key, val in dict(values).items():\n            key = key.lower()\n            if key not in self._reserved:\n                raise CookieError(\"Invalid attribute %r\" % (key,))\n            data[key] = val\n        dict.update(self, data)",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.isReservedKey": {
        "API_name": "http.cookies.Morsel.isReservedKey",
        "loc_name": "http.cookies.Morsel.isReservedKey",
        "args": "self;K",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 346,
        "namespace": "Morsel",
        "body": "    def isReservedKey(self, K):\n        return K.lower() in self._reserved",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.set": {
        "API_name": "http.cookies.Morsel.set",
        "loc_name": "http.cookies.Morsel.set",
        "args": "self;key;val;coded_val",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 349,
        "namespace": "Morsel",
        "body": "    def set(self, key, val, coded_val):\n        if key.lower() in self._reserved:\n            raise CookieError('Attempt to set a reserved key %r' % (key,))\n        if not _is_legal_key(key):\n            raise CookieError('Illegal key %r' % (key,))\n\n        # It's a good key, so save it.\n        self._key = key\n        self._value = val\n        self._coded_value = coded_val",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.__getstate__": {
        "API_name": "http.cookies.Morsel.__getstate__",
        "loc_name": "http.cookies.Morsel.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 360,
        "namespace": "Morsel",
        "body": "    def __getstate__(self):\n        return {\n            'key': self._key,\n            'value': self._value,\n            'coded_value': self._coded_value,\n        }",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.__setstate__": {
        "API_name": "http.cookies.Morsel.__setstate__",
        "loc_name": "http.cookies.Morsel.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 367,
        "namespace": "Morsel",
        "body": "    def __setstate__(self, state):\n        self._key = state['key']\n        self._value = state['value']\n        self._coded_value = state['coded_value']",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.output": {
        "API_name": "http.cookies.Morsel.output",
        "loc_name": "http.cookies.Morsel.output",
        "args": "self;attrs;header",
        "args_default": 2,
        "filepath": "http.cookies",
        "lineno": 372,
        "namespace": "Morsel",
        "body": "    def output(self, attrs=None, header=\"Set-Cookie:\"):\n        return \"%s %s\" % (header, self.OutputString(attrs))",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.__repr__": {
        "API_name": "http.cookies.Morsel.__repr__",
        "loc_name": "http.cookies.Morsel.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 377,
        "namespace": "Morsel",
        "body": "    def __repr__(self):\n        return '<%s: %s>' % (self.__class__.__name__, self.OutputString())",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.js_output": {
        "API_name": "http.cookies.Morsel.js_output",
        "loc_name": "http.cookies.Morsel.js_output",
        "args": "self;attrs",
        "args_default": 1,
        "filepath": "http.cookies",
        "lineno": 380,
        "namespace": "Morsel",
        "body": "    def js_output(self, attrs=None):\n        # Print javascript\n        return \"\"\"\n        <script type=\"text/javascript\">\n        <!-- begin hiding\n        document.cookie = \\\"%s\\\";\n        // end hiding -->\n        </script>\n        \"\"\" % (self.OutputString(attrs).replace('\"', r'\\\"'))",
        "name_type": "stdlib"
    },
    "http.cookies.Morsel.OutputString": {
        "API_name": "http.cookies.Morsel.OutputString",
        "loc_name": "http.cookies.Morsel.OutputString",
        "args": "self;attrs",
        "args_default": 1,
        "filepath": "http.cookies",
        "lineno": 390,
        "namespace": "Morsel",
        "body": "    def OutputString(self, attrs=None):\n        # Build up our result\n        #\n        result = []\n        append = result.append\n\n        # First, the key=value pair\n        append(\"%s=%s\" % (self.key, self.coded_value))\n\n        # Now add any defined attributes\n        if attrs is None:\n            attrs = self._reserved\n        items = sorted(self.items())\n        for key, value in items:\n            if value == \"\":\n                continue\n            if key not in attrs:\n                continue\n            if key == \"expires\" and isinstance(value, int):\n                append(\"%s=%s\" % (self._reserved[key], _getdate(value)))\n            elif key == \"max-age\" and isinstance(value, int):\n                append(\"%s=%d\" % (self._reserved[key], value))\n            elif key == \"comment\" and isinstance(value, str):\n                append(\"%s=%s\" % (self._reserved[key], _quote(value)))\n            elif key in self._flags:\n                if value:\n                    append(str(self._reserved[key]))\n            else:\n                append(\"%s=%s\" % (self._reserved[key], value))\n\n        # Return the result\n        return _semispacejoin(result)",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie": {
        "API_name": "http.cookies.BaseCookie",
        "loc_name": "http.cookies.BaseCookie",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookies",
        "lineno": 460,
        "namespace": "BaseCookie",
        "body": "",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.value_decode": {
        "API_name": "http.cookies.BaseCookie.value_decode",
        "loc_name": "http.cookies.BaseCookie.value_decode",
        "args": "self;val",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 463,
        "namespace": "BaseCookie",
        "body": "    def value_decode(self, val):\n        \"\"\"real_value, coded_value = value_decode(STRING)\n        Called prior to setting a cookie's value from the network\n        representation.  The VALUE is the value read from HTTP\n        header.\n        Override this function to modify the behavior of cookies.\n        \"\"\"\n        return val, val",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.value_encode": {
        "API_name": "http.cookies.BaseCookie.value_encode",
        "loc_name": "http.cookies.BaseCookie.value_encode",
        "args": "self;val",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 472,
        "namespace": "BaseCookie",
        "body": "    def value_encode(self, val):\n        \"\"\"real_value, coded_value = value_encode(VALUE)\n        Called prior to setting a cookie's value from the dictionary\n        representation.  The VALUE is the value being assigned.\n        Override this function to modify the behavior of cookies.\n        \"\"\"\n        strval = str(val)\n        return strval, strval",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.__init__": {
        "API_name": "http.cookies.BaseCookie.__init__",
        "loc_name": "http.cookies.BaseCookie.__init__",
        "args": "self;input",
        "args_default": 1,
        "filepath": "http.cookies",
        "lineno": 481,
        "namespace": "BaseCookie",
        "body": "    def __init__(self, input=None):\n        if input:\n            self.load(input)",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.__set": {
        "API_name": "http.cookies.BaseCookie.__set",
        "loc_name": "http.cookies.BaseCookie.__set",
        "args": "self;key;real_value;coded_value",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 485,
        "namespace": "BaseCookie",
        "body": "    def __set(self, key, real_value, coded_value):\n        \"\"\"Private method for setting a cookie's value\"\"\"\n        M = self.get(key, Morsel())\n        M.set(key, real_value, coded_value)\n        dict.__setitem__(self, key, M)",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.__setitem__": {
        "API_name": "http.cookies.BaseCookie.__setitem__",
        "loc_name": "http.cookies.BaseCookie.__setitem__",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 491,
        "namespace": "BaseCookie",
        "body": "    def __setitem__(self, key, value):\n        \"\"\"Dictionary style assignment.\"\"\"\n        if isinstance(value, Morsel):\n            # allow assignment of constructed Morsels (e.g. for pickling)\n            dict.__setitem__(self, key, value)\n        else:\n            rval, cval = self.value_encode(value)\n            self.__set(key, rval, cval)",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.output": {
        "API_name": "http.cookies.BaseCookie.output",
        "loc_name": "http.cookies.BaseCookie.output",
        "args": "self;attrs;header;sep",
        "args_default": 3,
        "filepath": "http.cookies",
        "lineno": 500,
        "namespace": "BaseCookie",
        "body": "    def output(self, attrs=None, header=\"Set-Cookie:\", sep=\"\\015\\012\"):\n        \"\"\"Return a string suitable for HTTP.\"\"\"\n        result = []\n        items = sorted(self.items())\n        for key, value in items:\n            result.append(value.output(attrs, header))\n        return sep.join(result)",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.__repr__": {
        "API_name": "http.cookies.BaseCookie.__repr__",
        "loc_name": "http.cookies.BaseCookie.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 510,
        "namespace": "BaseCookie",
        "body": "    def __repr__(self):\n        l = []\n        items = sorted(self.items())\n        for key, value in items:\n            l.append('%s=%s' % (key, repr(value.value)))\n        return '<%s: %s>' % (self.__class__.__name__, _spacejoin(l))",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.js_output": {
        "API_name": "http.cookies.BaseCookie.js_output",
        "loc_name": "http.cookies.BaseCookie.js_output",
        "args": "self;attrs",
        "args_default": 1,
        "filepath": "http.cookies",
        "lineno": 517,
        "namespace": "BaseCookie",
        "body": "    def js_output(self, attrs=None):\n        \"\"\"Return a string suitable for JavaScript.\"\"\"\n        result = []\n        items = sorted(self.items())\n        for key, value in items:\n            result.append(value.js_output(attrs))\n        return _nulljoin(result)",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.load": {
        "API_name": "http.cookies.BaseCookie.load",
        "loc_name": "http.cookies.BaseCookie.load",
        "args": "self;rawdata",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 525,
        "namespace": "BaseCookie",
        "body": "    def load(self, rawdata):\n        \"\"\"Load cookies from a string (presumably HTTP_COOKIE) or\n        from a dictionary.  Loading cookies from a dictionary 'd'\n        is equivalent to calling:\n            map(Cookie.__setitem__, d.keys(), d.values())\n        \"\"\"\n        if isinstance(rawdata, str):\n            self.__parse_string(rawdata)\n        else:\n            # self.update() wouldn't call our custom __setitem__\n            for key, value in rawdata.items():\n                self[key] = value\n        return",
        "name_type": "stdlib"
    },
    "http.cookies.BaseCookie.__parse_string": {
        "API_name": "http.cookies.BaseCookie.__parse_string",
        "loc_name": "http.cookies.BaseCookie.__parse_string",
        "args": "self;str;patt",
        "args_default": 1,
        "filepath": "http.cookies",
        "lineno": 539,
        "namespace": "BaseCookie",
        "body": "    def __parse_string(self, str, patt=_CookiePattern):\n        i = 0                 # Our starting point\n        n = len(str)          # Length of string\n        parsed_items = []     # Parsed (type, key, value) triples\n        morsel_seen = False   # A key=value pair was previously encountered\n\n        TYPE_ATTRIBUTE = 1\n        TYPE_KEYVALUE = 2\n\n        # We first parse the whole cookie string and reject it if it's\n        # syntactically invalid (this helps avoid some classes of injection\n        # attacks).\n        while 0 <= i < n:\n            # Start looking for a cookie\n            match = patt.match(str, i)\n            if not match:\n                # No more cookies\n                break\n\n            key, value = match.group(\"key\"), match.group(\"val\")\n            i = match.end(0)\n\n            if key[0] == \"$\":\n                if not morsel_seen:\n                    # We ignore attributes which pertain to the cookie\n                    # mechanism as a whole, such as \"$Version\".\n                    # See RFC 2965. (Does anyone care?)\n                    continue\n                parsed_items.append((TYPE_ATTRIBUTE, key[1:], value))\n            elif key.lower() in Morsel._reserved:\n                if not morsel_seen:\n                    # Invalid cookie string\n                    return\n                if value is None:\n                    if key.lower() in Morsel._flags:\n                        parsed_items.append((TYPE_ATTRIBUTE, key, True))\n                    else:\n                        # Invalid cookie string\n                        return\n                else:\n                    parsed_items.append((TYPE_ATTRIBUTE, key, _unquote(value)))\n            elif value is not None:\n                parsed_items.append((TYPE_KEYVALUE, key, self.value_decode(value)))\n                morsel_seen = True\n            else:\n                # Invalid cookie string\n                return\n\n        # The cookie string is valid, apply it.\n        M = None         # current morsel\n        for tp, key, value in parsed_items:\n            if tp == TYPE_ATTRIBUTE:\n                assert M is not None\n                M[key] = value\n            else:\n                assert tp == TYPE_KEYVALUE\n                rval, cval = value\n                self.__set(key, rval, cval)\n                M = self[key]",
        "name_type": "stdlib"
    },
    "http.cookies.SimpleCookie.value_decode": {
        "API_name": "http.cookies.SimpleCookie.value_decode",
        "loc_name": "http.cookies.SimpleCookie.value_decode",
        "args": "self;val",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 607,
        "namespace": "SimpleCookie",
        "body": "    def value_decode(self, val):\n        return _unquote(val), val",
        "name_type": "stdlib"
    },
    "http.cookies.SimpleCookie.value_encode": {
        "API_name": "http.cookies.SimpleCookie.value_encode",
        "loc_name": "http.cookies.SimpleCookie.value_encode",
        "args": "self;val",
        "args_default": 0,
        "filepath": "http.cookies",
        "lineno": 610,
        "namespace": "SimpleCookie",
        "body": "    def value_encode(self, val):\n        strval = str(val)\n        return strval, _quote(strval)",
        "name_type": "stdlib"
    },
    "http.cookies.SimpleCookie": {
        "API_name": "http.cookies.SimpleCookie",
        "loc_name": "http.cookies.SimpleCookie",
        "args": "*",
        "args_default": "*",
        "filepath": "http.cookies",
        "lineno": 600,
        "namespace": "SimpleCookie",
        "body": "",
        "name_type": "stdlib"
    },
    "http.server": {
        "API_name": "http.server",
        "loc_name": "http.server",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"HTTP server classes.\n\nNote: BaseHTTPRequestHandler doesn't implement any HTTP request; see\nSimpleHTTPRequestHandler for simple implementations of GET, HEAD and POST,\nand CGIHTTPRequestHandler for CGI scripts.\n\nIt does, however, optionally implement HTTP/1.1 persistent connections,\nas of version 0.3.\n\nNotes on CGIHTTPRequestHandler\n------------------------------\n\nThis class implements GET and POST requests to cgi-bin scripts.\n\nIf the os.fork() function is not present (e.g. on Windows),\nsubprocess.Popen() is used as a fallback, with slightly altered semantics.\n\nIn all cases, the implementation is intentionally naive -- all\nrequests are executed synchronously.\n\nSECURITY WARNING: DON'T USE THIS CODE UNLESS YOU ARE INSIDE A FIREWALL\n-- it may execute arbitrary Python code or external programs.\n\nNote that status code 200 is sent prior to execution of a CGI script, so\nscripts cannot send other status codes such as 302 (redirect).\n\nXXX To do:\n\n- log requests even later (to capture byte count)\n- log user-agent header and other interesting goodies\n- send error log to separate file\n\"\"\"\n__version__ = \"0.6\"\n__all__ = [\n    \"HTTPServer\", \"ThreadingHTTPServer\", \"BaseHTTPRequestHandler\",\n    \"SimpleHTTPRequestHandler\", \"CGIHTTPRequestHandler\",\n]\nDEFAULT_ERROR_MESSAGE = \"\"\"\\\n<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\"\n        \"http://www.w3.org/TR/html4/strict.dtd\">\n<html>\n    <head>\n        <meta http-equiv=\"Content-Type\" content=\"text/html;charset=utf-8\">\n        <title>Error response</title>\n    </head>\n    <body>\n        <h1>Error response</h1>\n        <p>Error code: %(code)d</p>\n        <p>Message: %(message)s.</p>\n        <p>Error code explanation: %(code)s - %(explain)s.</p>\n    </body>\n</html>\n\"\"\"\nDEFAULT_ERROR_CONTENT_TYPE = \"text/html;charset=utf-8\"\nnobody = None\nif __name__ == '__main__':\n    import argparse\n    import contextlib\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--cgi', action='store_true',\n                        help='run as CGI server')\n    parser.add_argument('--bind', '-b', metavar='ADDRESS',\n                        help='specify alternate bind address '\n                             '(default: all interfaces)')\n    parser.add_argument('--directory', '-d', default=os.getcwd(),\n                        help='specify alternate directory '\n                             '(default: current directory)')\n    parser.add_argument('port', action='store', default=8000, type=int,\n                        nargs='?',\n                        help='specify alternate port (default: 8000)')\n    args = parser.parse_args()\n    if args.cgi:\n        handler_class = CGIHTTPRequestHandler\n    else:\n        handler_class = SimpleHTTPRequestHandler\n\n    # ensure dual-stack is not disabled; ref #38907\n    class DualStackServer(ThreadingHTTPServer):\n\n        def server_bind(self):\n            # suppress exception when protocol is IPv4\n            with contextlib.suppress(Exception):\n                self.socket.setsockopt(\n                    socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 0)\n            return super().server_bind()\n\n        def finish_request(self, request, client_address):\n            self.RequestHandlerClass(request, client_address, self,\n                                     directory=args.directory)\n\n    test(\n        HandlerClass=handler_class,\n        ServerClass=DualStackServer,\n        port=args.port,\n        bind=args.bind,\n    )",
        "name_type": "stdlib"
    },
    "http.server.HTTPServer.server_bind": {
        "API_name": "http.server.HTTPServer.server_bind",
        "loc_name": "http.server.HTTPServer.server_bind",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 134,
        "namespace": "HTTPServer",
        "body": "    def server_bind(self):\n        \"\"\"Override server_bind to store the server name.\"\"\"\n        socketserver.TCPServer.server_bind(self)\n        host, port = self.server_address[:2]\n        self.server_name = socket.getfqdn(host)\n        self.server_port = port",
        "name_type": "stdlib"
    },
    "http.server.HTTPServer": {
        "API_name": "http.server.HTTPServer",
        "loc_name": "http.server.HTTPServer",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": 130,
        "namespace": "HTTPServer",
        "body": "",
        "name_type": "stdlib"
    },
    "http.server.ThreadingHTTPServer": {
        "API_name": "http.server.ThreadingHTTPServer",
        "loc_name": "http.server.ThreadingHTTPServer",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": 142,
        "namespace": "ThreadingHTTPServer",
        "body": "",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.parse_request": {
        "API_name": "http.server.BaseHTTPRequestHandler.parse_request",
        "loc_name": "http.server.BaseHTTPRequestHandler.parse_request",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 267,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def parse_request(self):\n        \"\"\"Parse a request (internal).\n\n        The request should be stored in self.raw_requestline; the results\n        are in self.command, self.path, self.request_version and\n        self.headers.\n\n        Return True for success, False for failure; on failure, any relevant\n        error response has already been sent back.\n\n        \"\"\"\n        self.command = None  # set in case of error on the first line\n        self.request_version = version = self.default_request_version\n        self.close_connection = True\n        requestline = str(self.raw_requestline, 'iso-8859-1')\n        requestline = requestline.rstrip('\\r\\n')\n        self.requestline = requestline\n        words = requestline.split()\n        if len(words) == 0:\n            return False\n\n        if len(words) >= 3:  # Enough to determine protocol version\n            version = words[-1]\n            try:\n                if not version.startswith('HTTP/'):\n                    raise ValueError\n                base_version_number = version.split('/', 1)[1]\n                version_number = base_version_number.split(\".\")\n                # RFC 2145 section 3.1 says there can be only one \".\" and\n                #   - major and minor numbers MUST be treated as\n                #      separate integers;\n                #   - HTTP/2.4 is a lower version than HTTP/2.13, which in\n                #      turn is lower than HTTP/12.3;\n                #   - Leading zeros MUST be ignored by recipients.\n                if len(version_number) != 2:\n                    raise ValueError\n                version_number = int(version_number[0]), int(version_number[1])\n            except (ValueError, IndexError):\n                self.send_error(\n                    HTTPStatus.BAD_REQUEST,\n                    \"Bad request version (%r)\" % version)\n                return False\n            if version_number >= (1, 1) and self.protocol_version >= \"HTTP/1.1\":\n                self.close_connection = False\n            if version_number >= (2, 0):\n                self.send_error(\n                    HTTPStatus.HTTP_VERSION_NOT_SUPPORTED,\n                    \"Invalid HTTP version (%s)\" % base_version_number)\n                return False\n            self.request_version = version\n\n        if not 2 <= len(words) <= 3:\n            self.send_error(\n                HTTPStatus.BAD_REQUEST,\n                \"Bad request syntax (%r)\" % requestline)\n            return False\n        command, path = words[:2]\n        if len(words) == 2:\n            self.close_connection = True\n            if command != 'GET':\n                self.send_error(\n                    HTTPStatus.BAD_REQUEST,\n                    \"Bad HTTP/0.9 request type (%r)\" % command)\n                return False\n        self.command, self.path = command, path\n\n        # Examine the headers and look for a Connection directive.\n        try:\n            self.headers = http.client.parse_headers(self.rfile,\n                                                     _class=self.MessageClass)\n        except http.client.LineTooLong as err:\n            self.send_error(\n                HTTPStatus.REQUEST_HEADER_FIELDS_TOO_LARGE,\n                \"Line too long\",\n                str(err))\n            return False\n        except http.client.HTTPException as err:\n            self.send_error(\n                HTTPStatus.REQUEST_HEADER_FIELDS_TOO_LARGE,\n                \"Too many headers\",\n                str(err)\n            )\n            return False\n\n        conntype = self.headers.get('Connection', \"\")\n        if conntype.lower() == 'close':\n            self.close_connection = True\n        elif (conntype.lower() == 'keep-alive' and\n              self.protocol_version >= \"HTTP/1.1\"):\n            self.close_connection = False\n        # Examine the headers and look for an Expect directive\n        expect = self.headers.get('Expect', \"\")\n        if (expect.lower() == \"100-continue\" and\n                self.protocol_version >= \"HTTP/1.1\" and\n                self.request_version >= \"HTTP/1.1\"):\n            if not self.handle_expect_100():\n                return False\n        return True",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.handle_expect_100": {
        "API_name": "http.server.BaseHTTPRequestHandler.handle_expect_100",
        "loc_name": "http.server.BaseHTTPRequestHandler.handle_expect_100",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 366,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def handle_expect_100(self):\n        \"\"\"Decide what to do with an \"Expect: 100-continue\" header.\n\n        If the client is expecting a 100 Continue response, we must\n        respond with either a 100 Continue or a final response before\n        waiting for the request body. The default is to always respond\n        with a 100 Continue. You can behave differently (for example,\n        reject unauthorized requests) by overriding this method.\n\n        This method should either return True (possibly after sending\n        a 100 Continue response) or send an error response and return\n        False.\n\n        \"\"\"\n        self.send_response_only(HTTPStatus.CONTINUE)\n        self.end_headers()\n        return True",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.handle_one_request": {
        "API_name": "http.server.BaseHTTPRequestHandler.handle_one_request",
        "loc_name": "http.server.BaseHTTPRequestHandler.handle_one_request",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 384,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def handle_one_request(self):\n        \"\"\"Handle a single HTTP request.\n\n        You normally don't need to override this method; see the class\n        __doc__ string for information on how to handle specific HTTP\n        commands such as GET and POST.\n\n        \"\"\"\n        try:\n            self.raw_requestline = self.rfile.readline(65537)\n            if len(self.raw_requestline) > 65536:\n                self.requestline = ''\n                self.request_version = ''\n                self.command = ''\n                self.send_error(HTTPStatus.REQUEST_URI_TOO_LONG)\n                return\n            if not self.raw_requestline:\n                self.close_connection = True\n                return\n            if not self.parse_request():\n                # An error code has been sent, just exit\n                return\n            mname = 'do_' + self.command\n            if not hasattr(self, mname):\n                self.send_error(\n                    HTTPStatus.NOT_IMPLEMENTED,\n                    \"Unsupported method (%r)\" % self.command)\n                return\n            method = getattr(self, mname)\n            method()\n            self.wfile.flush() #actually send the response if not already done.\n        except socket.timeout as e:\n            #a read or a write timed out.  Discard this connection\n            self.log_error(\"Request timed out: %r\", e)\n            self.close_connection = True\n            return",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.handle": {
        "API_name": "http.server.BaseHTTPRequestHandler.handle",
        "loc_name": "http.server.BaseHTTPRequestHandler.handle",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 421,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def handle(self):\n        \"\"\"Handle multiple requests if necessary.\"\"\"\n        self.close_connection = True\n\n        self.handle_one_request()\n        while not self.close_connection:\n            self.handle_one_request()",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.send_error": {
        "API_name": "http.server.BaseHTTPRequestHandler.send_error",
        "loc_name": "http.server.BaseHTTPRequestHandler.send_error",
        "args": "self;code;message;explain",
        "args_default": 2,
        "filepath": "http.server",
        "lineno": 429,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def send_error(self, code, message=None, explain=None):\n        \"\"\"Send and log an error reply.\n\n        Arguments are\n        * code:    an HTTP error code\n                   3 digits\n        * message: a simple optional 1 line reason phrase.\n                   *( HTAB / SP / VCHAR / %x80-FF )\n                   defaults to short entry matching the response code\n        * explain: a detailed message defaults to the long entry\n                   matching the response code.\n\n        This sends an error response (so it must be called before any\n        output has been generated), logs the error, and finally sends\n        a piece of HTML explaining the error to the user.\n\n        \"\"\"\n\n        try:\n            shortmsg, longmsg = self.responses[code]\n        except KeyError:\n            shortmsg, longmsg = '???', '???'\n        if message is None:\n            message = shortmsg\n        if explain is None:\n            explain = longmsg\n        self.log_error(\"code %d, message %s\", code, message)\n        self.send_response(code, message)\n        self.send_header('Connection', 'close')\n\n        # Message body is omitted for cases described in:\n        #  - RFC7230: 3.3. 1xx, 204(No Content), 304(Not Modified)\n        #  - RFC7231: 6.3.6. 205(Reset Content)\n        body = None\n        if (code >= 200 and\n            code not in (HTTPStatus.NO_CONTENT,\n                         HTTPStatus.RESET_CONTENT,\n                         HTTPStatus.NOT_MODIFIED)):\n            # HTML encode to prevent Cross Site Scripting attacks\n            # (see bug #1100201)\n            content = (self.error_message_format % {\n                'code': code,\n                'message': html.escape(message, quote=False),\n                'explain': html.escape(explain, quote=False)\n            })\n            body = content.encode('UTF-8', 'replace')\n            self.send_header(\"Content-Type\", self.error_content_type)\n            self.send_header('Content-Length', str(len(body)))\n        self.end_headers()\n\n        if self.command != 'HEAD' and body:\n            self.wfile.write(body)",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.send_response": {
        "API_name": "http.server.BaseHTTPRequestHandler.send_response",
        "loc_name": "http.server.BaseHTTPRequestHandler.send_response",
        "args": "self;code;message",
        "args_default": 1,
        "filepath": "http.server",
        "lineno": 482,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def send_response(self, code, message=None):\n        \"\"\"Add the response header to the headers buffer and log the\n        response code.\n\n        Also send two standard headers with the server software\n        version and the current date.\n\n        \"\"\"\n        self.log_request(code)\n        self.send_response_only(code, message)\n        self.send_header('Server', self.version_string())\n        self.send_header('Date', self.date_time_string())",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.send_response_only": {
        "API_name": "http.server.BaseHTTPRequestHandler.send_response_only",
        "loc_name": "http.server.BaseHTTPRequestHandler.send_response_only",
        "args": "self;code;message",
        "args_default": 1,
        "filepath": "http.server",
        "lineno": 495,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def send_response_only(self, code, message=None):\n        \"\"\"Send the response header only.\"\"\"\n        if self.request_version != 'HTTP/0.9':\n            if message is None:\n                if code in self.responses:\n                    message = self.responses[code][0]\n                else:\n                    message = ''\n            if not hasattr(self, '_headers_buffer'):\n                self._headers_buffer = []\n            self._headers_buffer.append((\"%s %d %s\\r\\n\" %\n                    (self.protocol_version, code, message)).encode(\n                        'latin-1', 'strict'))",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.send_header": {
        "API_name": "http.server.BaseHTTPRequestHandler.send_header",
        "loc_name": "http.server.BaseHTTPRequestHandler.send_header",
        "args": "self;keyword;value",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 509,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def send_header(self, keyword, value):\n        \"\"\"Send a MIME header to the headers buffer.\"\"\"\n        if self.request_version != 'HTTP/0.9':\n            if not hasattr(self, '_headers_buffer'):\n                self._headers_buffer = []\n            self._headers_buffer.append(\n                (\"%s: %s\\r\\n\" % (keyword, value)).encode('latin-1', 'strict'))\n\n        if keyword.lower() == 'connection':\n            if value.lower() == 'close':\n                self.close_connection = True\n            elif value.lower() == 'keep-alive':\n                self.close_connection = False",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.end_headers": {
        "API_name": "http.server.BaseHTTPRequestHandler.end_headers",
        "loc_name": "http.server.BaseHTTPRequestHandler.end_headers",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 523,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def end_headers(self):\n        \"\"\"Send the blank line ending the MIME headers.\"\"\"\n        if self.request_version != 'HTTP/0.9':\n            self._headers_buffer.append(b\"\\r\\n\")\n            self.flush_headers()",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.flush_headers": {
        "API_name": "http.server.BaseHTTPRequestHandler.flush_headers",
        "loc_name": "http.server.BaseHTTPRequestHandler.flush_headers",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 529,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def flush_headers(self):\n        if hasattr(self, '_headers_buffer'):\n            self.wfile.write(b\"\".join(self._headers_buffer))\n            self._headers_buffer = []",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.log_request": {
        "API_name": "http.server.BaseHTTPRequestHandler.log_request",
        "loc_name": "http.server.BaseHTTPRequestHandler.log_request",
        "args": "self;code;size",
        "args_default": 2,
        "filepath": "http.server",
        "lineno": 534,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def log_request(self, code='-', size='-'):\n        \"\"\"Log an accepted request.\n\n        This is called by send_response().\n\n        \"\"\"\n        if isinstance(code, HTTPStatus):\n            code = code.value\n        self.log_message('\"%s\" %s %s',\n                         self.requestline, str(code), str(size))",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.log_error": {
        "API_name": "http.server.BaseHTTPRequestHandler.log_error",
        "loc_name": "http.server.BaseHTTPRequestHandler.log_error",
        "args": "self;format",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 545,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def log_error(self, format, *args):\n        \"\"\"Log an error.\n\n        This is called when a request cannot be fulfilled.  By\n        default it passes the message on to log_message().\n\n        Arguments are the same as for log_message().\n\n        XXX This should go to the separate error log.\n\n        \"\"\"\n\n        self.log_message(format, *args)",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.log_message": {
        "API_name": "http.server.BaseHTTPRequestHandler.log_message",
        "loc_name": "http.server.BaseHTTPRequestHandler.log_message",
        "args": "self;format",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 559,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def log_message(self, format, *args):\n        \"\"\"Log an arbitrary message.\n\n        This is used by all other logging functions.  Override\n        it if you have specific logging wishes.\n\n        The first argument, FORMAT, is a format string for the\n        message to be logged.  If the format string contains\n        any % escapes requiring parameters, they should be\n        specified as subsequent arguments (it's just like\n        printf!).\n\n        The client ip and current date/time are prefixed to\n        every message.\n\n        \"\"\"\n\n        sys.stderr.write(\"%s - - [%s] %s\\n\" %\n                         (self.address_string(),\n                          self.log_date_time_string(),\n                          format%args))",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.version_string": {
        "API_name": "http.server.BaseHTTPRequestHandler.version_string",
        "loc_name": "http.server.BaseHTTPRequestHandler.version_string",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 581,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def version_string(self):\n        \"\"\"Return the server software version string.\"\"\"\n        return self.server_version + ' ' + self.sys_version",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.date_time_string": {
        "API_name": "http.server.BaseHTTPRequestHandler.date_time_string",
        "loc_name": "http.server.BaseHTTPRequestHandler.date_time_string",
        "args": "self;timestamp",
        "args_default": 1,
        "filepath": "http.server",
        "lineno": 585,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def date_time_string(self, timestamp=None):\n        \"\"\"Return the current date and time formatted for a message header.\"\"\"\n        if timestamp is None:\n            timestamp = time.time()\n        return email.utils.formatdate(timestamp, usegmt=True)",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.log_date_time_string": {
        "API_name": "http.server.BaseHTTPRequestHandler.log_date_time_string",
        "loc_name": "http.server.BaseHTTPRequestHandler.log_date_time_string",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 591,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def log_date_time_string(self):\n        \"\"\"Return the current time formatted for logging.\"\"\"\n        now = time.time()\n        year, month, day, hh, mm, ss, x, y, z = time.localtime(now)\n        s = \"%02d/%3s/%04d %02d:%02d:%02d\" % (\n                day, self.monthname[month], year, hh, mm, ss)\n        return s",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler.address_string": {
        "API_name": "http.server.BaseHTTPRequestHandler.address_string",
        "loc_name": "http.server.BaseHTTPRequestHandler.address_string",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 605,
        "namespace": "BaseHTTPRequestHandler",
        "body": "    def address_string(self):\n        \"\"\"Return the client address.\"\"\"\n\n        return self.client_address[0]",
        "name_type": "stdlib"
    },
    "http.server.BaseHTTPRequestHandler": {
        "API_name": "http.server.BaseHTTPRequestHandler",
        "loc_name": "http.server.BaseHTTPRequestHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": 146,
        "namespace": "BaseHTTPRequestHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler": {
        "API_name": "http.server.SimpleHTTPRequestHandler",
        "loc_name": "http.server.SimpleHTTPRequestHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": 626,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.__init__": {
        "API_name": "http.server.SimpleHTTPRequestHandler.__init__",
        "loc_name": "http.server.SimpleHTTPRequestHandler.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 647,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def __init__(self, *args, directory=None, **kwargs):\n        if directory is None:\n            directory = os.getcwd()\n        self.directory = os.fspath(directory)\n        super().__init__(*args, **kwargs)",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.do_GET": {
        "API_name": "http.server.SimpleHTTPRequestHandler.do_GET",
        "loc_name": "http.server.SimpleHTTPRequestHandler.do_GET",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 653,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def do_GET(self):\n        \"\"\"Serve a GET request.\"\"\"\n        f = self.send_head()\n        if f:\n            try:\n                self.copyfile(f, self.wfile)\n            finally:\n                f.close()",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.do_HEAD": {
        "API_name": "http.server.SimpleHTTPRequestHandler.do_HEAD",
        "loc_name": "http.server.SimpleHTTPRequestHandler.do_HEAD",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 662,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def do_HEAD(self):\n        \"\"\"Serve a HEAD request.\"\"\"\n        f = self.send_head()\n        if f:\n            f.close()",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.send_head": {
        "API_name": "http.server.SimpleHTTPRequestHandler.send_head",
        "loc_name": "http.server.SimpleHTTPRequestHandler.send_head",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 668,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def send_head(self):\n        \"\"\"Common code for GET and HEAD commands.\n\n        This sends the response code and MIME headers.\n\n        Return value is either a file object (which has to be copied\n        to the outputfile by the caller unless the command was HEAD,\n        and must be closed by the caller under all circumstances), or\n        None, in which case the caller has nothing further to do.\n\n        \"\"\"\n        path = self.translate_path(self.path)\n        f = None\n        if os.path.isdir(path):\n            parts = urllib.parse.urlsplit(self.path)\n            if not parts.path.endswith('/'):\n                # redirect browser - doing basically what apache does\n                self.send_response(HTTPStatus.MOVED_PERMANENTLY)\n                new_parts = (parts[0], parts[1], parts[2] + '/',\n                             parts[3], parts[4])\n                new_url = urllib.parse.urlunsplit(new_parts)\n                self.send_header(\"Location\", new_url)\n                self.send_header(\"Content-Length\", \"0\")\n                self.end_headers()\n                return None\n            for index in \"index.html\", \"index.htm\":\n                index = os.path.join(path, index)\n                if os.path.exists(index):\n                    path = index\n                    break\n            else:\n                return self.list_directory(path)\n        ctype = self.guess_type(path)\n        # check for trailing \"/\" which should return 404. See Issue17324\n        # The test for this was added in test_httpserver.py\n        # However, some OS platforms accept a trailingSlash as a filename\n        # See discussion on python-dev and Issue34711 regarding\n        # parseing and rejection of filenames with a trailing slash\n        if path.endswith(\"/\"):\n            self.send_error(HTTPStatus.NOT_FOUND, \"File not found\")\n            return None\n        try:\n            f = open(path, 'rb')\n        except OSError:\n            self.send_error(HTTPStatus.NOT_FOUND, \"File not found\")\n            return None\n\n        try:\n            fs = os.fstat(f.fileno())\n            # Use browser cache if possible\n            if (\"If-Modified-Since\" in self.headers\n                    and \"If-None-Match\" not in self.headers):\n                # compare If-Modified-Since and time of last file modification\n                try:\n                    ims = email.utils.parsedate_to_datetime(\n                        self.headers[\"If-Modified-Since\"])\n                except (TypeError, IndexError, OverflowError, ValueError):\n                    # ignore ill-formed values\n                    pass\n                else:\n                    if ims.tzinfo is None:\n                        # obsolete format with no timezone, cf.\n                        # https://tools.ietf.org/html/rfc7231#section-7.1.1.1\n                        ims = ims.replace(tzinfo=datetime.timezone.utc)\n                    if ims.tzinfo is datetime.timezone.utc:\n                        # compare to UTC datetime of last modification\n                        last_modif = datetime.datetime.fromtimestamp(\n                            fs.st_mtime, datetime.timezone.utc)\n                        # remove microseconds, like in If-Modified-Since\n                        last_modif = last_modif.replace(microsecond=0)\n\n                        if last_modif <= ims:\n                            self.send_response(HTTPStatus.NOT_MODIFIED)\n                            self.end_headers()\n                            f.close()\n                            return None\n\n            self.send_response(HTTPStatus.OK)\n            self.send_header(\"Content-type\", ctype)\n            self.send_header(\"Content-Length\", str(fs[6]))\n            self.send_header(\"Last-Modified\",\n                self.date_time_string(fs.st_mtime))\n            self.end_headers()\n            return f\n        except:\n            f.close()\n            raise",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.list_directory": {
        "API_name": "http.server.SimpleHTTPRequestHandler.list_directory",
        "loc_name": "http.server.SimpleHTTPRequestHandler.list_directory",
        "args": "self;path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 756,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def list_directory(self, path):\n        \"\"\"Helper to produce a directory listing (absent index.html).\n\n        Return value is either a file object, or None (indicating an\n        error).  In either case, the headers are sent, making the\n        interface the same as for send_head().\n\n        \"\"\"\n        try:\n            list = os.listdir(path)\n        except OSError:\n            self.send_error(\n                HTTPStatus.NOT_FOUND,\n                \"No permission to list directory\")\n            return None\n        list.sort(key=lambda a: a.lower())\n        r = []\n        try:\n            displaypath = urllib.parse.unquote(self.path,\n                                               errors='surrogatepass')\n        except UnicodeDecodeError:\n            displaypath = urllib.parse.unquote(path)\n        displaypath = html.escape(displaypath, quote=False)\n        enc = sys.getfilesystemencoding()\n        title = 'Directory listing for %s' % displaypath\n        r.append('<!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01//EN\" '\n                 '\"http://www.w3.org/TR/html4/strict.dtd\">')\n        r.append('<html>\\n<head>')\n        r.append('<meta http-equiv=\"Content-Type\" '\n                 'content=\"text/html; charset=%s\">' % enc)\n        r.append('<title>%s</title>\\n</head>' % title)\n        r.append('<body>\\n<h1>%s</h1>' % title)\n        r.append('<hr>\\n<ul>')\n        for name in list:\n            fullname = os.path.join(path, name)\n            displayname = linkname = name\n            # Append / for directories or @ for symbolic links\n            if os.path.isdir(fullname):\n                displayname = name + \"/\"\n                linkname = name + \"/\"\n            if os.path.islink(fullname):\n                displayname = name + \"@\"\n                # Note: a link to a directory displays with @ and links with /\n            r.append('<li><a href=\"%s\">%s</a></li>'\n                    % (urllib.parse.quote(linkname,\n                                          errors='surrogatepass'),\n                       html.escape(displayname, quote=False)))\n        r.append('</ul>\\n<hr>\\n</body>\\n</html>\\n')\n        encoded = '\\n'.join(r).encode(enc, 'surrogateescape')\n        f = io.BytesIO()\n        f.write(encoded)\n        f.seek(0)\n        self.send_response(HTTPStatus.OK)\n        self.send_header(\"Content-type\", \"text/html; charset=%s\" % enc)\n        self.send_header(\"Content-Length\", str(len(encoded)))\n        self.end_headers()\n        return f",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.translate_path": {
        "API_name": "http.server.SimpleHTTPRequestHandler.translate_path",
        "loc_name": "http.server.SimpleHTTPRequestHandler.translate_path",
        "args": "self;path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 814,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def translate_path(self, path):\n        \"\"\"Translate a /-separated PATH to the local filename syntax.\n\n        Components that mean special things to the local file system\n        (e.g. drive or directory names) are ignored.  (XXX They should\n        probably be diagnosed.)\n\n        \"\"\"\n        # abandon query parameters\n        path = path.split('?',1)[0]\n        path = path.split('#',1)[0]\n        # Don't forget explicit trailing slash when normalizing. Issue17324\n        trailing_slash = path.rstrip().endswith('/')\n        try:\n            path = urllib.parse.unquote(path, errors='surrogatepass')\n        except UnicodeDecodeError:\n            path = urllib.parse.unquote(path)\n        path = posixpath.normpath(path)\n        words = path.split('/')\n        words = filter(None, words)\n        path = self.directory\n        for word in words:\n            if os.path.dirname(word) or word in (os.curdir, os.pardir):\n                # Ignore components that are not a simple file/directory name\n                continue\n            path = os.path.join(path, word)\n        if trailing_slash:\n            path += '/'\n        return path",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.copyfile": {
        "API_name": "http.server.SimpleHTTPRequestHandler.copyfile",
        "loc_name": "http.server.SimpleHTTPRequestHandler.copyfile",
        "args": "self;source;outputfile",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 844,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def copyfile(self, source, outputfile):\n        \"\"\"Copy all data between two file objects.\n\n        The SOURCE argument is a file object open for reading\n        (or anything with a read() method) and the DESTINATION\n        argument is a file object open for writing (or\n        anything with a write() method).\n\n        The only reason for overriding this would be to change\n        the block size or perhaps to replace newlines by CRLF\n        -- note however that this the default server uses this\n        to copy binary data as well.\n\n        \"\"\"\n        shutil.copyfileobj(source, outputfile)",
        "name_type": "stdlib"
    },
    "http.server.SimpleHTTPRequestHandler.guess_type": {
        "API_name": "http.server.SimpleHTTPRequestHandler.guess_type",
        "loc_name": "http.server.SimpleHTTPRequestHandler.guess_type",
        "args": "self;path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 860,
        "namespace": "SimpleHTTPRequestHandler",
        "body": "    def guess_type(self, path):\n        \"\"\"Guess the type of a file.\n\n        Argument is a PATH (a filename).\n\n        Return value is a string of the form type/subtype,\n        usable for a MIME Content-type header.\n\n        The default implementation looks the file's extension\n        up in the table self.extensions_map, using application/octet-stream\n        as a default; however it would be permissible (if\n        slow) to look inside the data to make a better guess.\n\n        \"\"\"\n        base, ext = posixpath.splitext(path)\n        if ext in self.extensions_map:\n            return self.extensions_map[ext]\n        ext = ext.lower()\n        if ext in self.extensions_map:\n            return self.extensions_map[ext]\n        guess, _ = mimetypes.guess_type(path)\n        if guess:\n            return guess\n        return 'application/octet-stream'",
        "name_type": "stdlib"
    },
    "http.server._url_collapse_path": {
        "API_name": "http.server._url_collapse_path",
        "loc_name": "http.server._url_collapse_path",
        "args": "path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 888,
        "namespace": "*",
        "body": "def _url_collapse_path(path):\n    \"\"\"\n    Given a URL path, remove extra '/'s and '.' path elements and collapse\n    any '..' references and returns a collapsed path.\n\n    Implements something akin to RFC-2396 5.2 step 6 to parse relative paths.\n    The utility of this function is limited to is_cgi method and helps\n    preventing some security attacks.\n\n    Returns: The reconstituted URL, which will always start with a '/'.\n\n    Raises: IndexError if too many '..' occur within the path.\n\n    \"\"\"\n    # Query component should not be involved.\n    path, _, query = path.partition('?')\n    path = urllib.parse.unquote(path)\n\n    # Similar to os.path.split(os.path.normpath(path)) but specific to URL\n    # path semantics rather than local operating system semantics.\n    path_parts = path.split('/')\n    head_parts = []\n    for part in path_parts[:-1]:\n        if part == '..':\n            head_parts.pop() # IndexError if more '..' than prior parts\n        elif part and part != '.':\n            head_parts.append( part )\n    if path_parts:\n        tail_part = path_parts.pop()\n        if tail_part:\n            if tail_part == '..':\n                head_parts.pop()\n                tail_part = ''\n            elif tail_part == '.':\n                tail_part = ''\n    else:\n        tail_part = ''\n\n    if query:\n        tail_part = '?'.join((tail_part, query))\n\n    splitpath = ('/' + '/'.join(head_parts), tail_part)\n    collapsed_path = \"/\".join(splitpath)\n\n    return collapsed_path",
        "name_type": "stdlib"
    },
    "http.server.nobody_uid": {
        "API_name": "http.server.nobody_uid",
        "loc_name": "http.server.nobody_uid",
        "args": "",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 938,
        "namespace": "*",
        "body": "def nobody_uid():\n    \"\"\"Internal routine to get nobody's uid\"\"\"\n    global nobody\n    if nobody:\n        return nobody\n    try:\n        import pwd\n    except ImportError:\n        return -1\n    try:\n        nobody = pwd.getpwnam('nobody')[2]\n    except KeyError:\n        nobody = 1 + max(x[2] for x in pwd.getpwall())\n    return nobody",
        "name_type": "stdlib"
    },
    "http.server.executable": {
        "API_name": "http.server.executable",
        "loc_name": "http.server.executable",
        "args": "path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 954,
        "namespace": "*",
        "body": "def executable(path):\n    \"\"\"Test for executable file.\"\"\"\n    return os.access(path, os.X_OK)",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler.do_POST": {
        "API_name": "http.server.CGIHTTPRequestHandler.do_POST",
        "loc_name": "http.server.CGIHTTPRequestHandler.do_POST",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 976,
        "namespace": "CGIHTTPRequestHandler",
        "body": "    def do_POST(self):\n        \"\"\"Serve a POST request.\n\n        This is only implemented for CGI scripts.\n\n        \"\"\"\n\n        if self.is_cgi():\n            self.run_cgi()\n        else:\n            self.send_error(\n                HTTPStatus.NOT_IMPLEMENTED,\n                \"Can only POST to CGI scripts\")",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler.send_head": {
        "API_name": "http.server.CGIHTTPRequestHandler.send_head",
        "loc_name": "http.server.CGIHTTPRequestHandler.send_head",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 990,
        "namespace": "CGIHTTPRequestHandler",
        "body": "    def send_head(self):\n        \"\"\"Version of send_head that support CGI scripts\"\"\"\n        if self.is_cgi():\n            return self.run_cgi()\n        else:\n            return SimpleHTTPRequestHandler.send_head(self)",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler.is_cgi": {
        "API_name": "http.server.CGIHTTPRequestHandler.is_cgi",
        "loc_name": "http.server.CGIHTTPRequestHandler.is_cgi",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 997,
        "namespace": "CGIHTTPRequestHandler",
        "body": "    def is_cgi(self):\n        \"\"\"Test whether self.path corresponds to a CGI script.\n\n        Returns True and updates the cgi_info attribute to the tuple\n        (dir, rest) if self.path requires running a CGI script.\n        Returns False otherwise.\n\n        If any exception is raised, the caller should assume that\n        self.path was rejected as invalid and act accordingly.\n\n        The default implementation tests whether the normalized url\n        path begins with one of the strings in self.cgi_directories\n        (and the next character is a '/' or the end of the string).\n\n        \"\"\"\n        collapsed_path = _url_collapse_path(self.path)\n        dir_sep = collapsed_path.find('/', 1)\n        while dir_sep > 0 and not collapsed_path[:dir_sep] in self.cgi_directories:\n            dir_sep = collapsed_path.find('/', dir_sep+1)\n        if dir_sep > 0:\n            head, tail = collapsed_path[:dir_sep], collapsed_path[dir_sep+1:]\n            self.cgi_info = head, tail\n            return True\n        return False",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler.is_executable": {
        "API_name": "http.server.CGIHTTPRequestHandler.is_executable",
        "loc_name": "http.server.CGIHTTPRequestHandler.is_executable",
        "args": "self;path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 1025,
        "namespace": "CGIHTTPRequestHandler",
        "body": "    def is_executable(self, path):\n        \"\"\"Test whether argument path is an executable file.\"\"\"\n        return executable(path)",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler.is_python": {
        "API_name": "http.server.CGIHTTPRequestHandler.is_python",
        "loc_name": "http.server.CGIHTTPRequestHandler.is_python",
        "args": "self;path",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 1029,
        "namespace": "CGIHTTPRequestHandler",
        "body": "    def is_python(self, path):\n        \"\"\"Test whether argument path is a Python script.\"\"\"\n        head, tail = os.path.splitext(path)\n        return tail.lower() in (\".py\", \".pyw\")",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler.run_cgi": {
        "API_name": "http.server.CGIHTTPRequestHandler.run_cgi",
        "loc_name": "http.server.CGIHTTPRequestHandler.run_cgi",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 1034,
        "namespace": "CGIHTTPRequestHandler",
        "body": "    def run_cgi(self):\n        \"\"\"Execute a CGI script.\"\"\"\n        dir, rest = self.cgi_info\n        path = dir + '/' + rest\n        i = path.find('/', len(dir)+1)\n        while i >= 0:\n            nextdir = path[:i]\n            nextrest = path[i+1:]\n\n            scriptdir = self.translate_path(nextdir)\n            if os.path.isdir(scriptdir):\n                dir, rest = nextdir, nextrest\n                i = path.find('/', len(dir)+1)\n            else:\n                break\n\n        # find an explicit query string, if present.\n        rest, _, query = rest.partition('?')\n\n        # dissect the part after the directory name into a script name &\n        # a possible additional path, to be stored in PATH_INFO.\n        i = rest.find('/')\n        if i >= 0:\n            script, rest = rest[:i], rest[i:]\n        else:\n            script, rest = rest, ''\n\n        scriptname = dir + '/' + script\n        scriptfile = self.translate_path(scriptname)\n        if not os.path.exists(scriptfile):\n            self.send_error(\n                HTTPStatus.NOT_FOUND,\n                \"No such CGI script (%r)\" % scriptname)\n            return\n        if not os.path.isfile(scriptfile):\n            self.send_error(\n                HTTPStatus.FORBIDDEN,\n                \"CGI script is not a plain file (%r)\" % scriptname)\n            return\n        ispy = self.is_python(scriptname)\n        if self.have_fork or not ispy:\n            if not self.is_executable(scriptfile):\n                self.send_error(\n                    HTTPStatus.FORBIDDEN,\n                    \"CGI script is not executable (%r)\" % scriptname)\n                return\n\n        # Reference: http://hoohoo.ncsa.uiuc.edu/cgi/env.html\n        # XXX Much of the following could be prepared ahead of time!\n        env = copy.deepcopy(os.environ)\n        env['SERVER_SOFTWARE'] = self.version_string()\n        env['SERVER_NAME'] = self.server.server_name\n        env['GATEWAY_INTERFACE'] = 'CGI/1.1'\n        env['SERVER_PROTOCOL'] = self.protocol_version\n        env['SERVER_PORT'] = str(self.server.server_port)\n        env['REQUEST_METHOD'] = self.command\n        uqrest = urllib.parse.unquote(rest)\n        env['PATH_INFO'] = uqrest\n        env['PATH_TRANSLATED'] = self.translate_path(uqrest)\n        env['SCRIPT_NAME'] = scriptname\n        if query:\n            env['QUERY_STRING'] = query\n        env['REMOTE_ADDR'] = self.client_address[0]\n        authorization = self.headers.get(\"authorization\")\n        if authorization:\n            authorization = authorization.split()\n            if len(authorization) == 2:\n                import base64, binascii\n                env['AUTH_TYPE'] = authorization[0]\n                if authorization[0].lower() == \"basic\":\n                    try:\n                        authorization = authorization[1].encode('ascii')\n                        authorization = base64.decodebytes(authorization).\\\n                                        decode('ascii')\n                    except (binascii.Error, UnicodeError):\n                        pass\n                    else:\n                        authorization = authorization.split(':')\n                        if len(authorization) == 2:\n                            env['REMOTE_USER'] = authorization[0]\n        # XXX REMOTE_IDENT\n        if self.headers.get('content-type') is None:\n            env['CONTENT_TYPE'] = self.headers.get_content_type()\n        else:\n            env['CONTENT_TYPE'] = self.headers['content-type']\n        length = self.headers.get('content-length')\n        if length:\n            env['CONTENT_LENGTH'] = length\n        referer = self.headers.get('referer')\n        if referer:\n            env['HTTP_REFERER'] = referer\n        accept = self.headers.get_all('accept', ())\n        env['HTTP_ACCEPT'] = ','.join(accept)\n        ua = self.headers.get('user-agent')\n        if ua:\n            env['HTTP_USER_AGENT'] = ua\n        co = filter(None, self.headers.get_all('cookie', []))\n        cookie_str = ', '.join(co)\n        if cookie_str:\n            env['HTTP_COOKIE'] = cookie_str\n        # XXX Other HTTP_* headers\n        # Since we're setting the env in the parent, provide empty\n        # values to override previously set values\n        for k in ('QUERY_STRING', 'REMOTE_HOST', 'CONTENT_LENGTH',\n                  'HTTP_USER_AGENT', 'HTTP_COOKIE', 'HTTP_REFERER'):\n            env.setdefault(k, \"\")\n\n        self.send_response(HTTPStatus.OK, \"Script output follows\")\n        self.flush_headers()\n\n        decoded_query = query.replace('+', ' ')\n\n        if self.have_fork:\n            # Unix -- fork as we should\n            args = [script]\n            if '=' not in decoded_query:\n                args.append(decoded_query)\n            nobody = nobody_uid()\n            self.wfile.flush() # Always flush before forking\n            pid = os.fork()\n            if pid != 0:\n                # Parent\n                pid, sts = os.waitpid(pid, 0)\n                # throw away additional data [see bug #427345]\n                while select.select([self.rfile], [], [], 0)[0]:\n                    if not self.rfile.read(1):\n                        break\n                exitcode = os.waitstatus_to_exitcode(sts)\n                if exitcode:\n                    self.log_error(f\"CGI script exit code {exitcode}\")\n                return\n            # Child\n            try:\n                try:\n                    os.setuid(nobody)\n                except OSError:\n                    pass\n                os.dup2(self.rfile.fileno(), 0)\n                os.dup2(self.wfile.fileno(), 1)\n                os.execve(scriptfile, args, env)\n            except:\n                self.server.handle_error(self.request, self.client_address)\n                os._exit(127)\n\n        else:\n            # Non-Unix -- use subprocess\n            import subprocess\n            cmdline = [scriptfile]\n            if self.is_python(scriptfile):\n                interp = sys.executable\n                if interp.lower().endswith(\"w.exe\"):\n                    # On Windows, use python.exe, not pythonw.exe\n                    interp = interp[:-5] + interp[-4:]\n                cmdline = [interp, '-u'] + cmdline\n            if '=' not in query:\n                cmdline.append(query)\n            self.log_message(\"command: %s\", subprocess.list2cmdline(cmdline))\n            try:\n                nbytes = int(length)\n            except (TypeError, ValueError):\n                nbytes = 0\n            p = subprocess.Popen(cmdline,\n                                 stdin=subprocess.PIPE,\n                                 stdout=subprocess.PIPE,\n                                 stderr=subprocess.PIPE,\n                                 env = env\n                                 )\n            if self.command.lower() == \"post\" and nbytes > 0:\n                data = self.rfile.read(nbytes)\n            else:\n                data = None\n            # throw away additional data [see bug #427345]\n            while select.select([self.rfile._sock], [], [], 0)[0]:\n                if not self.rfile._sock.recv(1):\n                    break\n            stdout, stderr = p.communicate(data)\n            self.wfile.write(stdout)\n            if stderr:\n                self.log_error('%s', stderr)\n            p.stderr.close()\n            p.stdout.close()\n            status = p.returncode\n            if status:\n                self.log_error(\"CGI script exit status %#x\", status)\n            else:\n                self.log_message(\"CGI script exited OK\")",
        "name_type": "stdlib"
    },
    "http.server.CGIHTTPRequestHandler": {
        "API_name": "http.server.CGIHTTPRequestHandler",
        "loc_name": "http.server.CGIHTTPRequestHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": 959,
        "namespace": "CGIHTTPRequestHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "http.server._get_best_family": {
        "API_name": "http.server._get_best_family",
        "loc_name": "http.server._get_best_family",
        "args": "",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 1222,
        "namespace": "*",
        "body": "def _get_best_family(*address):\n    infos = socket.getaddrinfo(\n        *address,\n        type=socket.SOCK_STREAM,\n        flags=socket.AI_PASSIVE,\n    )\n    family, type, proto, canonname, sockaddr = next(iter(infos))\n    return family, sockaddr",
        "name_type": "stdlib"
    },
    "http.server.test": {
        "API_name": "http.server.test",
        "loc_name": "http.server.test",
        "args": "HandlerClass;ServerClass;protocol;port;bind",
        "args_default": 5,
        "filepath": "http.server",
        "lineno": 1232,
        "namespace": "*",
        "body": "def test(HandlerClass=BaseHTTPRequestHandler,\n         ServerClass=ThreadingHTTPServer,\n         protocol=\"HTTP/1.0\", port=8000, bind=None):\n    \"\"\"Test the HTTP request handler class.\n\n    This runs an HTTP server on port 8000 (or the port argument).\n\n    \"\"\"\n    ServerClass.address_family, addr = _get_best_family(bind, port)\n    HandlerClass.protocol_version = protocol\n    with ServerClass(addr, HandlerClass) as httpd:\n        host, port = httpd.socket.getsockname()[:2]\n        url_host = f'[{host}]' if ':' in host else host\n        print(\n            f\"Serving HTTP on {host} port {port} \"\n            f\"(http://{url_host}:{port}/) ...\"\n        )\n        try:\n            httpd.serve_forever()\n        except KeyboardInterrupt:\n            print(\"\\nKeyboard interrupt received, exiting.\")\n            sys.exit(0)",
        "name_type": "stdlib"
    },
    "http.server.DualStackServer.server_bind": {
        "API_name": "http.server.DualStackServer.server_bind",
        "loc_name": "http.server.DualStackServer.server_bind",
        "args": "self",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 1280,
        "namespace": "DualStackServer",
        "body": "        def server_bind(self):\n            # suppress exception when protocol is IPv4\n            with contextlib.suppress(Exception):\n                self.socket.setsockopt(\n                    socket.IPPROTO_IPV6, socket.IPV6_V6ONLY, 0)\n            return super().server_bind()",
        "name_type": "stdlib"
    },
    "http.server.DualStackServer.finish_request": {
        "API_name": "http.server.DualStackServer.finish_request",
        "loc_name": "http.server.DualStackServer.finish_request",
        "args": "self;request;client_address",
        "args_default": 0,
        "filepath": "http.server",
        "lineno": 1287,
        "namespace": "DualStackServer",
        "body": "        def finish_request(self, request, client_address):\n            self.RequestHandlerClass(request, client_address, self,\n                                     directory=args.directory)",
        "name_type": "stdlib"
    },
    "http.server.DualStackServer": {
        "API_name": "http.server.DualStackServer",
        "loc_name": "http.server.DualStackServer",
        "args": "*",
        "args_default": "*",
        "filepath": "http.server",
        "lineno": 1278,
        "namespace": "DualStackServer",
        "body": "",
        "name_type": "stdlib"
    },
    "http": {
        "API_name": "http",
        "loc_name": "http",
        "args": "*",
        "args_default": "*",
        "filepath": "http",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['HTTPStatus']",
        "name_type": "stdlib"
    },
    "http.HTTPStatus.__new__": {
        "API_name": "http.HTTPStatus.__new__",
        "loc_name": "http.HTTPStatus.__new__",
        "args": "cls;value;phrase;description",
        "args_default": 1,
        "filepath": "http",
        "lineno": 24,
        "namespace": "HTTPStatus",
        "body": "    def __new__(cls, value, phrase, description=''):\n        obj = int.__new__(cls, value)\n        obj._value_ = value\n\n        obj.phrase = phrase\n        obj.description = description\n        return obj",
        "name_type": "stdlib"
    },
    "http.HTTPStatus": {
        "API_name": "http.HTTPStatus",
        "loc_name": "http.HTTPStatus",
        "args": "*",
        "args_default": "*",
        "filepath": "http",
        "lineno": 5,
        "namespace": "HTTPStatus",
        "body": "",
        "name_type": "stdlib"
    },
    "json.decoder": {
        "API_name": "json.decoder",
        "loc_name": "json.decoder",
        "args": "*",
        "args_default": "*",
        "filepath": "json.decoder",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Implementation of JSONDecoder\n\"\"\"\ntry:\n    from _json import scanstring as c_scanstring\nexcept ImportError:\n    c_scanstring = None\n__all__ = ['JSONDecoder', 'JSONDecodeError']\nFLAGS = re.VERBOSE | re.MULTILINE | re.DOTALL\nNaN = float('nan')\nPosInf = float('inf')\nNegInf = float('-inf')\n_CONSTANTS = {\n    '-Infinity': NegInf,\n    'Infinity': PosInf,\n    'NaN': NaN,\n}\nSTRINGCHUNK = re.compile(r'(.*?)([\"\\\\\\x00-\\x1f])', FLAGS)\nBACKSLASH = {\n    '\"': '\"', '\\\\': '\\\\', '/': '/',\n    'b': '\\b', 'f': '\\f', 'n': '\\n', 'r': '\\r', 't': '\\t',\n}\nscanstring = c_scanstring or py_scanstring\nWHITESPACE = re.compile(r'[ \\t\\n\\r]*', FLAGS)\nWHITESPACE_STR = ' \\t\\n\\r'",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecodeError": {
        "API_name": "json.decoder.JSONDecodeError",
        "loc_name": "json.decoder.JSONDecodeError",
        "args": "*",
        "args_default": "*",
        "filepath": "json.decoder",
        "lineno": 20,
        "namespace": "JSONDecodeError",
        "body": "",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecodeError.__init__": {
        "API_name": "json.decoder.JSONDecodeError.__init__",
        "loc_name": "json.decoder.JSONDecodeError.__init__",
        "args": "self;msg;doc;pos",
        "args_default": 0,
        "filepath": "json.decoder",
        "lineno": 31,
        "namespace": "JSONDecodeError",
        "body": "    def __init__(self, msg, doc, pos):\n        lineno = doc.count('\\n', 0, pos) + 1\n        colno = pos - doc.rfind('\\n', 0, pos)\n        errmsg = '%s: line %d column %d (char %d)' % (msg, lineno, colno, pos)\n        ValueError.__init__(self, errmsg)\n        self.msg = msg\n        self.doc = doc\n        self.pos = pos\n        self.lineno = lineno\n        self.colno = colno",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecodeError.__reduce__": {
        "API_name": "json.decoder.JSONDecodeError.__reduce__",
        "loc_name": "json.decoder.JSONDecodeError.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "json.decoder",
        "lineno": 42,
        "namespace": "JSONDecodeError",
        "body": "    def __reduce__(self):\n        return self.__class__, (self.msg, self.doc, self.pos)",
        "name_type": "stdlib"
    },
    "json.decoder._decode_uXXXX": {
        "API_name": "json.decoder._decode_uXXXX",
        "loc_name": "json.decoder._decode_uXXXX",
        "args": "s;pos",
        "args_default": 0,
        "filepath": "json.decoder",
        "lineno": 59,
        "namespace": "*",
        "body": "def _decode_uXXXX(s, pos):\n    esc = s[pos + 1:pos + 5]\n    if len(esc) == 4 and esc[1] not in 'xX':\n        try:\n            return int(esc, 16)\n        except ValueError:\n            pass\n    msg = \"Invalid \\\\uXXXX escape\"\n    raise JSONDecodeError(msg, s, pos)",
        "name_type": "stdlib"
    },
    "json.decoder.py_scanstring": {
        "API_name": "json.decoder.py_scanstring",
        "loc_name": "json.decoder.py_scanstring",
        "args": "s;end;strict;_b;_m",
        "args_default": 3,
        "filepath": "json.decoder",
        "lineno": 69,
        "namespace": "*",
        "body": "def py_scanstring(s, end, strict=True,\n        _b=BACKSLASH, _m=STRINGCHUNK.match):\n    \"\"\"Scan the string s for a JSON string. End is the index of the\n    character in s after the quote that started the JSON string.\n    Unescapes all valid JSON string escape sequences and raises ValueError\n    on attempt to decode an invalid string. If strict is False then literal\n    control characters are allowed in the string.\n\n    Returns a tuple of the decoded string and the index of the character in s\n    after the end quote.\"\"\"\n    chunks = []\n    _append = chunks.append\n    begin = end - 1\n    while 1:\n        chunk = _m(s, end)\n        if chunk is None:\n            raise JSONDecodeError(\"Unterminated string starting at\", s, begin)\n        end = chunk.end()\n        content, terminator = chunk.groups()\n        # Content is contains zero or more unescaped string characters\n        if content:\n            _append(content)\n        # Terminator is the end of string, a literal control character,\n        # or a backslash denoting that an escape sequence follows\n        if terminator == '\"':\n            break\n        elif terminator != '\\\\':\n            if strict:\n                #msg = \"Invalid control character %r at\" % (terminator,)\n                msg = \"Invalid control character {0!r} at\".format(terminator)\n                raise JSONDecodeError(msg, s, end)\n            else:\n                _append(terminator)\n                continue\n        try:\n            esc = s[end]\n        except IndexError:\n            raise JSONDecodeError(\"Unterminated string starting at\",\n                                  s, begin) from None\n        # If not a unicode escape sequence, must be in the lookup table\n        if esc != 'u':\n            try:\n                char = _b[esc]\n            except KeyError:\n                msg = \"Invalid \\\\escape: {0!r}\".format(esc)\n                raise JSONDecodeError(msg, s, end)\n            end += 1\n        else:\n            uni = _decode_uXXXX(s, end)\n            end += 5\n            if 0xd800 <= uni <= 0xdbff and s[end:end + 2] == '\\\\u':\n                uni2 = _decode_uXXXX(s, end + 1)\n                if 0xdc00 <= uni2 <= 0xdfff:\n                    uni = 0x10000 + (((uni - 0xd800) << 10) | (uni2 - 0xdc00))\n                    end += 6\n            char = chr(uni)\n        _append(char)\n    return ''.join(chunks), end",
        "name_type": "stdlib"
    },
    "json.decoder.JSONObject": {
        "API_name": "json.decoder.JSONObject",
        "loc_name": "json.decoder.JSONObject",
        "args": "s_and_end;strict;scan_once;object_hook;object_pairs_hook;memo;_w;_ws",
        "args_default": 3,
        "filepath": "json.decoder",
        "lineno": 136,
        "namespace": "*",
        "body": "def JSONObject(s_and_end, strict, scan_once, object_hook, object_pairs_hook,\n               memo=None, _w=WHITESPACE.match, _ws=WHITESPACE_STR):\n    s, end = s_and_end\n    pairs = []\n    pairs_append = pairs.append\n    # Backwards compatibility\n    if memo is None:\n        memo = {}\n    memo_get = memo.setdefault\n    # Use a slice to prevent IndexError from being raised, the following\n    # check will raise a more specific ValueError if the string is empty\n    nextchar = s[end:end + 1]\n    # Normally we expect nextchar == '\"'\n    if nextchar != '\"':\n        if nextchar in _ws:\n            end = _w(s, end).end()\n            nextchar = s[end:end + 1]\n        # Trivial empty object\n        if nextchar == '}':\n            if object_pairs_hook is not None:\n                result = object_pairs_hook(pairs)\n                return result, end + 1\n            pairs = {}\n            if object_hook is not None:\n                pairs = object_hook(pairs)\n            return pairs, end + 1\n        elif nextchar != '\"':\n            raise JSONDecodeError(\n                \"Expecting property name enclosed in double quotes\", s, end)\n    end += 1\n    while True:\n        key, end = scanstring(s, end, strict)\n        key = memo_get(key, key)\n        # To skip some function call overhead we optimize the fast paths where\n        # the JSON key separator is \": \" or just \":\".\n        if s[end:end + 1] != ':':\n            end = _w(s, end).end()\n            if s[end:end + 1] != ':':\n                raise JSONDecodeError(\"Expecting ':' delimiter\", s, end)\n        end += 1\n\n        try:\n            if s[end] in _ws:\n                end += 1\n                if s[end] in _ws:\n                    end = _w(s, end + 1).end()\n        except IndexError:\n            pass\n\n        try:\n            value, end = scan_once(s, end)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        pairs_append((key, value))\n        try:\n            nextchar = s[end]\n            if nextchar in _ws:\n                end = _w(s, end + 1).end()\n                nextchar = s[end]\n        except IndexError:\n            nextchar = ''\n        end += 1\n\n        if nextchar == '}':\n            break\n        elif nextchar != ',':\n            raise JSONDecodeError(\"Expecting ',' delimiter\", s, end - 1)\n        end = _w(s, end).end()\n        nextchar = s[end:end + 1]\n        end += 1\n        if nextchar != '\"':\n            raise JSONDecodeError(\n                \"Expecting property name enclosed in double quotes\", s, end - 1)\n    if object_pairs_hook is not None:\n        result = object_pairs_hook(pairs)\n        return result, end\n    pairs = dict(pairs)\n    if object_hook is not None:\n        pairs = object_hook(pairs)\n    return pairs, end",
        "name_type": "stdlib"
    },
    "json.decoder.JSONArray": {
        "API_name": "json.decoder.JSONArray",
        "loc_name": "json.decoder.JSONArray",
        "args": "s_and_end;scan_once;_w;_ws",
        "args_default": 2,
        "filepath": "json.decoder",
        "lineno": 217,
        "namespace": "*",
        "body": "def JSONArray(s_and_end, scan_once, _w=WHITESPACE.match, _ws=WHITESPACE_STR):\n    s, end = s_and_end\n    values = []\n    nextchar = s[end:end + 1]\n    if nextchar in _ws:\n        end = _w(s, end + 1).end()\n        nextchar = s[end:end + 1]\n    # Look-ahead for trivial empty array\n    if nextchar == ']':\n        return values, end + 1\n    _append = values.append\n    while True:\n        try:\n            value, end = scan_once(s, end)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        _append(value)\n        nextchar = s[end:end + 1]\n        if nextchar in _ws:\n            end = _w(s, end + 1).end()\n            nextchar = s[end:end + 1]\n        end += 1\n        if nextchar == ']':\n            break\n        elif nextchar != ',':\n            raise JSONDecodeError(\"Expecting ',' delimiter\", s, end - 1)\n        try:\n            if s[end] in _ws:\n                end += 1\n                if s[end] in _ws:\n                    end = _w(s, end + 1).end()\n        except IndexError:\n            pass\n\n    return values, end",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecoder": {
        "API_name": "json.decoder.JSONDecoder",
        "loc_name": "json.decoder.JSONDecoder",
        "args": "*",
        "args_default": "*",
        "filepath": "json.decoder",
        "lineno": 254,
        "namespace": "JSONDecoder",
        "body": "",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecoder.__init__": {
        "API_name": "json.decoder.JSONDecoder.__init__",
        "loc_name": "json.decoder.JSONDecoder.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "json.decoder",
        "lineno": 284,
        "namespace": "JSONDecoder",
        "body": "    def __init__(self, *, object_hook=None, parse_float=None,\n            parse_int=None, parse_constant=None, strict=True,\n            object_pairs_hook=None):\n        \"\"\"``object_hook``, if specified, will be called with the result\n        of every JSON object decoded and its return value will be used in\n        place of the given ``dict``.  This can be used to provide custom\n        deserializations (e.g. to support JSON-RPC class hinting).\n\n        ``object_pairs_hook``, if specified will be called with the result of\n        every JSON object decoded with an ordered list of pairs.  The return\n        value of ``object_pairs_hook`` will be used instead of the ``dict``.\n        This feature can be used to implement custom decoders.\n        If ``object_hook`` is also defined, the ``object_pairs_hook`` takes\n        priority.\n\n        ``parse_float``, if specified, will be called with the string\n        of every JSON float to be decoded. By default this is equivalent to\n        float(num_str). This can be used to use another datatype or parser\n        for JSON floats (e.g. decimal.Decimal).\n\n        ``parse_int``, if specified, will be called with the string\n        of every JSON int to be decoded. By default this is equivalent to\n        int(num_str). This can be used to use another datatype or parser\n        for JSON integers (e.g. float).\n\n        ``parse_constant``, if specified, will be called with one of the\n        following strings: -Infinity, Infinity, NaN.\n        This can be used to raise an exception if invalid JSON numbers\n        are encountered.\n\n        If ``strict`` is false (true is the default), then control\n        characters will be allowed inside strings.  Control characters in\n        this context are those with character codes in the 0-31 range,\n        including ``'\\\\t'`` (tab), ``'\\\\n'``, ``'\\\\r'`` and ``'\\\\0'``.\n        \"\"\"\n        self.object_hook = object_hook\n        self.parse_float = parse_float or float\n        self.parse_int = parse_int or int\n        self.parse_constant = parse_constant or _CONSTANTS.__getitem__\n        self.strict = strict\n        self.object_pairs_hook = object_pairs_hook\n        self.parse_object = JSONObject\n        self.parse_array = JSONArray\n        self.parse_string = scanstring\n        self.memo = {}\n        self.scan_once = scanner.make_scanner(self)",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecoder.decode": {
        "API_name": "json.decoder.JSONDecoder.decode",
        "loc_name": "json.decoder.JSONDecoder.decode",
        "args": "self;s;_w",
        "args_default": 1,
        "filepath": "json.decoder",
        "lineno": 332,
        "namespace": "JSONDecoder",
        "body": "    def decode(self, s, _w=WHITESPACE.match):\n        \"\"\"Return the Python representation of ``s`` (a ``str`` instance\n        containing a JSON document).\n\n        \"\"\"\n        obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n        end = _w(s, end).end()\n        if end != len(s):\n            raise JSONDecodeError(\"Extra data\", s, end)\n        return obj",
        "name_type": "stdlib"
    },
    "json.decoder.JSONDecoder.raw_decode": {
        "API_name": "json.decoder.JSONDecoder.raw_decode",
        "loc_name": "json.decoder.JSONDecoder.raw_decode",
        "args": "self;s;idx",
        "args_default": 1,
        "filepath": "json.decoder",
        "lineno": 343,
        "namespace": "JSONDecoder",
        "body": "    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n\n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n\n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n            raise JSONDecodeError(\"Expecting value\", s, err.value) from None\n        return obj, end",
        "name_type": "stdlib"
    },
    "json.encoder": {
        "API_name": "json.encoder",
        "loc_name": "json.encoder",
        "args": "*",
        "args_default": "*",
        "filepath": "json.encoder",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Implementation of JSONEncoder\n\"\"\"\ntry:\n    from _json import encode_basestring_ascii as c_encode_basestring_ascii\nexcept ImportError:\n    c_encode_basestring_ascii = None\ntry:\n    from _json import encode_basestring as c_encode_basestring\nexcept ImportError:\n    c_encode_basestring = None\ntry:\n    from _json import make_encoder as c_make_encoder\nexcept ImportError:\n    c_make_encoder = None\nESCAPE = re.compile(r'[\\x00-\\x1f\\\\\"\\b\\f\\n\\r\\t]')\nESCAPE_ASCII = re.compile(r'([\\\\\"]|[^\\ -~])')\nHAS_UTF8 = re.compile(b'[\\x80-\\xff]')\nESCAPE_DCT = {\n    '\\\\': '\\\\\\\\',\n    '\"': '\\\\\"',\n    '\\b': '\\\\b',\n    '\\f': '\\\\f',\n    '\\n': '\\\\n',\n    '\\r': '\\\\r',\n    '\\t': '\\\\t',\n}\nfor i in range(0x20):\n    ESCAPE_DCT.setdefault(chr(i), '\\\\u{0:04x}'.format(i))\nINFINITY = float('inf')\nencode_basestring = (c_encode_basestring or py_encode_basestring)\nencode_basestring_ascii = (\n    c_encode_basestring_ascii or py_encode_basestring_ascii)",
        "name_type": "stdlib"
    },
    "json.encoder.py_encode_basestring": {
        "API_name": "json.encoder.py_encode_basestring",
        "loc_name": "json.encoder.py_encode_basestring",
        "args": "s",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 36,
        "namespace": "*",
        "body": "def py_encode_basestring(s):\n    \"\"\"Return a JSON representation of a Python string\n\n    \"\"\"\n    def replace(match):\n        return ESCAPE_DCT[match.group(0)]\n    return '\"' + ESCAPE.sub(replace, s) + '\"'",
        "name_type": "stdlib"
    },
    "json.encoder.py_encode_basestring.replace": {
        "API_name": "json.encoder.py_encode_basestring.replace",
        "loc_name": "json.encoder.py_encode_basestring.replace",
        "args": "match",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 40,
        "namespace": "*",
        "body": "    def replace(match):\n        return ESCAPE_DCT[match.group(0)]",
        "name_type": "stdlib"
    },
    "json.encoder.py_encode_basestring_ascii": {
        "API_name": "json.encoder.py_encode_basestring_ascii",
        "loc_name": "json.encoder.py_encode_basestring_ascii",
        "args": "s",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 48,
        "namespace": "*",
        "body": "def py_encode_basestring_ascii(s):\n    \"\"\"Return an ASCII-only JSON representation of a Python string\n\n    \"\"\"\n    def replace(match):\n        s = match.group(0)\n        try:\n            return ESCAPE_DCT[s]\n        except KeyError:\n            n = ord(s)\n            if n < 0x10000:\n                return '\\\\u{0:04x}'.format(n)\n                #return '\\\\u%04x' % (n,)\n            else:\n                # surrogate pair\n                n -= 0x10000\n                s1 = 0xd800 | ((n >> 10) & 0x3ff)\n                s2 = 0xdc00 | (n & 0x3ff)\n                return '\\\\u{0:04x}\\\\u{1:04x}'.format(s1, s2)\n    return '\"' + ESCAPE_ASCII.sub(replace, s) + '\"'",
        "name_type": "stdlib"
    },
    "json.encoder.py_encode_basestring_ascii.replace": {
        "API_name": "json.encoder.py_encode_basestring_ascii.replace",
        "loc_name": "json.encoder.py_encode_basestring_ascii.replace",
        "args": "match",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 52,
        "namespace": "*",
        "body": "    def replace(match):\n        s = match.group(0)\n        try:\n            return ESCAPE_DCT[s]\n        except KeyError:\n            n = ord(s)\n            if n < 0x10000:\n                return '\\\\u{0:04x}'.format(n)\n                #return '\\\\u%04x' % (n,)\n            else:\n                # surrogate pair\n                n -= 0x10000\n                s1 = 0xd800 | ((n >> 10) & 0x3ff)\n                s2 = 0xdc00 | (n & 0x3ff)\n                return '\\\\u{0:04x}\\\\u{1:04x}'.format(s1, s2)",
        "name_type": "stdlib"
    },
    "json.encoder.JSONEncoder": {
        "API_name": "json.encoder.JSONEncoder",
        "loc_name": "json.encoder.JSONEncoder",
        "args": "*",
        "args_default": "*",
        "filepath": "json.encoder",
        "lineno": 73,
        "namespace": "JSONEncoder",
        "body": "",
        "name_type": "stdlib"
    },
    "json.encoder.JSONEncoder.__init__": {
        "API_name": "json.encoder.JSONEncoder.__init__",
        "loc_name": "json.encoder.JSONEncoder.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 104,
        "namespace": "JSONEncoder",
        "body": "    def __init__(self, *, skipkeys=False, ensure_ascii=True,\n            check_circular=True, allow_nan=True, sort_keys=False,\n            indent=None, separators=None, default=None):\n        \"\"\"Constructor for JSONEncoder, with sensible defaults.\n\n        If skipkeys is false, then it is a TypeError to attempt\n        encoding of keys that are not str, int, float or None.  If\n        skipkeys is True, such items are simply skipped.\n\n        If ensure_ascii is true, the output is guaranteed to be str\n        objects with all incoming non-ASCII characters escaped.  If\n        ensure_ascii is false, the output can contain non-ASCII characters.\n\n        If check_circular is true, then lists, dicts, and custom encoded\n        objects will be checked for circular references during encoding to\n        prevent an infinite recursion (which would cause an RecursionError).\n        Otherwise, no such check takes place.\n\n        If allow_nan is true, then NaN, Infinity, and -Infinity will be\n        encoded as such.  This behavior is not JSON specification compliant,\n        but is consistent with most JavaScript based encoders and decoders.\n        Otherwise, it will be a ValueError to encode such floats.\n\n        If sort_keys is true, then the output of dictionaries will be\n        sorted by key; this is useful for regression tests to ensure\n        that JSON serializations can be compared on a day-to-day basis.\n\n        If indent is a non-negative integer, then JSON array\n        elements and object members will be pretty-printed with that\n        indent level.  An indent level of 0 will only insert newlines.\n        None is the most compact representation.\n\n        If specified, separators should be an (item_separator, key_separator)\n        tuple.  The default is (', ', ': ') if *indent* is ``None`` and\n        (',', ': ') otherwise.  To get the most compact JSON representation,\n        you should specify (',', ':') to eliminate whitespace.\n\n        If specified, default is a function that gets called for objects\n        that can't otherwise be serialized.  It should return a JSON encodable\n        version of the object or raise a ``TypeError``.\n\n        \"\"\"\n\n        self.skipkeys = skipkeys\n        self.ensure_ascii = ensure_ascii\n        self.check_circular = check_circular\n        self.allow_nan = allow_nan\n        self.sort_keys = sort_keys\n        self.indent = indent\n        if separators is not None:\n            self.item_separator, self.key_separator = separators\n        elif indent is not None:\n            self.item_separator = ','\n        if default is not None:\n            self.default = default",
        "name_type": "stdlib"
    },
    "json.encoder.JSONEncoder.default": {
        "API_name": "json.encoder.JSONEncoder.default",
        "loc_name": "json.encoder.JSONEncoder.default",
        "args": "self;o",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 160,
        "namespace": "JSONEncoder",
        "body": "    def default(self, o):\n        \"\"\"Implement this method in a subclass such that it returns\n        a serializable object for ``o``, or calls the base implementation\n        (to raise a ``TypeError``).\n\n        For example, to support arbitrary iterators, you could\n        implement default like this::\n\n            def default(self, o):\n                try:\n                    iterable = iter(o)\n                except TypeError:\n                    pass\n                else:\n                    return list(iterable)\n                # Let the base class default method raise the TypeError\n                return JSONEncoder.default(self, o)\n\n        \"\"\"\n        raise TypeError(f'Object of type {o.__class__.__name__} '\n                        f'is not JSON serializable')",
        "name_type": "stdlib"
    },
    "json.encoder.JSONEncoder.encode": {
        "API_name": "json.encoder.JSONEncoder.encode",
        "loc_name": "json.encoder.JSONEncoder.encode",
        "args": "self;o",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 182,
        "namespace": "JSONEncoder",
        "body": "    def encode(self, o):\n        \"\"\"Return a JSON string representation of a Python data structure.\n\n        >>> from json.encoder import JSONEncoder\n        >>> JSONEncoder().encode({\"foo\": [\"bar\", \"baz\"]})\n        '{\"foo\": [\"bar\", \"baz\"]}'\n\n        \"\"\"\n        # This is for extremely simple cases and benchmarks.\n        if isinstance(o, str):\n            if self.ensure_ascii:\n                return encode_basestring_ascii(o)\n            else:\n                return encode_basestring(o)\n        # This doesn't pass the iterator directly to ''.join() because the\n        # exceptions aren't as detailed.  The list call should be roughly\n        # equivalent to the PySequence_Fast that ''.join() would do.\n        chunks = self.iterencode(o, _one_shot=True)\n        if not isinstance(chunks, (list, tuple)):\n            chunks = list(chunks)\n        return ''.join(chunks)",
        "name_type": "stdlib"
    },
    "json.encoder.JSONEncoder.iterencode": {
        "API_name": "json.encoder.JSONEncoder.iterencode",
        "loc_name": "json.encoder.JSONEncoder.iterencode",
        "args": "self;o;_one_shot",
        "args_default": 1,
        "filepath": "json.encoder",
        "lineno": 204,
        "namespace": "JSONEncoder",
        "body": "    def iterencode(self, o, _one_shot=False):\n        \"\"\"Encode the given object and yield each string\n        representation as available.\n\n        For example::\n\n            for chunk in JSONEncoder().iterencode(bigobject):\n                mysocket.write(chunk)\n\n        \"\"\"\n        if self.check_circular:\n            markers = {}\n        else:\n            markers = None\n        if self.ensure_ascii:\n            _encoder = encode_basestring_ascii\n        else:\n            _encoder = encode_basestring\n\n        def floatstr(o, allow_nan=self.allow_nan,\n                _repr=float.__repr__, _inf=INFINITY, _neginf=-INFINITY):\n            # Check for specials.  Note that this type of test is processor\n            # and/or platform-specific, so do tests which don't depend on the\n            # internals.\n\n            if o != o:\n                text = 'NaN'\n            elif o == _inf:\n                text = 'Infinity'\n            elif o == _neginf:\n                text = '-Infinity'\n            else:\n                return _repr(o)\n\n            if not allow_nan:\n                raise ValueError(\n                    \"Out of range float values are not JSON compliant: \" +\n                    repr(o))\n\n            return text\n\n\n        if (_one_shot and c_make_encoder is not None\n                and self.indent is None):\n            _iterencode = c_make_encoder(\n                markers, self.default, _encoder, self.indent,\n                self.key_separator, self.item_separator, self.sort_keys,\n                self.skipkeys, self.allow_nan)\n        else:\n            _iterencode = _make_iterencode(\n                markers, self.default, _encoder, self.indent, floatstr,\n                self.key_separator, self.item_separator, self.sort_keys,\n                self.skipkeys, _one_shot)\n        return _iterencode(o, 0)",
        "name_type": "stdlib"
    },
    "json.encoder.JSONEncoder.iterencode.floatstr": {
        "API_name": "json.encoder.JSONEncoder.iterencode.floatstr",
        "loc_name": "json.encoder.JSONEncoder.iterencode.floatstr",
        "args": "o;allow_nan;_repr;_inf;_neginf",
        "args_default": 4,
        "filepath": "json.encoder",
        "lineno": 223,
        "namespace": "JSONEncoder",
        "body": "        def floatstr(o, allow_nan=self.allow_nan,\n                _repr=float.__repr__, _inf=INFINITY, _neginf=-INFINITY):\n            # Check for specials.  Note that this type of test is processor\n            # and/or platform-specific, so do tests which don't depend on the\n            # internals.\n\n            if o != o:\n                text = 'NaN'\n            elif o == _inf:\n                text = 'Infinity'\n            elif o == _neginf:\n                text = '-Infinity'\n            else:\n                return _repr(o)\n\n            if not allow_nan:\n                raise ValueError(\n                    \"Out of range float values are not JSON compliant: \" +\n                    repr(o))\n\n            return text",
        "name_type": "stdlib"
    },
    "json.encoder._make_iterencode": {
        "API_name": "json.encoder._make_iterencode",
        "loc_name": "json.encoder._make_iterencode",
        "args": "markers;_default;_encoder;_indent;_floatstr;_key_separator;_item_separator;_sort_keys;_skipkeys;_one_shot;ValueError;dict;float;id;int;isinstance;list;str;tuple;_intstr",
        "args_default": 10,
        "filepath": "json.encoder",
        "lineno": 259,
        "namespace": "*",
        "body": "def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n        _key_separator, _item_separator, _sort_keys, _skipkeys, _one_shot,\n        ## HACK: hand-optimized bytecode; turn globals into locals\n        ValueError=ValueError,\n        dict=dict,\n        float=float,\n        id=id,\n        int=int,\n        isinstance=isinstance,\n        list=list,\n        str=str,\n        tuple=tuple,\n        _intstr=int.__repr__,\n    ):\n\n    if _indent is not None and not isinstance(_indent, str):\n        _indent = ' ' * _indent\n\n    def _iterencode_list(lst, _current_indent_level):\n        if not lst:\n            yield '[]'\n            return\n        if markers is not None:\n            markerid = id(lst)\n            if markerid in markers:\n                raise ValueError(\"Circular reference detected\")\n            markers[markerid] = lst\n        buf = '['\n        if _indent is not None:\n            _current_indent_level += 1\n            newline_indent = '\\n' + _indent * _current_indent_level\n            separator = _item_separator + newline_indent\n            buf += newline_indent\n        else:\n            newline_indent = None\n            separator = _item_separator\n        first = True\n        for value in lst:\n            if first:\n                first = False\n            else:\n                buf = separator\n            if isinstance(value, str):\n                yield buf + _encoder(value)\n            elif value is None:\n                yield buf + 'null'\n            elif value is True:\n                yield buf + 'true'\n            elif value is False:\n                yield buf + 'false'\n            elif isinstance(value, int):\n                # Subclasses of int/float may override __repr__, but we still\n                # want to encode them as integers/floats in JSON. One example\n                # within the standard library is IntEnum.\n                yield buf + _intstr(value)\n            elif isinstance(value, float):\n                # see comment above for int\n                yield buf + _floatstr(value)\n            else:\n                yield buf\n                if isinstance(value, (list, tuple)):\n                    chunks = _iterencode_list(value, _current_indent_level)\n                elif isinstance(value, dict):\n                    chunks = _iterencode_dict(value, _current_indent_level)\n                else:\n                    chunks = _iterencode(value, _current_indent_level)\n                yield from chunks\n        if newline_indent is not None:\n            _current_indent_level -= 1\n            yield '\\n' + _indent * _current_indent_level\n        yield ']'\n        if markers is not None:\n            del markers[markerid]\n\n    def _iterencode_dict(dct, _current_indent_level):\n        if not dct:\n            yield '{}'\n            return\n        if markers is not None:\n            markerid = id(dct)\n            if markerid in markers:\n                raise ValueError(\"Circular reference detected\")\n            markers[markerid] = dct\n        yield '{'\n        if _indent is not None:\n            _current_indent_level += 1\n            newline_indent = '\\n' + _indent * _current_indent_level\n            item_separator = _item_separator + newline_indent\n            yield newline_indent\n        else:\n            newline_indent = None\n            item_separator = _item_separator\n        first = True\n        if _sort_keys:\n            items = sorted(dct.items())\n        else:\n            items = dct.items()\n        for key, value in items:\n            if isinstance(key, str):\n                pass\n            # JavaScript is weakly typed for these, so it makes sense to\n            # also allow them.  Many encoders seem to do something like this.\n            elif isinstance(key, float):\n                # see comment for int/float in _make_iterencode\n                key = _floatstr(key)\n            elif key is True:\n                key = 'true'\n            elif key is False:\n                key = 'false'\n            elif key is None:\n                key = 'null'\n            elif isinstance(key, int):\n                # see comment for int/float in _make_iterencode\n                key = _intstr(key)\n            elif _skipkeys:\n                continue\n            else:\n                raise TypeError(f'keys must be str, int, float, bool or None, '\n                                f'not {key.__class__.__name__}')\n            if first:\n                first = False\n            else:\n                yield item_separator\n            yield _encoder(key)\n            yield _key_separator\n            if isinstance(value, str):\n                yield _encoder(value)\n            elif value is None:\n                yield 'null'\n            elif value is True:\n                yield 'true'\n            elif value is False:\n                yield 'false'\n            elif isinstance(value, int):\n                # see comment for int/float in _make_iterencode\n                yield _intstr(value)\n            elif isinstance(value, float):\n                # see comment for int/float in _make_iterencode\n                yield _floatstr(value)\n            else:\n                if isinstance(value, (list, tuple)):\n                    chunks = _iterencode_list(value, _current_indent_level)\n                elif isinstance(value, dict):\n                    chunks = _iterencode_dict(value, _current_indent_level)\n                else:\n                    chunks = _iterencode(value, _current_indent_level)\n                yield from chunks\n        if newline_indent is not None:\n            _current_indent_level -= 1\n            yield '\\n' + _indent * _current_indent_level\n        yield '}'\n        if markers is not None:\n            del markers[markerid]\n\n    def _iterencode(o, _current_indent_level):\n        if isinstance(o, str):\n            yield _encoder(o)\n        elif o is None:\n            yield 'null'\n        elif o is True:\n            yield 'true'\n        elif o is False:\n            yield 'false'\n        elif isinstance(o, int):\n            # see comment for int/float in _make_iterencode\n            yield _intstr(o)\n        elif isinstance(o, float):\n            # see comment for int/float in _make_iterencode\n            yield _floatstr(o)\n        elif isinstance(o, (list, tuple)):\n            yield from _iterencode_list(o, _current_indent_level)\n        elif isinstance(o, dict):\n            yield from _iterencode_dict(o, _current_indent_level)\n        else:\n            if markers is not None:\n                markerid = id(o)\n                if markerid in markers:\n                    raise ValueError(\"Circular reference detected\")\n                markers[markerid] = o\n            o = _default(o)\n            yield from _iterencode(o, _current_indent_level)\n            if markers is not None:\n                del markers[markerid]\n    return _iterencode",
        "name_type": "stdlib"
    },
    "json.encoder._make_iterencode._iterencode_list": {
        "API_name": "json.encoder._make_iterencode._iterencode_list",
        "loc_name": "json.encoder._make_iterencode._iterencode_list",
        "args": "lst;_current_indent_level",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 277,
        "namespace": "*",
        "body": "    def _iterencode_list(lst, _current_indent_level):\n        if not lst:\n            yield '[]'\n            return\n        if markers is not None:\n            markerid = id(lst)\n            if markerid in markers:\n                raise ValueError(\"Circular reference detected\")\n            markers[markerid] = lst\n        buf = '['\n        if _indent is not None:\n            _current_indent_level += 1\n            newline_indent = '\\n' + _indent * _current_indent_level\n            separator = _item_separator + newline_indent\n            buf += newline_indent\n        else:\n            newline_indent = None\n            separator = _item_separator\n        first = True\n        for value in lst:\n            if first:\n                first = False\n            else:\n                buf = separator\n            if isinstance(value, str):\n                yield buf + _encoder(value)\n            elif value is None:\n                yield buf + 'null'\n            elif value is True:\n                yield buf + 'true'\n            elif value is False:\n                yield buf + 'false'\n            elif isinstance(value, int):\n                # Subclasses of int/float may override __repr__, but we still\n                # want to encode them as integers/floats in JSON. One example\n                # within the standard library is IntEnum.\n                yield buf + _intstr(value)\n            elif isinstance(value, float):\n                # see comment above for int\n                yield buf + _floatstr(value)\n            else:\n                yield buf\n                if isinstance(value, (list, tuple)):\n                    chunks = _iterencode_list(value, _current_indent_level)\n                elif isinstance(value, dict):\n                    chunks = _iterencode_dict(value, _current_indent_level)\n                else:\n                    chunks = _iterencode(value, _current_indent_level)\n                yield from chunks\n        if newline_indent is not None:\n            _current_indent_level -= 1\n            yield '\\n' + _indent * _current_indent_level\n        yield ']'\n        if markers is not None:\n            del markers[markerid]",
        "name_type": "stdlib"
    },
    "json.encoder._make_iterencode._iterencode_dict": {
        "API_name": "json.encoder._make_iterencode._iterencode_dict",
        "loc_name": "json.encoder._make_iterencode._iterencode_dict",
        "args": "dct;_current_indent_level",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 333,
        "namespace": "*",
        "body": "    def _iterencode_dict(dct, _current_indent_level):\n        if not dct:\n            yield '{}'\n            return\n        if markers is not None:\n            markerid = id(dct)\n            if markerid in markers:\n                raise ValueError(\"Circular reference detected\")\n            markers[markerid] = dct\n        yield '{'\n        if _indent is not None:\n            _current_indent_level += 1\n            newline_indent = '\\n' + _indent * _current_indent_level\n            item_separator = _item_separator + newline_indent\n            yield newline_indent\n        else:\n            newline_indent = None\n            item_separator = _item_separator\n        first = True\n        if _sort_keys:\n            items = sorted(dct.items())\n        else:\n            items = dct.items()\n        for key, value in items:\n            if isinstance(key, str):\n                pass\n            # JavaScript is weakly typed for these, so it makes sense to\n            # also allow them.  Many encoders seem to do something like this.\n            elif isinstance(key, float):\n                # see comment for int/float in _make_iterencode\n                key = _floatstr(key)\n            elif key is True:\n                key = 'true'\n            elif key is False:\n                key = 'false'\n            elif key is None:\n                key = 'null'\n            elif isinstance(key, int):\n                # see comment for int/float in _make_iterencode\n                key = _intstr(key)\n            elif _skipkeys:\n                continue\n            else:\n                raise TypeError(f'keys must be str, int, float, bool or None, '\n                                f'not {key.__class__.__name__}')\n            if first:\n                first = False\n            else:\n                yield item_separator\n            yield _encoder(key)\n            yield _key_separator\n            if isinstance(value, str):\n                yield _encoder(value)\n            elif value is None:\n                yield 'null'\n            elif value is True:\n                yield 'true'\n            elif value is False:\n                yield 'false'\n            elif isinstance(value, int):\n                # see comment for int/float in _make_iterencode\n                yield _intstr(value)\n            elif isinstance(value, float):\n                # see comment for int/float in _make_iterencode\n                yield _floatstr(value)\n            else:\n                if isinstance(value, (list, tuple)):\n                    chunks = _iterencode_list(value, _current_indent_level)\n                elif isinstance(value, dict):\n                    chunks = _iterencode_dict(value, _current_indent_level)\n                else:\n                    chunks = _iterencode(value, _current_indent_level)\n                yield from chunks\n        if newline_indent is not None:\n            _current_indent_level -= 1\n            yield '\\n' + _indent * _current_indent_level\n        yield '}'\n        if markers is not None:\n            del markers[markerid]",
        "name_type": "stdlib"
    },
    "json.encoder._make_iterencode._iterencode": {
        "API_name": "json.encoder._make_iterencode._iterencode",
        "loc_name": "json.encoder._make_iterencode._iterencode",
        "args": "o;_current_indent_level",
        "args_default": 0,
        "filepath": "json.encoder",
        "lineno": 413,
        "namespace": "*",
        "body": "    def _iterencode(o, _current_indent_level):\n        if isinstance(o, str):\n            yield _encoder(o)\n        elif o is None:\n            yield 'null'\n        elif o is True:\n            yield 'true'\n        elif o is False:\n            yield 'false'\n        elif isinstance(o, int):\n            # see comment for int/float in _make_iterencode\n            yield _intstr(o)\n        elif isinstance(o, float):\n            # see comment for int/float in _make_iterencode\n            yield _floatstr(o)\n        elif isinstance(o, (list, tuple)):\n            yield from _iterencode_list(o, _current_indent_level)\n        elif isinstance(o, dict):\n            yield from _iterencode_dict(o, _current_indent_level)\n        else:\n            if markers is not None:\n                markerid = id(o)\n                if markerid in markers:\n                    raise ValueError(\"Circular reference detected\")\n                markers[markerid] = o\n            o = _default(o)\n            yield from _iterencode(o, _current_indent_level)\n            if markers is not None:\n                del markers[markerid]",
        "name_type": "stdlib"
    },
    "json.scanner": {
        "API_name": "json.scanner",
        "loc_name": "json.scanner",
        "args": "*",
        "args_default": "*",
        "filepath": "json.scanner",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"JSON token scanner\n\"\"\"\ntry:\n    from _json import make_scanner as c_make_scanner\nexcept ImportError:\n    c_make_scanner = None\n__all__ = ['make_scanner']\nNUMBER_RE = re.compile(\n    r'(-?(?:0|[1-9]\\d*))(\\.\\d+)?([eE][-+]?\\d+)?',\n    (re.VERBOSE | re.MULTILINE | re.DOTALL))\nmake_scanner = c_make_scanner or py_make_scanner",
        "name_type": "stdlib"
    },
    "json.scanner.py_make_scanner": {
        "API_name": "json.scanner.py_make_scanner",
        "loc_name": "json.scanner.py_make_scanner",
        "args": "context",
        "args_default": 0,
        "filepath": "json.scanner",
        "lineno": 15,
        "namespace": "*",
        "body": "def py_make_scanner(context):\n    parse_object = context.parse_object\n    parse_array = context.parse_array\n    parse_string = context.parse_string\n    match_number = NUMBER_RE.match\n    strict = context.strict\n    parse_float = context.parse_float\n    parse_int = context.parse_int\n    parse_constant = context.parse_constant\n    object_hook = context.object_hook\n    object_pairs_hook = context.object_pairs_hook\n    memo = context.memo\n\n    def _scan_once(string, idx):\n        try:\n            nextchar = string[idx]\n        except IndexError:\n            raise StopIteration(idx) from None\n\n        if nextchar == '\"':\n            return parse_string(string, idx + 1, strict)\n        elif nextchar == '{':\n            return parse_object((string, idx + 1), strict,\n                _scan_once, object_hook, object_pairs_hook, memo)\n        elif nextchar == '[':\n            return parse_array((string, idx + 1), _scan_once)\n        elif nextchar == 'n' and string[idx:idx + 4] == 'null':\n            return None, idx + 4\n        elif nextchar == 't' and string[idx:idx + 4] == 'true':\n            return True, idx + 4\n        elif nextchar == 'f' and string[idx:idx + 5] == 'false':\n            return False, idx + 5\n\n        m = match_number(string, idx)\n        if m is not None:\n            integer, frac, exp = m.groups()\n            if frac or exp:\n                res = parse_float(integer + (frac or '') + (exp or ''))\n            else:\n                res = parse_int(integer)\n            return res, m.end()\n        elif nextchar == 'N' and string[idx:idx + 3] == 'NaN':\n            return parse_constant('NaN'), idx + 3\n        elif nextchar == 'I' and string[idx:idx + 8] == 'Infinity':\n            return parse_constant('Infinity'), idx + 8\n        elif nextchar == '-' and string[idx:idx + 9] == '-Infinity':\n            return parse_constant('-Infinity'), idx + 9\n        else:\n            raise StopIteration(idx)\n\n    def scan_once(string, idx):\n        try:\n            return _scan_once(string, idx)\n        finally:\n            memo.clear()\n\n    return scan_once",
        "name_type": "stdlib"
    },
    "json.scanner.py_make_scanner._scan_once": {
        "API_name": "json.scanner.py_make_scanner._scan_once",
        "loc_name": "json.scanner.py_make_scanner._scan_once",
        "args": "string;idx",
        "args_default": 0,
        "filepath": "json.scanner",
        "lineno": 28,
        "namespace": "*",
        "body": "    def _scan_once(string, idx):\n        try:\n            nextchar = string[idx]\n        except IndexError:\n            raise StopIteration(idx) from None\n\n        if nextchar == '\"':\n            return parse_string(string, idx + 1, strict)\n        elif nextchar == '{':\n            return parse_object((string, idx + 1), strict,\n                _scan_once, object_hook, object_pairs_hook, memo)\n        elif nextchar == '[':\n            return parse_array((string, idx + 1), _scan_once)\n        elif nextchar == 'n' and string[idx:idx + 4] == 'null':\n            return None, idx + 4\n        elif nextchar == 't' and string[idx:idx + 4] == 'true':\n            return True, idx + 4\n        elif nextchar == 'f' and string[idx:idx + 5] == 'false':\n            return False, idx + 5\n\n        m = match_number(string, idx)\n        if m is not None:\n            integer, frac, exp = m.groups()\n            if frac or exp:\n                res = parse_float(integer + (frac or '') + (exp or ''))\n            else:\n                res = parse_int(integer)\n            return res, m.end()\n        elif nextchar == 'N' and string[idx:idx + 3] == 'NaN':\n            return parse_constant('NaN'), idx + 3\n        elif nextchar == 'I' and string[idx:idx + 8] == 'Infinity':\n            return parse_constant('Infinity'), idx + 8\n        elif nextchar == '-' and string[idx:idx + 9] == '-Infinity':\n            return parse_constant('-Infinity'), idx + 9\n        else:\n            raise StopIteration(idx)",
        "name_type": "stdlib"
    },
    "json.scanner.py_make_scanner.scan_once": {
        "API_name": "json.scanner.py_make_scanner.scan_once",
        "loc_name": "json.scanner.py_make_scanner.scan_once",
        "args": "string;idx",
        "args_default": 0,
        "filepath": "json.scanner",
        "lineno": 65,
        "namespace": "*",
        "body": "    def scan_once(string, idx):\n        try:\n            return _scan_once(string, idx)\n        finally:\n            memo.clear()",
        "name_type": "stdlib"
    },
    "json.tool": {
        "API_name": "json.tool",
        "loc_name": "json.tool",
        "args": "*",
        "args_default": "*",
        "filepath": "json.tool",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"Command-line tool to validate and pretty-print JSON\n\nUsage::\n\n    $ echo '{\"json\":\"obj\"}' | python -m json.tool\n    {\n        \"json\": \"obj\"\n    }\n    $ echo '{ 1.2:3.4}' | python -m json.tool\n    Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n\n\"\"\"\nif __name__ == '__main__':\n    try:\n        main()\n    except BrokenPipeError as exc:\n        sys.exit(exc.errno)",
        "name_type": "stdlib"
    },
    "json.tool.main": {
        "API_name": "json.tool.main",
        "loc_name": "json.tool.main",
        "args": "",
        "args_default": 0,
        "filepath": "json.tool",
        "lineno": 19,
        "namespace": "*",
        "body": "def main():\n    prog = 'python -m json.tool'\n    description = ('A simple command line interface for json module '\n                   'to validate and pretty-print JSON objects.')\n    parser = argparse.ArgumentParser(prog=prog, description=description)\n    parser.add_argument('infile', nargs='?',\n                        type=argparse.FileType(encoding=\"utf-8\"),\n                        help='a JSON file to be validated or pretty-printed',\n                        default=sys.stdin)\n    parser.add_argument('outfile', nargs='?',\n                        type=Path,\n                        help='write the output of infile to outfile',\n                        default=None)\n    parser.add_argument('--sort-keys', action='store_true', default=False,\n                        help='sort the output of dictionaries alphabetically by key')\n    parser.add_argument('--no-ensure-ascii', dest='ensure_ascii', action='store_false',\n                        help='disable escaping of non-ASCII characters')\n    parser.add_argument('--json-lines', action='store_true', default=False,\n                        help='parse input using the JSON Lines format. '\n                        'Use with --no-indent or --compact to produce valid JSON Lines output.')\n    group = parser.add_mutually_exclusive_group()\n    group.add_argument('--indent', default=4, type=int,\n                       help='separate items with newlines and use this number '\n                       'of spaces for indentation')\n    group.add_argument('--tab', action='store_const', dest='indent',\n                       const='\\t', help='separate items with newlines and use '\n                       'tabs for indentation')\n    group.add_argument('--no-indent', action='store_const', dest='indent',\n                       const=None,\n                       help='separate items with spaces rather than newlines')\n    group.add_argument('--compact', action='store_true',\n                       help='suppress all whitespace separation (most compact)')\n    options = parser.parse_args()\n\n    dump_args = {\n        'sort_keys': options.sort_keys,\n        'indent': options.indent,\n        'ensure_ascii': options.ensure_ascii,\n    }\n    if options.compact:\n        dump_args['indent'] = None\n        dump_args['separators'] = ',', ':'\n\n    with options.infile as infile:\n        try:\n            if options.json_lines:\n                objs = (json.loads(line) for line in infile)\n            else:\n                objs = (json.load(infile),)\n\n            if options.outfile is None:\n                out = sys.stdout\n            else:\n                out = options.outfile.open('w', encoding='utf-8')\n            with out as outfile:\n                for obj in objs:\n                    json.dump(obj, outfile, **dump_args)\n                    outfile.write('\\n')\n        except ValueError as e:\n            raise SystemExit(e)",
        "name_type": "stdlib"
    },
    "json": {
        "API_name": "json",
        "loc_name": "json",
        "args": "*",
        "args_default": "*",
        "filepath": "json",
        "lineno": "*",
        "namespace": "*",
        "body": "r\"\"\"JSON (JavaScript Object Notation) <http://json.org> is a subset of\nJavaScript syntax (ECMA-262 3rd edition) used as a lightweight data\ninterchange format.\n\n:mod:`json` exposes an API familiar to users of the standard library\n:mod:`marshal` and :mod:`pickle` modules.  It is derived from a\nversion of the externally maintained simplejson library.\n\nEncoding basic Python object hierarchies::\n\n    >>> import json\n    >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])\n    '[\"foo\", {\"bar\": [\"baz\", null, 1.0, 2]}]'\n    >>> print(json.dumps(\"\\\"foo\\bar\"))\n    \"\\\"foo\\bar\"\n    >>> print(json.dumps('\\u1234'))\n    \"\\u1234\"\n    >>> print(json.dumps('\\\\'))\n    \"\\\\\"\n    >>> print(json.dumps({\"c\": 0, \"b\": 0, \"a\": 0}, sort_keys=True))\n    {\"a\": 0, \"b\": 0, \"c\": 0}\n    >>> from io import StringIO\n    >>> io = StringIO()\n    >>> json.dump(['streaming API'], io)\n    >>> io.getvalue()\n    '[\"streaming API\"]'\n\nCompact encoding::\n\n    >>> import json\n    >>> mydict = {'4': 5, '6': 7}\n    >>> json.dumps([1,2,3,mydict], separators=(',', ':'))\n    '[1,2,3,{\"4\":5,\"6\":7}]'\n\nPretty printing::\n\n    >>> import json\n    >>> print(json.dumps({'4': 5, '6': 7}, sort_keys=True, indent=4))\n    {\n        \"4\": 5,\n        \"6\": 7\n    }\n\nDecoding JSON::\n\n    >>> import json\n    >>> obj = ['foo', {'bar': ['baz', None, 1.0, 2]}]\n    >>> json.loads('[\"foo\", {\"bar\":[\"baz\", null, 1.0, 2]}]') == obj\n    True\n    >>> json.loads('\"\\\\\"foo\\\\bar\"') == '\"foo\\x08ar'\n    True\n    >>> from io import StringIO\n    >>> io = StringIO('[\"streaming API\"]')\n    >>> json.load(io)[0] == 'streaming API'\n    True\n\nSpecializing JSON object decoding::\n\n    >>> import json\n    >>> def as_complex(dct):\n    ...     if '__complex__' in dct:\n    ...         return complex(dct['real'], dct['imag'])\n    ...     return dct\n    ...\n    >>> json.loads('{\"__complex__\": true, \"real\": 1, \"imag\": 2}',\n    ...     object_hook=as_complex)\n    (1+2j)\n    >>> from decimal import Decimal\n    >>> json.loads('1.1', parse_float=Decimal) == Decimal('1.1')\n    True\n\nSpecializing JSON object encoding::\n\n    >>> import json\n    >>> def encode_complex(obj):\n    ...     if isinstance(obj, complex):\n    ...         return [obj.real, obj.imag]\n    ...     raise TypeError(f'Object of type {obj.__class__.__name__} '\n    ...                     f'is not JSON serializable')\n    ...\n    >>> json.dumps(2 + 1j, default=encode_complex)\n    '[2.0, 1.0]'\n    >>> json.JSONEncoder(default=encode_complex).encode(2 + 1j)\n    '[2.0, 1.0]'\n    >>> ''.join(json.JSONEncoder(default=encode_complex).iterencode(2 + 1j))\n    '[2.0, 1.0]'\n\n\nUsing json.tool from the shell to validate and pretty-print::\n\n    $ echo '{\"json\":\"obj\"}' | python -m json.tool\n    {\n        \"json\": \"obj\"\n    }\n    $ echo '{ 1.2:3.4}' | python -m json.tool\n    Expecting property name enclosed in double quotes: line 1 column 3 (char 2)\n\"\"\"\n__version__ = '2.0.9'\n__all__ = [\n    'dump', 'dumps', 'load', 'loads',\n    'JSONDecoder', 'JSONDecodeError', 'JSONEncoder',\n]\n__author__ = 'Bob Ippolito <bob@redivi.com>'\n_default_encoder = JSONEncoder(\n    skipkeys=False,\n    ensure_ascii=True,\n    check_circular=True,\n    allow_nan=True,\n    indent=None,\n    separators=None,\n    default=None,\n)\n_default_decoder = JSONDecoder(object_hook=None, object_pairs_hook=None)",
        "name_type": "stdlib"
    },
    "json.dump": {
        "API_name": "json.dump",
        "loc_name": "json.dump",
        "args": "obj;fp",
        "args_default": 0,
        "filepath": "json",
        "lineno": 120,
        "namespace": "*",
        "body": "def dump(obj, fp, *, skipkeys=False, ensure_ascii=True, check_circular=True,\n        allow_nan=True, cls=None, indent=None, separators=None,\n        default=None, sort_keys=False, **kw):\n    \"\"\"Serialize ``obj`` as a JSON formatted stream to ``fp`` (a\n    ``.write()``-supporting file-like object).\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the strings written to ``fp`` can\n    contain non-ASCII characters if they appear in strings contained in\n    ``obj``. Otherwise, all such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``RecursionError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``)\n    in strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    # cached encoder\n    if (not skipkeys and ensure_ascii and\n        check_circular and allow_nan and\n        cls is None and indent is None and separators is None and\n        default is None and not sort_keys and not kw):\n        iterable = _default_encoder.iterencode(obj)\n    else:\n        if cls is None:\n            cls = JSONEncoder\n        iterable = cls(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n            check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n            separators=separators,\n            default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n    # could accelerate with writelines in some versions of Python, at\n    # a debuggability cost\n    for chunk in iterable:\n        fp.write(chunk)",
        "name_type": "stdlib"
    },
    "json.dumps": {
        "API_name": "json.dumps",
        "loc_name": "json.dumps",
        "args": "obj",
        "args_default": 0,
        "filepath": "json",
        "lineno": 183,
        "namespace": "*",
        "body": "def dumps(obj, *, skipkeys=False, ensure_ascii=True, check_circular=True,\n        allow_nan=True, cls=None, indent=None, separators=None,\n        default=None, sort_keys=False, **kw):\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n    characters if they appear in strings contained in ``obj``. Otherwise, all\n    such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``RecursionError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n    strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    # cached encoder\n    if (not skipkeys and ensure_ascii and\n        check_circular and allow_nan and\n        cls is None and indent is None and separators is None and\n        default is None and not sort_keys and not kw):\n        return _default_encoder.encode(obj)\n    if cls is None:\n        cls = JSONEncoder\n    return cls(\n        skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n        check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n        separators=separators, default=default, sort_keys=sort_keys,\n        **kw).encode(obj)",
        "name_type": "stdlib"
    },
    "json.detect_encoding": {
        "API_name": "json.detect_encoding",
        "loc_name": "json.detect_encoding",
        "args": "b",
        "args_default": 0,
        "filepath": "json",
        "lineno": 244,
        "namespace": "*",
        "body": "def detect_encoding(b):\n    bstartswith = b.startswith\n    if bstartswith((codecs.BOM_UTF32_BE, codecs.BOM_UTF32_LE)):\n        return 'utf-32'\n    if bstartswith((codecs.BOM_UTF16_BE, codecs.BOM_UTF16_LE)):\n        return 'utf-16'\n    if bstartswith(codecs.BOM_UTF8):\n        return 'utf-8-sig'\n\n    if len(b) >= 4:\n        if not b[0]:\n            # 00 00 -- -- - utf-32-be\n            # 00 XX -- -- - utf-16-be\n            return 'utf-16-be' if b[1] else 'utf-32-be'\n        if not b[1]:\n            # XX 00 00 00 - utf-32-le\n            # XX 00 00 XX - utf-16-le\n            # XX 00 XX -- - utf-16-le\n            return 'utf-16-le' if b[2] or b[3] else 'utf-32-le'\n    elif len(b) == 2:\n        if not b[0]:\n            # 00 XX - utf-16-be\n            return 'utf-16-be'\n        if not b[1]:\n            # XX 00 - utf-16-le\n            return 'utf-16-le'\n    # default\n    return 'utf-8'",
        "name_type": "stdlib"
    },
    "json.load": {
        "API_name": "json.load",
        "loc_name": "json.load",
        "args": "fp",
        "args_default": 0,
        "filepath": "json",
        "lineno": 274,
        "namespace": "*",
        "body": "def load(fp, *, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):\n    \"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\n    a JSON document) to a Python object.\n\n    ``object_hook`` is an optional function that will be called with the\n    result of any object literal decode (a ``dict``). The return value of\n    ``object_hook`` will be used instead of the ``dict``. This feature\n    can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n\n    ``object_pairs_hook`` is an optional function that will be called with the\n    result of any object literal decoded with an ordered list of pairs.  The\n    return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n    This feature can be used to implement custom decoders.  If ``object_hook``\n    is also defined, the ``object_pairs_hook`` takes priority.\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n    kwarg; otherwise ``JSONDecoder`` is used.\n    \"\"\"\n    return loads(fp.read(),\n        cls=cls, object_hook=object_hook,\n        parse_float=parse_float, parse_int=parse_int,\n        parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)",
        "name_type": "stdlib"
    },
    "json.loads": {
        "API_name": "json.loads",
        "loc_name": "json.loads",
        "args": "s",
        "args_default": 0,
        "filepath": "json",
        "lineno": 299,
        "namespace": "*",
        "body": "def loads(s, *, cls=None, object_hook=None, parse_float=None,\n        parse_int=None, parse_constant=None, object_pairs_hook=None, **kw):\n    \"\"\"Deserialize ``s`` (a ``str``, ``bytes`` or ``bytearray`` instance\n    containing a JSON document) to a Python object.\n\n    ``object_hook`` is an optional function that will be called with the\n    result of any object literal decode (a ``dict``). The return value of\n    ``object_hook`` will be used instead of the ``dict``. This feature\n    can be used to implement custom decoders (e.g. JSON-RPC class hinting).\n\n    ``object_pairs_hook`` is an optional function that will be called with the\n    result of any object literal decoded with an ordered list of pairs.  The\n    return value of ``object_pairs_hook`` will be used instead of the ``dict``.\n    This feature can be used to implement custom decoders.  If ``object_hook``\n    is also defined, the ``object_pairs_hook`` takes priority.\n\n    ``parse_float``, if specified, will be called with the string\n    of every JSON float to be decoded. By default this is equivalent to\n    float(num_str). This can be used to use another datatype or parser\n    for JSON floats (e.g. decimal.Decimal).\n\n    ``parse_int``, if specified, will be called with the string\n    of every JSON int to be decoded. By default this is equivalent to\n    int(num_str). This can be used to use another datatype or parser\n    for JSON integers (e.g. float).\n\n    ``parse_constant``, if specified, will be called with one of the\n    following strings: -Infinity, Infinity, NaN.\n    This can be used to raise an exception if invalid JSON numbers\n    are encountered.\n\n    To use a custom ``JSONDecoder`` subclass, specify it with the ``cls``\n    kwarg; otherwise ``JSONDecoder`` is used.\n    \"\"\"\n    if isinstance(s, str):\n        if s.startswith('\\ufeff'):\n            raise JSONDecodeError(\"Unexpected UTF-8 BOM (decode using utf-8-sig)\",\n                                  s, 0)\n    else:\n        if not isinstance(s, (bytes, bytearray)):\n            raise TypeError(f'the JSON object must be str, bytes or bytearray, '\n                            f'not {s.__class__.__name__}')\n        s = s.decode(detect_encoding(s), 'surrogatepass')\n\n    if (cls is None and object_hook is None and\n            parse_int is None and parse_float is None and\n            parse_constant is None and object_pairs_hook is None and not kw):\n        return _default_decoder.decode(s)\n    if cls is None:\n        cls = JSONDecoder\n    if object_hook is not None:\n        kw['object_hook'] = object_hook\n    if object_pairs_hook is not None:\n        kw['object_pairs_hook'] = object_pairs_hook\n    if parse_float is not None:\n        kw['parse_float'] = parse_float\n    if parse_int is not None:\n        kw['parse_int'] = parse_int\n    if parse_constant is not None:\n        kw['parse_constant'] = parse_constant\n    return cls(**kw).decode(s)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection": {
        "API_name": "multiprocessing.connection",
        "loc_name": "multiprocessing.connection",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [ 'Client', 'Listener', 'Pipe', 'wait' ]\n_ForkingPickler = reduction.ForkingPickler\ntry:\n    import _winapi\n    from _winapi import WAIT_OBJECT_0, WAIT_ABANDONED_0, WAIT_TIMEOUT, INFINITE\nexcept ImportError:\n    if sys.platform == 'win32':\n        raise\n    _winapi = None\nBUFSIZE = 8192\nCONNECTION_TIMEOUT = 20.\n_mmap_counter = itertools.count()\ndefault_family = 'AF_INET'\nfamilies = ['AF_INET']\nif hasattr(socket, 'AF_UNIX'):\n    default_family = 'AF_UNIX'\n    families += ['AF_UNIX']\nif sys.platform == 'win32':\n    default_family = 'AF_PIPE'\n    families += ['AF_PIPE']\nif _winapi:\n\n    class PipeConnection(_ConnectionBase):\n        \"\"\"\n        Connection class based on a Windows named pipe.\n        Overlapped I/O is used, so the handles must have been created\n        with FILE_FLAG_OVERLAPPED.\n        \"\"\"\n        _got_empty_message = False\n\n        def _close(self, _CloseHandle=_winapi.CloseHandle):\n            _CloseHandle(self._handle)\n\n        def _send_bytes(self, buf):\n            ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n            try:\n                if err == _winapi.ERROR_IO_PENDING:\n                    waitres = _winapi.WaitForMultipleObjects(\n                        [ov.event], False, INFINITE)\n                    assert waitres == WAIT_OBJECT_0\n            except:\n                ov.cancel()\n                raise\n            finally:\n                nwritten, err = ov.GetOverlappedResult(True)\n            assert err == 0\n            assert nwritten == len(buf)\n\n        def _recv_bytes(self, maxsize=None):\n            if self._got_empty_message:\n                self._got_empty_message = False\n                return io.BytesIO()\n            else:\n                bsize = 128 if maxsize is None else min(maxsize, 128)\n                try:\n                    ov, err = _winapi.ReadFile(self._handle, bsize,\n                                                overlapped=True)\n                    try:\n                        if err == _winapi.ERROR_IO_PENDING:\n                            waitres = _winapi.WaitForMultipleObjects(\n                                [ov.event], False, INFINITE)\n                            assert waitres == WAIT_OBJECT_0\n                    except:\n                        ov.cancel()\n                        raise\n                    finally:\n                        nread, err = ov.GetOverlappedResult(True)\n                        if err == 0:\n                            f = io.BytesIO()\n                            f.write(ov.getbuffer())\n                            return f\n                        elif err == _winapi.ERROR_MORE_DATA:\n                            return self._get_more_data(ov, maxsize)\n                except OSError as e:\n                    if e.winerror == _winapi.ERROR_BROKEN_PIPE:\n                        raise EOFError\n                    else:\n                        raise\n            raise RuntimeError(\"shouldn't get here; expected KeyboardInterrupt\")\n\n        def _poll(self, timeout):\n            if (self._got_empty_message or\n                        _winapi.PeekNamedPipe(self._handle)[0] != 0):\n                return True\n            return bool(wait([self], timeout))\n\n        def _get_more_data(self, ov, maxsize):\n            buf = ov.getbuffer()\n            f = io.BytesIO()\n            f.write(buf)\n            left = _winapi.PeekNamedPipe(self._handle)[1]\n            assert left > 0\n            if maxsize is not None and len(buf) + left > maxsize:\n                self._bad_message_length()\n            ov, err = _winapi.ReadFile(self._handle, left, overlapped=True)\n            rbytes, err = ov.GetOverlappedResult(True)\n            assert err == 0\n            assert rbytes == left\n            f.write(ov.getbuffer())\n            return f\nif sys.platform != 'win32':\n\n    def Pipe(duplex=True):\n        '''\n        Returns pair of connection objects at either end of a pipe\n        '''\n        if duplex:\n            s1, s2 = socket.socketpair()\n            s1.setblocking(True)\n            s2.setblocking(True)\n            c1 = Connection(s1.detach())\n            c2 = Connection(s2.detach())\n        else:\n            fd1, fd2 = os.pipe()\n            c1 = Connection(fd1, writable=False)\n            c2 = Connection(fd2, readable=False)\n\n        return c1, c2\n\nelse:\n\n    def Pipe(duplex=True):\n        '''\n        Returns pair of connection objects at either end of a pipe\n        '''\n        address = arbitrary_address('AF_PIPE')\n        if duplex:\n            openmode = _winapi.PIPE_ACCESS_DUPLEX\n            access = _winapi.GENERIC_READ | _winapi.GENERIC_WRITE\n            obsize, ibsize = BUFSIZE, BUFSIZE\n        else:\n            openmode = _winapi.PIPE_ACCESS_INBOUND\n            access = _winapi.GENERIC_WRITE\n            obsize, ibsize = 0, BUFSIZE\n\n        h1 = _winapi.CreateNamedPipe(\n            address, openmode | _winapi.FILE_FLAG_OVERLAPPED |\n            _winapi.FILE_FLAG_FIRST_PIPE_INSTANCE,\n            _winapi.PIPE_TYPE_MESSAGE | _winapi.PIPE_READMODE_MESSAGE |\n            _winapi.PIPE_WAIT,\n            1, obsize, ibsize, _winapi.NMPWAIT_WAIT_FOREVER,\n            # default security descriptor: the handle cannot be inherited\n            _winapi.NULL\n            )\n        h2 = _winapi.CreateFile(\n            address, access, 0, _winapi.NULL, _winapi.OPEN_EXISTING,\n            _winapi.FILE_FLAG_OVERLAPPED, _winapi.NULL\n            )\n        _winapi.SetNamedPipeHandleState(\n            h2, _winapi.PIPE_READMODE_MESSAGE, None, None\n            )\n\n        overlapped = _winapi.ConnectNamedPipe(h1, overlapped=True)\n        _, err = overlapped.GetOverlappedResult(True)\n        assert err == 0\n\n        c1 = PipeConnection(h1, writable=duplex)\n        c2 = PipeConnection(h2, readable=duplex)\n\n        return c1, c2\nif sys.platform == 'win32':\n\n    class PipeListener(object):\n        '''\n        Representation of a named pipe\n        '''\n        def __init__(self, address, backlog=None):\n            self._address = address\n            self._handle_queue = [self._new_handle(first=True)]\n\n            self._last_accepted = None\n            util.sub_debug('listener created with address=%r', self._address)\n            self.close = util.Finalize(\n                self, PipeListener._finalize_pipe_listener,\n                args=(self._handle_queue, self._address), exitpriority=0\n                )\n\n        def _new_handle(self, first=False):\n            flags = _winapi.PIPE_ACCESS_DUPLEX | _winapi.FILE_FLAG_OVERLAPPED\n            if first:\n                flags |= _winapi.FILE_FLAG_FIRST_PIPE_INSTANCE\n            return _winapi.CreateNamedPipe(\n                self._address, flags,\n                _winapi.PIPE_TYPE_MESSAGE | _winapi.PIPE_READMODE_MESSAGE |\n                _winapi.PIPE_WAIT,\n                _winapi.PIPE_UNLIMITED_INSTANCES, BUFSIZE, BUFSIZE,\n                _winapi.NMPWAIT_WAIT_FOREVER, _winapi.NULL\n                )\n\n        def accept(self):\n            self._handle_queue.append(self._new_handle())\n            handle = self._handle_queue.pop(0)\n            try:\n                ov = _winapi.ConnectNamedPipe(handle, overlapped=True)\n            except OSError as e:\n                if e.winerror != _winapi.ERROR_NO_DATA:\n                    raise\n                # ERROR_NO_DATA can occur if a client has already connected,\n                # written data and then disconnected -- see Issue 14725.\n            else:\n                try:\n                    res = _winapi.WaitForMultipleObjects(\n                        [ov.event], False, INFINITE)\n                except:\n                    ov.cancel()\n                    _winapi.CloseHandle(handle)\n                    raise\n                finally:\n                    _, err = ov.GetOverlappedResult(True)\n                    assert err == 0\n            return PipeConnection(handle)\n\n        @staticmethod\n        def _finalize_pipe_listener(queue, address):\n            util.sub_debug('closing listener with address=%r', address)\n            for handle in queue:\n                _winapi.CloseHandle(handle)\n\n    def PipeClient(address):\n        '''\n        Return a connection object connected to the pipe given by `address`\n        '''\n        t = _init_timeout()\n        while 1:\n            try:\n                _winapi.WaitNamedPipe(address, 1000)\n                h = _winapi.CreateFile(\n                    address, _winapi.GENERIC_READ | _winapi.GENERIC_WRITE,\n                    0, _winapi.NULL, _winapi.OPEN_EXISTING,\n                    _winapi.FILE_FLAG_OVERLAPPED, _winapi.NULL\n                    )\n            except OSError as e:\n                if e.winerror not in (_winapi.ERROR_SEM_TIMEOUT,\n                                      _winapi.ERROR_PIPE_BUSY) or _check_timeout(t):\n                    raise\n            else:\n                break\n        else:\n            raise\n\n        _winapi.SetNamedPipeHandleState(\n            h, _winapi.PIPE_READMODE_MESSAGE, None, None\n            )\n        return PipeConnection(h)\nMESSAGE_LENGTH = 20\nCHALLENGE = b'#CHALLENGE#'\nWELCOME = b'#WELCOME#'\nFAILURE = b'#FAILURE#'\nif sys.platform == 'win32':\n\n    def _exhaustive_wait(handles, timeout):\n        # Return ALL handles which are currently signalled.  (Only\n        # returning the first signalled might create starvation issues.)\n        L = list(handles)\n        ready = []\n        while L:\n            res = _winapi.WaitForMultipleObjects(L, False, timeout)\n            if res == WAIT_TIMEOUT:\n                break\n            elif WAIT_OBJECT_0 <= res < WAIT_OBJECT_0 + len(L):\n                res -= WAIT_OBJECT_0\n            elif WAIT_ABANDONED_0 <= res < WAIT_ABANDONED_0 + len(L):\n                res -= WAIT_ABANDONED_0\n            else:\n                raise RuntimeError('Should not get here')\n            ready.append(L[res])\n            L = L[res+1:]\n            timeout = 0\n        return ready\n\n    _ready_errors = {_winapi.ERROR_BROKEN_PIPE, _winapi.ERROR_NETNAME_DELETED}\n\n    def wait(object_list, timeout=None):\n        '''\n        Wait till an object in object_list is ready/readable.\n\n        Returns list of those objects in object_list which are ready/readable.\n        '''\n        if timeout is None:\n            timeout = INFINITE\n        elif timeout < 0:\n            timeout = 0\n        else:\n            timeout = int(timeout * 1000 + 0.5)\n\n        object_list = list(object_list)\n        waithandle_to_obj = {}\n        ov_list = []\n        ready_objects = set()\n        ready_handles = set()\n\n        try:\n            for o in object_list:\n                try:\n                    fileno = getattr(o, 'fileno')\n                except AttributeError:\n                    waithandle_to_obj[o.__index__()] = o\n                else:\n                    # start an overlapped read of length zero\n                    try:\n                        ov, err = _winapi.ReadFile(fileno(), 0, True)\n                    except OSError as e:\n                        ov, err = None, e.winerror\n                        if err not in _ready_errors:\n                            raise\n                    if err == _winapi.ERROR_IO_PENDING:\n                        ov_list.append(ov)\n                        waithandle_to_obj[ov.event] = o\n                    else:\n                        # If o.fileno() is an overlapped pipe handle and\n                        # err == 0 then there is a zero length message\n                        # in the pipe, but it HAS NOT been consumed...\n                        if ov and sys.getwindowsversion()[:2] >= (6, 2):\n                            # ... except on Windows 8 and later, where\n                            # the message HAS been consumed.\n                            try:\n                                _, err = ov.GetOverlappedResult(False)\n                            except OSError as e:\n                                err = e.winerror\n                            if not err and hasattr(o, '_got_empty_message'):\n                                o._got_empty_message = True\n                        ready_objects.add(o)\n                        timeout = 0\n\n            ready_handles = _exhaustive_wait(waithandle_to_obj.keys(), timeout)\n        finally:\n            # request that overlapped reads stop\n            for ov in ov_list:\n                ov.cancel()\n\n            # wait for all overlapped reads to stop\n            for ov in ov_list:\n                try:\n                    _, err = ov.GetOverlappedResult(True)\n                except OSError as e:\n                    err = e.winerror\n                    if err not in _ready_errors:\n                        raise\n                if err != _winapi.ERROR_OPERATION_ABORTED:\n                    o = waithandle_to_obj[ov.event]\n                    ready_objects.add(o)\n                    if err == 0:\n                        # If o.fileno() is an overlapped pipe handle then\n                        # a zero length message HAS been consumed.\n                        if hasattr(o, '_got_empty_message'):\n                            o._got_empty_message = True\n\n        ready_objects.update(waithandle_to_obj[h] for h in ready_handles)\n        return [o for o in object_list if o in ready_objects]\n\nelse:\n\n    import selectors\n\n    # poll/select have the advantage of not requiring any extra file\n    # descriptor, contrarily to epoll/kqueue (also, they require a single\n    # syscall).\n    if hasattr(selectors, 'PollSelector'):\n        _WaitSelector = selectors.PollSelector\n    else:\n        _WaitSelector = selectors.SelectSelector\n\n    def wait(object_list, timeout=None):\n        '''\n        Wait till an object in object_list is ready/readable.\n\n        Returns list of those objects in object_list which are ready/readable.\n        '''\n        with _WaitSelector() as selector:\n            for obj in object_list:\n                selector.register(obj, selectors.EVENT_READ)\n\n            if timeout is not None:\n                deadline = time.monotonic() + timeout\n\n            while True:\n                ready = selector.select(timeout)\n                if ready:\n                    return [key.fileobj for (key, events) in ready]\n                else:\n                    if timeout is not None:\n                        timeout = deadline - time.monotonic()\n                        if timeout < 0:\n                            return ready\nif sys.platform == 'win32':\n    def reduce_connection(conn):\n        handle = conn.fileno()\n        with socket.fromfd(handle, socket.AF_INET, socket.SOCK_STREAM) as s:\n            from . import resource_sharer\n            ds = resource_sharer.DupSocket(s)\n            return rebuild_connection, (ds, conn.readable, conn.writable)\n    def rebuild_connection(ds, readable, writable):\n        sock = ds.detach()\n        return Connection(sock.detach(), readable, writable)\n    reduction.register(Connection, reduce_connection)\n\n    def reduce_pipe_connection(conn):\n        access = ((_winapi.FILE_GENERIC_READ if conn.readable else 0) |\n                  (_winapi.FILE_GENERIC_WRITE if conn.writable else 0))\n        dh = reduction.DupHandle(conn.fileno(), access)\n        return rebuild_pipe_connection, (dh, conn.readable, conn.writable)\n    def rebuild_pipe_connection(dh, readable, writable):\n        handle = dh.detach()\n        return PipeConnection(handle, readable, writable)\n    reduction.register(PipeConnection, reduce_pipe_connection)\n\nelse:\n    def reduce_connection(conn):\n        df = reduction.DupFd(conn.fileno())\n        return rebuild_connection, (df, conn.readable, conn.writable)\n    def rebuild_connection(df, readable, writable):\n        fd = df.detach()\n        return Connection(fd, readable, writable)\n    reduction.register(Connection, reduce_connection)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._init_timeout": {
        "API_name": "multiprocessing.connection._init_timeout",
        "loc_name": "multiprocessing.connection._init_timeout",
        "args": "timeout",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 59,
        "namespace": "*",
        "body": "def _init_timeout(timeout=CONNECTION_TIMEOUT):\n    return time.monotonic() + timeout",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._check_timeout": {
        "API_name": "multiprocessing.connection._check_timeout",
        "loc_name": "multiprocessing.connection._check_timeout",
        "args": "t",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 62,
        "namespace": "*",
        "body": "def _check_timeout(t):\n    return time.monotonic() > t",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.arbitrary_address": {
        "API_name": "multiprocessing.connection.arbitrary_address",
        "loc_name": "multiprocessing.connection.arbitrary_address",
        "args": "family",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 69,
        "namespace": "*",
        "body": "def arbitrary_address(family):\n    '''\n    Return an arbitrary free address for the given family\n    '''\n    if family == 'AF_INET':\n        return ('localhost', 0)\n    elif family == 'AF_UNIX':\n        # Prefer abstract sockets if possible to avoid problems with the address\n        # size.  When coding portable applications, some implementations have\n        # sun_path as short as 92 bytes in the sockaddr_un struct.\n        if util.abstract_sockets_supported:\n            return f\"\\0listener-{os.getpid()}-{next(_mmap_counter)}\"\n        return tempfile.mktemp(prefix='listener-', dir=util.get_temp_dir())\n    elif family == 'AF_PIPE':\n        return tempfile.mktemp(prefix=r'\\\\.\\pipe\\pyc-%d-%d-' %\n                               (os.getpid(), next(_mmap_counter)), dir=\"\")\n    else:\n        raise ValueError('unrecognized family')",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._validate_family": {
        "API_name": "multiprocessing.connection._validate_family",
        "loc_name": "multiprocessing.connection._validate_family",
        "args": "family",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 88,
        "namespace": "*",
        "body": "def _validate_family(family):\n    '''\n    Checks if the family is valid for the current environment.\n    '''\n    if sys.platform != 'win32' and family == 'AF_PIPE':\n        raise ValueError('Family %s is not recognized.' % family)\n\n    if sys.platform == 'win32' and family == 'AF_UNIX':\n        # double check\n        if not hasattr(socket, family):\n            raise ValueError('Family %s is not recognized.' % family)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.address_type": {
        "API_name": "multiprocessing.connection.address_type",
        "loc_name": "multiprocessing.connection.address_type",
        "args": "address",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 100,
        "namespace": "*",
        "body": "def address_type(address):\n    '''\n    Return the types of the address\n\n    This can be 'AF_INET', 'AF_UNIX', or 'AF_PIPE'\n    '''\n    if type(address) == tuple:\n        return 'AF_INET'\n    elif type(address) is str and address.startswith('\\\\\\\\'):\n        return 'AF_PIPE'\n    elif type(address) is str or util.is_abstract_socket_namespace(address):\n        return 'AF_UNIX'\n    else:\n        raise ValueError('address type of %r unrecognized' % address)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase": {
        "API_name": "multiprocessing.connection._ConnectionBase",
        "loc_name": "multiprocessing.connection._ConnectionBase",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 119,
        "namespace": "_ConnectionBase",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.__init__": {
        "API_name": "multiprocessing.connection._ConnectionBase.__init__",
        "loc_name": "multiprocessing.connection._ConnectionBase.__init__",
        "args": "self;handle;readable;writable",
        "args_default": 2,
        "filepath": "multiprocessing.connection",
        "lineno": 122,
        "namespace": "_ConnectionBase",
        "body": "    def __init__(self, handle, readable=True, writable=True):\n        handle = handle.__index__()\n        if handle < 0:\n            raise ValueError(\"invalid handle\")\n        if not readable and not writable:\n            raise ValueError(\n                \"at least one of `readable` and `writable` must be True\")\n        self._handle = handle\n        self._readable = readable\n        self._writable = writable",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.__del__": {
        "API_name": "multiprocessing.connection._ConnectionBase.__del__",
        "loc_name": "multiprocessing.connection._ConnectionBase.__del__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 135,
        "namespace": "_ConnectionBase",
        "body": "    def __del__(self):\n        if self._handle is not None:\n            self._close()",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase._check_closed": {
        "API_name": "multiprocessing.connection._ConnectionBase._check_closed",
        "loc_name": "multiprocessing.connection._ConnectionBase._check_closed",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 139,
        "namespace": "_ConnectionBase",
        "body": "    def _check_closed(self):\n        if self._handle is None:\n            raise OSError(\"handle is closed\")",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase._check_readable": {
        "API_name": "multiprocessing.connection._ConnectionBase._check_readable",
        "loc_name": "multiprocessing.connection._ConnectionBase._check_readable",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 143,
        "namespace": "_ConnectionBase",
        "body": "    def _check_readable(self):\n        if not self._readable:\n            raise OSError(\"connection is write-only\")",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase._check_writable": {
        "API_name": "multiprocessing.connection._ConnectionBase._check_writable",
        "loc_name": "multiprocessing.connection._ConnectionBase._check_writable",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 147,
        "namespace": "_ConnectionBase",
        "body": "    def _check_writable(self):\n        if not self._writable:\n            raise OSError(\"connection is read-only\")",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase._bad_message_length": {
        "API_name": "multiprocessing.connection._ConnectionBase._bad_message_length",
        "loc_name": "multiprocessing.connection._ConnectionBase._bad_message_length",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 151,
        "namespace": "_ConnectionBase",
        "body": "    def _bad_message_length(self):\n        if self._writable:\n            self._readable = False\n        else:\n            self.close()\n        raise OSError(\"bad message length\")",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.closed": {
        "API_name": "multiprocessing.connection._ConnectionBase.closed",
        "loc_name": "multiprocessing.connection._ConnectionBase.closed",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 159,
        "namespace": "_ConnectionBase",
        "body": "    def closed(self):\n        \"\"\"True if the connection is closed\"\"\"\n        return self._handle is None",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.readable": {
        "API_name": "multiprocessing.connection._ConnectionBase.readable",
        "loc_name": "multiprocessing.connection._ConnectionBase.readable",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 164,
        "namespace": "_ConnectionBase",
        "body": "    def readable(self):\n        \"\"\"True if the connection is readable\"\"\"\n        return self._readable",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.writable": {
        "API_name": "multiprocessing.connection._ConnectionBase.writable",
        "loc_name": "multiprocessing.connection._ConnectionBase.writable",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 169,
        "namespace": "_ConnectionBase",
        "body": "    def writable(self):\n        \"\"\"True if the connection is writable\"\"\"\n        return self._writable",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.fileno": {
        "API_name": "multiprocessing.connection._ConnectionBase.fileno",
        "loc_name": "multiprocessing.connection._ConnectionBase.fileno",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 173,
        "namespace": "_ConnectionBase",
        "body": "    def fileno(self):\n        \"\"\"File descriptor or handle of the connection\"\"\"\n        self._check_closed()\n        return self._handle",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.close": {
        "API_name": "multiprocessing.connection._ConnectionBase.close",
        "loc_name": "multiprocessing.connection._ConnectionBase.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 178,
        "namespace": "_ConnectionBase",
        "body": "    def close(self):\n        \"\"\"Close the connection\"\"\"\n        if self._handle is not None:\n            try:\n                self._close()\n            finally:\n                self._handle = None",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.send_bytes": {
        "API_name": "multiprocessing.connection._ConnectionBase.send_bytes",
        "loc_name": "multiprocessing.connection._ConnectionBase.send_bytes",
        "args": "self;buf;offset;size",
        "args_default": 2,
        "filepath": "multiprocessing.connection",
        "lineno": 186,
        "namespace": "_ConnectionBase",
        "body": "    def send_bytes(self, buf, offset=0, size=None):\n        \"\"\"Send the bytes data from a bytes-like object\"\"\"\n        self._check_closed()\n        self._check_writable()\n        m = memoryview(buf)\n        # HACK for byte-indexing of non-bytewise buffers (e.g. array.array)\n        if m.itemsize > 1:\n            m = memoryview(bytes(m))\n        n = len(m)\n        if offset < 0:\n            raise ValueError(\"offset is negative\")\n        if n < offset:\n            raise ValueError(\"buffer length < offset\")\n        if size is None:\n            size = n - offset\n        elif size < 0:\n            raise ValueError(\"size is negative\")\n        elif offset + size > n:\n            raise ValueError(\"buffer length < offset + size\")\n        self._send_bytes(m[offset:offset + size])",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.send": {
        "API_name": "multiprocessing.connection._ConnectionBase.send",
        "loc_name": "multiprocessing.connection._ConnectionBase.send",
        "args": "self;obj",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 207,
        "namespace": "_ConnectionBase",
        "body": "    def send(self, obj):\n        \"\"\"Send a (picklable) object\"\"\"\n        self._check_closed()\n        self._check_writable()\n        self._send_bytes(_ForkingPickler.dumps(obj))",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.recv_bytes": {
        "API_name": "multiprocessing.connection._ConnectionBase.recv_bytes",
        "loc_name": "multiprocessing.connection._ConnectionBase.recv_bytes",
        "args": "self;maxlength",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 213,
        "namespace": "_ConnectionBase",
        "body": "    def recv_bytes(self, maxlength=None):\n        \"\"\"\n        Receive bytes data as a bytes object.\n        \"\"\"\n        self._check_closed()\n        self._check_readable()\n        if maxlength is not None and maxlength < 0:\n            raise ValueError(\"negative maxlength\")\n        buf = self._recv_bytes(maxlength)\n        if buf is None:\n            self._bad_message_length()\n        return buf.getvalue()",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.recv_bytes_into": {
        "API_name": "multiprocessing.connection._ConnectionBase.recv_bytes_into",
        "loc_name": "multiprocessing.connection._ConnectionBase.recv_bytes_into",
        "args": "self;buf;offset",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 226,
        "namespace": "_ConnectionBase",
        "body": "    def recv_bytes_into(self, buf, offset=0):\n        \"\"\"\n        Receive bytes data into a writeable bytes-like object.\n        Return the number of bytes read.\n        \"\"\"\n        self._check_closed()\n        self._check_readable()\n        with memoryview(buf) as m:\n            # Get bytesize of arbitrary buffer\n            itemsize = m.itemsize\n            bytesize = itemsize * len(m)\n            if offset < 0:\n                raise ValueError(\"negative offset\")\n            elif offset > bytesize:\n                raise ValueError(\"offset too large\")\n            result = self._recv_bytes()\n            size = result.tell()\n            if bytesize < offset + size:\n                raise BufferTooShort(result.getvalue())\n            # Message can fit in dest\n            result.seek(0)\n            result.readinto(m[offset // itemsize :\n                              (offset + size) // itemsize])\n            return size",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.recv": {
        "API_name": "multiprocessing.connection._ConnectionBase.recv",
        "loc_name": "multiprocessing.connection._ConnectionBase.recv",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 251,
        "namespace": "_ConnectionBase",
        "body": "    def recv(self):\n        \"\"\"Receive a (picklable) object\"\"\"\n        self._check_closed()\n        self._check_readable()\n        buf = self._recv_bytes()\n        return _ForkingPickler.loads(buf.getbuffer())",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.poll": {
        "API_name": "multiprocessing.connection._ConnectionBase.poll",
        "loc_name": "multiprocessing.connection._ConnectionBase.poll",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 258,
        "namespace": "_ConnectionBase",
        "body": "    def poll(self, timeout=0.0):\n        \"\"\"Whether there is any input available to be read\"\"\"\n        self._check_closed()\n        self._check_readable()\n        return self._poll(timeout)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.__enter__": {
        "API_name": "multiprocessing.connection._ConnectionBase.__enter__",
        "loc_name": "multiprocessing.connection._ConnectionBase.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 264,
        "namespace": "_ConnectionBase",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._ConnectionBase.__exit__": {
        "API_name": "multiprocessing.connection._ConnectionBase.__exit__",
        "loc_name": "multiprocessing.connection._ConnectionBase.__exit__",
        "args": "self;exc_type;exc_value;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 267,
        "namespace": "_ConnectionBase",
        "body": "    def __exit__(self, exc_type, exc_value, exc_tb):\n        self.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeConnection._close": {
        "API_name": "multiprocessing.connection.PipeConnection._close",
        "loc_name": "multiprocessing.connection.PipeConnection._close",
        "args": "self;_CloseHandle",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 281,
        "namespace": "PipeConnection",
        "body": "        def _close(self, _CloseHandle=_winapi.CloseHandle):\n            _CloseHandle(self._handle)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeConnection._send_bytes": {
        "API_name": "multiprocessing.connection.PipeConnection._send_bytes",
        "loc_name": "multiprocessing.connection.PipeConnection._send_bytes",
        "args": "self;buf",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 284,
        "namespace": "PipeConnection",
        "body": "        def _send_bytes(self, buf):\n            ov, err = _winapi.WriteFile(self._handle, buf, overlapped=True)\n            try:\n                if err == _winapi.ERROR_IO_PENDING:\n                    waitres = _winapi.WaitForMultipleObjects(\n                        [ov.event], False, INFINITE)\n                    assert waitres == WAIT_OBJECT_0\n            except:\n                ov.cancel()\n                raise\n            finally:\n                nwritten, err = ov.GetOverlappedResult(True)\n            assert err == 0\n            assert nwritten == len(buf)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeConnection._recv_bytes": {
        "API_name": "multiprocessing.connection.PipeConnection._recv_bytes",
        "loc_name": "multiprocessing.connection.PipeConnection._recv_bytes",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 299,
        "namespace": "PipeConnection",
        "body": "        def _recv_bytes(self, maxsize=None):\n            if self._got_empty_message:\n                self._got_empty_message = False\n                return io.BytesIO()\n            else:\n                bsize = 128 if maxsize is None else min(maxsize, 128)\n                try:\n                    ov, err = _winapi.ReadFile(self._handle, bsize,\n                                                overlapped=True)\n                    try:\n                        if err == _winapi.ERROR_IO_PENDING:\n                            waitres = _winapi.WaitForMultipleObjects(\n                                [ov.event], False, INFINITE)\n                            assert waitres == WAIT_OBJECT_0\n                    except:\n                        ov.cancel()\n                        raise\n                    finally:\n                        nread, err = ov.GetOverlappedResult(True)\n                        if err == 0:\n                            f = io.BytesIO()\n                            f.write(ov.getbuffer())\n                            return f\n                        elif err == _winapi.ERROR_MORE_DATA:\n                            return self._get_more_data(ov, maxsize)\n                except OSError as e:\n                    if e.winerror == _winapi.ERROR_BROKEN_PIPE:\n                        raise EOFError\n                    else:\n                        raise\n            raise RuntimeError(\"shouldn't get here; expected KeyboardInterrupt\")",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeConnection._poll": {
        "API_name": "multiprocessing.connection.PipeConnection._poll",
        "loc_name": "multiprocessing.connection.PipeConnection._poll",
        "args": "self;timeout",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 331,
        "namespace": "PipeConnection",
        "body": "        def _poll(self, timeout):\n            if (self._got_empty_message or\n                        _winapi.PeekNamedPipe(self._handle)[0] != 0):\n                return True\n            return bool(wait([self], timeout))",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeConnection._get_more_data": {
        "API_name": "multiprocessing.connection.PipeConnection._get_more_data",
        "loc_name": "multiprocessing.connection.PipeConnection._get_more_data",
        "args": "self;ov;maxsize",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 337,
        "namespace": "PipeConnection",
        "body": "        def _get_more_data(self, ov, maxsize):\n            buf = ov.getbuffer()\n            f = io.BytesIO()\n            f.write(buf)\n            left = _winapi.PeekNamedPipe(self._handle)[1]\n            assert left > 0\n            if maxsize is not None and len(buf) + left > maxsize:\n                self._bad_message_length()\n            ov, err = _winapi.ReadFile(self._handle, left, overlapped=True)\n            rbytes, err = ov.GetOverlappedResult(True)\n            assert err == 0\n            assert rbytes == left\n            f.write(ov.getbuffer())\n            return f",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeConnection": {
        "API_name": "multiprocessing.connection.PipeConnection",
        "loc_name": "multiprocessing.connection.PipeConnection",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 273,
        "namespace": "PipeConnection",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Connection._send": {
        "API_name": "multiprocessing.connection.Connection._send",
        "loc_name": "multiprocessing.connection.Connection._send",
        "args": "self;buf;write",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 370,
        "namespace": "Connection",
        "body": "    def _send(self, buf, write=_write):\n        remaining = len(buf)\n        while True:\n            n = write(self._handle, buf)\n            remaining -= n\n            if remaining == 0:\n                break\n            buf = buf[n:]",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Connection._recv": {
        "API_name": "multiprocessing.connection.Connection._recv",
        "loc_name": "multiprocessing.connection.Connection._recv",
        "args": "self;size;read",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 379,
        "namespace": "Connection",
        "body": "    def _recv(self, size, read=_read):\n        buf = io.BytesIO()\n        handle = self._handle\n        remaining = size\n        while remaining > 0:\n            chunk = read(handle, remaining)\n            n = len(chunk)\n            if n == 0:\n                if remaining == size:\n                    raise EOFError\n                else:\n                    raise OSError(\"got end of file during message\")\n            buf.write(chunk)\n            remaining -= n\n        return buf",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Connection._send_bytes": {
        "API_name": "multiprocessing.connection.Connection._send_bytes",
        "loc_name": "multiprocessing.connection.Connection._send_bytes",
        "args": "self;buf",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 395,
        "namespace": "Connection",
        "body": "    def _send_bytes(self, buf):\n        n = len(buf)\n        if n > 0x7fffffff:\n            pre_header = struct.pack(\"!i\", -1)\n            header = struct.pack(\"!Q\", n)\n            self._send(pre_header)\n            self._send(header)\n            self._send(buf)\n        else:\n            # For wire compatibility with 3.7 and lower\n            header = struct.pack(\"!i\", n)\n            if n > 16384:\n                # The payload is large so Nagle's algorithm won't be triggered\n                # and we'd better avoid the cost of concatenation.\n                self._send(header)\n                self._send(buf)\n            else:\n                # Issue #20540: concatenate before sending, to avoid delays due\n                # to Nagle's algorithm on a TCP socket.\n                # Also note we want to avoid sending a 0-length buffer separately,\n                # to avoid \"broken pipe\" errors if the other end closed the pipe.\n                self._send(header + buf)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Connection._recv_bytes": {
        "API_name": "multiprocessing.connection.Connection._recv_bytes",
        "loc_name": "multiprocessing.connection.Connection._recv_bytes",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 418,
        "namespace": "Connection",
        "body": "    def _recv_bytes(self, maxsize=None):\n        buf = self._recv(4)\n        size, = struct.unpack(\"!i\", buf.getvalue())\n        if size == -1:\n            buf = self._recv(8)\n            size, = struct.unpack(\"!Q\", buf.getvalue())\n        if maxsize is not None and size > maxsize:\n            return None\n        return self._recv(size)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Connection._poll": {
        "API_name": "multiprocessing.connection.Connection._poll",
        "loc_name": "multiprocessing.connection.Connection._poll",
        "args": "self;timeout",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 428,
        "namespace": "Connection",
        "body": "    def _poll(self, timeout):\n        r = wait([self], timeout)\n        return bool(r)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Connection": {
        "API_name": "multiprocessing.connection.Connection",
        "loc_name": "multiprocessing.connection.Connection",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 353,
        "namespace": "Connection",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener": {
        "API_name": "multiprocessing.connection.Listener",
        "loc_name": "multiprocessing.connection.Listener",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 437,
        "namespace": "Listener",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.__init__": {
        "API_name": "multiprocessing.connection.Listener.__init__",
        "loc_name": "multiprocessing.connection.Listener.__init__",
        "args": "self;address;family;backlog;authkey",
        "args_default": 4,
        "filepath": "multiprocessing.connection",
        "lineno": 444,
        "namespace": "Listener",
        "body": "    def __init__(self, address=None, family=None, backlog=1, authkey=None):\n        family = family or (address and address_type(address)) \\\n                 or default_family\n        address = address or arbitrary_address(family)\n\n        _validate_family(family)\n        if family == 'AF_PIPE':\n            self._listener = PipeListener(address, backlog)\n        else:\n            self._listener = SocketListener(address, family, backlog)\n\n        if authkey is not None and not isinstance(authkey, bytes):\n            raise TypeError('authkey should be a byte string')\n\n        self._authkey = authkey",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.accept": {
        "API_name": "multiprocessing.connection.Listener.accept",
        "loc_name": "multiprocessing.connection.Listener.accept",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 460,
        "namespace": "Listener",
        "body": "    def accept(self):\n        '''\n        Accept a connection on the bound socket or named pipe of `self`.\n\n        Returns a `Connection` object.\n        '''\n        if self._listener is None:\n            raise OSError('listener is closed')\n        c = self._listener.accept()\n        if self._authkey:\n            deliver_challenge(c, self._authkey)\n            answer_challenge(c, self._authkey)\n        return c",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.close": {
        "API_name": "multiprocessing.connection.Listener.close",
        "loc_name": "multiprocessing.connection.Listener.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 474,
        "namespace": "Listener",
        "body": "    def close(self):\n        '''\n        Close the bound socket or named pipe of `self`.\n        '''\n        listener = self._listener\n        if listener is not None:\n            self._listener = None\n            listener.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.address": {
        "API_name": "multiprocessing.connection.Listener.address",
        "loc_name": "multiprocessing.connection.Listener.address",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 484,
        "namespace": "Listener",
        "body": "    def address(self):\n        return self._listener._address",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.last_accepted": {
        "API_name": "multiprocessing.connection.Listener.last_accepted",
        "loc_name": "multiprocessing.connection.Listener.last_accepted",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 488,
        "namespace": "Listener",
        "body": "    def last_accepted(self):\n        return self._listener._last_accepted",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.__enter__": {
        "API_name": "multiprocessing.connection.Listener.__enter__",
        "loc_name": "multiprocessing.connection.Listener.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 491,
        "namespace": "Listener",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Listener.__exit__": {
        "API_name": "multiprocessing.connection.Listener.__exit__",
        "loc_name": "multiprocessing.connection.Listener.__exit__",
        "args": "self;exc_type;exc_value;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 494,
        "namespace": "Listener",
        "body": "    def __exit__(self, exc_type, exc_value, exc_tb):\n        self.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Client": {
        "API_name": "multiprocessing.connection.Client",
        "loc_name": "multiprocessing.connection.Client",
        "args": "address;family;authkey",
        "args_default": 2,
        "filepath": "multiprocessing.connection",
        "lineno": 498,
        "namespace": "*",
        "body": "def Client(address, family=None, authkey=None):\n    '''\n    Returns a connection to the address of a `Listener`\n    '''\n    family = family or address_type(address)\n    _validate_family(family)\n    if family == 'AF_PIPE':\n        c = PipeClient(address)\n    else:\n        c = SocketClient(address)\n\n    if authkey is not None and not isinstance(authkey, bytes):\n        raise TypeError('authkey should be a byte string')\n\n    if authkey is not None:\n        answer_challenge(c, authkey)\n        deliver_challenge(c, authkey)\n\n    return c",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.Pipe": {
        "API_name": "multiprocessing.connection.Pipe",
        "loc_name": "multiprocessing.connection.Pipe",
        "args": "duplex",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 540,
        "namespace": "*",
        "body": "    def Pipe(duplex=True):\n        '''\n        Returns pair of connection objects at either end of a pipe\n        '''\n        address = arbitrary_address('AF_PIPE')\n        if duplex:\n            openmode = _winapi.PIPE_ACCESS_DUPLEX\n            access = _winapi.GENERIC_READ | _winapi.GENERIC_WRITE\n            obsize, ibsize = BUFSIZE, BUFSIZE\n        else:\n            openmode = _winapi.PIPE_ACCESS_INBOUND\n            access = _winapi.GENERIC_WRITE\n            obsize, ibsize = 0, BUFSIZE\n\n        h1 = _winapi.CreateNamedPipe(\n            address, openmode | _winapi.FILE_FLAG_OVERLAPPED |\n            _winapi.FILE_FLAG_FIRST_PIPE_INSTANCE,\n            _winapi.PIPE_TYPE_MESSAGE | _winapi.PIPE_READMODE_MESSAGE |\n            _winapi.PIPE_WAIT,\n            1, obsize, ibsize, _winapi.NMPWAIT_WAIT_FOREVER,\n            # default security descriptor: the handle cannot be inherited\n            _winapi.NULL\n            )\n        h2 = _winapi.CreateFile(\n            address, access, 0, _winapi.NULL, _winapi.OPEN_EXISTING,\n            _winapi.FILE_FLAG_OVERLAPPED, _winapi.NULL\n            )\n        _winapi.SetNamedPipeHandleState(\n            h2, _winapi.PIPE_READMODE_MESSAGE, None, None\n            )\n\n        overlapped = _winapi.ConnectNamedPipe(h1, overlapped=True)\n        _, err = overlapped.GetOverlappedResult(True)\n        assert err == 0\n\n        c1 = PipeConnection(h1, writable=duplex)\n        c2 = PipeConnection(h2, readable=duplex)\n\n        return c1, c2",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.SocketListener": {
        "API_name": "multiprocessing.connection.SocketListener",
        "loc_name": "multiprocessing.connection.SocketListener",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 584,
        "namespace": "SocketListener",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.SocketListener.__init__": {
        "API_name": "multiprocessing.connection.SocketListener.__init__",
        "loc_name": "multiprocessing.connection.SocketListener.__init__",
        "args": "self;address;family;backlog",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 588,
        "namespace": "SocketListener",
        "body": "    def __init__(self, address, family, backlog=1):\n        self._socket = socket.socket(getattr(socket, family))\n        try:\n            # SO_REUSEADDR has different semantics on Windows (issue #2550).\n            if os.name == 'posix':\n                self._socket.setsockopt(socket.SOL_SOCKET,\n                                        socket.SO_REUSEADDR, 1)\n            self._socket.setblocking(True)\n            self._socket.bind(address)\n            self._socket.listen(backlog)\n            self._address = self._socket.getsockname()\n        except OSError:\n            self._socket.close()\n            raise\n        self._family = family\n        self._last_accepted = None\n\n        if family == 'AF_UNIX' and not util.is_abstract_socket_namespace(address):\n            # Linux abstract socket namespaces do not need to be explicitly unlinked\n            self._unlink = util.Finalize(\n                self, os.unlink, args=(address,), exitpriority=0\n                )\n        else:\n            self._unlink = None",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.SocketListener.accept": {
        "API_name": "multiprocessing.connection.SocketListener.accept",
        "loc_name": "multiprocessing.connection.SocketListener.accept",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 613,
        "namespace": "SocketListener",
        "body": "    def accept(self):\n        s, self._last_accepted = self._socket.accept()\n        s.setblocking(True)\n        return Connection(s.detach())",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.SocketListener.close": {
        "API_name": "multiprocessing.connection.SocketListener.close",
        "loc_name": "multiprocessing.connection.SocketListener.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 618,
        "namespace": "SocketListener",
        "body": "    def close(self):\n        try:\n            self._socket.close()\n        finally:\n            unlink = self._unlink\n            if unlink is not None:\n                self._unlink = None\n                unlink()",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.SocketClient": {
        "API_name": "multiprocessing.connection.SocketClient",
        "loc_name": "multiprocessing.connection.SocketClient",
        "args": "address",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 628,
        "namespace": "*",
        "body": "def SocketClient(address):\n    '''\n    Return a connection object connected to the socket given by `address`\n    '''\n    family = address_type(address)\n    with socket.socket( getattr(socket, family) ) as s:\n        s.setblocking(True)\n        s.connect(address)\n        return Connection(s.detach())",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeListener": {
        "API_name": "multiprocessing.connection.PipeListener",
        "loc_name": "multiprocessing.connection.PipeListener",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 644,
        "namespace": "PipeListener",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeListener.__init__": {
        "API_name": "multiprocessing.connection.PipeListener.__init__",
        "loc_name": "multiprocessing.connection.PipeListener.__init__",
        "args": "self;address;backlog",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 648,
        "namespace": "PipeListener",
        "body": "        def __init__(self, address, backlog=None):\n            self._address = address\n            self._handle_queue = [self._new_handle(first=True)]\n\n            self._last_accepted = None\n            util.sub_debug('listener created with address=%r', self._address)\n            self.close = util.Finalize(\n                self, PipeListener._finalize_pipe_listener,\n                args=(self._handle_queue, self._address), exitpriority=0\n                )",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeListener._new_handle": {
        "API_name": "multiprocessing.connection.PipeListener._new_handle",
        "loc_name": "multiprocessing.connection.PipeListener._new_handle",
        "args": "self;first",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 659,
        "namespace": "PipeListener",
        "body": "        def _new_handle(self, first=False):\n            flags = _winapi.PIPE_ACCESS_DUPLEX | _winapi.FILE_FLAG_OVERLAPPED\n            if first:\n                flags |= _winapi.FILE_FLAG_FIRST_PIPE_INSTANCE\n            return _winapi.CreateNamedPipe(\n                self._address, flags,\n                _winapi.PIPE_TYPE_MESSAGE | _winapi.PIPE_READMODE_MESSAGE |\n                _winapi.PIPE_WAIT,\n                _winapi.PIPE_UNLIMITED_INSTANCES, BUFSIZE, BUFSIZE,\n                _winapi.NMPWAIT_WAIT_FOREVER, _winapi.NULL\n                )",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeListener.accept": {
        "API_name": "multiprocessing.connection.PipeListener.accept",
        "loc_name": "multiprocessing.connection.PipeListener.accept",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 671,
        "namespace": "PipeListener",
        "body": "        def accept(self):\n            self._handle_queue.append(self._new_handle())\n            handle = self._handle_queue.pop(0)\n            try:\n                ov = _winapi.ConnectNamedPipe(handle, overlapped=True)\n            except OSError as e:\n                if e.winerror != _winapi.ERROR_NO_DATA:\n                    raise\n                # ERROR_NO_DATA can occur if a client has already connected,\n                # written data and then disconnected -- see Issue 14725.\n            else:\n                try:\n                    res = _winapi.WaitForMultipleObjects(\n                        [ov.event], False, INFINITE)\n                except:\n                    ov.cancel()\n                    _winapi.CloseHandle(handle)\n                    raise\n                finally:\n                    _, err = ov.GetOverlappedResult(True)\n                    assert err == 0\n            return PipeConnection(handle)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeListener._finalize_pipe_listener": {
        "API_name": "multiprocessing.connection.PipeListener._finalize_pipe_listener",
        "loc_name": "multiprocessing.connection.PipeListener._finalize_pipe_listener",
        "args": "queue;address",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 695,
        "namespace": "PipeListener",
        "body": "        def _finalize_pipe_listener(queue, address):\n            util.sub_debug('closing listener with address=%r', address)\n            for handle in queue:\n                _winapi.CloseHandle(handle)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.PipeClient": {
        "API_name": "multiprocessing.connection.PipeClient",
        "loc_name": "multiprocessing.connection.PipeClient",
        "args": "address",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 700,
        "namespace": "*",
        "body": "    def PipeClient(address):\n        '''\n        Return a connection object connected to the pipe given by `address`\n        '''\n        t = _init_timeout()\n        while 1:\n            try:\n                _winapi.WaitNamedPipe(address, 1000)\n                h = _winapi.CreateFile(\n                    address, _winapi.GENERIC_READ | _winapi.GENERIC_WRITE,\n                    0, _winapi.NULL, _winapi.OPEN_EXISTING,\n                    _winapi.FILE_FLAG_OVERLAPPED, _winapi.NULL\n                    )\n            except OSError as e:\n                if e.winerror not in (_winapi.ERROR_SEM_TIMEOUT,\n                                      _winapi.ERROR_PIPE_BUSY) or _check_timeout(t):\n                    raise\n            else:\n                break\n        else:\n            raise\n\n        _winapi.SetNamedPipeHandleState(\n            h, _winapi.PIPE_READMODE_MESSAGE, None, None\n            )\n        return PipeConnection(h)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.deliver_challenge": {
        "API_name": "multiprocessing.connection.deliver_challenge",
        "loc_name": "multiprocessing.connection.deliver_challenge",
        "args": "connection;authkey",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 737,
        "namespace": "*",
        "body": "def deliver_challenge(connection, authkey):\n    import hmac\n    if not isinstance(authkey, bytes):\n        raise ValueError(\n            \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n    message = os.urandom(MESSAGE_LENGTH)\n    connection.send_bytes(CHALLENGE + message)\n    digest = hmac.new(authkey, message, 'md5').digest()\n    response = connection.recv_bytes(256)        # reject large message\n    if response == digest:\n        connection.send_bytes(WELCOME)\n    else:\n        connection.send_bytes(FAILURE)\n        raise AuthenticationError('digest received was wrong')",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.answer_challenge": {
        "API_name": "multiprocessing.connection.answer_challenge",
        "loc_name": "multiprocessing.connection.answer_challenge",
        "args": "connection;authkey",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 752,
        "namespace": "*",
        "body": "def answer_challenge(connection, authkey):\n    import hmac\n    if not isinstance(authkey, bytes):\n        raise ValueError(\n            \"Authkey must be bytes, not {0!s}\".format(type(authkey)))\n    message = connection.recv_bytes(256)         # reject large message\n    assert message[:len(CHALLENGE)] == CHALLENGE, 'message = %r' % message\n    message = message[len(CHALLENGE):]\n    digest = hmac.new(authkey, message, 'md5').digest()\n    connection.send_bytes(digest)\n    response = connection.recv_bytes(256)        # reject large message\n    if response != WELCOME:\n        raise AuthenticationError('digest sent was rejected')",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.ConnectionWrapper": {
        "API_name": "multiprocessing.connection.ConnectionWrapper",
        "loc_name": "multiprocessing.connection.ConnectionWrapper",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 770,
        "namespace": "ConnectionWrapper",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.ConnectionWrapper.__init__": {
        "API_name": "multiprocessing.connection.ConnectionWrapper.__init__",
        "loc_name": "multiprocessing.connection.ConnectionWrapper.__init__",
        "args": "self;conn;dumps;loads",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 771,
        "namespace": "ConnectionWrapper",
        "body": "    def __init__(self, conn, dumps, loads):\n        self._conn = conn\n        self._dumps = dumps\n        self._loads = loads\n        for attr in ('fileno', 'close', 'poll', 'recv_bytes', 'send_bytes'):\n            obj = getattr(conn, attr)\n            setattr(self, attr, obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.ConnectionWrapper.send": {
        "API_name": "multiprocessing.connection.ConnectionWrapper.send",
        "loc_name": "multiprocessing.connection.ConnectionWrapper.send",
        "args": "self;obj",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 778,
        "namespace": "ConnectionWrapper",
        "body": "    def send(self, obj):\n        s = self._dumps(obj)\n        self._conn.send_bytes(s)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.ConnectionWrapper.recv": {
        "API_name": "multiprocessing.connection.ConnectionWrapper.recv",
        "loc_name": "multiprocessing.connection.ConnectionWrapper.recv",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 781,
        "namespace": "ConnectionWrapper",
        "body": "    def recv(self):\n        s = self._conn.recv_bytes()\n        return self._loads(s)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._xml_dumps": {
        "API_name": "multiprocessing.connection._xml_dumps",
        "loc_name": "multiprocessing.connection._xml_dumps",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 785,
        "namespace": "*",
        "body": "def _xml_dumps(obj):\n    return xmlrpclib.dumps((obj,), None, None, None, 1).encode('utf-8')",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._xml_loads": {
        "API_name": "multiprocessing.connection._xml_loads",
        "loc_name": "multiprocessing.connection._xml_loads",
        "args": "s",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 788,
        "namespace": "*",
        "body": "def _xml_loads(s):\n    (obj,), method = xmlrpclib.loads(s.decode('utf-8'))\n    return obj",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.XmlListener.accept": {
        "API_name": "multiprocessing.connection.XmlListener.accept",
        "loc_name": "multiprocessing.connection.XmlListener.accept",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 793,
        "namespace": "XmlListener",
        "body": "    def accept(self):\n        global xmlrpclib\n        import xmlrpc.client as xmlrpclib\n        obj = Listener.accept(self)\n        return ConnectionWrapper(obj, _xml_dumps, _xml_loads)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.XmlListener": {
        "API_name": "multiprocessing.connection.XmlListener",
        "loc_name": "multiprocessing.connection.XmlListener",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.connection",
        "lineno": 792,
        "namespace": "XmlListener",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.XmlClient": {
        "API_name": "multiprocessing.connection.XmlClient",
        "loc_name": "multiprocessing.connection.XmlClient",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 799,
        "namespace": "*",
        "body": "def XmlClient(*args, **kwds):\n    global xmlrpclib\n    import xmlrpc.client as xmlrpclib\n    return ConnectionWrapper(Client(*args, **kwds), _xml_dumps, _xml_loads)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection._exhaustive_wait": {
        "API_name": "multiprocessing.connection._exhaustive_wait",
        "loc_name": "multiprocessing.connection._exhaustive_wait",
        "args": "handles;timeout",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 810,
        "namespace": "*",
        "body": "    def _exhaustive_wait(handles, timeout):\n        # Return ALL handles which are currently signalled.  (Only\n        # returning the first signalled might create starvation issues.)\n        L = list(handles)\n        ready = []\n        while L:\n            res = _winapi.WaitForMultipleObjects(L, False, timeout)\n            if res == WAIT_TIMEOUT:\n                break\n            elif WAIT_OBJECT_0 <= res < WAIT_OBJECT_0 + len(L):\n                res -= WAIT_OBJECT_0\n            elif WAIT_ABANDONED_0 <= res < WAIT_ABANDONED_0 + len(L):\n                res -= WAIT_ABANDONED_0\n            else:\n                raise RuntimeError('Should not get here')\n            ready.append(L[res])\n            L = L[res+1:]\n            timeout = 0\n        return ready",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.wait": {
        "API_name": "multiprocessing.connection.wait",
        "loc_name": "multiprocessing.connection.wait",
        "args": "object_list;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.connection",
        "lineno": 922,
        "namespace": "*",
        "body": "    def wait(object_list, timeout=None):\n        '''\n        Wait till an object in object_list is ready/readable.\n\n        Returns list of those objects in object_list which are ready/readable.\n        '''\n        with _WaitSelector() as selector:\n            for obj in object_list:\n                selector.register(obj, selectors.EVENT_READ)\n\n            if timeout is not None:\n                deadline = time.monotonic() + timeout\n\n            while True:\n                ready = selector.select(timeout)\n                if ready:\n                    return [key.fileobj for (key, events) in ready]\n                else:\n                    if timeout is not None:\n                        timeout = deadline - time.monotonic()\n                        if timeout < 0:\n                            return ready",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.reduce_connection": {
        "API_name": "multiprocessing.connection.reduce_connection",
        "loc_name": "multiprocessing.connection.reduce_connection",
        "args": "conn",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 972,
        "namespace": "*",
        "body": "    def reduce_connection(conn):\n        df = reduction.DupFd(conn.fileno())\n        return rebuild_connection, (df, conn.readable, conn.writable)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.rebuild_connection": {
        "API_name": "multiprocessing.connection.rebuild_connection",
        "loc_name": "multiprocessing.connection.rebuild_connection",
        "args": "df;readable;writable",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 975,
        "namespace": "*",
        "body": "    def rebuild_connection(df, readable, writable):\n        fd = df.detach()\n        return Connection(fd, readable, writable)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.reduce_pipe_connection": {
        "API_name": "multiprocessing.connection.reduce_pipe_connection",
        "loc_name": "multiprocessing.connection.reduce_pipe_connection",
        "args": "conn",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 961,
        "namespace": "*",
        "body": "    def reduce_pipe_connection(conn):\n        access = ((_winapi.FILE_GENERIC_READ if conn.readable else 0) |\n                  (_winapi.FILE_GENERIC_WRITE if conn.writable else 0))\n        dh = reduction.DupHandle(conn.fileno(), access)\n        return rebuild_pipe_connection, (dh, conn.readable, conn.writable)",
        "name_type": "stdlib"
    },
    "multiprocessing.connection.rebuild_pipe_connection": {
        "API_name": "multiprocessing.connection.rebuild_pipe_connection",
        "loc_name": "multiprocessing.connection.rebuild_pipe_connection",
        "args": "dh;readable;writable",
        "args_default": 0,
        "filepath": "multiprocessing.connection",
        "lineno": 966,
        "namespace": "*",
        "body": "    def rebuild_pipe_connection(dh, readable, writable):\n        handle = dh.detach()\n        return PipeConnection(handle, readable, writable)",
        "name_type": "stdlib"
    },
    "multiprocessing.context": {
        "API_name": "multiprocessing.context",
        "loc_name": "multiprocessing.context",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ()\nif sys.platform != 'win32':\n\n    class ForkProcess(process.BaseProcess):\n        _start_method = 'fork'\n        @staticmethod\n        def _Popen(process_obj):\n            from .popen_fork import Popen\n            return Popen(process_obj)\n\n    class SpawnProcess(process.BaseProcess):\n        _start_method = 'spawn'\n        @staticmethod\n        def _Popen(process_obj):\n            from .popen_spawn_posix import Popen\n            return Popen(process_obj)\n\n    class ForkServerProcess(process.BaseProcess):\n        _start_method = 'forkserver'\n        @staticmethod\n        def _Popen(process_obj):\n            from .popen_forkserver import Popen\n            return Popen(process_obj)\n\n    class ForkContext(BaseContext):\n        _name = 'fork'\n        Process = ForkProcess\n\n    class SpawnContext(BaseContext):\n        _name = 'spawn'\n        Process = SpawnProcess\n\n    class ForkServerContext(BaseContext):\n        _name = 'forkserver'\n        Process = ForkServerProcess\n        def _check_available(self):\n            if not reduction.HAVE_SEND_HANDLE:\n                raise ValueError('forkserver start method not available')\n\n    _concrete_contexts = {\n        'fork': ForkContext(),\n        'spawn': SpawnContext(),\n        'forkserver': ForkServerContext(),\n    }\n    if sys.platform == 'darwin':\n        # bpo-33725: running arbitrary code after fork() is no longer reliable\n        # on macOS since macOS 10.14 (Mojave). Use spawn by default instead.\n        _default_context = DefaultContext(_concrete_contexts['spawn'])\n    else:\n        _default_context = DefaultContext(_concrete_contexts['fork'])\n\nelse:\n\n    class SpawnProcess(process.BaseProcess):\n        _start_method = 'spawn'\n        @staticmethod\n        def _Popen(process_obj):\n            from .popen_spawn_win32 import Popen\n            return Popen(process_obj)\n\n    class SpawnContext(BaseContext):\n        _name = 'spawn'\n        Process = SpawnProcess\n\n    _concrete_contexts = {\n        'spawn': SpawnContext(),\n    }\n    _default_context = DefaultContext(_concrete_contexts['spawn'])\n_tls = threading.local()",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ProcessError": {
        "API_name": "multiprocessing.context.ProcessError",
        "loc_name": "multiprocessing.context.ProcessError",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 14,
        "namespace": "ProcessError",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BufferTooShort": {
        "API_name": "multiprocessing.context.BufferTooShort",
        "loc_name": "multiprocessing.context.BufferTooShort",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 17,
        "namespace": "BufferTooShort",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.TimeoutError": {
        "API_name": "multiprocessing.context.TimeoutError",
        "loc_name": "multiprocessing.context.TimeoutError",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 20,
        "namespace": "TimeoutError",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.AuthenticationError": {
        "API_name": "multiprocessing.context.AuthenticationError",
        "loc_name": "multiprocessing.context.AuthenticationError",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 23,
        "namespace": "AuthenticationError",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.cpu_count": {
        "API_name": "multiprocessing.context.BaseContext.cpu_count",
        "loc_name": "multiprocessing.context.BaseContext.cpu_count",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 41,
        "namespace": "BaseContext",
        "body": "    def cpu_count(self):\n        '''Returns the number of CPUs in the system'''\n        num = os.cpu_count()\n        if num is None:\n            raise NotImplementedError('cannot determine number of cpus')\n        else:\n            return num",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Manager": {
        "API_name": "multiprocessing.context.BaseContext.Manager",
        "loc_name": "multiprocessing.context.BaseContext.Manager",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 49,
        "namespace": "BaseContext",
        "body": "    def Manager(self):\n        '''Returns a manager associated with a running server process\n\n        The managers methods such as `Lock()`, `Condition()` and `Queue()`\n        can be used to create shared objects.\n        '''\n        from .managers import SyncManager\n        m = SyncManager(ctx=self.get_context())\n        m.start()\n        return m",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Pipe": {
        "API_name": "multiprocessing.context.BaseContext.Pipe",
        "loc_name": "multiprocessing.context.BaseContext.Pipe",
        "args": "self;duplex",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 60,
        "namespace": "BaseContext",
        "body": "    def Pipe(self, duplex=True):\n        '''Returns two connection object connected by a pipe'''\n        from .connection import Pipe\n        return Pipe(duplex)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Lock": {
        "API_name": "multiprocessing.context.BaseContext.Lock",
        "loc_name": "multiprocessing.context.BaseContext.Lock",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 65,
        "namespace": "BaseContext",
        "body": "    def Lock(self):\n        '''Returns a non-recursive lock object'''\n        from .synchronize import Lock\n        return Lock(ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.RLock": {
        "API_name": "multiprocessing.context.BaseContext.RLock",
        "loc_name": "multiprocessing.context.BaseContext.RLock",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 70,
        "namespace": "BaseContext",
        "body": "    def RLock(self):\n        '''Returns a recursive lock object'''\n        from .synchronize import RLock\n        return RLock(ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Condition": {
        "API_name": "multiprocessing.context.BaseContext.Condition",
        "loc_name": "multiprocessing.context.BaseContext.Condition",
        "args": "self;lock",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 75,
        "namespace": "BaseContext",
        "body": "    def Condition(self, lock=None):\n        '''Returns a condition object'''\n        from .synchronize import Condition\n        return Condition(lock, ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Semaphore": {
        "API_name": "multiprocessing.context.BaseContext.Semaphore",
        "loc_name": "multiprocessing.context.BaseContext.Semaphore",
        "args": "self;value",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 80,
        "namespace": "BaseContext",
        "body": "    def Semaphore(self, value=1):\n        '''Returns a semaphore object'''\n        from .synchronize import Semaphore\n        return Semaphore(value, ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.BoundedSemaphore": {
        "API_name": "multiprocessing.context.BaseContext.BoundedSemaphore",
        "loc_name": "multiprocessing.context.BaseContext.BoundedSemaphore",
        "args": "self;value",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 85,
        "namespace": "BaseContext",
        "body": "    def BoundedSemaphore(self, value=1):\n        '''Returns a bounded semaphore object'''\n        from .synchronize import BoundedSemaphore\n        return BoundedSemaphore(value, ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Event": {
        "API_name": "multiprocessing.context.BaseContext.Event",
        "loc_name": "multiprocessing.context.BaseContext.Event",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 90,
        "namespace": "BaseContext",
        "body": "    def Event(self):\n        '''Returns an event object'''\n        from .synchronize import Event\n        return Event(ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Barrier": {
        "API_name": "multiprocessing.context.BaseContext.Barrier",
        "loc_name": "multiprocessing.context.BaseContext.Barrier",
        "args": "self;parties;action;timeout",
        "args_default": 2,
        "filepath": "multiprocessing.context",
        "lineno": 95,
        "namespace": "BaseContext",
        "body": "    def Barrier(self, parties, action=None, timeout=None):\n        '''Returns a barrier object'''\n        from .synchronize import Barrier\n        return Barrier(parties, action, timeout, ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Queue": {
        "API_name": "multiprocessing.context.BaseContext.Queue",
        "loc_name": "multiprocessing.context.BaseContext.Queue",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 100,
        "namespace": "BaseContext",
        "body": "    def Queue(self, maxsize=0):\n        '''Returns a queue object'''\n        from .queues import Queue\n        return Queue(maxsize, ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.JoinableQueue": {
        "API_name": "multiprocessing.context.BaseContext.JoinableQueue",
        "loc_name": "multiprocessing.context.BaseContext.JoinableQueue",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 105,
        "namespace": "BaseContext",
        "body": "    def JoinableQueue(self, maxsize=0):\n        '''Returns a queue object'''\n        from .queues import JoinableQueue\n        return JoinableQueue(maxsize, ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.SimpleQueue": {
        "API_name": "multiprocessing.context.BaseContext.SimpleQueue",
        "loc_name": "multiprocessing.context.BaseContext.SimpleQueue",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 110,
        "namespace": "BaseContext",
        "body": "    def SimpleQueue(self):\n        '''Returns a queue object'''\n        from .queues import SimpleQueue\n        return SimpleQueue(ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Pool": {
        "API_name": "multiprocessing.context.BaseContext.Pool",
        "loc_name": "multiprocessing.context.BaseContext.Pool",
        "args": "self;processes;initializer;initargs;maxtasksperchild",
        "args_default": 4,
        "filepath": "multiprocessing.context",
        "lineno": 115,
        "namespace": "BaseContext",
        "body": "    def Pool(self, processes=None, initializer=None, initargs=(),\n             maxtasksperchild=None):\n        '''Returns a process pool object'''\n        from .pool import Pool\n        return Pool(processes, initializer, initargs, maxtasksperchild,\n                    context=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.RawValue": {
        "API_name": "multiprocessing.context.BaseContext.RawValue",
        "loc_name": "multiprocessing.context.BaseContext.RawValue",
        "args": "self;typecode_or_type",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 122,
        "namespace": "BaseContext",
        "body": "    def RawValue(self, typecode_or_type, *args):\n        '''Returns a shared object'''\n        from .sharedctypes import RawValue\n        return RawValue(typecode_or_type, *args)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.RawArray": {
        "API_name": "multiprocessing.context.BaseContext.RawArray",
        "loc_name": "multiprocessing.context.BaseContext.RawArray",
        "args": "self;typecode_or_type;size_or_initializer",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 127,
        "namespace": "BaseContext",
        "body": "    def RawArray(self, typecode_or_type, size_or_initializer):\n        '''Returns a shared array'''\n        from .sharedctypes import RawArray\n        return RawArray(typecode_or_type, size_or_initializer)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Value": {
        "API_name": "multiprocessing.context.BaseContext.Value",
        "loc_name": "multiprocessing.context.BaseContext.Value",
        "args": "self;typecode_or_type",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 132,
        "namespace": "BaseContext",
        "body": "    def Value(self, typecode_or_type, *args, lock=True):\n        '''Returns a synchronized shared object'''\n        from .sharedctypes import Value\n        return Value(typecode_or_type, *args, lock=lock,\n                     ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.Array": {
        "API_name": "multiprocessing.context.BaseContext.Array",
        "loc_name": "multiprocessing.context.BaseContext.Array",
        "args": "self;typecode_or_type;size_or_initializer",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 138,
        "namespace": "BaseContext",
        "body": "    def Array(self, typecode_or_type, size_or_initializer, *, lock=True):\n        '''Returns a synchronized shared array'''\n        from .sharedctypes import Array\n        return Array(typecode_or_type, size_or_initializer, lock=lock,\n                     ctx=self.get_context())",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.freeze_support": {
        "API_name": "multiprocessing.context.BaseContext.freeze_support",
        "loc_name": "multiprocessing.context.BaseContext.freeze_support",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 144,
        "namespace": "BaseContext",
        "body": "    def freeze_support(self):\n        '''Check whether this is a fake forked process in a frozen executable.\n        If so then run code specified by commandline and exit.\n        '''\n        if sys.platform == 'win32' and getattr(sys, 'frozen', False):\n            from .spawn import freeze_support\n            freeze_support()",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.get_logger": {
        "API_name": "multiprocessing.context.BaseContext.get_logger",
        "loc_name": "multiprocessing.context.BaseContext.get_logger",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 152,
        "namespace": "BaseContext",
        "body": "    def get_logger(self):\n        '''Return package logger -- if it does not already exist then\n        it is created.\n        '''\n        from .util import get_logger\n        return get_logger()",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.log_to_stderr": {
        "API_name": "multiprocessing.context.BaseContext.log_to_stderr",
        "loc_name": "multiprocessing.context.BaseContext.log_to_stderr",
        "args": "self;level",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 159,
        "namespace": "BaseContext",
        "body": "    def log_to_stderr(self, level=None):\n        '''Turn on logging and add a handler which prints to stderr'''\n        from .util import log_to_stderr\n        return log_to_stderr(level)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.allow_connection_pickling": {
        "API_name": "multiprocessing.context.BaseContext.allow_connection_pickling",
        "loc_name": "multiprocessing.context.BaseContext.allow_connection_pickling",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 164,
        "namespace": "BaseContext",
        "body": "    def allow_connection_pickling(self):\n        '''Install support for sending connections and sockets\n        between processes\n        '''\n        # This is undocumented.  In previous versions of multiprocessing\n        # its only effect was to make socket objects inheritable on Windows.\n        from . import connection",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.set_executable": {
        "API_name": "multiprocessing.context.BaseContext.set_executable",
        "loc_name": "multiprocessing.context.BaseContext.set_executable",
        "args": "self;executable",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 172,
        "namespace": "BaseContext",
        "body": "    def set_executable(self, executable):\n        '''Sets the path to a python.exe or pythonw.exe binary used to run\n        child processes instead of sys.executable when using the 'spawn'\n        start method.  Useful for people embedding Python.\n        '''\n        from .spawn import set_executable\n        set_executable(executable)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.set_forkserver_preload": {
        "API_name": "multiprocessing.context.BaseContext.set_forkserver_preload",
        "loc_name": "multiprocessing.context.BaseContext.set_forkserver_preload",
        "args": "self;module_names",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 180,
        "namespace": "BaseContext",
        "body": "    def set_forkserver_preload(self, module_names):\n        '''Set list of module names to try to load in forkserver process.\n        This is really just a hint.\n        '''\n        from .forkserver import set_forkserver_preload\n        set_forkserver_preload(module_names)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.get_context": {
        "API_name": "multiprocessing.context.BaseContext.get_context",
        "loc_name": "multiprocessing.context.BaseContext.get_context",
        "args": "self;method",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 187,
        "namespace": "BaseContext",
        "body": "    def get_context(self, method=None):\n        if method is None:\n            return self\n        try:\n            ctx = _concrete_contexts[method]\n        except KeyError:\n            raise ValueError('cannot find context for %r' % method) from None\n        ctx._check_available()\n        return ctx",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.get_start_method": {
        "API_name": "multiprocessing.context.BaseContext.get_start_method",
        "loc_name": "multiprocessing.context.BaseContext.get_start_method",
        "args": "self;allow_none",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 197,
        "namespace": "BaseContext",
        "body": "    def get_start_method(self, allow_none=False):\n        return self._name",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.set_start_method": {
        "API_name": "multiprocessing.context.BaseContext.set_start_method",
        "loc_name": "multiprocessing.context.BaseContext.set_start_method",
        "args": "self;method;force",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 200,
        "namespace": "BaseContext",
        "body": "    def set_start_method(self, method, force=False):\n        raise ValueError('cannot set start method of concrete context')",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext.reducer": {
        "API_name": "multiprocessing.context.BaseContext.reducer",
        "loc_name": "multiprocessing.context.BaseContext.reducer",
        "args": "self;reduction",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 210,
        "namespace": "BaseContext",
        "body": "    def reducer(self, reduction):\n        globals()['reduction'] = reduction",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext._check_available": {
        "API_name": "multiprocessing.context.BaseContext._check_available",
        "loc_name": "multiprocessing.context.BaseContext._check_available",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 213,
        "namespace": "BaseContext",
        "body": "    def _check_available(self):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.context.BaseContext": {
        "API_name": "multiprocessing.context.BaseContext",
        "loc_name": "multiprocessing.context.BaseContext",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 30,
        "namespace": "BaseContext",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.Process._Popen": {
        "API_name": "multiprocessing.context.Process._Popen",
        "loc_name": "multiprocessing.context.Process._Popen",
        "args": "process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 223,
        "namespace": "Process",
        "body": "    def _Popen(process_obj):\n        return _default_context.get_context().Process._Popen(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.Process": {
        "API_name": "multiprocessing.context.Process",
        "loc_name": "multiprocessing.context.Process",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 220,
        "namespace": "Process",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.DefaultContext": {
        "API_name": "multiprocessing.context.DefaultContext",
        "loc_name": "multiprocessing.context.DefaultContext",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 226,
        "namespace": "DefaultContext",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.DefaultContext.__init__": {
        "API_name": "multiprocessing.context.DefaultContext.__init__",
        "loc_name": "multiprocessing.context.DefaultContext.__init__",
        "args": "self;context",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 229,
        "namespace": "DefaultContext",
        "body": "    def __init__(self, context):\n        self._default_context = context\n        self._actual_context = None",
        "name_type": "stdlib"
    },
    "multiprocessing.context.DefaultContext.get_context": {
        "API_name": "multiprocessing.context.DefaultContext.get_context",
        "loc_name": "multiprocessing.context.DefaultContext.get_context",
        "args": "self;method",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 233,
        "namespace": "DefaultContext",
        "body": "    def get_context(self, method=None):\n        if method is None:\n            if self._actual_context is None:\n                self._actual_context = self._default_context\n            return self._actual_context\n        else:\n            return super().get_context(method)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.DefaultContext.set_start_method": {
        "API_name": "multiprocessing.context.DefaultContext.set_start_method",
        "loc_name": "multiprocessing.context.DefaultContext.set_start_method",
        "args": "self;method;force",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 241,
        "namespace": "DefaultContext",
        "body": "    def set_start_method(self, method, force=False):\n        if self._actual_context is not None and not force:\n            raise RuntimeError('context has already been set')\n        if method is None and force:\n            self._actual_context = None\n            return\n        self._actual_context = self.get_context(method)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.DefaultContext.get_start_method": {
        "API_name": "multiprocessing.context.DefaultContext.get_start_method",
        "loc_name": "multiprocessing.context.DefaultContext.get_start_method",
        "args": "self;allow_none",
        "args_default": 1,
        "filepath": "multiprocessing.context",
        "lineno": 249,
        "namespace": "DefaultContext",
        "body": "    def get_start_method(self, allow_none=False):\n        if self._actual_context is None:\n            if allow_none:\n                return None\n            self._actual_context = self._default_context\n        return self._actual_context._name",
        "name_type": "stdlib"
    },
    "multiprocessing.context.DefaultContext.get_all_start_methods": {
        "API_name": "multiprocessing.context.DefaultContext.get_all_start_methods",
        "loc_name": "multiprocessing.context.DefaultContext.get_all_start_methods",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 256,
        "namespace": "DefaultContext",
        "body": "    def get_all_start_methods(self):\n        if sys.platform == 'win32':\n            return ['spawn']\n        else:\n            methods = ['spawn', 'fork'] if sys.platform == 'darwin' else ['fork', 'spawn']\n            if reduction.HAVE_SEND_HANDLE:\n                methods.append('forkserver')\n            return methods",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkProcess._Popen": {
        "API_name": "multiprocessing.context.ForkProcess._Popen",
        "loc_name": "multiprocessing.context.ForkProcess._Popen",
        "args": "process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 275,
        "namespace": "ForkProcess",
        "body": "        def _Popen(process_obj):\n            from .popen_fork import Popen\n            return Popen(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkProcess": {
        "API_name": "multiprocessing.context.ForkProcess",
        "loc_name": "multiprocessing.context.ForkProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 272,
        "namespace": "ForkProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.SpawnProcess._Popen": {
        "API_name": "multiprocessing.context.SpawnProcess._Popen",
        "loc_name": "multiprocessing.context.SpawnProcess._Popen",
        "args": "process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 325,
        "namespace": "SpawnProcess",
        "body": "        def _Popen(process_obj):\n            from .popen_spawn_win32 import Popen\n            return Popen(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.SpawnProcess": {
        "API_name": "multiprocessing.context.SpawnProcess",
        "loc_name": "multiprocessing.context.SpawnProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 322,
        "namespace": "SpawnProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkServerProcess._Popen": {
        "API_name": "multiprocessing.context.ForkServerProcess._Popen",
        "loc_name": "multiprocessing.context.ForkServerProcess._Popen",
        "args": "process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 289,
        "namespace": "ForkServerProcess",
        "body": "        def _Popen(process_obj):\n            from .popen_forkserver import Popen\n            return Popen(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkServerProcess": {
        "API_name": "multiprocessing.context.ForkServerProcess",
        "loc_name": "multiprocessing.context.ForkServerProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 286,
        "namespace": "ForkServerProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkContext": {
        "API_name": "multiprocessing.context.ForkContext",
        "loc_name": "multiprocessing.context.ForkContext",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 293,
        "namespace": "ForkContext",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.SpawnContext": {
        "API_name": "multiprocessing.context.SpawnContext",
        "loc_name": "multiprocessing.context.SpawnContext",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 329,
        "namespace": "SpawnContext",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkServerContext._check_available": {
        "API_name": "multiprocessing.context.ForkServerContext._check_available",
        "loc_name": "multiprocessing.context.ForkServerContext._check_available",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 304,
        "namespace": "ForkServerContext",
        "body": "        def _check_available(self):\n            if not reduction.HAVE_SEND_HANDLE:\n                raise ValueError('forkserver start method not available')",
        "name_type": "stdlib"
    },
    "multiprocessing.context.ForkServerContext": {
        "API_name": "multiprocessing.context.ForkServerContext",
        "loc_name": "multiprocessing.context.ForkServerContext",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.context",
        "lineno": 301,
        "namespace": "ForkServerContext",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.context._force_start_method": {
        "API_name": "multiprocessing.context._force_start_method",
        "loc_name": "multiprocessing.context._force_start_method",
        "args": "method",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 342,
        "namespace": "*",
        "body": "def _force_start_method(method):\n    _default_context._actual_context = _concrete_contexts[method]",
        "name_type": "stdlib"
    },
    "multiprocessing.context.get_spawning_popen": {
        "API_name": "multiprocessing.context.get_spawning_popen",
        "loc_name": "multiprocessing.context.get_spawning_popen",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 351,
        "namespace": "*",
        "body": "def get_spawning_popen():\n    return getattr(_tls, 'spawning_popen', None)",
        "name_type": "stdlib"
    },
    "multiprocessing.context.set_spawning_popen": {
        "API_name": "multiprocessing.context.set_spawning_popen",
        "loc_name": "multiprocessing.context.set_spawning_popen",
        "args": "popen",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 354,
        "namespace": "*",
        "body": "def set_spawning_popen(popen):\n    _tls.spawning_popen = popen",
        "name_type": "stdlib"
    },
    "multiprocessing.context.assert_spawning": {
        "API_name": "multiprocessing.context.assert_spawning",
        "loc_name": "multiprocessing.context.assert_spawning",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.context",
        "lineno": 357,
        "namespace": "*",
        "body": "def assert_spawning(obj):\n    if get_spawning_popen() is None:\n        raise RuntimeError(\n            '%s objects should only be shared between processes'\n            ' through inheritance' % type(obj).__name__\n            )",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver": {
        "API_name": "multiprocessing.forkserver",
        "loc_name": "multiprocessing.forkserver",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.forkserver",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['ensure_running', 'get_inherited_fds', 'connect_to_new_process',\n           'set_forkserver_preload']\nMAXFDS_TO_SEND = 256\nSIGNED_STRUCT = struct.Struct('q')     # large enough for pid_t\n_forkserver = ForkServer()\nensure_running = _forkserver.ensure_running\nget_inherited_fds = _forkserver.get_inherited_fds\nconnect_to_new_process = _forkserver.connect_to_new_process\nset_forkserver_preload = _forkserver.set_forkserver_preload",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer": {
        "API_name": "multiprocessing.forkserver.ForkServer",
        "loc_name": "multiprocessing.forkserver.ForkServer",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.forkserver",
        "lineno": 32,
        "namespace": "ForkServer",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer.__init__": {
        "API_name": "multiprocessing.forkserver.ForkServer.__init__",
        "loc_name": "multiprocessing.forkserver.ForkServer.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 34,
        "namespace": "ForkServer",
        "body": "    def __init__(self):\n        self._forkserver_address = None\n        self._forkserver_alive_fd = None\n        self._forkserver_pid = None\n        self._inherited_fds = None\n        self._lock = threading.Lock()\n        self._preload_modules = ['__main__']",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer._stop": {
        "API_name": "multiprocessing.forkserver.ForkServer._stop",
        "loc_name": "multiprocessing.forkserver.ForkServer._stop",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 42,
        "namespace": "ForkServer",
        "body": "    def _stop(self):\n        # Method used by unit tests to stop the server\n        with self._lock:\n            self._stop_unlocked()",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer._stop_unlocked": {
        "API_name": "multiprocessing.forkserver.ForkServer._stop_unlocked",
        "loc_name": "multiprocessing.forkserver.ForkServer._stop_unlocked",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 47,
        "namespace": "ForkServer",
        "body": "    def _stop_unlocked(self):\n        if self._forkserver_pid is None:\n            return\n\n        # close the \"alive\" file descriptor asks the server to stop\n        os.close(self._forkserver_alive_fd)\n        self._forkserver_alive_fd = None\n\n        os.waitpid(self._forkserver_pid, 0)\n        self._forkserver_pid = None\n\n        if not util.is_abstract_socket_namespace(self._forkserver_address):\n            os.unlink(self._forkserver_address)\n        self._forkserver_address = None",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer.set_forkserver_preload": {
        "API_name": "multiprocessing.forkserver.ForkServer.set_forkserver_preload",
        "loc_name": "multiprocessing.forkserver.ForkServer.set_forkserver_preload",
        "args": "self;modules_names",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 62,
        "namespace": "ForkServer",
        "body": "    def set_forkserver_preload(self, modules_names):\n        '''Set list of module names to try to load in forkserver process.'''\n        if not all(type(mod) is str for mod in self._preload_modules):\n            raise TypeError('module_names must be a list of strings')\n        self._preload_modules = modules_names",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer.get_inherited_fds": {
        "API_name": "multiprocessing.forkserver.ForkServer.get_inherited_fds",
        "loc_name": "multiprocessing.forkserver.ForkServer.get_inherited_fds",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 68,
        "namespace": "ForkServer",
        "body": "    def get_inherited_fds(self):\n        '''Return list of fds inherited from parent process.\n\n        This returns None if the current process was not started by fork\n        server.\n        '''\n        return self._inherited_fds",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer.connect_to_new_process": {
        "API_name": "multiprocessing.forkserver.ForkServer.connect_to_new_process",
        "loc_name": "multiprocessing.forkserver.ForkServer.connect_to_new_process",
        "args": "self;fds",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 76,
        "namespace": "ForkServer",
        "body": "    def connect_to_new_process(self, fds):\n        '''Request forkserver to create a child process.\n\n        Returns a pair of fds (status_r, data_w).  The calling process can read\n        the child process's pid and (eventually) its returncode from status_r.\n        The calling process should write to data_w the pickled preparation and\n        process data.\n        '''\n        self.ensure_running()\n        if len(fds) + 4 >= MAXFDS_TO_SEND:\n            raise ValueError('too many fds')\n        with socket.socket(socket.AF_UNIX) as client:\n            client.connect(self._forkserver_address)\n            parent_r, child_w = os.pipe()\n            child_r, parent_w = os.pipe()\n            allfds = [child_r, child_w, self._forkserver_alive_fd,\n                      resource_tracker.getfd()]\n            allfds += fds\n            try:\n                reduction.sendfds(client, allfds)\n                return parent_r, parent_w\n            except:\n                os.close(parent_r)\n                os.close(parent_w)\n                raise\n            finally:\n                os.close(child_r)\n                os.close(child_w)",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.ForkServer.ensure_running": {
        "API_name": "multiprocessing.forkserver.ForkServer.ensure_running",
        "loc_name": "multiprocessing.forkserver.ForkServer.ensure_running",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 105,
        "namespace": "ForkServer",
        "body": "    def ensure_running(self):\n        '''Make sure that a fork server is running.\n\n        This can be called from any process.  Note that usually a child\n        process will just reuse the forkserver started by its parent, so\n        ensure_running() will do nothing.\n        '''\n        with self._lock:\n            resource_tracker.ensure_running()\n            if self._forkserver_pid is not None:\n                # forkserver was launched before, is it still running?\n                pid, status = os.waitpid(self._forkserver_pid, os.WNOHANG)\n                if not pid:\n                    # still alive\n                    return\n                # dead, launch it again\n                os.close(self._forkserver_alive_fd)\n                self._forkserver_address = None\n                self._forkserver_alive_fd = None\n                self._forkserver_pid = None\n\n            cmd = ('from multiprocessing.forkserver import main; ' +\n                   'main(%d, %d, %r, **%r)')\n\n            if self._preload_modules:\n                desired_keys = {'main_path', 'sys_path'}\n                data = spawn.get_preparation_data('ignore')\n                data = {x: y for x, y in data.items() if x in desired_keys}\n            else:\n                data = {}\n\n            with socket.socket(socket.AF_UNIX) as listener:\n                address = connection.arbitrary_address('AF_UNIX')\n                listener.bind(address)\n                if not util.is_abstract_socket_namespace(address):\n                    os.chmod(address, 0o600)\n                listener.listen()\n\n                # all client processes own the write end of the \"alive\" pipe;\n                # when they all terminate the read end becomes ready.\n                alive_r, alive_w = os.pipe()\n                try:\n                    fds_to_pass = [listener.fileno(), alive_r]\n                    cmd %= (listener.fileno(), alive_r, self._preload_modules,\n                            data)\n                    exe = spawn.get_executable()\n                    args = [exe] + util._args_from_interpreter_flags()\n                    args += ['-c', cmd]\n                    pid = util.spawnv_passfds(exe, args, fds_to_pass)\n                except:\n                    os.close(alive_w)\n                    raise\n                finally:\n                    os.close(alive_r)\n                self._forkserver_address = address\n                self._forkserver_alive_fd = alive_w\n                self._forkserver_pid = pid",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.main": {
        "API_name": "multiprocessing.forkserver.main",
        "loc_name": "multiprocessing.forkserver.main",
        "args": "listener_fd;alive_r;preload;main_path;sys_path",
        "args_default": 2,
        "filepath": "multiprocessing.forkserver",
        "lineno": 167,
        "namespace": "*",
        "body": "def main(listener_fd, alive_r, preload, main_path=None, sys_path=None):\n    '''Run forkserver.'''\n    if preload:\n        if '__main__' in preload and main_path is not None:\n            process.current_process()._inheriting = True\n            try:\n                spawn.import_main_path(main_path)\n            finally:\n                del process.current_process()._inheriting\n        for modname in preload:\n            try:\n                __import__(modname)\n            except ImportError:\n                pass\n\n    util._close_stdin()\n\n    sig_r, sig_w = os.pipe()\n    os.set_blocking(sig_r, False)\n    os.set_blocking(sig_w, False)\n\n    def sigchld_handler(*_unused):\n        # Dummy signal handler, doesn't do anything\n        pass\n\n    handlers = {\n        # unblocking SIGCHLD allows the wakeup fd to notify our event loop\n        signal.SIGCHLD: sigchld_handler,\n        # protect the process from ^C\n        signal.SIGINT: signal.SIG_IGN,\n        }\n    old_handlers = {sig: signal.signal(sig, val)\n                    for (sig, val) in handlers.items()}\n\n    # calling os.write() in the Python signal handler is racy\n    signal.set_wakeup_fd(sig_w)\n\n    # map child pids to client fds\n    pid_to_fd = {}\n\n    with socket.socket(socket.AF_UNIX, fileno=listener_fd) as listener, \\\n         selectors.DefaultSelector() as selector:\n        _forkserver._forkserver_address = listener.getsockname()\n\n        selector.register(listener, selectors.EVENT_READ)\n        selector.register(alive_r, selectors.EVENT_READ)\n        selector.register(sig_r, selectors.EVENT_READ)\n\n        while True:\n            try:\n                while True:\n                    rfds = [key.fileobj for (key, events) in selector.select()]\n                    if rfds:\n                        break\n\n                if alive_r in rfds:\n                    # EOF because no more client processes left\n                    assert os.read(alive_r, 1) == b'', \"Not at EOF?\"\n                    raise SystemExit\n\n                if sig_r in rfds:\n                    # Got SIGCHLD\n                    os.read(sig_r, 65536)  # exhaust\n                    while True:\n                        # Scan for child processes\n                        try:\n                            pid, sts = os.waitpid(-1, os.WNOHANG)\n                        except ChildProcessError:\n                            break\n                        if pid == 0:\n                            break\n                        child_w = pid_to_fd.pop(pid, None)\n                        if child_w is not None:\n                            returncode = os.waitstatus_to_exitcode(sts)\n\n                            # Send exit code to client process\n                            try:\n                                write_signed(child_w, returncode)\n                            except BrokenPipeError:\n                                # client vanished\n                                pass\n                            os.close(child_w)\n                        else:\n                            # This shouldn't happen really\n                            warnings.warn('forkserver: waitpid returned '\n                                          'unexpected pid %d' % pid)\n\n                if listener in rfds:\n                    # Incoming fork request\n                    with listener.accept()[0] as s:\n                        # Receive fds from client\n                        fds = reduction.recvfds(s, MAXFDS_TO_SEND + 1)\n                        if len(fds) > MAXFDS_TO_SEND:\n                            raise RuntimeError(\n                                \"Too many ({0:n}) fds to send\".format(\n                                    len(fds)))\n                        child_r, child_w, *fds = fds\n                        s.close()\n                        pid = os.fork()\n                        if pid == 0:\n                            # Child\n                            code = 1\n                            try:\n                                listener.close()\n                                selector.close()\n                                unused_fds = [alive_r, child_w, sig_r, sig_w]\n                                unused_fds.extend(pid_to_fd.values())\n                                code = _serve_one(child_r, fds,\n                                                  unused_fds,\n                                                  old_handlers)\n                            except Exception:\n                                sys.excepthook(*sys.exc_info())\n                                sys.stderr.flush()\n                            finally:\n                                os._exit(code)\n                        else:\n                            # Send pid to client process\n                            try:\n                                write_signed(child_w, pid)\n                            except BrokenPipeError:\n                                # client vanished\n                                pass\n                            pid_to_fd[pid] = child_w\n                            os.close(child_r)\n                            for fd in fds:\n                                os.close(fd)\n\n            except OSError as e:\n                if e.errno != errno.ECONNABORTED:\n                    raise",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.main.sigchld_handler": {
        "API_name": "multiprocessing.forkserver.main.sigchld_handler",
        "loc_name": "multiprocessing.forkserver.main.sigchld_handler",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 188,
        "namespace": "*",
        "body": "    def sigchld_handler(*_unused):\n        # Dummy signal handler, doesn't do anything\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver._serve_one": {
        "API_name": "multiprocessing.forkserver._serve_one",
        "loc_name": "multiprocessing.forkserver._serve_one",
        "args": "child_r;fds;unused_fds;handlers",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 299,
        "namespace": "*",
        "body": "def _serve_one(child_r, fds, unused_fds, handlers):\n    # close unnecessary stuff and reset signal handlers\n    signal.set_wakeup_fd(-1)\n    for sig, val in handlers.items():\n        signal.signal(sig, val)\n    for fd in unused_fds:\n        os.close(fd)\n\n    (_forkserver._forkserver_alive_fd,\n     resource_tracker._resource_tracker._fd,\n     *_forkserver._inherited_fds) = fds\n\n    # Run process object received over pipe\n    parent_sentinel = os.dup(child_r)\n    code = spawn._main(child_r, parent_sentinel)\n\n    return code",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.read_signed": {
        "API_name": "multiprocessing.forkserver.read_signed",
        "loc_name": "multiprocessing.forkserver.read_signed",
        "args": "fd",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 322,
        "namespace": "*",
        "body": "def read_signed(fd):\n    data = b''\n    length = SIGNED_STRUCT.size\n    while len(data) < length:\n        s = os.read(fd, length - len(data))\n        if not s:\n            raise EOFError('unexpected EOF')\n        data += s\n    return SIGNED_STRUCT.unpack(data)[0]",
        "name_type": "stdlib"
    },
    "multiprocessing.forkserver.write_signed": {
        "API_name": "multiprocessing.forkserver.write_signed",
        "loc_name": "multiprocessing.forkserver.write_signed",
        "args": "fd;n",
        "args_default": 0,
        "filepath": "multiprocessing.forkserver",
        "lineno": 332,
        "namespace": "*",
        "body": "def write_signed(fd, n):\n    msg = SIGNED_STRUCT.pack(n)\n    while msg:\n        nbytes = os.write(fd, msg)\n        if nbytes == 0:\n            raise RuntimeError('should not get here')\n        msg = msg[nbytes:]",
        "name_type": "stdlib"
    },
    "multiprocessing.heap": {
        "API_name": "multiprocessing.heap",
        "loc_name": "multiprocessing.heap",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.heap",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['BufferWrapper']\nif sys.platform == 'win32':\n\n    import _winapi\n\n    class Arena(object):\n        \"\"\"\n        A shared memory area backed by anonymous memory (Windows).\n        \"\"\"\n\n        _rand = tempfile._RandomNameSequence()\n\n        def __init__(self, size):\n            self.size = size\n            for i in range(100):\n                name = 'pym-%d-%s' % (os.getpid(), next(self._rand))\n                buf = mmap.mmap(-1, size, tagname=name)\n                if _winapi.GetLastError() == 0:\n                    break\n                # We have reopened a preexisting mmap.\n                buf.close()\n            else:\n                raise FileExistsError('Cannot find name for new mmap')\n            self.name = name\n            self.buffer = buf\n            self._state = (self.size, self.name)\n\n        def __getstate__(self):\n            assert_spawning(self)\n            return self._state\n\n        def __setstate__(self, state):\n            self.size, self.name = self._state = state\n            # Reopen existing mmap\n            self.buffer = mmap.mmap(-1, self.size, tagname=self.name)\n            # XXX Temporarily preventing buildbot failures while determining\n            # XXX the correct long-term fix. See issue 23060\n            #assert _winapi.GetLastError() == _winapi.ERROR_ALREADY_EXISTS\n\nelse:\n\n    class Arena(object):\n        \"\"\"\n        A shared memory area backed by a temporary file (POSIX).\n        \"\"\"\n\n        if sys.platform == 'linux':\n            _dir_candidates = ['/dev/shm']\n        else:\n            _dir_candidates = []\n\n        def __init__(self, size, fd=-1):\n            self.size = size\n            self.fd = fd\n            if fd == -1:\n                # Arena is created anew (if fd != -1, it means we're coming\n                # from rebuild_arena() below)\n                self.fd, name = tempfile.mkstemp(\n                     prefix='pym-%d-'%os.getpid(),\n                     dir=self._choose_dir(size))\n                os.unlink(name)\n                util.Finalize(self, os.close, (self.fd,))\n                os.ftruncate(self.fd, size)\n            self.buffer = mmap.mmap(self.fd, self.size)\n\n        def _choose_dir(self, size):\n            # Choose a non-storage backed directory if possible,\n            # to improve performance\n            for d in self._dir_candidates:\n                st = os.statvfs(d)\n                if st.f_bavail * st.f_frsize >= size:  # enough free space?\n                    return d\n            return util.get_temp_dir()\n\n    def reduce_arena(a):\n        if a.fd == -1:\n            raise ValueError('Arena is unpicklable because '\n                             'forking was enabled when it was created')\n        return rebuild_arena, (a.size, reduction.DupFd(a.fd))\n\n    def rebuild_arena(size, dupfd):\n        return Arena(size, dupfd.detach())\n\n    reduction.register(Arena, reduce_arena)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Arena": {
        "API_name": "multiprocessing.heap.Arena",
        "loc_name": "multiprocessing.heap.Arena",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.heap",
        "lineno": 67,
        "namespace": "Arena",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Arena.__init__": {
        "API_name": "multiprocessing.heap.Arena.__init__",
        "loc_name": "multiprocessing.heap.Arena.__init__",
        "args": "self;size;fd",
        "args_default": 1,
        "filepath": "multiprocessing.heap",
        "lineno": 77,
        "namespace": "Arena",
        "body": "        def __init__(self, size, fd=-1):\n            self.size = size\n            self.fd = fd\n            if fd == -1:\n                # Arena is created anew (if fd != -1, it means we're coming\n                # from rebuild_arena() below)\n                self.fd, name = tempfile.mkstemp(\n                     prefix='pym-%d-'%os.getpid(),\n                     dir=self._choose_dir(size))\n                os.unlink(name)\n                util.Finalize(self, os.close, (self.fd,))\n                os.ftruncate(self.fd, size)\n            self.buffer = mmap.mmap(self.fd, self.size)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Arena._choose_dir": {
        "API_name": "multiprocessing.heap.Arena._choose_dir",
        "loc_name": "multiprocessing.heap.Arena._choose_dir",
        "args": "self;size",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 91,
        "namespace": "Arena",
        "body": "        def _choose_dir(self, size):\n            # Choose a non-storage backed directory if possible,\n            # to improve performance\n            for d in self._dir_candidates:\n                st = os.statvfs(d)\n                if st.f_bavail * st.f_frsize >= size:  # enough free space?\n                    return d\n            return util.get_temp_dir()",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.reduce_arena": {
        "API_name": "multiprocessing.heap.reduce_arena",
        "loc_name": "multiprocessing.heap.reduce_arena",
        "args": "a",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 100,
        "namespace": "*",
        "body": "    def reduce_arena(a):\n        if a.fd == -1:\n            raise ValueError('Arena is unpicklable because '\n                             'forking was enabled when it was created')\n        return rebuild_arena, (a.size, reduction.DupFd(a.fd))",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.rebuild_arena": {
        "API_name": "multiprocessing.heap.rebuild_arena",
        "loc_name": "multiprocessing.heap.rebuild_arena",
        "args": "size;dupfd",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 106,
        "namespace": "*",
        "body": "    def rebuild_arena(size, dupfd):\n        return Arena(size, dupfd.detach())",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap": {
        "API_name": "multiprocessing.heap.Heap",
        "loc_name": "multiprocessing.heap.Heap",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.heap",
        "lineno": 115,
        "namespace": "Heap",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap.__init__": {
        "API_name": "multiprocessing.heap.Heap.__init__",
        "loc_name": "multiprocessing.heap.Heap.__init__",
        "args": "self;size",
        "args_default": 1,
        "filepath": "multiprocessing.heap",
        "lineno": 123,
        "namespace": "Heap",
        "body": "    def __init__(self, size=mmap.PAGESIZE):\n        self._lastpid = os.getpid()\n        self._lock = threading.Lock()\n        # Current arena allocation size\n        self._size = size\n        # A sorted list of available block sizes in arenas\n        self._lengths = []\n\n        # Free block management:\n        # - map each block size to a list of `(Arena, start, stop)` blocks\n        self._len_to_seq = {}\n        # - map `(Arena, start)` tuple to the `(Arena, start, stop)` block\n        #   starting at that offset\n        self._start_to_block = {}\n        # - map `(Arena, stop)` tuple to the `(Arena, start, stop)` block\n        #   ending at that offset\n        self._stop_to_block = {}\n\n        # Map arenas to their `(Arena, start, stop)` blocks in use\n        self._allocated_blocks = defaultdict(set)\n        self._arenas = []\n\n        # List of pending blocks to free - see comment in free() below\n        self._pending_free_blocks = []\n\n        # Statistics\n        self._n_mallocs = 0\n        self._n_frees = 0",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._roundup": {
        "API_name": "multiprocessing.heap.Heap._roundup",
        "loc_name": "multiprocessing.heap.Heap._roundup",
        "args": "n;alignment",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 153,
        "namespace": "Heap",
        "body": "    def _roundup(n, alignment):\n        # alignment must be a power of 2\n        mask = alignment - 1\n        return (n + mask) & ~mask",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._new_arena": {
        "API_name": "multiprocessing.heap.Heap._new_arena",
        "loc_name": "multiprocessing.heap.Heap._new_arena",
        "args": "self;size",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 158,
        "namespace": "Heap",
        "body": "    def _new_arena(self, size):\n        # Create a new arena with at least the given *size*\n        length = self._roundup(max(self._size, size), mmap.PAGESIZE)\n        # We carve larger and larger arenas, for efficiency, until we\n        # reach a large-ish size (roughly L3 cache-sized)\n        if self._size < self._DOUBLE_ARENA_SIZE_UNTIL:\n            self._size *= 2\n        util.info('allocating a new mmap of length %d', length)\n        arena = Arena(length)\n        self._arenas.append(arena)\n        return (arena, 0, length)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._discard_arena": {
        "API_name": "multiprocessing.heap.Heap._discard_arena",
        "loc_name": "multiprocessing.heap.Heap._discard_arena",
        "args": "self;arena",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 170,
        "namespace": "Heap",
        "body": "    def _discard_arena(self, arena):\n        # Possibly delete the given (unused) arena\n        length = arena.size\n        # Reusing an existing arena is faster than creating a new one, so\n        # we only reclaim space if it's large enough.\n        if length < self._DISCARD_FREE_SPACE_LARGER_THAN:\n            return\n        blocks = self._allocated_blocks.pop(arena)\n        assert not blocks\n        del self._start_to_block[(arena, 0)]\n        del self._stop_to_block[(arena, length)]\n        self._arenas.remove(arena)\n        seq = self._len_to_seq[length]\n        seq.remove((arena, 0, length))\n        if not seq:\n            del self._len_to_seq[length]\n            self._lengths.remove(length)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._malloc": {
        "API_name": "multiprocessing.heap.Heap._malloc",
        "loc_name": "multiprocessing.heap.Heap._malloc",
        "args": "self;size",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 188,
        "namespace": "Heap",
        "body": "    def _malloc(self, size):\n        # returns a large enough block -- it might be much larger\n        i = bisect.bisect_left(self._lengths, size)\n        if i == len(self._lengths):\n            return self._new_arena(size)\n        else:\n            length = self._lengths[i]\n            seq = self._len_to_seq[length]\n            block = seq.pop()\n            if not seq:\n                del self._len_to_seq[length], self._lengths[i]\n\n        (arena, start, stop) = block\n        del self._start_to_block[(arena, start)]\n        del self._stop_to_block[(arena, stop)]\n        return block",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._add_free_block": {
        "API_name": "multiprocessing.heap.Heap._add_free_block",
        "loc_name": "multiprocessing.heap.Heap._add_free_block",
        "args": "self;block",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 205,
        "namespace": "Heap",
        "body": "    def _add_free_block(self, block):\n        # make block available and try to merge with its neighbours in the arena\n        (arena, start, stop) = block\n\n        try:\n            prev_block = self._stop_to_block[(arena, start)]\n        except KeyError:\n            pass\n        else:\n            start, _ = self._absorb(prev_block)\n\n        try:\n            next_block = self._start_to_block[(arena, stop)]\n        except KeyError:\n            pass\n        else:\n            _, stop = self._absorb(next_block)\n\n        block = (arena, start, stop)\n        length = stop - start\n\n        try:\n            self._len_to_seq[length].append(block)\n        except KeyError:\n            self._len_to_seq[length] = [block]\n            bisect.insort(self._lengths, length)\n\n        self._start_to_block[(arena, start)] = block\n        self._stop_to_block[(arena, stop)] = block",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._absorb": {
        "API_name": "multiprocessing.heap.Heap._absorb",
        "loc_name": "multiprocessing.heap.Heap._absorb",
        "args": "self;block",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 235,
        "namespace": "Heap",
        "body": "    def _absorb(self, block):\n        # deregister this block so it can be merged with a neighbour\n        (arena, start, stop) = block\n        del self._start_to_block[(arena, start)]\n        del self._stop_to_block[(arena, stop)]\n\n        length = stop - start\n        seq = self._len_to_seq[length]\n        seq.remove(block)\n        if not seq:\n            del self._len_to_seq[length]\n            self._lengths.remove(length)\n\n        return start, stop",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._remove_allocated_block": {
        "API_name": "multiprocessing.heap.Heap._remove_allocated_block",
        "loc_name": "multiprocessing.heap.Heap._remove_allocated_block",
        "args": "self;block",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 250,
        "namespace": "Heap",
        "body": "    def _remove_allocated_block(self, block):\n        arena, start, stop = block\n        blocks = self._allocated_blocks[arena]\n        blocks.remove((start, stop))\n        if not blocks:\n            # Arena is entirely free, discard it from this process\n            self._discard_arena(arena)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap._free_pending_blocks": {
        "API_name": "multiprocessing.heap.Heap._free_pending_blocks",
        "loc_name": "multiprocessing.heap.Heap._free_pending_blocks",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 258,
        "namespace": "Heap",
        "body": "    def _free_pending_blocks(self):\n        # Free all the blocks in the pending list - called with the lock held.\n        while True:\n            try:\n                block = self._pending_free_blocks.pop()\n            except IndexError:\n                break\n            self._add_free_block(block)\n            self._remove_allocated_block(block)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap.free": {
        "API_name": "multiprocessing.heap.Heap.free",
        "loc_name": "multiprocessing.heap.Heap.free",
        "args": "self;block",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 268,
        "namespace": "Heap",
        "body": "    def free(self, block):\n        # free a block returned by malloc()\n        # Since free() can be called asynchronously by the GC, it could happen\n        # that it's called while self._lock is held: in that case,\n        # self._lock.acquire() would deadlock (issue #12352). To avoid that, a\n        # trylock is used instead, and if the lock can't be acquired\n        # immediately, the block is added to a list of blocks to be freed\n        # synchronously sometimes later from malloc() or free(), by calling\n        # _free_pending_blocks() (appending and retrieving from a list is not\n        # strictly thread-safe but under CPython it's atomic thanks to the GIL).\n        if os.getpid() != self._lastpid:\n            raise ValueError(\n                \"My pid ({0:n}) is not last pid {1:n}\".format(\n                    os.getpid(),self._lastpid))\n        if not self._lock.acquire(False):\n            # can't acquire the lock right now, add the block to the list of\n            # pending blocks to free\n            self._pending_free_blocks.append(block)\n        else:\n            # we hold the lock\n            try:\n                self._n_frees += 1\n                self._free_pending_blocks()\n                self._add_free_block(block)\n                self._remove_allocated_block(block)\n            finally:\n                self._lock.release()",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.Heap.malloc": {
        "API_name": "multiprocessing.heap.Heap.malloc",
        "loc_name": "multiprocessing.heap.Heap.malloc",
        "args": "self;size",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 296,
        "namespace": "Heap",
        "body": "    def malloc(self, size):\n        # return a block of right size (possibly rounded up)\n        if size < 0:\n            raise ValueError(\"Size {0:n} out of range\".format(size))\n        if sys.maxsize <= size:\n            raise OverflowError(\"Size {0:n} too large\".format(size))\n        if os.getpid() != self._lastpid:\n            self.__init__()                     # reinitialize after fork\n        with self._lock:\n            self._n_mallocs += 1\n            # allow pending blocks to be marked available\n            self._free_pending_blocks()\n            size = self._roundup(max(size, 1), self._alignment)\n            (arena, start, stop) = self._malloc(size)\n            real_stop = start + size\n            if real_stop < stop:\n                # if the returned block is larger than necessary, mark\n                # the remainder available\n                self._add_free_block((arena, real_stop, stop))\n            self._allocated_blocks[arena].add((start, real_stop))\n            return (arena, start, real_stop)",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.BufferWrapper": {
        "API_name": "multiprocessing.heap.BufferWrapper",
        "loc_name": "multiprocessing.heap.BufferWrapper",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.heap",
        "lineno": 322,
        "namespace": "BufferWrapper",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.BufferWrapper.__init__": {
        "API_name": "multiprocessing.heap.BufferWrapper.__init__",
        "loc_name": "multiprocessing.heap.BufferWrapper.__init__",
        "args": "self;size",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 326,
        "namespace": "BufferWrapper",
        "body": "    def __init__(self, size):\n        if size < 0:\n            raise ValueError(\"Size {0:n} out of range\".format(size))\n        if sys.maxsize <= size:\n            raise OverflowError(\"Size {0:n} too large\".format(size))\n        block = BufferWrapper._heap.malloc(size)\n        self._state = (block, size)\n        util.Finalize(self, BufferWrapper._heap.free, args=(block,))",
        "name_type": "stdlib"
    },
    "multiprocessing.heap.BufferWrapper.create_memoryview": {
        "API_name": "multiprocessing.heap.BufferWrapper.create_memoryview",
        "loc_name": "multiprocessing.heap.BufferWrapper.create_memoryview",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.heap",
        "lineno": 335,
        "namespace": "BufferWrapper",
        "body": "    def create_memoryview(self):\n        (arena, start, stop), size = self._state\n        return memoryview(arena.buffer)[start:start+size]",
        "name_type": "stdlib"
    },
    "multiprocessing.managers": {
        "API_name": "multiprocessing.managers",
        "loc_name": "multiprocessing.managers",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [ 'BaseManager', 'SyncManager', 'BaseProxy', 'Token' ]\ntry:\n    from . import shared_memory\nexcept ImportError:\n    HAS_SHMEM = False\nelse:\n    HAS_SHMEM = True\n    __all__.append('SharedMemoryManager')\nreduction.register(array.array, reduce_array)\nview_types = [type(getattr({}, name)()) for name in ('items','keys','values')]\nif view_types[0] is not list:       # only needed in Py3.0\n    def rebuild_as_list(obj):\n        return list, (list(obj),)\n    for view_type in view_types:\n        reduction.register(view_type, rebuild_as_list)\nlistener_client = {\n    'pickle' : (connection.Listener, connection.Client),\n    'xmlrpclib' : (connection.XmlListener, connection.XmlClient)\n    }\nBaseListProxy = MakeProxyType('BaseListProxy', (\n    '__add__', '__contains__', '__delitem__', '__getitem__', '__len__',\n    '__mul__', '__reversed__', '__rmul__', '__setitem__',\n    'append', 'count', 'extend', 'index', 'insert', 'pop', 'remove',\n    'reverse', 'sort', '__imul__'\n    ))\nDictProxy = MakeProxyType('DictProxy', (\n    '__contains__', '__delitem__', '__getitem__', '__iter__', '__len__',\n    '__setitem__', 'clear', 'copy', 'get', 'items',\n    'keys', 'pop', 'popitem', 'setdefault', 'update', 'values'\n    ))\nDictProxy._method_to_typeid_ = {\n    '__iter__': 'Iterator',\n    }\nArrayProxy = MakeProxyType('ArrayProxy', (\n    '__len__', '__getitem__', '__setitem__'\n    ))\nBasePoolProxy = MakeProxyType('PoolProxy', (\n    'apply', 'apply_async', 'close', 'imap', 'imap_unordered', 'join',\n    'map', 'map_async', 'starmap', 'starmap_async', 'terminate',\n    ))\nBasePoolProxy._method_to_typeid_ = {\n    'apply_async': 'AsyncResult',\n    'map_async': 'AsyncResult',\n    'starmap_async': 'AsyncResult',\n    'imap': 'Iterator',\n    'imap_unordered': 'Iterator'\n    }\nSyncManager.register('Queue', queue.Queue)\nSyncManager.register('JoinableQueue', queue.Queue)\nSyncManager.register('Event', threading.Event, EventProxy)\nSyncManager.register('Lock', threading.Lock, AcquirerProxy)\nSyncManager.register('RLock', threading.RLock, AcquirerProxy)\nSyncManager.register('Semaphore', threading.Semaphore, AcquirerProxy)\nSyncManager.register('BoundedSemaphore', threading.BoundedSemaphore,\n                     AcquirerProxy)\nSyncManager.register('Condition', threading.Condition, ConditionProxy)\nSyncManager.register('Barrier', threading.Barrier, BarrierProxy)\nSyncManager.register('Pool', pool.Pool, PoolProxy)\nSyncManager.register('list', list, ListProxy)\nSyncManager.register('dict', dict, DictProxy)\nSyncManager.register('Value', Value, ValueProxy)\nSyncManager.register('Array', Array, ArrayProxy)\nSyncManager.register('Namespace', Namespace, NamespaceProxy)\nSyncManager.register('Iterator', proxytype=IteratorProxy, create_method=False)\nSyncManager.register('AsyncResult', create_method=False)\nif HAS_SHMEM:\n    class _SharedMemoryTracker:\n        \"Manages one or more shared memory segments.\"\n\n        def __init__(self, name, segment_names=[]):\n            self.shared_memory_context_name = name\n            self.segment_names = segment_names\n\n        def register_segment(self, segment_name):\n            \"Adds the supplied shared memory block name to tracker.\"\n            util.debug(f\"Register segment {segment_name!r} in pid {getpid()}\")\n            self.segment_names.append(segment_name)\n\n        def destroy_segment(self, segment_name):\n            \"\"\"Calls unlink() on the shared memory block with the supplied name\n            and removes it from the list of blocks being tracked.\"\"\"\n            util.debug(f\"Destroy segment {segment_name!r} in pid {getpid()}\")\n            self.segment_names.remove(segment_name)\n            segment = shared_memory.SharedMemory(segment_name)\n            segment.close()\n            segment.unlink()\n\n        def unlink(self):\n            \"Calls destroy_segment() on all tracked shared memory blocks.\"\n            for segment_name in self.segment_names[:]:\n                self.destroy_segment(segment_name)\n\n        def __del__(self):\n            util.debug(f\"Call {self.__class__.__name__}.__del__ in {getpid()}\")\n            self.unlink()\n\n        def __getstate__(self):\n            return (self.shared_memory_context_name, self.segment_names)\n\n        def __setstate__(self, state):\n            self.__init__(*state)\n\n\n    class SharedMemoryServer(Server):\n\n        public = Server.public + \\\n                 ['track_segment', 'release_segment', 'list_segments']\n\n        def __init__(self, *args, **kwargs):\n            Server.__init__(self, *args, **kwargs)\n            address = self.address\n            # The address of Linux abstract namespaces can be bytes\n            if isinstance(address, bytes):\n                address = os.fsdecode(address)\n            self.shared_memory_context = \\\n                _SharedMemoryTracker(f\"shm_{address}_{getpid()}\")\n            util.debug(f\"SharedMemoryServer started by pid {getpid()}\")\n\n        def create(self, c, typeid, /, *args, **kwargs):\n            \"\"\"Create a new distributed-shared object (not backed by a shared\n            memory block) and return its id to be used in a Proxy Object.\"\"\"\n            # Unless set up as a shared proxy, don't make shared_memory_context\n            # a standard part of kwargs.  This makes things easier for supplying\n            # simple functions.\n            if hasattr(self.registry[typeid][-1], \"_shared_memory_proxy\"):\n                kwargs['shared_memory_context'] = self.shared_memory_context\n            return Server.create(self, c, typeid, *args, **kwargs)\n\n        def shutdown(self, c):\n            \"Call unlink() on all tracked shared memory, terminate the Server.\"\n            self.shared_memory_context.unlink()\n            return Server.shutdown(self, c)\n\n        def track_segment(self, c, segment_name):\n            \"Adds the supplied shared memory block name to Server's tracker.\"\n            self.shared_memory_context.register_segment(segment_name)\n\n        def release_segment(self, c, segment_name):\n            \"\"\"Calls unlink() on the shared memory block with the supplied name\n            and removes it from the tracker instance inside the Server.\"\"\"\n            self.shared_memory_context.destroy_segment(segment_name)\n\n        def list_segments(self, c):\n            \"\"\"Returns a list of names of shared memory blocks that the Server\n            is currently tracking.\"\"\"\n            return self.shared_memory_context.segment_names\n\n\n    class SharedMemoryManager(BaseManager):\n        \"\"\"Like SyncManager but uses SharedMemoryServer instead of Server.\n\n        It provides methods for creating and returning SharedMemory instances\n        and for creating a list-like object (ShareableList) backed by shared\n        memory.  It also provides methods that create and return Proxy Objects\n        that support synchronization across processes (i.e. multi-process-safe\n        locks and semaphores).\n        \"\"\"\n\n        _Server = SharedMemoryServer\n\n        def __init__(self, *args, **kwargs):\n            if os.name == \"posix\":\n                # bpo-36867: Ensure the resource_tracker is running before\n                # launching the manager process, so that concurrent\n                # shared_memory manipulation both in the manager and in the\n                # current process does not create two resource_tracker\n                # processes.\n                from . import resource_tracker\n                resource_tracker.ensure_running()\n            BaseManager.__init__(self, *args, **kwargs)\n            util.debug(f\"{self.__class__.__name__} created by pid {getpid()}\")\n\n        def __del__(self):\n            util.debug(f\"{self.__class__.__name__}.__del__ by pid {getpid()}\")\n            pass\n\n        def get_server(self):\n            'Better than monkeypatching for now; merge into Server ultimately'\n            if self._state.value != State.INITIAL:\n                if self._state.value == State.STARTED:\n                    raise ProcessError(\"Already started SharedMemoryServer\")\n                elif self._state.value == State.SHUTDOWN:\n                    raise ProcessError(\"SharedMemoryManager has shut down\")\n                else:\n                    raise ProcessError(\n                        \"Unknown state {!r}\".format(self._state.value))\n            return self._Server(self._registry, self._address,\n                                self._authkey, self._serializer)\n\n        def SharedMemory(self, size):\n            \"\"\"Returns a new SharedMemory instance with the specified size in\n            bytes, to be tracked by the manager.\"\"\"\n            with self._Client(self._address, authkey=self._authkey) as conn:\n                sms = shared_memory.SharedMemory(None, create=True, size=size)\n                try:\n                    dispatch(conn, None, 'track_segment', (sms.name,))\n                except BaseException as e:\n                    sms.unlink()\n                    raise e\n            return sms\n\n        def ShareableList(self, sequence):\n            \"\"\"Returns a new ShareableList instance populated with the values\n            from the input sequence, to be tracked by the manager.\"\"\"\n            with self._Client(self._address, authkey=self._authkey) as conn:\n                sl = shared_memory.ShareableList(sequence)\n                try:\n                    dispatch(conn, None, 'track_segment', (sl.shm.name,))\n                except BaseException as e:\n                    sl.shm.unlink()\n                    raise e\n            return sl",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.reduce_array": {
        "API_name": "multiprocessing.managers.reduce_array",
        "loc_name": "multiprocessing.managers.reduce_array",
        "args": "a",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 47,
        "namespace": "*",
        "body": "def reduce_array(a):\n    return array.array, (a.typecode, a.tobytes())",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.rebuild_as_list": {
        "API_name": "multiprocessing.managers.rebuild_as_list",
        "loc_name": "multiprocessing.managers.rebuild_as_list",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 53,
        "namespace": "*",
        "body": "    def rebuild_as_list(obj):\n        return list, (list(obj),)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Token": {
        "API_name": "multiprocessing.managers.Token",
        "loc_name": "multiprocessing.managers.Token",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 62,
        "namespace": "Token",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Token.__init__": {
        "API_name": "multiprocessing.managers.Token.__init__",
        "loc_name": "multiprocessing.managers.Token.__init__",
        "args": "self;typeid;address;id",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 68,
        "namespace": "Token",
        "body": "    def __init__(self, typeid, address, id):\n        (self.typeid, self.address, self.id) = (typeid, address, id)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Token.__getstate__": {
        "API_name": "multiprocessing.managers.Token.__getstate__",
        "loc_name": "multiprocessing.managers.Token.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 71,
        "namespace": "Token",
        "body": "    def __getstate__(self):\n        return (self.typeid, self.address, self.id)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Token.__setstate__": {
        "API_name": "multiprocessing.managers.Token.__setstate__",
        "loc_name": "multiprocessing.managers.Token.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 74,
        "namespace": "Token",
        "body": "    def __setstate__(self, state):\n        (self.typeid, self.address, self.id) = state",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Token.__repr__": {
        "API_name": "multiprocessing.managers.Token.__repr__",
        "loc_name": "multiprocessing.managers.Token.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 77,
        "namespace": "Token",
        "body": "    def __repr__(self):\n        return '%s(typeid=%r, address=%r, id=%r)' % \\\n               (self.__class__.__name__, self.typeid, self.address, self.id)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.dispatch": {
        "API_name": "multiprocessing.managers.dispatch",
        "loc_name": "multiprocessing.managers.dispatch",
        "args": "c;id;methodname;args;kwds",
        "args_default": 2,
        "filepath": "multiprocessing.managers",
        "lineno": 85,
        "namespace": "*",
        "body": "def dispatch(c, id, methodname, args=(), kwds={}):\n    '''\n    Send a message to manager using connection `c` and return response\n    '''\n    c.send((id, methodname, args, kwds))\n    kind, result = c.recv()\n    if kind == '#RETURN':\n        return result\n    raise convert_to_error(kind, result)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.convert_to_error": {
        "API_name": "multiprocessing.managers.convert_to_error",
        "loc_name": "multiprocessing.managers.convert_to_error",
        "args": "kind;result",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 95,
        "namespace": "*",
        "body": "def convert_to_error(kind, result):\n    if kind == '#ERROR':\n        return result\n    elif kind in ('#TRACEBACK', '#UNSERIALIZABLE'):\n        if not isinstance(result, str):\n            raise TypeError(\n                \"Result {0!r} (kind '{1}') type is {2}, not str\".format(\n                    result, kind, type(result)))\n        if kind == '#UNSERIALIZABLE':\n            return RemoteError('Unserializable message: %s\\n' % result)\n        else:\n            return RemoteError(result)\n    else:\n        return ValueError('Unrecognized message type {!r}'.format(kind))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.RemoteError.__str__": {
        "API_name": "multiprocessing.managers.RemoteError.__str__",
        "loc_name": "multiprocessing.managers.RemoteError.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 111,
        "namespace": "RemoteError",
        "body": "    def __str__(self):\n        return ('\\n' + '-'*75 + '\\n' + str(self.args[0]) + '-'*75)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.RemoteError": {
        "API_name": "multiprocessing.managers.RemoteError",
        "loc_name": "multiprocessing.managers.RemoteError",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 110,
        "namespace": "RemoteError",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.all_methods": {
        "API_name": "multiprocessing.managers.all_methods",
        "loc_name": "multiprocessing.managers.all_methods",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 118,
        "namespace": "*",
        "body": "def all_methods(obj):\n    '''\n    Return a list of names of methods of `obj`\n    '''\n    temp = []\n    for name in dir(obj):\n        func = getattr(obj, name)\n        if callable(func):\n            temp.append(name)\n    return temp",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.public_methods": {
        "API_name": "multiprocessing.managers.public_methods",
        "loc_name": "multiprocessing.managers.public_methods",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 129,
        "namespace": "*",
        "body": "def public_methods(obj):\n    '''\n    Return a list of names of methods of `obj` which do not start with '_'\n    '''\n    return [name for name in all_methods(obj) if name[0] != '_']",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server": {
        "API_name": "multiprocessing.managers.Server",
        "loc_name": "multiprocessing.managers.Server",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 139,
        "namespace": "Server",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.__init__": {
        "API_name": "multiprocessing.managers.Server.__init__",
        "loc_name": "multiprocessing.managers.Server.__init__",
        "args": "self;registry;address;authkey;serializer",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 146,
        "namespace": "Server",
        "body": "    def __init__(self, registry, address, authkey, serializer):\n        if not isinstance(authkey, bytes):\n            raise TypeError(\n                \"Authkey {0!r} is type {1!s}, not bytes\".format(\n                    authkey, type(authkey)))\n        self.registry = registry\n        self.authkey = process.AuthenticationString(authkey)\n        Listener, Client = listener_client[serializer]\n\n        # do authentication later\n        self.listener = Listener(address=address, backlog=16)\n        self.address = self.listener.address\n\n        self.id_to_obj = {'0': (None, ())}\n        self.id_to_refcount = {}\n        self.id_to_local_proxy_obj = {}\n        self.mutex = threading.Lock()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.serve_forever": {
        "API_name": "multiprocessing.managers.Server.serve_forever",
        "loc_name": "multiprocessing.managers.Server.serve_forever",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 164,
        "namespace": "Server",
        "body": "    def serve_forever(self):\n        '''\n        Run the server forever\n        '''\n        self.stop_event = threading.Event()\n        process.current_process()._manager_server = self\n        try:\n            accepter = threading.Thread(target=self.accepter)\n            accepter.daemon = True\n            accepter.start()\n            try:\n                while not self.stop_event.is_set():\n                    self.stop_event.wait(1)\n            except (KeyboardInterrupt, SystemExit):\n                pass\n        finally:\n            if sys.stdout != sys.__stdout__: # what about stderr?\n                util.debug('resetting stdout, stderr')\n                sys.stdout = sys.__stdout__\n                sys.stderr = sys.__stderr__\n            sys.exit(0)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.accepter": {
        "API_name": "multiprocessing.managers.Server.accepter",
        "loc_name": "multiprocessing.managers.Server.accepter",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 186,
        "namespace": "Server",
        "body": "    def accepter(self):\n        while True:\n            try:\n                c = self.listener.accept()\n            except OSError:\n                continue\n            t = threading.Thread(target=self.handle_request, args=(c,))\n            t.daemon = True\n            t.start()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.handle_request": {
        "API_name": "multiprocessing.managers.Server.handle_request",
        "loc_name": "multiprocessing.managers.Server.handle_request",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 196,
        "namespace": "Server",
        "body": "    def handle_request(self, c):\n        '''\n        Handle a new connection\n        '''\n        funcname = result = request = None\n        try:\n            connection.deliver_challenge(c, self.authkey)\n            connection.answer_challenge(c, self.authkey)\n            request = c.recv()\n            ignore, funcname, args, kwds = request\n            assert funcname in self.public, '%r unrecognized' % funcname\n            func = getattr(self, funcname)\n        except Exception:\n            msg = ('#TRACEBACK', format_exc())\n        else:\n            try:\n                result = func(c, *args, **kwds)\n            except Exception:\n                msg = ('#TRACEBACK', format_exc())\n            else:\n                msg = ('#RETURN', result)\n        try:\n            c.send(msg)\n        except Exception as e:\n            try:\n                c.send(('#TRACEBACK', format_exc()))\n            except Exception:\n                pass\n            util.info('Failure to send message: %r', msg)\n            util.info(' ... request was %r', request)\n            util.info(' ... exception was %r', e)\n\n        c.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.serve_client": {
        "API_name": "multiprocessing.managers.Server.serve_client",
        "loc_name": "multiprocessing.managers.Server.serve_client",
        "args": "self;conn",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 230,
        "namespace": "Server",
        "body": "    def serve_client(self, conn):\n        '''\n        Handle requests from the proxies in a particular process/thread\n        '''\n        util.debug('starting server thread to service %r',\n                   threading.current_thread().name)\n\n        recv = conn.recv\n        send = conn.send\n        id_to_obj = self.id_to_obj\n\n        while not self.stop_event.is_set():\n\n            try:\n                methodname = obj = None\n                request = recv()\n                ident, methodname, args, kwds = request\n                try:\n                    obj, exposed, gettypeid = id_to_obj[ident]\n                except KeyError as ke:\n                    try:\n                        obj, exposed, gettypeid = \\\n                            self.id_to_local_proxy_obj[ident]\n                    except KeyError:\n                        raise ke\n\n                if methodname not in exposed:\n                    raise AttributeError(\n                        'method %r of %r object is not in exposed=%r' %\n                        (methodname, type(obj), exposed)\n                        )\n\n                function = getattr(obj, methodname)\n\n                try:\n                    res = function(*args, **kwds)\n                except Exception as e:\n                    msg = ('#ERROR', e)\n                else:\n                    typeid = gettypeid and gettypeid.get(methodname, None)\n                    if typeid:\n                        rident, rexposed = self.create(conn, typeid, res)\n                        token = Token(typeid, self.address, rident)\n                        msg = ('#PROXY', (rexposed, token))\n                    else:\n                        msg = ('#RETURN', res)\n\n            except AttributeError:\n                if methodname is None:\n                    msg = ('#TRACEBACK', format_exc())\n                else:\n                    try:\n                        fallback_func = self.fallback_mapping[methodname]\n                        result = fallback_func(\n                            self, conn, ident, obj, *args, **kwds\n                            )\n                        msg = ('#RETURN', result)\n                    except Exception:\n                        msg = ('#TRACEBACK', format_exc())\n\n            except EOFError:\n                util.debug('got EOF -- exiting thread serving %r',\n                           threading.current_thread().name)\n                sys.exit(0)\n\n            except Exception:\n                msg = ('#TRACEBACK', format_exc())\n\n            try:\n                try:\n                    send(msg)\n                except Exception:\n                    send(('#UNSERIALIZABLE', format_exc()))\n            except Exception as e:\n                util.info('exception in thread serving %r',\n                        threading.current_thread().name)\n                util.info(' ... message was %r', msg)\n                util.info(' ... exception was %r', e)\n                conn.close()\n                sys.exit(1)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.fallback_getvalue": {
        "API_name": "multiprocessing.managers.Server.fallback_getvalue",
        "loc_name": "multiprocessing.managers.Server.fallback_getvalue",
        "args": "self;conn;ident;obj",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 311,
        "namespace": "Server",
        "body": "    def fallback_getvalue(self, conn, ident, obj):\n        return obj",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.fallback_str": {
        "API_name": "multiprocessing.managers.Server.fallback_str",
        "loc_name": "multiprocessing.managers.Server.fallback_str",
        "args": "self;conn;ident;obj",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 314,
        "namespace": "Server",
        "body": "    def fallback_str(self, conn, ident, obj):\n        return str(obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.fallback_repr": {
        "API_name": "multiprocessing.managers.Server.fallback_repr",
        "loc_name": "multiprocessing.managers.Server.fallback_repr",
        "args": "self;conn;ident;obj",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 317,
        "namespace": "Server",
        "body": "    def fallback_repr(self, conn, ident, obj):\n        return repr(obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.dummy": {
        "API_name": "multiprocessing.managers.Server.dummy",
        "loc_name": "multiprocessing.managers.Server.dummy",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 326,
        "namespace": "Server",
        "body": "    def dummy(self, c):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.debug_info": {
        "API_name": "multiprocessing.managers.Server.debug_info",
        "loc_name": "multiprocessing.managers.Server.debug_info",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 329,
        "namespace": "Server",
        "body": "    def debug_info(self, c):\n        '''\n        Return some info --- useful to spot problems with refcounting\n        '''\n        # Perhaps include debug info about 'c'?\n        with self.mutex:\n            result = []\n            keys = list(self.id_to_refcount.keys())\n            keys.sort()\n            for ident in keys:\n                if ident != '0':\n                    result.append('  %s:       refcount=%s\\n    %s' %\n                                  (ident, self.id_to_refcount[ident],\n                                   str(self.id_to_obj[ident][0])[:75]))\n            return '\\n'.join(result)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.number_of_objects": {
        "API_name": "multiprocessing.managers.Server.number_of_objects",
        "loc_name": "multiprocessing.managers.Server.number_of_objects",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 345,
        "namespace": "Server",
        "body": "    def number_of_objects(self, c):\n        '''\n        Number of shared objects\n        '''\n        # Doesn't use (len(self.id_to_obj) - 1) as we shouldn't count ident='0'\n        return len(self.id_to_refcount)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.shutdown": {
        "API_name": "multiprocessing.managers.Server.shutdown",
        "loc_name": "multiprocessing.managers.Server.shutdown",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 352,
        "namespace": "Server",
        "body": "    def shutdown(self, c):\n        '''\n        Shutdown this process\n        '''\n        try:\n            util.debug('manager received shutdown message')\n            c.send(('#RETURN', None))\n        except:\n            import traceback\n            traceback.print_exc()\n        finally:\n            self.stop_event.set()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.create": {
        "API_name": "multiprocessing.managers.Server.create",
        "loc_name": "multiprocessing.managers.Server.create",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 365,
        "namespace": "Server",
        "body": "    def create(self, c, typeid, /, *args, **kwds):\n        '''\n        Create a new shared object and return its id\n        '''\n        with self.mutex:\n            callable, exposed, method_to_typeid, proxytype = \\\n                      self.registry[typeid]\n\n            if callable is None:\n                if kwds or (len(args) != 1):\n                    raise ValueError(\n                        \"Without callable, must have one non-keyword argument\")\n                obj = args[0]\n            else:\n                obj = callable(*args, **kwds)\n\n            if exposed is None:\n                exposed = public_methods(obj)\n            if method_to_typeid is not None:\n                if not isinstance(method_to_typeid, dict):\n                    raise TypeError(\n                        \"Method_to_typeid {0!r}: type {1!s}, not dict\".format(\n                            method_to_typeid, type(method_to_typeid)))\n                exposed = list(exposed) + list(method_to_typeid)\n\n            ident = '%x' % id(obj)  # convert to string because xmlrpclib\n                                    # only has 32 bit signed integers\n            util.debug('%r callable returned object with id %r', typeid, ident)\n\n            self.id_to_obj[ident] = (obj, set(exposed), method_to_typeid)\n            if ident not in self.id_to_refcount:\n                self.id_to_refcount[ident] = 0\n\n        self.incref(c, ident)\n        return ident, tuple(exposed)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.get_methods": {
        "API_name": "multiprocessing.managers.Server.get_methods",
        "loc_name": "multiprocessing.managers.Server.get_methods",
        "args": "self;c;token",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 401,
        "namespace": "Server",
        "body": "    def get_methods(self, c, token):\n        '''\n        Return the methods of the shared object indicated by token\n        '''\n        return tuple(self.id_to_obj[token.id][1])",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.accept_connection": {
        "API_name": "multiprocessing.managers.Server.accept_connection",
        "loc_name": "multiprocessing.managers.Server.accept_connection",
        "args": "self;c;name",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 407,
        "namespace": "Server",
        "body": "    def accept_connection(self, c, name):\n        '''\n        Spawn a new thread to serve this connection\n        '''\n        threading.current_thread().name = name\n        c.send(('#RETURN', None))\n        self.serve_client(c)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.incref": {
        "API_name": "multiprocessing.managers.Server.incref",
        "loc_name": "multiprocessing.managers.Server.incref",
        "args": "self;c;ident",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 415,
        "namespace": "Server",
        "body": "    def incref(self, c, ident):\n        with self.mutex:\n            try:\n                self.id_to_refcount[ident] += 1\n            except KeyError as ke:\n                # If no external references exist but an internal (to the\n                # manager) still does and a new external reference is created\n                # from it, restore the manager's tracking of it from the\n                # previously stashed internal ref.\n                if ident in self.id_to_local_proxy_obj:\n                    self.id_to_refcount[ident] = 1\n                    self.id_to_obj[ident] = \\\n                        self.id_to_local_proxy_obj[ident]\n                    obj, exposed, gettypeid = self.id_to_obj[ident]\n                    util.debug('Server re-enabled tracking & INCREF %r', ident)\n                else:\n                    raise ke",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Server.decref": {
        "API_name": "multiprocessing.managers.Server.decref",
        "loc_name": "multiprocessing.managers.Server.decref",
        "args": "self;c;ident",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 433,
        "namespace": "Server",
        "body": "    def decref(self, c, ident):\n        if ident not in self.id_to_refcount and \\\n            ident in self.id_to_local_proxy_obj:\n            util.debug('Server DECREF skipping %r', ident)\n            return\n\n        with self.mutex:\n            if self.id_to_refcount[ident] <= 0:\n                raise AssertionError(\n                    \"Id {0!s} ({1!r}) has refcount {2:n}, not 1+\".format(\n                        ident, self.id_to_obj[ident],\n                        self.id_to_refcount[ident]))\n            self.id_to_refcount[ident] -= 1\n            if self.id_to_refcount[ident] == 0:\n                del self.id_to_refcount[ident]\n\n        if ident not in self.id_to_refcount:\n            # Two-step process in case the object turns out to contain other\n            # proxy objects (e.g. a managed list of managed lists).\n            # Otherwise, deleting self.id_to_obj[ident] would trigger the\n            # deleting of the stored value (another managed object) which would\n            # in turn attempt to acquire the mutex that is already held here.\n            self.id_to_obj[ident] = (None, (), None)  # thread-safe\n            util.debug('disposing of obj with id %r', ident)\n            with self.mutex:\n                del self.id_to_obj[ident]",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.State": {
        "API_name": "multiprocessing.managers.State",
        "loc_name": "multiprocessing.managers.State",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 465,
        "namespace": "State",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager": {
        "API_name": "multiprocessing.managers.BaseManager",
        "loc_name": "multiprocessing.managers.BaseManager",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 484,
        "namespace": "BaseManager",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.__init__": {
        "API_name": "multiprocessing.managers.BaseManager.__init__",
        "loc_name": "multiprocessing.managers.BaseManager.__init__",
        "args": "self;address;authkey;serializer;ctx",
        "args_default": 4,
        "filepath": "multiprocessing.managers",
        "lineno": 491,
        "namespace": "BaseManager",
        "body": "    def __init__(self, address=None, authkey=None, serializer='pickle',\n                 ctx=None):\n        if authkey is None:\n            authkey = process.current_process().authkey\n        self._address = address     # XXX not final address if eg ('', 0)\n        self._authkey = process.AuthenticationString(authkey)\n        self._state = State()\n        self._state.value = State.INITIAL\n        self._serializer = serializer\n        self._Listener, self._Client = listener_client[serializer]\n        self._ctx = ctx or get_context()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.get_server": {
        "API_name": "multiprocessing.managers.BaseManager.get_server",
        "loc_name": "multiprocessing.managers.BaseManager.get_server",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 503,
        "namespace": "BaseManager",
        "body": "    def get_server(self):\n        '''\n        Return server object with serve_forever() method and address attribute\n        '''\n        if self._state.value != State.INITIAL:\n            if self._state.value == State.STARTED:\n                raise ProcessError(\"Already started server\")\n            elif self._state.value == State.SHUTDOWN:\n                raise ProcessError(\"Manager has shut down\")\n            else:\n                raise ProcessError(\n                    \"Unknown state {!r}\".format(self._state.value))\n        return Server(self._registry, self._address,\n                      self._authkey, self._serializer)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.connect": {
        "API_name": "multiprocessing.managers.BaseManager.connect",
        "loc_name": "multiprocessing.managers.BaseManager.connect",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 518,
        "namespace": "BaseManager",
        "body": "    def connect(self):\n        '''\n        Connect manager object to the server process\n        '''\n        Listener, Client = listener_client[self._serializer]\n        conn = Client(self._address, authkey=self._authkey)\n        dispatch(conn, None, 'dummy')\n        self._state.value = State.STARTED",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.start": {
        "API_name": "multiprocessing.managers.BaseManager.start",
        "loc_name": "multiprocessing.managers.BaseManager.start",
        "args": "self;initializer;initargs",
        "args_default": 2,
        "filepath": "multiprocessing.managers",
        "lineno": 527,
        "namespace": "BaseManager",
        "body": "    def start(self, initializer=None, initargs=()):\n        '''\n        Spawn a server process for this manager object\n        '''\n        if self._state.value != State.INITIAL:\n            if self._state.value == State.STARTED:\n                raise ProcessError(\"Already started server\")\n            elif self._state.value == State.SHUTDOWN:\n                raise ProcessError(\"Manager has shut down\")\n            else:\n                raise ProcessError(\n                    \"Unknown state {!r}\".format(self._state.value))\n\n        if initializer is not None and not callable(initializer):\n            raise TypeError('initializer must be a callable')\n\n        # pipe over which we will retrieve address of server\n        reader, writer = connection.Pipe(duplex=False)\n\n        # spawn process which runs a server\n        self._process = self._ctx.Process(\n            target=type(self)._run_server,\n            args=(self._registry, self._address, self._authkey,\n                  self._serializer, writer, initializer, initargs),\n            )\n        ident = ':'.join(str(i) for i in self._process._identity)\n        self._process.name = type(self).__name__  + '-' + ident\n        self._process.start()\n\n        # get address of server\n        writer.close()\n        self._address = reader.recv()\n        reader.close()\n\n        # register a finalizer\n        self._state.value = State.STARTED\n        self.shutdown = util.Finalize(\n            self, type(self)._finalize_manager,\n            args=(self._process, self._address, self._authkey,\n                  self._state, self._Client),\n            exitpriority=0\n            )",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager._run_server": {
        "API_name": "multiprocessing.managers.BaseManager._run_server",
        "loc_name": "multiprocessing.managers.BaseManager._run_server",
        "args": "cls;registry;address;authkey;serializer;writer;initializer;initargs",
        "args_default": 2,
        "filepath": "multiprocessing.managers",
        "lineno": 571,
        "namespace": "BaseManager",
        "body": "    def _run_server(cls, registry, address, authkey, serializer, writer,\n                    initializer=None, initargs=()):\n        '''\n        Create a server, report its address and run it\n        '''\n        # bpo-36368: protect server process from KeyboardInterrupt signals\n        signal.signal(signal.SIGINT, signal.SIG_IGN)\n\n        if initializer is not None:\n            initializer(*initargs)\n\n        # create server\n        server = cls._Server(registry, address, authkey, serializer)\n\n        # inform parent process of the server's address\n        writer.send(server.address)\n        writer.close()\n\n        # run the manager\n        util.info('manager serving at %r', server.address)\n        server.serve_forever()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager._create": {
        "API_name": "multiprocessing.managers.BaseManager._create",
        "loc_name": "multiprocessing.managers.BaseManager._create",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 593,
        "namespace": "BaseManager",
        "body": "    def _create(self, typeid, /, *args, **kwds):\n        '''\n        Create a new shared object; return the token and exposed tuple\n        '''\n        assert self._state.value == State.STARTED, 'server not yet started'\n        conn = self._Client(self._address, authkey=self._authkey)\n        try:\n            id, exposed = dispatch(conn, None, 'create', (typeid,)+args, kwds)\n        finally:\n            conn.close()\n        return Token(typeid, self._address, id), exposed",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.join": {
        "API_name": "multiprocessing.managers.BaseManager.join",
        "loc_name": "multiprocessing.managers.BaseManager.join",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 605,
        "namespace": "BaseManager",
        "body": "    def join(self, timeout=None):\n        '''\n        Join the manager process (if it has been spawned)\n        '''\n        if self._process is not None:\n            self._process.join(timeout)\n            if not self._process.is_alive():\n                self._process = None",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager._debug_info": {
        "API_name": "multiprocessing.managers.BaseManager._debug_info",
        "loc_name": "multiprocessing.managers.BaseManager._debug_info",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 614,
        "namespace": "BaseManager",
        "body": "    def _debug_info(self):\n        '''\n        Return some info about the servers shared objects and connections\n        '''\n        conn = self._Client(self._address, authkey=self._authkey)\n        try:\n            return dispatch(conn, None, 'debug_info')\n        finally:\n            conn.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager._number_of_objects": {
        "API_name": "multiprocessing.managers.BaseManager._number_of_objects",
        "loc_name": "multiprocessing.managers.BaseManager._number_of_objects",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 624,
        "namespace": "BaseManager",
        "body": "    def _number_of_objects(self):\n        '''\n        Return the number of shared objects\n        '''\n        conn = self._Client(self._address, authkey=self._authkey)\n        try:\n            return dispatch(conn, None, 'number_of_objects')\n        finally:\n            conn.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.__enter__": {
        "API_name": "multiprocessing.managers.BaseManager.__enter__",
        "loc_name": "multiprocessing.managers.BaseManager.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 634,
        "namespace": "BaseManager",
        "body": "    def __enter__(self):\n        if self._state.value == State.INITIAL:\n            self.start()\n        if self._state.value != State.STARTED:\n            if self._state.value == State.INITIAL:\n                raise ProcessError(\"Unable to start server\")\n            elif self._state.value == State.SHUTDOWN:\n                raise ProcessError(\"Manager has shut down\")\n            else:\n                raise ProcessError(\n                    \"Unknown state {!r}\".format(self._state.value))\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.__exit__": {
        "API_name": "multiprocessing.managers.BaseManager.__exit__",
        "loc_name": "multiprocessing.managers.BaseManager.__exit__",
        "args": "self;exc_type;exc_val;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 647,
        "namespace": "BaseManager",
        "body": "    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.shutdown()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager._finalize_manager": {
        "API_name": "multiprocessing.managers.BaseManager._finalize_manager",
        "loc_name": "multiprocessing.managers.BaseManager._finalize_manager",
        "args": "process;address;authkey;state;_Client",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 651,
        "namespace": "BaseManager",
        "body": "    def _finalize_manager(process, address, authkey, state, _Client):\n        '''\n        Shutdown the manager process; will be registered as a finalizer\n        '''\n        if process.is_alive():\n            util.info('sending shutdown message to manager')\n            try:\n                conn = _Client(address, authkey=authkey)\n                try:\n                    dispatch(conn, None, 'shutdown')\n                finally:\n                    conn.close()\n            except Exception:\n                pass\n\n            process.join(timeout=1.0)\n            if process.is_alive():\n                util.info('manager still alive')\n                if hasattr(process, 'terminate'):\n                    util.info('trying to `terminate()` manager process')\n                    process.terminate()\n                    process.join(timeout=1.0)\n                    if process.is_alive():\n                        util.info('manager still alive after terminate')\n\n        state.value = State.SHUTDOWN\n        try:\n            del BaseProxy._address_to_local[address]\n        except KeyError:\n            pass",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.address": {
        "API_name": "multiprocessing.managers.BaseManager.address",
        "loc_name": "multiprocessing.managers.BaseManager.address",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 683,
        "namespace": "BaseManager",
        "body": "    def address(self):\n        return self._address",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseManager.register": {
        "API_name": "multiprocessing.managers.BaseManager.register",
        "loc_name": "multiprocessing.managers.BaseManager.register",
        "args": "cls;typeid;callable;proxytype;exposed;method_to_typeid;create_method",
        "args_default": 5,
        "filepath": "multiprocessing.managers",
        "lineno": 687,
        "namespace": "BaseManager",
        "body": "    def register(cls, typeid, callable=None, proxytype=None, exposed=None,\n                 method_to_typeid=None, create_method=True):\n        '''\n        Register a typeid with the manager type\n        '''\n        if '_registry' not in cls.__dict__:\n            cls._registry = cls._registry.copy()\n\n        if proxytype is None:\n            proxytype = AutoProxy\n\n        exposed = exposed or getattr(proxytype, '_exposed_', None)\n\n        method_to_typeid = method_to_typeid or \\\n                           getattr(proxytype, '_method_to_typeid_', None)\n\n        if method_to_typeid:\n            for key, value in list(method_to_typeid.items()): # isinstance?\n                assert type(key) is str, '%r is not a string' % key\n                assert type(value) is str, '%r is not a string' % value\n\n        cls._registry[typeid] = (\n            callable, exposed, method_to_typeid, proxytype\n            )\n\n        if create_method:\n            def temp(self, /, *args, **kwds):\n                util.debug('requesting creation of a shared %r object', typeid)\n                token, exp = self._create(typeid, *args, **kwds)\n                proxy = proxytype(\n                    token, self._serializer, manager=self,\n                    authkey=self._authkey, exposed=exp\n                    )\n                conn = self._Client(token.address, authkey=self._authkey)\n                dispatch(conn, None, 'decref', (token.id,))\n                return proxy\n            temp.__name__ = typeid\n            setattr(cls, typeid, temp)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ProcessLocalSet": {
        "API_name": "multiprocessing.managers.ProcessLocalSet",
        "loc_name": "multiprocessing.managers.ProcessLocalSet",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 730,
        "namespace": "ProcessLocalSet",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ProcessLocalSet.__init__": {
        "API_name": "multiprocessing.managers.ProcessLocalSet.__init__",
        "loc_name": "multiprocessing.managers.ProcessLocalSet.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 731,
        "namespace": "ProcessLocalSet",
        "body": "    def __init__(self):\n        util.register_after_fork(self, lambda obj: obj.clear())",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ProcessLocalSet.__reduce__": {
        "API_name": "multiprocessing.managers.ProcessLocalSet.__reduce__",
        "loc_name": "multiprocessing.managers.ProcessLocalSet.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 733,
        "namespace": "ProcessLocalSet",
        "body": "    def __reduce__(self):\n        return type(self), ()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy": {
        "API_name": "multiprocessing.managers.BaseProxy",
        "loc_name": "multiprocessing.managers.BaseProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 740,
        "namespace": "BaseProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy.__init__": {
        "API_name": "multiprocessing.managers.BaseProxy.__init__",
        "loc_name": "multiprocessing.managers.BaseProxy.__init__",
        "args": "self;token;serializer;manager;authkey;exposed;incref;manager_owned",
        "args_default": 5,
        "filepath": "multiprocessing.managers",
        "lineno": 747,
        "namespace": "BaseProxy",
        "body": "    def __init__(self, token, serializer, manager=None,\n                 authkey=None, exposed=None, incref=True, manager_owned=False):\n        with BaseProxy._mutex:\n            tls_idset = BaseProxy._address_to_local.get(token.address, None)\n            if tls_idset is None:\n                tls_idset = util.ForkAwareLocal(), ProcessLocalSet()\n                BaseProxy._address_to_local[token.address] = tls_idset\n\n        # self._tls is used to record the connection used by this\n        # thread to communicate with the manager at token.address\n        self._tls = tls_idset[0]\n\n        # self._idset is used to record the identities of all shared\n        # objects for which the current process owns references and\n        # which are in the manager at token.address\n        self._idset = tls_idset[1]\n\n        self._token = token\n        self._id = self._token.id\n        self._manager = manager\n        self._serializer = serializer\n        self._Client = listener_client[serializer][1]\n\n        # Should be set to True only when a proxy object is being created\n        # on the manager server; primary use case: nested proxy objects.\n        # RebuildProxy detects when a proxy is being created on the manager\n        # and sets this value appropriately.\n        self._owned_by_manager = manager_owned\n\n        if authkey is not None:\n            self._authkey = process.AuthenticationString(authkey)\n        elif self._manager is not None:\n            self._authkey = self._manager._authkey\n        else:\n            self._authkey = process.current_process().authkey\n\n        if incref:\n            self._incref()\n\n        util.register_after_fork(self, BaseProxy._after_fork)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy._connect": {
        "API_name": "multiprocessing.managers.BaseProxy._connect",
        "loc_name": "multiprocessing.managers.BaseProxy._connect",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 788,
        "namespace": "BaseProxy",
        "body": "    def _connect(self):\n        util.debug('making connection to manager')\n        name = process.current_process().name\n        if threading.current_thread().name != 'MainThread':\n            name += '|' + threading.current_thread().name\n        conn = self._Client(self._token.address, authkey=self._authkey)\n        dispatch(conn, None, 'accept_connection', (name,))\n        self._tls.connection = conn",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy._callmethod": {
        "API_name": "multiprocessing.managers.BaseProxy._callmethod",
        "loc_name": "multiprocessing.managers.BaseProxy._callmethod",
        "args": "self;methodname;args;kwds",
        "args_default": 2,
        "filepath": "multiprocessing.managers",
        "lineno": 797,
        "namespace": "BaseProxy",
        "body": "    def _callmethod(self, methodname, args=(), kwds={}):\n        '''\n        Try to call a method of the referent and return a copy of the result\n        '''\n        try:\n            conn = self._tls.connection\n        except AttributeError:\n            util.debug('thread %r does not own a connection',\n                       threading.current_thread().name)\n            self._connect()\n            conn = self._tls.connection\n\n        conn.send((self._id, methodname, args, kwds))\n        kind, result = conn.recv()\n\n        if kind == '#RETURN':\n            return result\n        elif kind == '#PROXY':\n            exposed, token = result\n            proxytype = self._manager._registry[token.typeid][-1]\n            token.address = self._token.address\n            proxy = proxytype(\n                token, self._serializer, manager=self._manager,\n                authkey=self._authkey, exposed=exposed\n                )\n            conn = self._Client(token.address, authkey=self._authkey)\n            dispatch(conn, None, 'decref', (token.id,))\n            return proxy\n        raise convert_to_error(kind, result)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy._getvalue": {
        "API_name": "multiprocessing.managers.BaseProxy._getvalue",
        "loc_name": "multiprocessing.managers.BaseProxy._getvalue",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 827,
        "namespace": "BaseProxy",
        "body": "    def _getvalue(self):\n        '''\n        Get a copy of the value of the referent\n        '''\n        return self._callmethod('#GETVALUE')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy._incref": {
        "API_name": "multiprocessing.managers.BaseProxy._incref",
        "loc_name": "multiprocessing.managers.BaseProxy._incref",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 833,
        "namespace": "BaseProxy",
        "body": "    def _incref(self):\n        if self._owned_by_manager:\n            util.debug('owned_by_manager skipped INCREF of %r', self._token.id)\n            return\n\n        conn = self._Client(self._token.address, authkey=self._authkey)\n        dispatch(conn, None, 'incref', (self._id,))\n        util.debug('INCREF %r', self._token.id)\n\n        self._idset.add(self._id)\n\n        state = self._manager and self._manager._state\n\n        self._close = util.Finalize(\n            self, BaseProxy._decref,\n            args=(self._token, self._authkey, state,\n                  self._tls, self._idset, self._Client),\n            exitpriority=10\n            )",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy._decref": {
        "API_name": "multiprocessing.managers.BaseProxy._decref",
        "loc_name": "multiprocessing.managers.BaseProxy._decref",
        "args": "token;authkey;state;tls;idset;_Client",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 854,
        "namespace": "BaseProxy",
        "body": "    def _decref(token, authkey, state, tls, idset, _Client):\n        idset.discard(token.id)\n\n        # check whether manager is still alive\n        if state is None or state.value == State.STARTED:\n            # tell manager this process no longer cares about referent\n            try:\n                util.debug('DECREF %r', token.id)\n                conn = _Client(token.address, authkey=authkey)\n                dispatch(conn, None, 'decref', (token.id,))\n            except Exception as e:\n                util.debug('... decref failed %s', e)\n\n        else:\n            util.debug('DECREF %r -- manager already shutdown', token.id)\n\n        # check whether we can close this thread's connection because\n        # the process owns no more references to objects for this manager\n        if not idset and hasattr(tls, 'connection'):\n            util.debug('thread %r has no more proxies so closing conn',\n                       threading.current_thread().name)\n            tls.connection.close()\n            del tls.connection",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy._after_fork": {
        "API_name": "multiprocessing.managers.BaseProxy._after_fork",
        "loc_name": "multiprocessing.managers.BaseProxy._after_fork",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 878,
        "namespace": "BaseProxy",
        "body": "    def _after_fork(self):\n        self._manager = None\n        try:\n            self._incref()\n        except Exception as e:\n            # the proxy may just be for a manager which has shutdown\n            util.info('incref failed: %s' % e)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy.__reduce__": {
        "API_name": "multiprocessing.managers.BaseProxy.__reduce__",
        "loc_name": "multiprocessing.managers.BaseProxy.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 886,
        "namespace": "BaseProxy",
        "body": "    def __reduce__(self):\n        kwds = {}\n        if get_spawning_popen() is not None:\n            kwds['authkey'] = self._authkey\n\n        if getattr(self, '_isauto', False):\n            kwds['exposed'] = self._exposed_\n            return (RebuildProxy,\n                    (AutoProxy, self._token, self._serializer, kwds))\n        else:\n            return (RebuildProxy,\n                    (type(self), self._token, self._serializer, kwds))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy.__deepcopy__": {
        "API_name": "multiprocessing.managers.BaseProxy.__deepcopy__",
        "loc_name": "multiprocessing.managers.BaseProxy.__deepcopy__",
        "args": "self;memo",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 899,
        "namespace": "BaseProxy",
        "body": "    def __deepcopy__(self, memo):\n        return self._getvalue()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy.__repr__": {
        "API_name": "multiprocessing.managers.BaseProxy.__repr__",
        "loc_name": "multiprocessing.managers.BaseProxy.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 902,
        "namespace": "BaseProxy",
        "body": "    def __repr__(self):\n        return '<%s object, typeid %r at %#x>' % \\\n               (type(self).__name__, self._token.typeid, id(self))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BaseProxy.__str__": {
        "API_name": "multiprocessing.managers.BaseProxy.__str__",
        "loc_name": "multiprocessing.managers.BaseProxy.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 906,
        "namespace": "BaseProxy",
        "body": "    def __str__(self):\n        '''\n        Return representation of the referent (or a fall-back if that fails)\n        '''\n        try:\n            return self._callmethod('__repr__')\n        except Exception:\n            return repr(self)[:-1] + \"; '__str__()' failed>\"",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.RebuildProxy": {
        "API_name": "multiprocessing.managers.RebuildProxy",
        "loc_name": "multiprocessing.managers.RebuildProxy",
        "args": "func;token;serializer;kwds",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 919,
        "namespace": "*",
        "body": "def RebuildProxy(func, token, serializer, kwds):\n    '''\n    Function used for unpickling proxy objects.\n    '''\n    server = getattr(process.current_process(), '_manager_server', None)\n    if server and server.address == token.address:\n        util.debug('Rebuild a proxy owned by manager, token=%r', token)\n        kwds['manager_owned'] = True\n        if token.id not in server.id_to_local_proxy_obj:\n            server.id_to_local_proxy_obj[token.id] = \\\n                server.id_to_obj[token.id]\n    incref = (\n        kwds.pop('incref', True) and\n        not getattr(process.current_process(), '_inheriting', False)\n        )\n    return func(token, serializer, incref=incref, **kwds)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.MakeProxyType": {
        "API_name": "multiprocessing.managers.MakeProxyType",
        "loc_name": "multiprocessing.managers.MakeProxyType",
        "args": "name;exposed;_cache",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 940,
        "namespace": "*",
        "body": "def MakeProxyType(name, exposed, _cache={}):\n    '''\n    Return a proxy type whose methods are given by `exposed`\n    '''\n    exposed = tuple(exposed)\n    try:\n        return _cache[(name, exposed)]\n    except KeyError:\n        pass\n\n    dic = {}\n\n    for meth in exposed:\n        exec('''def %s(self, /, *args, **kwds):\n        return self._callmethod(%r, args, kwds)''' % (meth, meth), dic)\n\n    ProxyType = type(name, (BaseProxy,), dic)\n    ProxyType._exposed_ = exposed\n    _cache[(name, exposed)] = ProxyType\n    return ProxyType",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.AutoProxy": {
        "API_name": "multiprocessing.managers.AutoProxy",
        "loc_name": "multiprocessing.managers.AutoProxy",
        "args": "token;serializer;manager;authkey;exposed;incref;manager_owned",
        "args_default": 5,
        "filepath": "multiprocessing.managers",
        "lineno": 962,
        "namespace": "*",
        "body": "def AutoProxy(token, serializer, manager=None, authkey=None,\n              exposed=None, incref=True, manager_owned=False):\n    '''\n    Return an auto-proxy for `token`\n    '''\n    _Client = listener_client[serializer][1]\n\n    if exposed is None:\n        conn = _Client(token.address, authkey=authkey)\n        try:\n            exposed = dispatch(conn, None, 'get_methods', (token,))\n        finally:\n            conn.close()\n\n    if authkey is None and manager is not None:\n        authkey = manager._authkey\n    if authkey is None:\n        authkey = process.current_process().authkey\n\n    ProxyType = MakeProxyType('AutoProxy[%s]' % token.typeid, exposed)\n    proxy = ProxyType(token, serializer, manager=manager, authkey=authkey,\n                      incref=incref, manager_owned=manager_owned)\n    proxy._isauto = True\n    return proxy",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Namespace": {
        "API_name": "multiprocessing.managers.Namespace",
        "loc_name": "multiprocessing.managers.Namespace",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 991,
        "namespace": "Namespace",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Namespace.__init__": {
        "API_name": "multiprocessing.managers.Namespace.__init__",
        "loc_name": "multiprocessing.managers.Namespace.__init__",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 992,
        "namespace": "Namespace",
        "body": "    def __init__(self, /, **kwds):\n        self.__dict__.update(kwds)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Namespace.__repr__": {
        "API_name": "multiprocessing.managers.Namespace.__repr__",
        "loc_name": "multiprocessing.managers.Namespace.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 994,
        "namespace": "Namespace",
        "body": "    def __repr__(self):\n        items = list(self.__dict__.items())\n        temp = []\n        for name, value in items:\n            if not name.startswith('_'):\n                temp.append('%s=%r' % (name, value))\n        temp.sort()\n        return '%s(%s)' % (self.__class__.__name__, ', '.join(temp))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Value": {
        "API_name": "multiprocessing.managers.Value",
        "loc_name": "multiprocessing.managers.Value",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1003,
        "namespace": "Value",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Value.__init__": {
        "API_name": "multiprocessing.managers.Value.__init__",
        "loc_name": "multiprocessing.managers.Value.__init__",
        "args": "self;typecode;value;lock",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1004,
        "namespace": "Value",
        "body": "    def __init__(self, typecode, value, lock=True):\n        self._typecode = typecode\n        self._value = value",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Value.get": {
        "API_name": "multiprocessing.managers.Value.get",
        "loc_name": "multiprocessing.managers.Value.get",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1007,
        "namespace": "Value",
        "body": "    def get(self):\n        return self._value",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Value.set": {
        "API_name": "multiprocessing.managers.Value.set",
        "loc_name": "multiprocessing.managers.Value.set",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1009,
        "namespace": "Value",
        "body": "    def set(self, value):\n        self._value = value",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Value.__repr__": {
        "API_name": "multiprocessing.managers.Value.__repr__",
        "loc_name": "multiprocessing.managers.Value.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1011,
        "namespace": "Value",
        "body": "    def __repr__(self):\n        return '%s(%r, %r)'%(type(self).__name__, self._typecode, self._value)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.Array": {
        "API_name": "multiprocessing.managers.Array",
        "loc_name": "multiprocessing.managers.Array",
        "args": "typecode;sequence;lock",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1015,
        "namespace": "*",
        "body": "def Array(typecode, sequence, lock=True):\n    return array.array(typecode, sequence)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.IteratorProxy.__iter__": {
        "API_name": "multiprocessing.managers.IteratorProxy.__iter__",
        "loc_name": "multiprocessing.managers.IteratorProxy.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1024,
        "namespace": "IteratorProxy",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.IteratorProxy.__next__": {
        "API_name": "multiprocessing.managers.IteratorProxy.__next__",
        "loc_name": "multiprocessing.managers.IteratorProxy.__next__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1026,
        "namespace": "IteratorProxy",
        "body": "    def __next__(self, *args):\n        return self._callmethod('__next__', args)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.IteratorProxy.send": {
        "API_name": "multiprocessing.managers.IteratorProxy.send",
        "loc_name": "multiprocessing.managers.IteratorProxy.send",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1028,
        "namespace": "IteratorProxy",
        "body": "    def send(self, *args):\n        return self._callmethod('send', args)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.IteratorProxy.throw": {
        "API_name": "multiprocessing.managers.IteratorProxy.throw",
        "loc_name": "multiprocessing.managers.IteratorProxy.throw",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1030,
        "namespace": "IteratorProxy",
        "body": "    def throw(self, *args):\n        return self._callmethod('throw', args)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.IteratorProxy.close": {
        "API_name": "multiprocessing.managers.IteratorProxy.close",
        "loc_name": "multiprocessing.managers.IteratorProxy.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1032,
        "namespace": "IteratorProxy",
        "body": "    def close(self, *args):\n        return self._callmethod('close', args)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.IteratorProxy": {
        "API_name": "multiprocessing.managers.IteratorProxy",
        "loc_name": "multiprocessing.managers.IteratorProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1022,
        "namespace": "IteratorProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.AcquirerProxy.acquire": {
        "API_name": "multiprocessing.managers.AcquirerProxy.acquire",
        "loc_name": "multiprocessing.managers.AcquirerProxy.acquire",
        "args": "self;blocking;timeout",
        "args_default": 2,
        "filepath": "multiprocessing.managers",
        "lineno": 1038,
        "namespace": "AcquirerProxy",
        "body": "    def acquire(self, blocking=True, timeout=None):\n        args = (blocking,) if timeout is None else (blocking, timeout)\n        return self._callmethod('acquire', args)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.AcquirerProxy.release": {
        "API_name": "multiprocessing.managers.AcquirerProxy.release",
        "loc_name": "multiprocessing.managers.AcquirerProxy.release",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1041,
        "namespace": "AcquirerProxy",
        "body": "    def release(self):\n        return self._callmethod('release')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.AcquirerProxy.__enter__": {
        "API_name": "multiprocessing.managers.AcquirerProxy.__enter__",
        "loc_name": "multiprocessing.managers.AcquirerProxy.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1043,
        "namespace": "AcquirerProxy",
        "body": "    def __enter__(self):\n        return self._callmethod('acquire')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.AcquirerProxy.__exit__": {
        "API_name": "multiprocessing.managers.AcquirerProxy.__exit__",
        "loc_name": "multiprocessing.managers.AcquirerProxy.__exit__",
        "args": "self;exc_type;exc_val;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1045,
        "namespace": "AcquirerProxy",
        "body": "    def __exit__(self, exc_type, exc_val, exc_tb):\n        return self._callmethod('release')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.AcquirerProxy": {
        "API_name": "multiprocessing.managers.AcquirerProxy",
        "loc_name": "multiprocessing.managers.AcquirerProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1036,
        "namespace": "AcquirerProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ConditionProxy.wait": {
        "API_name": "multiprocessing.managers.ConditionProxy.wait",
        "loc_name": "multiprocessing.managers.ConditionProxy.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1051,
        "namespace": "ConditionProxy",
        "body": "    def wait(self, timeout=None):\n        return self._callmethod('wait', (timeout,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ConditionProxy.notify": {
        "API_name": "multiprocessing.managers.ConditionProxy.notify",
        "loc_name": "multiprocessing.managers.ConditionProxy.notify",
        "args": "self;n",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1053,
        "namespace": "ConditionProxy",
        "body": "    def notify(self, n=1):\n        return self._callmethod('notify', (n,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ConditionProxy.notify_all": {
        "API_name": "multiprocessing.managers.ConditionProxy.notify_all",
        "loc_name": "multiprocessing.managers.ConditionProxy.notify_all",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1055,
        "namespace": "ConditionProxy",
        "body": "    def notify_all(self):\n        return self._callmethod('notify_all')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ConditionProxy.wait_for": {
        "API_name": "multiprocessing.managers.ConditionProxy.wait_for",
        "loc_name": "multiprocessing.managers.ConditionProxy.wait_for",
        "args": "self;predicate;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1057,
        "namespace": "ConditionProxy",
        "body": "    def wait_for(self, predicate, timeout=None):\n        result = predicate()\n        if result:\n            return result\n        if timeout is not None:\n            endtime = time.monotonic() + timeout\n        else:\n            endtime = None\n            waittime = None\n        while not result:\n            if endtime is not None:\n                waittime = endtime - time.monotonic()\n                if waittime <= 0:\n                    break\n            self.wait(waittime)\n            result = predicate()\n        return result",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ConditionProxy": {
        "API_name": "multiprocessing.managers.ConditionProxy",
        "loc_name": "multiprocessing.managers.ConditionProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1049,
        "namespace": "ConditionProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.EventProxy.is_set": {
        "API_name": "multiprocessing.managers.EventProxy.is_set",
        "loc_name": "multiprocessing.managers.EventProxy.is_set",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1078,
        "namespace": "EventProxy",
        "body": "    def is_set(self):\n        return self._callmethod('is_set')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.EventProxy.set": {
        "API_name": "multiprocessing.managers.EventProxy.set",
        "loc_name": "multiprocessing.managers.EventProxy.set",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1080,
        "namespace": "EventProxy",
        "body": "    def set(self):\n        return self._callmethod('set')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.EventProxy.clear": {
        "API_name": "multiprocessing.managers.EventProxy.clear",
        "loc_name": "multiprocessing.managers.EventProxy.clear",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1082,
        "namespace": "EventProxy",
        "body": "    def clear(self):\n        return self._callmethod('clear')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.EventProxy.wait": {
        "API_name": "multiprocessing.managers.EventProxy.wait",
        "loc_name": "multiprocessing.managers.EventProxy.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1084,
        "namespace": "EventProxy",
        "body": "    def wait(self, timeout=None):\n        return self._callmethod('wait', (timeout,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.EventProxy": {
        "API_name": "multiprocessing.managers.EventProxy",
        "loc_name": "multiprocessing.managers.EventProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1076,
        "namespace": "EventProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy.wait": {
        "API_name": "multiprocessing.managers.BarrierProxy.wait",
        "loc_name": "multiprocessing.managers.BarrierProxy.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1090,
        "namespace": "BarrierProxy",
        "body": "    def wait(self, timeout=None):\n        return self._callmethod('wait', (timeout,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy.abort": {
        "API_name": "multiprocessing.managers.BarrierProxy.abort",
        "loc_name": "multiprocessing.managers.BarrierProxy.abort",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1092,
        "namespace": "BarrierProxy",
        "body": "    def abort(self):\n        return self._callmethod('abort')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy.reset": {
        "API_name": "multiprocessing.managers.BarrierProxy.reset",
        "loc_name": "multiprocessing.managers.BarrierProxy.reset",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1094,
        "namespace": "BarrierProxy",
        "body": "    def reset(self):\n        return self._callmethod('reset')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy.parties": {
        "API_name": "multiprocessing.managers.BarrierProxy.parties",
        "loc_name": "multiprocessing.managers.BarrierProxy.parties",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1097,
        "namespace": "BarrierProxy",
        "body": "    def parties(self):\n        return self._callmethod('__getattribute__', ('parties',))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy.n_waiting": {
        "API_name": "multiprocessing.managers.BarrierProxy.n_waiting",
        "loc_name": "multiprocessing.managers.BarrierProxy.n_waiting",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1100,
        "namespace": "BarrierProxy",
        "body": "    def n_waiting(self):\n        return self._callmethod('__getattribute__', ('n_waiting',))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy.broken": {
        "API_name": "multiprocessing.managers.BarrierProxy.broken",
        "loc_name": "multiprocessing.managers.BarrierProxy.broken",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1103,
        "namespace": "BarrierProxy",
        "body": "    def broken(self):\n        return self._callmethod('__getattribute__', ('broken',))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.BarrierProxy": {
        "API_name": "multiprocessing.managers.BarrierProxy",
        "loc_name": "multiprocessing.managers.BarrierProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1088,
        "namespace": "BarrierProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.NamespaceProxy.__getattr__": {
        "API_name": "multiprocessing.managers.NamespaceProxy.__getattr__",
        "loc_name": "multiprocessing.managers.NamespaceProxy.__getattr__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1109,
        "namespace": "NamespaceProxy",
        "body": "    def __getattr__(self, key):\n        if key[0] == '_':\n            return object.__getattribute__(self, key)\n        callmethod = object.__getattribute__(self, '_callmethod')\n        return callmethod('__getattribute__', (key,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.NamespaceProxy.__setattr__": {
        "API_name": "multiprocessing.managers.NamespaceProxy.__setattr__",
        "loc_name": "multiprocessing.managers.NamespaceProxy.__setattr__",
        "args": "self;key;value",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1114,
        "namespace": "NamespaceProxy",
        "body": "    def __setattr__(self, key, value):\n        if key[0] == '_':\n            return object.__setattr__(self, key, value)\n        callmethod = object.__getattribute__(self, '_callmethod')\n        return callmethod('__setattr__', (key, value))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.NamespaceProxy.__delattr__": {
        "API_name": "multiprocessing.managers.NamespaceProxy.__delattr__",
        "loc_name": "multiprocessing.managers.NamespaceProxy.__delattr__",
        "args": "self;key",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1119,
        "namespace": "NamespaceProxy",
        "body": "    def __delattr__(self, key):\n        if key[0] == '_':\n            return object.__delattr__(self, key)\n        callmethod = object.__getattribute__(self, '_callmethod')\n        return callmethod('__delattr__', (key,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.NamespaceProxy": {
        "API_name": "multiprocessing.managers.NamespaceProxy",
        "loc_name": "multiprocessing.managers.NamespaceProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1107,
        "namespace": "NamespaceProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ValueProxy.get": {
        "API_name": "multiprocessing.managers.ValueProxy.get",
        "loc_name": "multiprocessing.managers.ValueProxy.get",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1128,
        "namespace": "ValueProxy",
        "body": "    def get(self):\n        return self._callmethod('get')",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ValueProxy.set": {
        "API_name": "multiprocessing.managers.ValueProxy.set",
        "loc_name": "multiprocessing.managers.ValueProxy.set",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1130,
        "namespace": "ValueProxy",
        "body": "    def set(self, value):\n        return self._callmethod('set', (value,))",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ValueProxy": {
        "API_name": "multiprocessing.managers.ValueProxy",
        "loc_name": "multiprocessing.managers.ValueProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1126,
        "namespace": "ValueProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ListProxy.__iadd__": {
        "API_name": "multiprocessing.managers.ListProxy.__iadd__",
        "loc_name": "multiprocessing.managers.ListProxy.__iadd__",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1144,
        "namespace": "ListProxy",
        "body": "    def __iadd__(self, value):\n        self._callmethod('extend', (value,))\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ListProxy.__imul__": {
        "API_name": "multiprocessing.managers.ListProxy.__imul__",
        "loc_name": "multiprocessing.managers.ListProxy.__imul__",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1147,
        "namespace": "ListProxy",
        "body": "    def __imul__(self, value):\n        self._callmethod('__imul__', (value,))\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.ListProxy": {
        "API_name": "multiprocessing.managers.ListProxy",
        "loc_name": "multiprocessing.managers.ListProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1143,
        "namespace": "ListProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.PoolProxy.__enter__": {
        "API_name": "multiprocessing.managers.PoolProxy.__enter__",
        "loc_name": "multiprocessing.managers.PoolProxy.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1179,
        "namespace": "PoolProxy",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.PoolProxy.__exit__": {
        "API_name": "multiprocessing.managers.PoolProxy.__exit__",
        "loc_name": "multiprocessing.managers.PoolProxy.__exit__",
        "args": "self;exc_type;exc_val;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1181,
        "namespace": "PoolProxy",
        "body": "    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.terminate()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.PoolProxy": {
        "API_name": "multiprocessing.managers.PoolProxy",
        "loc_name": "multiprocessing.managers.PoolProxy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1178,
        "namespace": "PoolProxy",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SyncManager": {
        "API_name": "multiprocessing.managers.SyncManager",
        "loc_name": "multiprocessing.managers.SyncManager",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1188,
        "namespace": "SyncManager",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1225,
        "namespace": "_SharedMemoryTracker",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.__init__": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.__init__",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.__init__",
        "args": "self;name;segment_names",
        "args_default": 1,
        "filepath": "multiprocessing.managers",
        "lineno": 1228,
        "namespace": "_SharedMemoryTracker",
        "body": "        def __init__(self, name, segment_names=[]):\n            self.shared_memory_context_name = name\n            self.segment_names = segment_names",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.register_segment": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.register_segment",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.register_segment",
        "args": "self;segment_name",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1232,
        "namespace": "_SharedMemoryTracker",
        "body": "        def register_segment(self, segment_name):\n            \"Adds the supplied shared memory block name to tracker.\"\n            util.debug(f\"Register segment {segment_name!r} in pid {getpid()}\")\n            self.segment_names.append(segment_name)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.destroy_segment": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.destroy_segment",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.destroy_segment",
        "args": "self;segment_name",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1237,
        "namespace": "_SharedMemoryTracker",
        "body": "        def destroy_segment(self, segment_name):\n            \"\"\"Calls unlink() on the shared memory block with the supplied name\n            and removes it from the list of blocks being tracked.\"\"\"\n            util.debug(f\"Destroy segment {segment_name!r} in pid {getpid()}\")\n            self.segment_names.remove(segment_name)\n            segment = shared_memory.SharedMemory(segment_name)\n            segment.close()\n            segment.unlink()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.unlink": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.unlink",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.unlink",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1246,
        "namespace": "_SharedMemoryTracker",
        "body": "        def unlink(self):\n            \"Calls destroy_segment() on all tracked shared memory blocks.\"\n            for segment_name in self.segment_names[:]:\n                self.destroy_segment(segment_name)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.__del__": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.__del__",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.__del__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1251,
        "namespace": "_SharedMemoryTracker",
        "body": "        def __del__(self):\n            util.debug(f\"Call {self.__class__.__name__}.__del__ in {getpid()}\")\n            self.unlink()",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.__getstate__": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.__getstate__",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1255,
        "namespace": "_SharedMemoryTracker",
        "body": "        def __getstate__(self):\n            return (self.shared_memory_context_name, self.segment_names)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers._SharedMemoryTracker.__setstate__": {
        "API_name": "multiprocessing.managers._SharedMemoryTracker.__setstate__",
        "loc_name": "multiprocessing.managers._SharedMemoryTracker.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1258,
        "namespace": "_SharedMemoryTracker",
        "body": "        def __setstate__(self, state):\n            self.__init__(*state)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer": {
        "API_name": "multiprocessing.managers.SharedMemoryServer",
        "loc_name": "multiprocessing.managers.SharedMemoryServer",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1262,
        "namespace": "SharedMemoryServer",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer.__init__": {
        "API_name": "multiprocessing.managers.SharedMemoryServer.__init__",
        "loc_name": "multiprocessing.managers.SharedMemoryServer.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1267,
        "namespace": "SharedMemoryServer",
        "body": "        def __init__(self, *args, **kwargs):\n            Server.__init__(self, *args, **kwargs)\n            address = self.address\n            # The address of Linux abstract namespaces can be bytes\n            if isinstance(address, bytes):\n                address = os.fsdecode(address)\n            self.shared_memory_context = \\\n                _SharedMemoryTracker(f\"shm_{address}_{getpid()}\")\n            util.debug(f\"SharedMemoryServer started by pid {getpid()}\")",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer.create": {
        "API_name": "multiprocessing.managers.SharedMemoryServer.create",
        "loc_name": "multiprocessing.managers.SharedMemoryServer.create",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1277,
        "namespace": "SharedMemoryServer",
        "body": "        def create(self, c, typeid, /, *args, **kwargs):\n            \"\"\"Create a new distributed-shared object (not backed by a shared\n            memory block) and return its id to be used in a Proxy Object.\"\"\"\n            # Unless set up as a shared proxy, don't make shared_memory_context\n            # a standard part of kwargs.  This makes things easier for supplying\n            # simple functions.\n            if hasattr(self.registry[typeid][-1], \"_shared_memory_proxy\"):\n                kwargs['shared_memory_context'] = self.shared_memory_context\n            return Server.create(self, c, typeid, *args, **kwargs)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer.shutdown": {
        "API_name": "multiprocessing.managers.SharedMemoryServer.shutdown",
        "loc_name": "multiprocessing.managers.SharedMemoryServer.shutdown",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1287,
        "namespace": "SharedMemoryServer",
        "body": "        def shutdown(self, c):\n            \"Call unlink() on all tracked shared memory, terminate the Server.\"\n            self.shared_memory_context.unlink()\n            return Server.shutdown(self, c)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer.track_segment": {
        "API_name": "multiprocessing.managers.SharedMemoryServer.track_segment",
        "loc_name": "multiprocessing.managers.SharedMemoryServer.track_segment",
        "args": "self;c;segment_name",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1292,
        "namespace": "SharedMemoryServer",
        "body": "        def track_segment(self, c, segment_name):\n            \"Adds the supplied shared memory block name to Server's tracker.\"\n            self.shared_memory_context.register_segment(segment_name)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer.release_segment": {
        "API_name": "multiprocessing.managers.SharedMemoryServer.release_segment",
        "loc_name": "multiprocessing.managers.SharedMemoryServer.release_segment",
        "args": "self;c;segment_name",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1296,
        "namespace": "SharedMemoryServer",
        "body": "        def release_segment(self, c, segment_name):\n            \"\"\"Calls unlink() on the shared memory block with the supplied name\n            and removes it from the tracker instance inside the Server.\"\"\"\n            self.shared_memory_context.destroy_segment(segment_name)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryServer.list_segments": {
        "API_name": "multiprocessing.managers.SharedMemoryServer.list_segments",
        "loc_name": "multiprocessing.managers.SharedMemoryServer.list_segments",
        "args": "self;c",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1301,
        "namespace": "SharedMemoryServer",
        "body": "        def list_segments(self, c):\n            \"\"\"Returns a list of names of shared memory blocks that the Server\n            is currently tracking.\"\"\"\n            return self.shared_memory_context.segment_names",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryManager": {
        "API_name": "multiprocessing.managers.SharedMemoryManager",
        "loc_name": "multiprocessing.managers.SharedMemoryManager",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.managers",
        "lineno": 1307,
        "namespace": "SharedMemoryManager",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryManager.__init__": {
        "API_name": "multiprocessing.managers.SharedMemoryManager.__init__",
        "loc_name": "multiprocessing.managers.SharedMemoryManager.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1319,
        "namespace": "SharedMemoryManager",
        "body": "        def __init__(self, *args, **kwargs):\n            if os.name == \"posix\":\n                # bpo-36867: Ensure the resource_tracker is running before\n                # launching the manager process, so that concurrent\n                # shared_memory manipulation both in the manager and in the\n                # current process does not create two resource_tracker\n                # processes.\n                from . import resource_tracker\n                resource_tracker.ensure_running()\n            BaseManager.__init__(self, *args, **kwargs)\n            util.debug(f\"{self.__class__.__name__} created by pid {getpid()}\")",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryManager.__del__": {
        "API_name": "multiprocessing.managers.SharedMemoryManager.__del__",
        "loc_name": "multiprocessing.managers.SharedMemoryManager.__del__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1331,
        "namespace": "SharedMemoryManager",
        "body": "        def __del__(self):\n            util.debug(f\"{self.__class__.__name__}.__del__ by pid {getpid()}\")\n            pass",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryManager.get_server": {
        "API_name": "multiprocessing.managers.SharedMemoryManager.get_server",
        "loc_name": "multiprocessing.managers.SharedMemoryManager.get_server",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1335,
        "namespace": "SharedMemoryManager",
        "body": "        def get_server(self):\n            'Better than monkeypatching for now; merge into Server ultimately'\n            if self._state.value != State.INITIAL:\n                if self._state.value == State.STARTED:\n                    raise ProcessError(\"Already started SharedMemoryServer\")\n                elif self._state.value == State.SHUTDOWN:\n                    raise ProcessError(\"SharedMemoryManager has shut down\")\n                else:\n                    raise ProcessError(\n                        \"Unknown state {!r}\".format(self._state.value))\n            return self._Server(self._registry, self._address,\n                                self._authkey, self._serializer)",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryManager.SharedMemory": {
        "API_name": "multiprocessing.managers.SharedMemoryManager.SharedMemory",
        "loc_name": "multiprocessing.managers.SharedMemoryManager.SharedMemory",
        "args": "self;size",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1348,
        "namespace": "SharedMemoryManager",
        "body": "        def SharedMemory(self, size):\n            \"\"\"Returns a new SharedMemory instance with the specified size in\n            bytes, to be tracked by the manager.\"\"\"\n            with self._Client(self._address, authkey=self._authkey) as conn:\n                sms = shared_memory.SharedMemory(None, create=True, size=size)\n                try:\n                    dispatch(conn, None, 'track_segment', (sms.name,))\n                except BaseException as e:\n                    sms.unlink()\n                    raise e\n            return sms",
        "name_type": "stdlib"
    },
    "multiprocessing.managers.SharedMemoryManager.ShareableList": {
        "API_name": "multiprocessing.managers.SharedMemoryManager.ShareableList",
        "loc_name": "multiprocessing.managers.SharedMemoryManager.ShareableList",
        "args": "self;sequence",
        "args_default": 0,
        "filepath": "multiprocessing.managers",
        "lineno": 1360,
        "namespace": "SharedMemoryManager",
        "body": "        def ShareableList(self, sequence):\n            \"\"\"Returns a new ShareableList instance populated with the values\n            from the input sequence, to be tracked by the manager.\"\"\"\n            with self._Client(self._address, authkey=self._authkey) as conn:\n                sl = shared_memory.ShareableList(sequence)\n                try:\n                    dispatch(conn, None, 'track_segment', (sl.shm.name,))\n                except BaseException as e:\n                    sl.shm.unlink()\n                    raise e\n            return sl",
        "name_type": "stdlib"
    },
    "multiprocessing.pool": {
        "API_name": "multiprocessing.pool",
        "loc_name": "multiprocessing.pool",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['Pool', 'ThreadPool']\nINIT = \"INIT\"\nRUN = \"RUN\"\nCLOSE = \"CLOSE\"\nTERMINATE = \"TERMINATE\"\njob_counter = itertools.count()\nAsyncResult = ApplyResult       # create alias -- see #17805",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.mapstar": {
        "API_name": "multiprocessing.pool.mapstar",
        "loc_name": "multiprocessing.pool.mapstar",
        "args": "args",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 47,
        "namespace": "*",
        "body": "def mapstar(args):\n    return list(map(*args))",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.starmapstar": {
        "API_name": "multiprocessing.pool.starmapstar",
        "loc_name": "multiprocessing.pool.starmapstar",
        "args": "args",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 50,
        "namespace": "*",
        "body": "def starmapstar(args):\n    return list(itertools.starmap(args[0], args[1]))",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.RemoteTraceback": {
        "API_name": "multiprocessing.pool.RemoteTraceback",
        "loc_name": "multiprocessing.pool.RemoteTraceback",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 57,
        "namespace": "RemoteTraceback",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.RemoteTraceback.__init__": {
        "API_name": "multiprocessing.pool.RemoteTraceback.__init__",
        "loc_name": "multiprocessing.pool.RemoteTraceback.__init__",
        "args": "self;tb",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 58,
        "namespace": "RemoteTraceback",
        "body": "    def __init__(self, tb):\n        self.tb = tb",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.RemoteTraceback.__str__": {
        "API_name": "multiprocessing.pool.RemoteTraceback.__str__",
        "loc_name": "multiprocessing.pool.RemoteTraceback.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 60,
        "namespace": "RemoteTraceback",
        "body": "    def __str__(self):\n        return self.tb",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ExceptionWithTraceback": {
        "API_name": "multiprocessing.pool.ExceptionWithTraceback",
        "loc_name": "multiprocessing.pool.ExceptionWithTraceback",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 63,
        "namespace": "ExceptionWithTraceback",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ExceptionWithTraceback.__init__": {
        "API_name": "multiprocessing.pool.ExceptionWithTraceback.__init__",
        "loc_name": "multiprocessing.pool.ExceptionWithTraceback.__init__",
        "args": "self;exc;tb",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 64,
        "namespace": "ExceptionWithTraceback",
        "body": "    def __init__(self, exc, tb):\n        tb = traceback.format_exception(type(exc), exc, tb)\n        tb = ''.join(tb)\n        self.exc = exc\n        self.tb = '\\n\"\"\"\\n%s\"\"\"' % tb",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ExceptionWithTraceback.__reduce__": {
        "API_name": "multiprocessing.pool.ExceptionWithTraceback.__reduce__",
        "loc_name": "multiprocessing.pool.ExceptionWithTraceback.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 69,
        "namespace": "ExceptionWithTraceback",
        "body": "    def __reduce__(self):\n        return rebuild_exc, (self.exc, self.tb)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.rebuild_exc": {
        "API_name": "multiprocessing.pool.rebuild_exc",
        "loc_name": "multiprocessing.pool.rebuild_exc",
        "args": "exc;tb",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 72,
        "namespace": "*",
        "body": "def rebuild_exc(exc, tb):\n    exc.__cause__ = RemoteTraceback(tb)\n    return exc",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MaybeEncodingError": {
        "API_name": "multiprocessing.pool.MaybeEncodingError",
        "loc_name": "multiprocessing.pool.MaybeEncodingError",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 80,
        "namespace": "MaybeEncodingError",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MaybeEncodingError.__init__": {
        "API_name": "multiprocessing.pool.MaybeEncodingError.__init__",
        "loc_name": "multiprocessing.pool.MaybeEncodingError.__init__",
        "args": "self;exc;value",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 84,
        "namespace": "MaybeEncodingError",
        "body": "    def __init__(self, exc, value):\n        self.exc = repr(exc)\n        self.value = repr(value)\n        super(MaybeEncodingError, self).__init__(self.exc, self.value)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MaybeEncodingError.__str__": {
        "API_name": "multiprocessing.pool.MaybeEncodingError.__str__",
        "loc_name": "multiprocessing.pool.MaybeEncodingError.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 89,
        "namespace": "MaybeEncodingError",
        "body": "    def __str__(self):\n        return \"Error sending result: '%s'. Reason: '%s'\" % (self.value,\n                                                             self.exc)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MaybeEncodingError.__repr__": {
        "API_name": "multiprocessing.pool.MaybeEncodingError.__repr__",
        "loc_name": "multiprocessing.pool.MaybeEncodingError.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 93,
        "namespace": "MaybeEncodingError",
        "body": "    def __repr__(self):\n        return \"<%s: %s>\" % (self.__class__.__name__, self)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.worker": {
        "API_name": "multiprocessing.pool.worker",
        "loc_name": "multiprocessing.pool.worker",
        "args": "inqueue;outqueue;initializer;initargs;maxtasks;wrap_exception",
        "args_default": 4,
        "filepath": "multiprocessing.pool",
        "lineno": 97,
        "namespace": "*",
        "body": "def worker(inqueue, outqueue, initializer=None, initargs=(), maxtasks=None,\n           wrap_exception=False):\n    if (maxtasks is not None) and not (isinstance(maxtasks, int)\n                                       and maxtasks >= 1):\n        raise AssertionError(\"Maxtasks {!r} is not valid\".format(maxtasks))\n    put = outqueue.put\n    get = inqueue.get\n    if hasattr(inqueue, '_writer'):\n        inqueue._writer.close()\n        outqueue._reader.close()\n\n    if initializer is not None:\n        initializer(*initargs)\n\n    completed = 0\n    while maxtasks is None or (maxtasks and completed < maxtasks):\n        try:\n            task = get()\n        except (EOFError, OSError):\n            util.debug('worker got EOFError or OSError -- exiting')\n            break\n\n        if task is None:\n            util.debug('worker got sentinel -- exiting')\n            break\n\n        job, i, func, args, kwds = task\n        try:\n            result = (True, func(*args, **kwds))\n        except Exception as e:\n            if wrap_exception and func is not _helper_reraises_exception:\n                e = ExceptionWithTraceback(e, e.__traceback__)\n            result = (False, e)\n        try:\n            put((job, i, result))\n        except Exception as e:\n            wrapped = MaybeEncodingError(e, result[1])\n            util.debug(\"Possible encoding error while sending result: %s\" % (\n                wrapped))\n            put((job, i, (False, wrapped)))\n\n        task = job = result = func = args = kwds = None\n        completed += 1\n    util.debug('worker exiting after %d tasks' % completed)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool._helper_reraises_exception": {
        "API_name": "multiprocessing.pool._helper_reraises_exception",
        "loc_name": "multiprocessing.pool._helper_reraises_exception",
        "args": "ex",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 142,
        "namespace": "*",
        "body": "def _helper_reraises_exception(ex):\n    'Pickle-able helper function for use by _guarded_task_generation.'\n    raise ex",
        "name_type": "stdlib"
    },
    "multiprocessing.pool._PoolCache": {
        "API_name": "multiprocessing.pool._PoolCache",
        "loc_name": "multiprocessing.pool._PoolCache",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 150,
        "namespace": "_PoolCache",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool._PoolCache.__init__": {
        "API_name": "multiprocessing.pool._PoolCache.__init__",
        "loc_name": "multiprocessing.pool._PoolCache.__init__",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 157,
        "namespace": "_PoolCache",
        "body": "    def __init__(self, /, *args, notifier=None, **kwds):\n        self.notifier = notifier\n        super().__init__(*args, **kwds)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool._PoolCache.__delitem__": {
        "API_name": "multiprocessing.pool._PoolCache.__delitem__",
        "loc_name": "multiprocessing.pool._PoolCache.__delitem__",
        "args": "self;item",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 161,
        "namespace": "_PoolCache",
        "body": "    def __delitem__(self, item):\n        super().__delitem__(item)\n\n        # Notify that the cache is empty. This is important because the\n        # pool keeps maintaining workers until the cache gets drained. This\n        # eliminates a race condition in which a task is finished after the\n        # the pool's _handle_workers method has enter another iteration of the\n        # loop. In this situation, the only event that can wake up the pool\n        # is the cache to be emptied (no more tasks available).\n        if not self:\n            self.notifier.put(None)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool": {
        "API_name": "multiprocessing.pool.Pool",
        "loc_name": "multiprocessing.pool.Pool",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 173,
        "namespace": "Pool",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.Process": {
        "API_name": "multiprocessing.pool.Pool.Process",
        "loc_name": "multiprocessing.pool.Pool.Process",
        "args": "ctx",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 180,
        "namespace": "Pool",
        "body": "    def Process(ctx, *args, **kwds):\n        return ctx.Process(*args, **kwds)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.__init__": {
        "API_name": "multiprocessing.pool.Pool.__init__",
        "loc_name": "multiprocessing.pool.Pool.__init__",
        "args": "self;processes;initializer;initargs;maxtasksperchild;context",
        "args_default": 5,
        "filepath": "multiprocessing.pool",
        "lineno": 183,
        "namespace": "Pool",
        "body": "    def __init__(self, processes=None, initializer=None, initargs=(),\n                 maxtasksperchild=None, context=None):\n        # Attributes initialized early to make sure that they exist in\n        # __del__() if __init__() raises an exception\n        self._pool = []\n        self._state = INIT\n\n        self._ctx = context or get_context()\n        self._setup_queues()\n        self._taskqueue = queue.SimpleQueue()\n        # The _change_notifier queue exist to wake up self._handle_workers()\n        # when the cache (self._cache) is empty or when there is a change in\n        # the _state variable of the thread that runs _handle_workers.\n        self._change_notifier = self._ctx.SimpleQueue()\n        self._cache = _PoolCache(notifier=self._change_notifier)\n        self._maxtasksperchild = maxtasksperchild\n        self._initializer = initializer\n        self._initargs = initargs\n\n        if processes is None:\n            processes = os.cpu_count() or 1\n        if processes < 1:\n            raise ValueError(\"Number of processes must be at least 1\")\n\n        if initializer is not None and not callable(initializer):\n            raise TypeError('initializer must be a callable')\n\n        self._processes = processes\n        try:\n            self._repopulate_pool()\n        except Exception:\n            for p in self._pool:\n                if p.exitcode is None:\n                    p.terminate()\n            for p in self._pool:\n                p.join()\n            raise\n\n        sentinels = self._get_sentinels()\n\n        self._worker_handler = threading.Thread(\n            target=Pool._handle_workers,\n            args=(self._cache, self._taskqueue, self._ctx, self.Process,\n                  self._processes, self._pool, self._inqueue, self._outqueue,\n                  self._initializer, self._initargs, self._maxtasksperchild,\n                  self._wrap_exception, sentinels, self._change_notifier)\n            )\n        self._worker_handler.daemon = True\n        self._worker_handler._state = RUN\n        self._worker_handler.start()\n\n\n        self._task_handler = threading.Thread(\n            target=Pool._handle_tasks,\n            args=(self._taskqueue, self._quick_put, self._outqueue,\n                  self._pool, self._cache)\n            )\n        self._task_handler.daemon = True\n        self._task_handler._state = RUN\n        self._task_handler.start()\n\n        self._result_handler = threading.Thread(\n            target=Pool._handle_results,\n            args=(self._outqueue, self._quick_get, self._cache)\n            )\n        self._result_handler.daemon = True\n        self._result_handler._state = RUN\n        self._result_handler.start()\n\n        self._terminate = util.Finalize(\n            self, self._terminate_pool,\n            args=(self._taskqueue, self._inqueue, self._outqueue, self._pool,\n                  self._change_notifier, self._worker_handler, self._task_handler,\n                  self._result_handler, self._cache),\n            exitpriority=15\n            )\n        self._state = RUN",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.__del__": {
        "API_name": "multiprocessing.pool.Pool.__del__",
        "loc_name": "multiprocessing.pool.Pool.__del__",
        "args": "self;_warn;RUN",
        "args_default": 2,
        "filepath": "multiprocessing.pool",
        "lineno": 263,
        "namespace": "Pool",
        "body": "    def __del__(self, _warn=warnings.warn, RUN=RUN):\n        if self._state == RUN:\n            _warn(f\"unclosed running multiprocessing pool {self!r}\",\n                  ResourceWarning, source=self)\n            if getattr(self, '_change_notifier', None) is not None:\n                self._change_notifier.put(None)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.__repr__": {
        "API_name": "multiprocessing.pool.Pool.__repr__",
        "loc_name": "multiprocessing.pool.Pool.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 270,
        "namespace": "Pool",
        "body": "    def __repr__(self):\n        cls = self.__class__\n        return (f'<{cls.__module__}.{cls.__qualname__} '\n                f'state={self._state} '\n                f'pool_size={len(self._pool)}>')",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._get_sentinels": {
        "API_name": "multiprocessing.pool.Pool._get_sentinels",
        "loc_name": "multiprocessing.pool.Pool._get_sentinels",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 276,
        "namespace": "Pool",
        "body": "    def _get_sentinels(self):\n        task_queue_sentinels = [self._outqueue._reader]\n        self_notifier_sentinels = [self._change_notifier._reader]\n        return [*task_queue_sentinels, *self_notifier_sentinels]",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._get_worker_sentinels": {
        "API_name": "multiprocessing.pool.Pool._get_worker_sentinels",
        "loc_name": "multiprocessing.pool.Pool._get_worker_sentinels",
        "args": "workers",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 282,
        "namespace": "Pool",
        "body": "    def _get_worker_sentinels(workers):\n        return [worker.sentinel for worker in\n                workers if hasattr(worker, \"sentinel\")]",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._join_exited_workers": {
        "API_name": "multiprocessing.pool.Pool._join_exited_workers",
        "loc_name": "multiprocessing.pool.Pool._join_exited_workers",
        "args": "pool",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 287,
        "namespace": "Pool",
        "body": "    def _join_exited_workers(pool):\n        \"\"\"Cleanup after any worker processes which have exited due to reaching\n        their specified lifetime.  Returns True if any workers were cleaned up.\n        \"\"\"\n        cleaned = False\n        for i in reversed(range(len(pool))):\n            worker = pool[i]\n            if worker.exitcode is not None:\n                # worker exited\n                util.debug('cleaning up worker %d' % i)\n                worker.join()\n                cleaned = True\n                del pool[i]\n        return cleaned",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._repopulate_pool": {
        "API_name": "multiprocessing.pool.Pool._repopulate_pool",
        "loc_name": "multiprocessing.pool.Pool._repopulate_pool",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 302,
        "namespace": "Pool",
        "body": "    def _repopulate_pool(self):\n        return self._repopulate_pool_static(self._ctx, self.Process,\n                                            self._processes,\n                                            self._pool, self._inqueue,\n                                            self._outqueue, self._initializer,\n                                            self._initargs,\n                                            self._maxtasksperchild,\n                                            self._wrap_exception)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._repopulate_pool_static": {
        "API_name": "multiprocessing.pool.Pool._repopulate_pool_static",
        "loc_name": "multiprocessing.pool.Pool._repopulate_pool_static",
        "args": "ctx;Process;processes;pool;inqueue;outqueue;initializer;initargs;maxtasksperchild;wrap_exception",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 312,
        "namespace": "Pool",
        "body": "    def _repopulate_pool_static(ctx, Process, processes, pool, inqueue,\n                                outqueue, initializer, initargs,\n                                maxtasksperchild, wrap_exception):\n        \"\"\"Bring the number of pool processes up to the specified number,\n        for use after reaping workers which have exited.\n        \"\"\"\n        for i in range(processes - len(pool)):\n            w = Process(ctx, target=worker,\n                        args=(inqueue, outqueue,\n                              initializer,\n                              initargs, maxtasksperchild,\n                              wrap_exception))\n            w.name = w.name.replace('Process', 'PoolWorker')\n            w.daemon = True\n            w.start()\n            pool.append(w)\n            util.debug('added worker')",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._maintain_pool": {
        "API_name": "multiprocessing.pool.Pool._maintain_pool",
        "loc_name": "multiprocessing.pool.Pool._maintain_pool",
        "args": "ctx;Process;processes;pool;inqueue;outqueue;initializer;initargs;maxtasksperchild;wrap_exception",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 331,
        "namespace": "Pool",
        "body": "    def _maintain_pool(ctx, Process, processes, pool, inqueue, outqueue,\n                       initializer, initargs, maxtasksperchild,\n                       wrap_exception):\n        \"\"\"Clean up any exited workers and start replacements for them.\n        \"\"\"\n        if Pool._join_exited_workers(pool):\n            Pool._repopulate_pool_static(ctx, Process, processes, pool,\n                                         inqueue, outqueue, initializer,\n                                         initargs, maxtasksperchild,\n                                         wrap_exception)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._setup_queues": {
        "API_name": "multiprocessing.pool.Pool._setup_queues",
        "loc_name": "multiprocessing.pool.Pool._setup_queues",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 342,
        "namespace": "Pool",
        "body": "    def _setup_queues(self):\n        self._inqueue = self._ctx.SimpleQueue()\n        self._outqueue = self._ctx.SimpleQueue()\n        self._quick_put = self._inqueue._writer.send\n        self._quick_get = self._outqueue._reader.recv",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._check_running": {
        "API_name": "multiprocessing.pool.Pool._check_running",
        "loc_name": "multiprocessing.pool.Pool._check_running",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 348,
        "namespace": "Pool",
        "body": "    def _check_running(self):\n        if self._state != RUN:\n            raise ValueError(\"Pool not running\")",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.apply": {
        "API_name": "multiprocessing.pool.Pool.apply",
        "loc_name": "multiprocessing.pool.Pool.apply",
        "args": "self;func;args;kwds",
        "args_default": 2,
        "filepath": "multiprocessing.pool",
        "lineno": 352,
        "namespace": "Pool",
        "body": "    def apply(self, func, args=(), kwds={}):\n        '''\n        Equivalent of `func(*args, **kwds)`.\n        Pool must be running.\n        '''\n        return self.apply_async(func, args, kwds).get()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.map": {
        "API_name": "multiprocessing.pool.Pool.map",
        "loc_name": "multiprocessing.pool.Pool.map",
        "args": "self;func;iterable;chunksize",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 359,
        "namespace": "Pool",
        "body": "    def map(self, func, iterable, chunksize=None):\n        '''\n        Apply `func` to each element in `iterable`, collecting the results\n        in a list that is returned.\n        '''\n        return self._map_async(func, iterable, mapstar, chunksize).get()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.starmap": {
        "API_name": "multiprocessing.pool.Pool.starmap",
        "loc_name": "multiprocessing.pool.Pool.starmap",
        "args": "self;func;iterable;chunksize",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 366,
        "namespace": "Pool",
        "body": "    def starmap(self, func, iterable, chunksize=None):\n        '''\n        Like `map()` method but the elements of the `iterable` are expected to\n        be iterables as well and will be unpacked as arguments. Hence\n        `func` and (a, b) becomes func(a, b).\n        '''\n        return self._map_async(func, iterable, starmapstar, chunksize).get()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.starmap_async": {
        "API_name": "multiprocessing.pool.Pool.starmap_async",
        "loc_name": "multiprocessing.pool.Pool.starmap_async",
        "args": "self;func;iterable;chunksize;callback;error_callback",
        "args_default": 3,
        "filepath": "multiprocessing.pool",
        "lineno": 374,
        "namespace": "Pool",
        "body": "    def starmap_async(self, func, iterable, chunksize=None, callback=None,\n            error_callback=None):\n        '''\n        Asynchronous version of `starmap()` method.\n        '''\n        return self._map_async(func, iterable, starmapstar, chunksize,\n                               callback, error_callback)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._guarded_task_generation": {
        "API_name": "multiprocessing.pool.Pool._guarded_task_generation",
        "loc_name": "multiprocessing.pool.Pool._guarded_task_generation",
        "args": "self;result_job;func;iterable",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 382,
        "namespace": "Pool",
        "body": "    def _guarded_task_generation(self, result_job, func, iterable):\n        '''Provides a generator of tasks for imap and imap_unordered with\n        appropriate handling for iterables which throw exceptions during\n        iteration.'''\n        try:\n            i = -1\n            for i, x in enumerate(iterable):\n                yield (result_job, i, func, (x,), {})\n        except Exception as e:\n            yield (result_job, i+1, _helper_reraises_exception, (e,), {})",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.imap": {
        "API_name": "multiprocessing.pool.Pool.imap",
        "loc_name": "multiprocessing.pool.Pool.imap",
        "args": "self;func;iterable;chunksize",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 393,
        "namespace": "Pool",
        "body": "    def imap(self, func, iterable, chunksize=1):\n        '''\n        Equivalent of `map()` -- can be MUCH slower than `Pool.map()`.\n        '''\n        self._check_running()\n        if chunksize == 1:\n            result = IMapIterator(self)\n            self._taskqueue.put(\n                (\n                    self._guarded_task_generation(result._job, func, iterable),\n                    result._set_length\n                ))\n            return result\n        else:\n            if chunksize < 1:\n                raise ValueError(\n                    \"Chunksize must be 1+, not {0:n}\".format(\n                        chunksize))\n            task_batches = Pool._get_tasks(func, iterable, chunksize)\n            result = IMapIterator(self)\n            self._taskqueue.put(\n                (\n                    self._guarded_task_generation(result._job,\n                                                  mapstar,\n                                                  task_batches),\n                    result._set_length\n                ))\n            return (item for chunk in result for item in chunk)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.imap_unordered": {
        "API_name": "multiprocessing.pool.Pool.imap_unordered",
        "loc_name": "multiprocessing.pool.Pool.imap_unordered",
        "args": "self;func;iterable;chunksize",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 422,
        "namespace": "Pool",
        "body": "    def imap_unordered(self, func, iterable, chunksize=1):\n        '''\n        Like `imap()` method but ordering of results is arbitrary.\n        '''\n        self._check_running()\n        if chunksize == 1:\n            result = IMapUnorderedIterator(self)\n            self._taskqueue.put(\n                (\n                    self._guarded_task_generation(result._job, func, iterable),\n                    result._set_length\n                ))\n            return result\n        else:\n            if chunksize < 1:\n                raise ValueError(\n                    \"Chunksize must be 1+, not {0!r}\".format(chunksize))\n            task_batches = Pool._get_tasks(func, iterable, chunksize)\n            result = IMapUnorderedIterator(self)\n            self._taskqueue.put(\n                (\n                    self._guarded_task_generation(result._job,\n                                                  mapstar,\n                                                  task_batches),\n                    result._set_length\n                ))\n            return (item for chunk in result for item in chunk)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.apply_async": {
        "API_name": "multiprocessing.pool.Pool.apply_async",
        "loc_name": "multiprocessing.pool.Pool.apply_async",
        "args": "self;func;args;kwds;callback;error_callback",
        "args_default": 4,
        "filepath": "multiprocessing.pool",
        "lineno": 450,
        "namespace": "Pool",
        "body": "    def apply_async(self, func, args=(), kwds={}, callback=None,\n            error_callback=None):\n        '''\n        Asynchronous version of `apply()` method.\n        '''\n        self._check_running()\n        result = ApplyResult(self, callback, error_callback)\n        self._taskqueue.put(([(result._job, 0, func, args, kwds)], None))\n        return result",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.map_async": {
        "API_name": "multiprocessing.pool.Pool.map_async",
        "loc_name": "multiprocessing.pool.Pool.map_async",
        "args": "self;func;iterable;chunksize;callback;error_callback",
        "args_default": 3,
        "filepath": "multiprocessing.pool",
        "lineno": 460,
        "namespace": "Pool",
        "body": "    def map_async(self, func, iterable, chunksize=None, callback=None,\n            error_callback=None):\n        '''\n        Asynchronous version of `map()` method.\n        '''\n        return self._map_async(func, iterable, mapstar, chunksize, callback,\n            error_callback)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._map_async": {
        "API_name": "multiprocessing.pool.Pool._map_async",
        "loc_name": "multiprocessing.pool.Pool._map_async",
        "args": "self;func;iterable;mapper;chunksize;callback;error_callback",
        "args_default": 3,
        "filepath": "multiprocessing.pool",
        "lineno": 468,
        "namespace": "Pool",
        "body": "    def _map_async(self, func, iterable, mapper, chunksize=None, callback=None,\n            error_callback=None):\n        '''\n        Helper function to implement map, starmap and their async counterparts.\n        '''\n        self._check_running()\n        if not hasattr(iterable, '__len__'):\n            iterable = list(iterable)\n\n        if chunksize is None:\n            chunksize, extra = divmod(len(iterable), len(self._pool) * 4)\n            if extra:\n                chunksize += 1\n        if len(iterable) == 0:\n            chunksize = 0\n\n        task_batches = Pool._get_tasks(func, iterable, chunksize)\n        result = MapResult(self, chunksize, len(iterable), callback,\n                           error_callback=error_callback)\n        self._taskqueue.put(\n            (\n                self._guarded_task_generation(result._job,\n                                              mapper,\n                                              task_batches),\n                None\n            )\n        )\n        return result",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._wait_for_updates": {
        "API_name": "multiprocessing.pool.Pool._wait_for_updates",
        "loc_name": "multiprocessing.pool.Pool._wait_for_updates",
        "args": "sentinels;change_notifier;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 498,
        "namespace": "Pool",
        "body": "    def _wait_for_updates(sentinels, change_notifier, timeout=None):\n        wait(sentinels, timeout=timeout)\n        while not change_notifier.empty():\n            change_notifier.get()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._handle_workers": {
        "API_name": "multiprocessing.pool.Pool._handle_workers",
        "loc_name": "multiprocessing.pool.Pool._handle_workers",
        "args": "cls;cache;taskqueue;ctx;Process;processes;pool;inqueue;outqueue;initializer;initargs;maxtasksperchild;wrap_exception;sentinels;change_notifier",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 504,
        "namespace": "Pool",
        "body": "    def _handle_workers(cls, cache, taskqueue, ctx, Process, processes,\n                        pool, inqueue, outqueue, initializer, initargs,\n                        maxtasksperchild, wrap_exception, sentinels,\n                        change_notifier):\n        thread = threading.current_thread()\n\n        # Keep maintaining workers until the cache gets drained, unless the pool\n        # is terminated.\n        while thread._state == RUN or (cache and thread._state != TERMINATE):\n            cls._maintain_pool(ctx, Process, processes, pool, inqueue,\n                               outqueue, initializer, initargs,\n                               maxtasksperchild, wrap_exception)\n\n            current_sentinels = [*cls._get_worker_sentinels(pool), *sentinels]\n\n            cls._wait_for_updates(current_sentinels, change_notifier)\n        # send sentinel to stop workers\n        taskqueue.put(None)\n        util.debug('worker handler exiting')",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._handle_tasks": {
        "API_name": "multiprocessing.pool.Pool._handle_tasks",
        "loc_name": "multiprocessing.pool.Pool._handle_tasks",
        "args": "taskqueue;put;outqueue;pool;cache",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 525,
        "namespace": "Pool",
        "body": "    def _handle_tasks(taskqueue, put, outqueue, pool, cache):\n        thread = threading.current_thread()\n\n        for taskseq, set_length in iter(taskqueue.get, None):\n            task = None\n            try:\n                # iterating taskseq cannot fail\n                for task in taskseq:\n                    if thread._state != RUN:\n                        util.debug('task handler found thread._state != RUN')\n                        break\n                    try:\n                        put(task)\n                    except Exception as e:\n                        job, idx = task[:2]\n                        try:\n                            cache[job]._set(idx, (False, e))\n                        except KeyError:\n                            pass\n                else:\n                    if set_length:\n                        util.debug('doing set_length()')\n                        idx = task[1] if task else -1\n                        set_length(idx + 1)\n                    continue\n                break\n            finally:\n                task = taskseq = job = None\n        else:\n            util.debug('task handler got sentinel')\n\n        try:\n            # tell result handler to finish when cache is empty\n            util.debug('task handler sending sentinel to result handler')\n            outqueue.put(None)\n\n            # tell workers there is no more work\n            util.debug('task handler sending sentinel to workers')\n            for p in pool:\n                put(None)\n        except OSError:\n            util.debug('task handler got OSError when sending sentinels')\n\n        util.debug('task handler exiting')",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._handle_results": {
        "API_name": "multiprocessing.pool.Pool._handle_results",
        "loc_name": "multiprocessing.pool.Pool._handle_results",
        "args": "outqueue;get;cache",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 571,
        "namespace": "Pool",
        "body": "    def _handle_results(outqueue, get, cache):\n        thread = threading.current_thread()\n\n        while 1:\n            try:\n                task = get()\n            except (OSError, EOFError):\n                util.debug('result handler got EOFError/OSError -- exiting')\n                return\n\n            if thread._state != RUN:\n                assert thread._state == TERMINATE, \"Thread not in TERMINATE\"\n                util.debug('result handler found thread._state=TERMINATE')\n                break\n\n            if task is None:\n                util.debug('result handler got sentinel')\n                break\n\n            job, i, obj = task\n            try:\n                cache[job]._set(i, obj)\n            except KeyError:\n                pass\n            task = job = obj = None\n\n        while cache and thread._state != TERMINATE:\n            try:\n                task = get()\n            except (OSError, EOFError):\n                util.debug('result handler got EOFError/OSError -- exiting')\n                return\n\n            if task is None:\n                util.debug('result handler ignoring extra sentinel')\n                continue\n            job, i, obj = task\n            try:\n                cache[job]._set(i, obj)\n            except KeyError:\n                pass\n            task = job = obj = None\n\n        if hasattr(outqueue, '_reader'):\n            util.debug('ensuring that outqueue is not full')\n            # If we don't make room available in outqueue then\n            # attempts to add the sentinel (None) to outqueue may\n            # block.  There is guaranteed to be no more than 2 sentinels.\n            try:\n                for i in range(10):\n                    if not outqueue._reader.poll():\n                        break\n                    get()\n            except (OSError, EOFError):\n                pass\n\n        util.debug('result handler exiting: len(cache)=%s, thread._state=%s',\n              len(cache), thread._state)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._get_tasks": {
        "API_name": "multiprocessing.pool.Pool._get_tasks",
        "loc_name": "multiprocessing.pool.Pool._get_tasks",
        "args": "func;it;size",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 631,
        "namespace": "Pool",
        "body": "    def _get_tasks(func, it, size):\n        it = iter(it)\n        while 1:\n            x = tuple(itertools.islice(it, size))\n            if not x:\n                return\n            yield (func, x)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.__reduce__": {
        "API_name": "multiprocessing.pool.Pool.__reduce__",
        "loc_name": "multiprocessing.pool.Pool.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 639,
        "namespace": "Pool",
        "body": "    def __reduce__(self):\n        raise NotImplementedError(\n              'pool objects cannot be passed between processes or pickled'\n              )",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.close": {
        "API_name": "multiprocessing.pool.Pool.close",
        "loc_name": "multiprocessing.pool.Pool.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 644,
        "namespace": "Pool",
        "body": "    def close(self):\n        util.debug('closing pool')\n        if self._state == RUN:\n            self._state = CLOSE\n            self._worker_handler._state = CLOSE\n            self._change_notifier.put(None)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.terminate": {
        "API_name": "multiprocessing.pool.Pool.terminate",
        "loc_name": "multiprocessing.pool.Pool.terminate",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 651,
        "namespace": "Pool",
        "body": "    def terminate(self):\n        util.debug('terminating pool')\n        self._state = TERMINATE\n        self._terminate()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.join": {
        "API_name": "multiprocessing.pool.Pool.join",
        "loc_name": "multiprocessing.pool.Pool.join",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 656,
        "namespace": "Pool",
        "body": "    def join(self):\n        util.debug('joining pool')\n        if self._state == RUN:\n            raise ValueError(\"Pool is still running\")\n        elif self._state not in (CLOSE, TERMINATE):\n            raise ValueError(\"In unknown state\")\n        self._worker_handler.join()\n        self._task_handler.join()\n        self._result_handler.join()\n        for p in self._pool:\n            p.join()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._help_stuff_finish": {
        "API_name": "multiprocessing.pool.Pool._help_stuff_finish",
        "loc_name": "multiprocessing.pool.Pool._help_stuff_finish",
        "args": "inqueue;task_handler;size",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 669,
        "namespace": "Pool",
        "body": "    def _help_stuff_finish(inqueue, task_handler, size):\n        # task_handler may be blocked trying to put items on inqueue\n        util.debug('removing tasks from inqueue until task handler finished')\n        inqueue._rlock.acquire()\n        while task_handler.is_alive() and inqueue._reader.poll():\n            inqueue._reader.recv()\n            time.sleep(0)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool._terminate_pool": {
        "API_name": "multiprocessing.pool.Pool._terminate_pool",
        "loc_name": "multiprocessing.pool.Pool._terminate_pool",
        "args": "cls;taskqueue;inqueue;outqueue;pool;change_notifier;worker_handler;task_handler;result_handler;cache",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 678,
        "namespace": "Pool",
        "body": "    def _terminate_pool(cls, taskqueue, inqueue, outqueue, pool, change_notifier,\n                        worker_handler, task_handler, result_handler, cache):\n        # this is guaranteed to only be called once\n        util.debug('finalizing pool')\n\n        # Notify that the worker_handler state has been changed so the\n        # _handle_workers loop can be unblocked (and exited) in order to\n        # send the finalization sentinel all the workers.\n        worker_handler._state = TERMINATE\n        change_notifier.put(None)\n\n        task_handler._state = TERMINATE\n\n        util.debug('helping task handler/workers to finish')\n        cls._help_stuff_finish(inqueue, task_handler, len(pool))\n\n        if (not result_handler.is_alive()) and (len(cache) != 0):\n            raise AssertionError(\n                \"Cannot have cache with result_hander not alive\")\n\n        result_handler._state = TERMINATE\n        change_notifier.put(None)\n        outqueue.put(None)                  # sentinel\n\n        # We must wait for the worker handler to exit before terminating\n        # workers because we don't want workers to be restarted behind our back.\n        util.debug('joining worker handler')\n        if threading.current_thread() is not worker_handler:\n            worker_handler.join()\n\n        # Terminate workers which haven't already finished.\n        if pool and hasattr(pool[0], 'terminate'):\n            util.debug('terminating workers')\n            for p in pool:\n                if p.exitcode is None:\n                    p.terminate()\n\n        util.debug('joining task handler')\n        if threading.current_thread() is not task_handler:\n            task_handler.join()\n\n        util.debug('joining result handler')\n        if threading.current_thread() is not result_handler:\n            result_handler.join()\n\n        if pool and hasattr(pool[0], 'terminate'):\n            util.debug('joining pool workers')\n            for p in pool:\n                if p.is_alive():\n                    # worker has not yet exited\n                    util.debug('cleaning up worker %d' % p.pid)\n                    p.join()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.__enter__": {
        "API_name": "multiprocessing.pool.Pool.__enter__",
        "loc_name": "multiprocessing.pool.Pool.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 731,
        "namespace": "Pool",
        "body": "    def __enter__(self):\n        self._check_running()\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.Pool.__exit__": {
        "API_name": "multiprocessing.pool.Pool.__exit__",
        "loc_name": "multiprocessing.pool.Pool.__exit__",
        "args": "self;exc_type;exc_val;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 735,
        "namespace": "Pool",
        "body": "    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.terminate()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult": {
        "API_name": "multiprocessing.pool.ApplyResult",
        "loc_name": "multiprocessing.pool.ApplyResult",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 742,
        "namespace": "ApplyResult",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult.__init__": {
        "API_name": "multiprocessing.pool.ApplyResult.__init__",
        "loc_name": "multiprocessing.pool.ApplyResult.__init__",
        "args": "self;pool;callback;error_callback",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 744,
        "namespace": "ApplyResult",
        "body": "    def __init__(self, pool, callback, error_callback):\n        self._pool = pool\n        self._event = threading.Event()\n        self._job = next(job_counter)\n        self._cache = pool._cache\n        self._callback = callback\n        self._error_callback = error_callback\n        self._cache[self._job] = self",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult.ready": {
        "API_name": "multiprocessing.pool.ApplyResult.ready",
        "loc_name": "multiprocessing.pool.ApplyResult.ready",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 753,
        "namespace": "ApplyResult",
        "body": "    def ready(self):\n        return self._event.is_set()",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult.successful": {
        "API_name": "multiprocessing.pool.ApplyResult.successful",
        "loc_name": "multiprocessing.pool.ApplyResult.successful",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 756,
        "namespace": "ApplyResult",
        "body": "    def successful(self):\n        if not self.ready():\n            raise ValueError(\"{0!r} not ready\".format(self))\n        return self._success",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult.wait": {
        "API_name": "multiprocessing.pool.ApplyResult.wait",
        "loc_name": "multiprocessing.pool.ApplyResult.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 761,
        "namespace": "ApplyResult",
        "body": "    def wait(self, timeout=None):\n        self._event.wait(timeout)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult.get": {
        "API_name": "multiprocessing.pool.ApplyResult.get",
        "loc_name": "multiprocessing.pool.ApplyResult.get",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 764,
        "namespace": "ApplyResult",
        "body": "    def get(self, timeout=None):\n        self.wait(timeout)\n        if not self.ready():\n            raise TimeoutError\n        if self._success:\n            return self._value\n        else:\n            raise self._value",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ApplyResult._set": {
        "API_name": "multiprocessing.pool.ApplyResult._set",
        "loc_name": "multiprocessing.pool.ApplyResult._set",
        "args": "self;i;obj",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 773,
        "namespace": "ApplyResult",
        "body": "    def _set(self, i, obj):\n        self._success, self._value = obj\n        if self._callback and self._success:\n            self._callback(self._value)\n        if self._error_callback and not self._success:\n            self._error_callback(self._value)\n        self._event.set()\n        del self._cache[self._job]\n        self._pool = None",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MapResult": {
        "API_name": "multiprocessing.pool.MapResult",
        "loc_name": "multiprocessing.pool.MapResult",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 791,
        "namespace": "MapResult",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MapResult.__init__": {
        "API_name": "multiprocessing.pool.MapResult.__init__",
        "loc_name": "multiprocessing.pool.MapResult.__init__",
        "args": "self;pool;chunksize;length;callback;error_callback",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 793,
        "namespace": "MapResult",
        "body": "    def __init__(self, pool, chunksize, length, callback, error_callback):\n        ApplyResult.__init__(self, pool, callback,\n                             error_callback=error_callback)\n        self._success = True\n        self._value = [None] * length\n        self._chunksize = chunksize\n        if chunksize <= 0:\n            self._number_left = 0\n            self._event.set()\n            del self._cache[self._job]\n        else:\n            self._number_left = length//chunksize + bool(length % chunksize)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.MapResult._set": {
        "API_name": "multiprocessing.pool.MapResult._set",
        "loc_name": "multiprocessing.pool.MapResult._set",
        "args": "self;i;success_result",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 806,
        "namespace": "MapResult",
        "body": "    def _set(self, i, success_result):\n        self._number_left -= 1\n        success, result = success_result\n        if success and self._success:\n            self._value[i*self._chunksize:(i+1)*self._chunksize] = result\n            if self._number_left == 0:\n                if self._callback:\n                    self._callback(self._value)\n                del self._cache[self._job]\n                self._event.set()\n                self._pool = None\n        else:\n            if not success and self._success:\n                # only store first exception\n                self._success = False\n                self._value = result\n            if self._number_left == 0:\n                # only consider the result ready once all jobs are done\n                if self._error_callback:\n                    self._error_callback(self._value)\n                del self._cache[self._job]\n                self._event.set()\n                self._pool = None",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapIterator": {
        "API_name": "multiprocessing.pool.IMapIterator",
        "loc_name": "multiprocessing.pool.IMapIterator",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 834,
        "namespace": "IMapIterator",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapIterator.__init__": {
        "API_name": "multiprocessing.pool.IMapIterator.__init__",
        "loc_name": "multiprocessing.pool.IMapIterator.__init__",
        "args": "self;pool",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 836,
        "namespace": "IMapIterator",
        "body": "    def __init__(self, pool):\n        self._pool = pool\n        self._cond = threading.Condition(threading.Lock())\n        self._job = next(job_counter)\n        self._cache = pool._cache\n        self._items = collections.deque()\n        self._index = 0\n        self._length = None\n        self._unsorted = {}\n        self._cache[self._job] = self",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapIterator.__iter__": {
        "API_name": "multiprocessing.pool.IMapIterator.__iter__",
        "loc_name": "multiprocessing.pool.IMapIterator.__iter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 847,
        "namespace": "IMapIterator",
        "body": "    def __iter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapIterator.next": {
        "API_name": "multiprocessing.pool.IMapIterator.next",
        "loc_name": "multiprocessing.pool.IMapIterator.next",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.pool",
        "lineno": 850,
        "namespace": "IMapIterator",
        "body": "    def next(self, timeout=None):\n        with self._cond:\n            try:\n                item = self._items.popleft()\n            except IndexError:\n                if self._index == self._length:\n                    self._pool = None\n                    raise StopIteration from None\n                self._cond.wait(timeout)\n                try:\n                    item = self._items.popleft()\n                except IndexError:\n                    if self._index == self._length:\n                        self._pool = None\n                        raise StopIteration from None\n                    raise TimeoutError from None\n\n        success, value = item\n        if success:\n            return value\n        raise value",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapIterator._set": {
        "API_name": "multiprocessing.pool.IMapIterator._set",
        "loc_name": "multiprocessing.pool.IMapIterator._set",
        "args": "self;i;obj",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 874,
        "namespace": "IMapIterator",
        "body": "    def _set(self, i, obj):\n        with self._cond:\n            if self._index == i:\n                self._items.append(obj)\n                self._index += 1\n                while self._index in self._unsorted:\n                    obj = self._unsorted.pop(self._index)\n                    self._items.append(obj)\n                    self._index += 1\n                self._cond.notify()\n            else:\n                self._unsorted[i] = obj\n\n            if self._index == self._length:\n                del self._cache[self._job]\n                self._pool = None",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapIterator._set_length": {
        "API_name": "multiprocessing.pool.IMapIterator._set_length",
        "loc_name": "multiprocessing.pool.IMapIterator._set_length",
        "args": "self;length",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 891,
        "namespace": "IMapIterator",
        "body": "    def _set_length(self, length):\n        with self._cond:\n            self._length = length\n            if self._index == self._length:\n                self._cond.notify()\n                del self._cache[self._job]\n                self._pool = None",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapUnorderedIterator._set": {
        "API_name": "multiprocessing.pool.IMapUnorderedIterator._set",
        "loc_name": "multiprocessing.pool.IMapUnorderedIterator._set",
        "args": "self;i;obj",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 905,
        "namespace": "IMapUnorderedIterator",
        "body": "    def _set(self, i, obj):\n        with self._cond:\n            self._items.append(obj)\n            self._index += 1\n            self._cond.notify()\n            if self._index == self._length:\n                del self._cache[self._job]\n                self._pool = None",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.IMapUnorderedIterator": {
        "API_name": "multiprocessing.pool.IMapUnorderedIterator",
        "loc_name": "multiprocessing.pool.IMapUnorderedIterator",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 903,
        "namespace": "IMapUnorderedIterator",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool": {
        "API_name": "multiprocessing.pool.ThreadPool",
        "loc_name": "multiprocessing.pool.ThreadPool",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.pool",
        "lineno": 918,
        "namespace": "ThreadPool",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool.Process": {
        "API_name": "multiprocessing.pool.ThreadPool.Process",
        "loc_name": "multiprocessing.pool.ThreadPool.Process",
        "args": "ctx",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 922,
        "namespace": "ThreadPool",
        "body": "    def Process(ctx, *args, **kwds):\n        from .dummy import Process\n        return Process(*args, **kwds)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool.__init__": {
        "API_name": "multiprocessing.pool.ThreadPool.__init__",
        "loc_name": "multiprocessing.pool.ThreadPool.__init__",
        "args": "self;processes;initializer;initargs",
        "args_default": 3,
        "filepath": "multiprocessing.pool",
        "lineno": 926,
        "namespace": "ThreadPool",
        "body": "    def __init__(self, processes=None, initializer=None, initargs=()):\n        Pool.__init__(self, processes, initializer, initargs)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool._setup_queues": {
        "API_name": "multiprocessing.pool.ThreadPool._setup_queues",
        "loc_name": "multiprocessing.pool.ThreadPool._setup_queues",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 929,
        "namespace": "ThreadPool",
        "body": "    def _setup_queues(self):\n        self._inqueue = queue.SimpleQueue()\n        self._outqueue = queue.SimpleQueue()\n        self._quick_put = self._inqueue.put\n        self._quick_get = self._outqueue.get",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool._get_sentinels": {
        "API_name": "multiprocessing.pool.ThreadPool._get_sentinels",
        "loc_name": "multiprocessing.pool.ThreadPool._get_sentinels",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 935,
        "namespace": "ThreadPool",
        "body": "    def _get_sentinels(self):\n        return [self._change_notifier._reader]",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool._get_worker_sentinels": {
        "API_name": "multiprocessing.pool.ThreadPool._get_worker_sentinels",
        "loc_name": "multiprocessing.pool.ThreadPool._get_worker_sentinels",
        "args": "workers",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 939,
        "namespace": "ThreadPool",
        "body": "    def _get_worker_sentinels(workers):\n        return []",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool._help_stuff_finish": {
        "API_name": "multiprocessing.pool.ThreadPool._help_stuff_finish",
        "loc_name": "multiprocessing.pool.ThreadPool._help_stuff_finish",
        "args": "inqueue;task_handler;size",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 943,
        "namespace": "ThreadPool",
        "body": "    def _help_stuff_finish(inqueue, task_handler, size):\n        # drain inqueue, and put sentinels at its head to make workers finish\n        try:\n            while True:\n                inqueue.get(block=False)\n        except queue.Empty:\n            pass\n        for i in range(size):\n            inqueue.put(None)",
        "name_type": "stdlib"
    },
    "multiprocessing.pool.ThreadPool._wait_for_updates": {
        "API_name": "multiprocessing.pool.ThreadPool._wait_for_updates",
        "loc_name": "multiprocessing.pool.ThreadPool._wait_for_updates",
        "args": "self;sentinels;change_notifier;timeout",
        "args_default": 0,
        "filepath": "multiprocessing.pool",
        "lineno": 953,
        "namespace": "ThreadPool",
        "body": "    def _wait_for_updates(self, sentinels, change_notifier, timeout):\n        time.sleep(timeout)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork": {
        "API_name": "multiprocessing.popen_fork",
        "loc_name": "multiprocessing.popen_fork",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_fork",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['Popen']",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen": {
        "API_name": "multiprocessing.popen_fork.Popen",
        "loc_name": "multiprocessing.popen_fork.Popen",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_fork",
        "lineno": 12,
        "namespace": "Popen",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.__init__": {
        "API_name": "multiprocessing.popen_fork.Popen.__init__",
        "loc_name": "multiprocessing.popen_fork.Popen.__init__",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 15,
        "namespace": "Popen",
        "body": "    def __init__(self, process_obj):\n        util._flush_std_streams()\n        self.returncode = None\n        self.finalizer = None\n        self._launch(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.duplicate_for_child": {
        "API_name": "multiprocessing.popen_fork.Popen.duplicate_for_child",
        "loc_name": "multiprocessing.popen_fork.Popen.duplicate_for_child",
        "args": "self;fd",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 21,
        "namespace": "Popen",
        "body": "    def duplicate_for_child(self, fd):\n        return fd",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.poll": {
        "API_name": "multiprocessing.popen_fork.Popen.poll",
        "loc_name": "multiprocessing.popen_fork.Popen.poll",
        "args": "self;flag",
        "args_default": 1,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 24,
        "namespace": "Popen",
        "body": "    def poll(self, flag=os.WNOHANG):\n        if self.returncode is None:\n            try:\n                pid, sts = os.waitpid(self.pid, flag)\n            except OSError:\n                # Child process not yet created. See #1731717\n                # e.errno == errno.ECHILD == 10\n                return None\n            if pid == self.pid:\n                self.returncode = os.waitstatus_to_exitcode(sts)\n        return self.returncode",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.wait": {
        "API_name": "multiprocessing.popen_fork.Popen.wait",
        "loc_name": "multiprocessing.popen_fork.Popen.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 36,
        "namespace": "Popen",
        "body": "    def wait(self, timeout=None):\n        if self.returncode is None:\n            if timeout is not None:\n                from multiprocessing.connection import wait\n                if not wait([self.sentinel], timeout):\n                    return None\n            # This shouldn't block if wait() returned successfully.\n            return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n        return self.returncode",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen._send_signal": {
        "API_name": "multiprocessing.popen_fork.Popen._send_signal",
        "loc_name": "multiprocessing.popen_fork.Popen._send_signal",
        "args": "self;sig",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 46,
        "namespace": "Popen",
        "body": "    def _send_signal(self, sig):\n        if self.returncode is None:\n            try:\n                os.kill(self.pid, sig)\n            except ProcessLookupError:\n                pass\n            except OSError:\n                if self.wait(timeout=0.1) is None:\n                    raise",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.terminate": {
        "API_name": "multiprocessing.popen_fork.Popen.terminate",
        "loc_name": "multiprocessing.popen_fork.Popen.terminate",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 56,
        "namespace": "Popen",
        "body": "    def terminate(self):\n        self._send_signal(signal.SIGTERM)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.kill": {
        "API_name": "multiprocessing.popen_fork.Popen.kill",
        "loc_name": "multiprocessing.popen_fork.Popen.kill",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 59,
        "namespace": "Popen",
        "body": "    def kill(self):\n        self._send_signal(signal.SIGKILL)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen._launch": {
        "API_name": "multiprocessing.popen_fork.Popen._launch",
        "loc_name": "multiprocessing.popen_fork.Popen._launch",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 62,
        "namespace": "Popen",
        "body": "    def _launch(self, process_obj):\n        code = 1\n        parent_r, child_w = os.pipe()\n        child_r, parent_w = os.pipe()\n        self.pid = os.fork()\n        if self.pid == 0:\n            try:\n                os.close(parent_r)\n                os.close(parent_w)\n                code = process_obj._bootstrap(parent_sentinel=child_r)\n            finally:\n                os._exit(code)\n        else:\n            os.close(child_w)\n            os.close(child_r)\n            self.finalizer = util.Finalize(self, util.close_fds,\n                                           (parent_r, parent_w,))\n            self.sentinel = parent_r",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_fork.Popen.close": {
        "API_name": "multiprocessing.popen_fork.Popen.close",
        "loc_name": "multiprocessing.popen_fork.Popen.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_fork",
        "lineno": 81,
        "namespace": "Popen",
        "body": "    def close(self):\n        if self.finalizer is not None:\n            self.finalizer()",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver": {
        "API_name": "multiprocessing.popen_forkserver",
        "loc_name": "multiprocessing.popen_forkserver",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": "*",
        "namespace": "*",
        "body": "if not reduction.HAVE_SEND_HANDLE:\n    raise ImportError('No support for sending fds between processes')\n__all__ = ['Popen']",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver._DupFd": {
        "API_name": "multiprocessing.popen_forkserver._DupFd",
        "loc_name": "multiprocessing.popen_forkserver._DupFd",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 19,
        "namespace": "_DupFd",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver._DupFd.__init__": {
        "API_name": "multiprocessing.popen_forkserver._DupFd.__init__",
        "loc_name": "multiprocessing.popen_forkserver._DupFd.__init__",
        "args": "self;ind",
        "args_default": 0,
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 20,
        "namespace": "_DupFd",
        "body": "    def __init__(self, ind):\n        self.ind = ind",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver._DupFd.detach": {
        "API_name": "multiprocessing.popen_forkserver._DupFd.detach",
        "loc_name": "multiprocessing.popen_forkserver._DupFd.detach",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 22,
        "namespace": "_DupFd",
        "body": "    def detach(self):\n        return forkserver.get_inherited_fds()[self.ind]",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver.Popen": {
        "API_name": "multiprocessing.popen_forkserver.Popen",
        "loc_name": "multiprocessing.popen_forkserver.Popen",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 29,
        "namespace": "Popen",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver.Popen.__init__": {
        "API_name": "multiprocessing.popen_forkserver.Popen.__init__",
        "loc_name": "multiprocessing.popen_forkserver.Popen.__init__",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 33,
        "namespace": "Popen",
        "body": "    def __init__(self, process_obj):\n        self._fds = []\n        super().__init__(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver.Popen.duplicate_for_child": {
        "API_name": "multiprocessing.popen_forkserver.Popen.duplicate_for_child",
        "loc_name": "multiprocessing.popen_forkserver.Popen.duplicate_for_child",
        "args": "self;fd",
        "args_default": 0,
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 37,
        "namespace": "Popen",
        "body": "    def duplicate_for_child(self, fd):\n        self._fds.append(fd)\n        return len(self._fds) - 1",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver.Popen._launch": {
        "API_name": "multiprocessing.popen_forkserver.Popen._launch",
        "loc_name": "multiprocessing.popen_forkserver.Popen._launch",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 41,
        "namespace": "Popen",
        "body": "    def _launch(self, process_obj):\n        prep_data = spawn.get_preparation_data(process_obj._name)\n        buf = io.BytesIO()\n        set_spawning_popen(self)\n        try:\n            reduction.dump(prep_data, buf)\n            reduction.dump(process_obj, buf)\n        finally:\n            set_spawning_popen(None)\n\n        self.sentinel, w = forkserver.connect_to_new_process(self._fds)\n        # Keep a duplicate of the data pipe's write end as a sentinel of the\n        # parent process used by the child process.\n        _parent_w = os.dup(w)\n        self.finalizer = util.Finalize(self, util.close_fds,\n                                       (_parent_w, self.sentinel))\n        with open(w, 'wb', closefd=True) as f:\n            f.write(buf.getbuffer())\n        self.pid = forkserver.read_signed(self.sentinel)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_forkserver.Popen.poll": {
        "API_name": "multiprocessing.popen_forkserver.Popen.poll",
        "loc_name": "multiprocessing.popen_forkserver.Popen.poll",
        "args": "self;flag",
        "args_default": 1,
        "filepath": "multiprocessing.popen_forkserver",
        "lineno": 61,
        "namespace": "Popen",
        "body": "    def poll(self, flag=os.WNOHANG):\n        if self.returncode is None:\n            from multiprocessing.connection import wait\n            timeout = 0 if flag == os.WNOHANG else None\n            if not wait([self.sentinel], timeout):\n                return None\n            try:\n                self.returncode = forkserver.read_signed(self.sentinel)\n            except (OSError, EOFError):\n                # This should not happen usually, but perhaps the forkserver\n                # process itself got killed\n                self.returncode = 255\n\n        return self.returncode",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix": {
        "API_name": "multiprocessing.popen_spawn_posix",
        "loc_name": "multiprocessing.popen_spawn_posix",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['Popen']",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix._DupFd": {
        "API_name": "multiprocessing.popen_spawn_posix._DupFd",
        "loc_name": "multiprocessing.popen_spawn_posix._DupFd",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 16,
        "namespace": "_DupFd",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix._DupFd.__init__": {
        "API_name": "multiprocessing.popen_spawn_posix._DupFd.__init__",
        "loc_name": "multiprocessing.popen_spawn_posix._DupFd.__init__",
        "args": "self;fd",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 17,
        "namespace": "_DupFd",
        "body": "    def __init__(self, fd):\n        self.fd = fd",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix._DupFd.detach": {
        "API_name": "multiprocessing.popen_spawn_posix._DupFd.detach",
        "loc_name": "multiprocessing.popen_spawn_posix._DupFd.detach",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 19,
        "namespace": "_DupFd",
        "body": "    def detach(self):\n        return self.fd",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix.Popen": {
        "API_name": "multiprocessing.popen_spawn_posix.Popen",
        "loc_name": "multiprocessing.popen_spawn_posix.Popen",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 26,
        "namespace": "Popen",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix.Popen.__init__": {
        "API_name": "multiprocessing.popen_spawn_posix.Popen.__init__",
        "loc_name": "multiprocessing.popen_spawn_posix.Popen.__init__",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 30,
        "namespace": "Popen",
        "body": "    def __init__(self, process_obj):\n        self._fds = []\n        super().__init__(process_obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix.Popen.duplicate_for_child": {
        "API_name": "multiprocessing.popen_spawn_posix.Popen.duplicate_for_child",
        "loc_name": "multiprocessing.popen_spawn_posix.Popen.duplicate_for_child",
        "args": "self;fd",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 34,
        "namespace": "Popen",
        "body": "    def duplicate_for_child(self, fd):\n        self._fds.append(fd)\n        return fd",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_posix.Popen._launch": {
        "API_name": "multiprocessing.popen_spawn_posix.Popen._launch",
        "loc_name": "multiprocessing.popen_spawn_posix.Popen._launch",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_posix",
        "lineno": 38,
        "namespace": "Popen",
        "body": "    def _launch(self, process_obj):\n        from . import resource_tracker\n        tracker_fd = resource_tracker.getfd()\n        self._fds.append(tracker_fd)\n        prep_data = spawn.get_preparation_data(process_obj._name)\n        fp = io.BytesIO()\n        set_spawning_popen(self)\n        try:\n            reduction.dump(prep_data, fp)\n            reduction.dump(process_obj, fp)\n        finally:\n            set_spawning_popen(None)\n\n        parent_r = child_w = child_r = parent_w = None\n        try:\n            parent_r, child_w = os.pipe()\n            child_r, parent_w = os.pipe()\n            cmd = spawn.get_command_line(tracker_fd=tracker_fd,\n                                         pipe_handle=child_r)\n            self._fds.extend([child_r, child_w])\n            self.pid = util.spawnv_passfds(spawn.get_executable(),\n                                           cmd, self._fds)\n            self.sentinel = parent_r\n            with open(parent_w, 'wb', closefd=False) as f:\n                f.write(fp.getbuffer())\n        finally:\n            fds_to_close = []\n            for fd in (parent_r, parent_w):\n                if fd is not None:\n                    fds_to_close.append(fd)\n            self.finalizer = util.Finalize(self, util.close_fds, fds_to_close)\n\n            for fd in (child_r, child_w):\n                if fd is not None:\n                    os.close(fd)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32": {
        "API_name": "multiprocessing.popen_spawn_win32",
        "loc_name": "multiprocessing.popen_spawn_win32",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['Popen']\nTERMINATE = 0x10000\nWINEXE = (sys.platform == 'win32' and getattr(sys, 'frozen', False))\nWINSERVICE = sys.executable.lower().endswith(\"pythonservice.exe\")\nWINENV = not _path_eq(sys.executable, sys._base_executable)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32._path_eq": {
        "API_name": "multiprocessing.popen_spawn_win32._path_eq",
        "loc_name": "multiprocessing.popen_spawn_win32._path_eq",
        "args": "p1;p2",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 22,
        "namespace": "*",
        "body": "def _path_eq(p1, p2):\n    return p1 == p2 or os.path.normcase(p1) == os.path.normcase(p2)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32._close_handles": {
        "API_name": "multiprocessing.popen_spawn_win32._close_handles",
        "loc_name": "multiprocessing.popen_spawn_win32._close_handles",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 28,
        "namespace": "*",
        "body": "def _close_handles(*handles):\n    for handle in handles:\n        _winapi.CloseHandle(handle)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 38,
        "namespace": "Popen",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen.__init__": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen.__init__",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen.__init__",
        "args": "self;process_obj",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 44,
        "namespace": "Popen",
        "body": "    def __init__(self, process_obj):\n        prep_data = spawn.get_preparation_data(process_obj._name)\n\n        # read end of pipe will be duplicated by the child process\n        # -- see spawn_main() in spawn.py.\n        #\n        # bpo-33929: Previously, the read end of pipe was \"stolen\" by the child\n        # process, but it leaked a handle if the child process had been\n        # terminated before it could steal the handle from the parent process.\n        rhandle, whandle = _winapi.CreatePipe(None, 0)\n        wfd = msvcrt.open_osfhandle(whandle, 0)\n        cmd = spawn.get_command_line(parent_pid=os.getpid(),\n                                     pipe_handle=rhandle)\n        cmd = ' '.join('\"%s\"' % x for x in cmd)\n\n        python_exe = spawn.get_executable()\n\n        # bpo-35797: When running in a venv, we bypass the redirect\n        # executor and launch our base Python.\n        if WINENV and _path_eq(python_exe, sys.executable):\n            python_exe = sys._base_executable\n            env = os.environ.copy()\n            env[\"__PYVENV_LAUNCHER__\"] = sys.executable\n        else:\n            env = None\n\n        with open(wfd, 'wb', closefd=True) as to_child:\n            # start process\n            try:\n                hp, ht, pid, tid = _winapi.CreateProcess(\n                    python_exe, cmd,\n                    None, None, False, 0, env, None, None)\n                _winapi.CloseHandle(ht)\n            except:\n                _winapi.CloseHandle(rhandle)\n                raise\n\n            # set attributes of self\n            self.pid = pid\n            self.returncode = None\n            self._handle = hp\n            self.sentinel = int(hp)\n            self.finalizer = util.Finalize(self, _close_handles,\n                                           (self.sentinel, int(rhandle)))\n\n            # send information to child\n            set_spawning_popen(self)\n            try:\n                reduction.dump(prep_data, to_child)\n                reduction.dump(process_obj, to_child)\n            finally:\n                set_spawning_popen(None)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen.duplicate_for_child": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen.duplicate_for_child",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen.duplicate_for_child",
        "args": "self;handle",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 97,
        "namespace": "Popen",
        "body": "    def duplicate_for_child(self, handle):\n        assert self is get_spawning_popen()\n        return reduction.duplicate(handle, self.sentinel)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen.wait": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen.wait",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 101,
        "namespace": "Popen",
        "body": "    def wait(self, timeout=None):\n        if self.returncode is None:\n            if timeout is None:\n                msecs = _winapi.INFINITE\n            else:\n                msecs = max(0, int(timeout * 1000 + 0.5))\n\n            res = _winapi.WaitForSingleObject(int(self._handle), msecs)\n            if res == _winapi.WAIT_OBJECT_0:\n                code = _winapi.GetExitCodeProcess(self._handle)\n                if code == TERMINATE:\n                    code = -signal.SIGTERM\n                self.returncode = code\n\n        return self.returncode",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen.poll": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen.poll",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen.poll",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 117,
        "namespace": "Popen",
        "body": "    def poll(self):\n        return self.wait(timeout=0)",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen.terminate": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen.terminate",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen.terminate",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 120,
        "namespace": "Popen",
        "body": "    def terminate(self):\n        if self.returncode is None:\n            try:\n                _winapi.TerminateProcess(int(self._handle), TERMINATE)\n            except OSError:\n                if self.wait(timeout=1.0) is None:\n                    raise",
        "name_type": "stdlib"
    },
    "multiprocessing.popen_spawn_win32.Popen.close": {
        "API_name": "multiprocessing.popen_spawn_win32.Popen.close",
        "loc_name": "multiprocessing.popen_spawn_win32.Popen.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.popen_spawn_win32",
        "lineno": 130,
        "namespace": "Popen",
        "body": "    def close(self):\n        self.finalizer()",
        "name_type": "stdlib"
    },
    "multiprocessing.process": {
        "API_name": "multiprocessing.process",
        "loc_name": "multiprocessing.process",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.process",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['BaseProcess', 'current_process', 'active_children',\n           'parent_process']\ntry:\n    ORIGINAL_DIR = os.path.abspath(os.getcwd())\nexcept OSError:\n    ORIGINAL_DIR = None\n_parent_process = None\n_current_process = _MainProcess()\n_process_counter = itertools.count(1)\n_children = set()\ndel _MainProcess\n_exitcode_to_name = {}\nfor name, signum in list(signal.__dict__.items()):\n    if name[:3]=='SIG' and '_' not in name:\n        _exitcode_to_name[-signum] = f'-{name}'\n_dangling = WeakSet()",
        "name_type": "stdlib"
    },
    "multiprocessing.process.current_process": {
        "API_name": "multiprocessing.process.current_process",
        "loc_name": "multiprocessing.process.current_process",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 37,
        "namespace": "*",
        "body": "def current_process():\n    '''\n    Return process object representing the current process\n    '''\n    return _current_process",
        "name_type": "stdlib"
    },
    "multiprocessing.process.active_children": {
        "API_name": "multiprocessing.process.active_children",
        "loc_name": "multiprocessing.process.active_children",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 43,
        "namespace": "*",
        "body": "def active_children():\n    '''\n    Return list of process objects corresponding to live child processes\n    '''\n    _cleanup()\n    return list(_children)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.parent_process": {
        "API_name": "multiprocessing.process.parent_process",
        "loc_name": "multiprocessing.process.parent_process",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 51,
        "namespace": "*",
        "body": "def parent_process():\n    '''\n    Return process object representing the parent process\n    '''\n    return _parent_process",
        "name_type": "stdlib"
    },
    "multiprocessing.process._cleanup": {
        "API_name": "multiprocessing.process._cleanup",
        "loc_name": "multiprocessing.process._cleanup",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 61,
        "namespace": "*",
        "body": "def _cleanup():\n    # check for processes which have finished\n    for p in list(_children):\n        if p._popen.poll() is not None:\n            _children.discard(p)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess": {
        "API_name": "multiprocessing.process.BaseProcess",
        "loc_name": "multiprocessing.process.BaseProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.process",
        "lineno": 71,
        "namespace": "BaseProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess._Popen": {
        "API_name": "multiprocessing.process.BaseProcess._Popen",
        "loc_name": "multiprocessing.process.BaseProcess._Popen",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 77,
        "namespace": "BaseProcess",
        "body": "    def _Popen(self):\n        raise NotImplementedError",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.__init__": {
        "API_name": "multiprocessing.process.BaseProcess.__init__",
        "loc_name": "multiprocessing.process.BaseProcess.__init__",
        "args": "self;group;target;name;args;kwargs",
        "args_default": 5,
        "filepath": "multiprocessing.process",
        "lineno": 80,
        "namespace": "BaseProcess",
        "body": "    def __init__(self, group=None, target=None, name=None, args=(), kwargs={},\n                 *, daemon=None):\n        assert group is None, 'group argument must be None for now'\n        count = next(_process_counter)\n        self._identity = _current_process._identity + (count,)\n        self._config = _current_process._config.copy()\n        self._parent_pid = os.getpid()\n        self._parent_name = _current_process.name\n        self._popen = None\n        self._closed = False\n        self._target = target\n        self._args = tuple(args)\n        self._kwargs = dict(kwargs)\n        self._name = name or type(self).__name__ + '-' + \\\n                     ':'.join(str(i) for i in self._identity)\n        if daemon is not None:\n            self.daemon = daemon\n        _dangling.add(self)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess._check_closed": {
        "API_name": "multiprocessing.process.BaseProcess._check_closed",
        "loc_name": "multiprocessing.process.BaseProcess._check_closed",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 99,
        "namespace": "BaseProcess",
        "body": "    def _check_closed(self):\n        if self._closed:\n            raise ValueError(\"process object is closed\")",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.run": {
        "API_name": "multiprocessing.process.BaseProcess.run",
        "loc_name": "multiprocessing.process.BaseProcess.run",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 103,
        "namespace": "BaseProcess",
        "body": "    def run(self):\n        '''\n        Method to be run in sub-process; can be overridden in sub-class\n        '''\n        if self._target:\n            self._target(*self._args, **self._kwargs)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.start": {
        "API_name": "multiprocessing.process.BaseProcess.start",
        "loc_name": "multiprocessing.process.BaseProcess.start",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 110,
        "namespace": "BaseProcess",
        "body": "    def start(self):\n        '''\n        Start child process\n        '''\n        self._check_closed()\n        assert self._popen is None, 'cannot start a process twice'\n        assert self._parent_pid == os.getpid(), \\\n               'can only start a process object created by current process'\n        assert not _current_process._config.get('daemon'), \\\n               'daemonic processes are not allowed to have children'\n        _cleanup()\n        self._popen = self._Popen(self)\n        self._sentinel = self._popen.sentinel\n        # Avoid a refcycle if the target function holds an indirect\n        # reference to the process object (see bpo-30775)\n        del self._target, self._args, self._kwargs\n        _children.add(self)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.terminate": {
        "API_name": "multiprocessing.process.BaseProcess.terminate",
        "loc_name": "multiprocessing.process.BaseProcess.terminate",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 128,
        "namespace": "BaseProcess",
        "body": "    def terminate(self):\n        '''\n        Terminate process; sends SIGTERM signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.terminate()",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.kill": {
        "API_name": "multiprocessing.process.BaseProcess.kill",
        "loc_name": "multiprocessing.process.BaseProcess.kill",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 135,
        "namespace": "BaseProcess",
        "body": "    def kill(self):\n        '''\n        Terminate process; sends SIGKILL signal or uses TerminateProcess()\n        '''\n        self._check_closed()\n        self._popen.kill()",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.join": {
        "API_name": "multiprocessing.process.BaseProcess.join",
        "loc_name": "multiprocessing.process.BaseProcess.join",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.process",
        "lineno": 142,
        "namespace": "BaseProcess",
        "body": "    def join(self, timeout=None):\n        '''\n        Wait until child process terminates\n        '''\n        self._check_closed()\n        assert self._parent_pid == os.getpid(), 'can only join a child process'\n        assert self._popen is not None, 'can only join a started process'\n        res = self._popen.wait(timeout)\n        if res is not None:\n            _children.discard(self)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.is_alive": {
        "API_name": "multiprocessing.process.BaseProcess.is_alive",
        "loc_name": "multiprocessing.process.BaseProcess.is_alive",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 153,
        "namespace": "BaseProcess",
        "body": "    def is_alive(self):\n        '''\n        Return whether process is alive\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return True\n        assert self._parent_pid == os.getpid(), 'can only test a child process'\n\n        if self._popen is None:\n            return False\n\n        returncode = self._popen.poll()\n        if returncode is None:\n            return True\n        else:\n            _children.discard(self)\n            return False",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.close": {
        "API_name": "multiprocessing.process.BaseProcess.close",
        "loc_name": "multiprocessing.process.BaseProcess.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 172,
        "namespace": "BaseProcess",
        "body": "    def close(self):\n        '''\n        Close the Process object.\n\n        This method releases resources held by the Process object.  It is\n        an error to call this method if the child process is still running.\n        '''\n        if self._popen is not None:\n            if self._popen.poll() is None:\n                raise ValueError(\"Cannot close a process while it is still running. \"\n                                 \"You should first call join() or terminate().\")\n            self._popen.close()\n            self._popen = None\n            del self._sentinel\n            _children.discard(self)\n        self._closed = True",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.name": {
        "API_name": "multiprocessing.process.BaseProcess.name",
        "loc_name": "multiprocessing.process.BaseProcess.name",
        "args": "self;name",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 194,
        "namespace": "BaseProcess",
        "body": "    def name(self, name):\n        assert isinstance(name, str), 'name must be a string'\n        self._name = name",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.daemon": {
        "API_name": "multiprocessing.process.BaseProcess.daemon",
        "loc_name": "multiprocessing.process.BaseProcess.daemon",
        "args": "self;daemonic",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 206,
        "namespace": "BaseProcess",
        "body": "    def daemon(self, daemonic):\n        '''\n        Set whether process is a daemon\n        '''\n        assert self._popen is None, 'process has already started'\n        self._config['daemon'] = daemonic",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.authkey": {
        "API_name": "multiprocessing.process.BaseProcess.authkey",
        "loc_name": "multiprocessing.process.BaseProcess.authkey",
        "args": "self;authkey",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 218,
        "namespace": "BaseProcess",
        "body": "    def authkey(self, authkey):\n        '''\n        Set authorization key of process\n        '''\n        self._config['authkey'] = AuthenticationString(authkey)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.exitcode": {
        "API_name": "multiprocessing.process.BaseProcess.exitcode",
        "loc_name": "multiprocessing.process.BaseProcess.exitcode",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 225,
        "namespace": "BaseProcess",
        "body": "    def exitcode(self):\n        '''\n        Return exit code of process or `None` if it has yet to stop\n        '''\n        self._check_closed()\n        if self._popen is None:\n            return self._popen\n        return self._popen.poll()",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.ident": {
        "API_name": "multiprocessing.process.BaseProcess.ident",
        "loc_name": "multiprocessing.process.BaseProcess.ident",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 235,
        "namespace": "BaseProcess",
        "body": "    def ident(self):\n        '''\n        Return identifier (PID) of process or `None` if it has yet to start\n        '''\n        self._check_closed()\n        if self is _current_process:\n            return os.getpid()\n        else:\n            return self._popen and self._popen.pid",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.sentinel": {
        "API_name": "multiprocessing.process.BaseProcess.sentinel",
        "loc_name": "multiprocessing.process.BaseProcess.sentinel",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 248,
        "namespace": "BaseProcess",
        "body": "    def sentinel(self):\n        '''\n        Return a file descriptor (Unix) or handle (Windows) suitable for\n        waiting for process termination.\n        '''\n        self._check_closed()\n        try:\n            return self._sentinel\n        except AttributeError:\n            raise ValueError(\"process not started\") from None",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess.__repr__": {
        "API_name": "multiprocessing.process.BaseProcess.__repr__",
        "loc_name": "multiprocessing.process.BaseProcess.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 259,
        "namespace": "BaseProcess",
        "body": "    def __repr__(self):\n        exitcode = None\n        if self is _current_process:\n            status = 'started'\n        elif self._closed:\n            status = 'closed'\n        elif self._parent_pid != os.getpid():\n            status = 'unknown'\n        elif self._popen is None:\n            status = 'initial'\n        else:\n            exitcode = self._popen.poll()\n            if exitcode is not None:\n                status = 'stopped'\n            else:\n                status = 'started'\n\n        info = [type(self).__name__, 'name=%r' % self._name]\n        if self._popen is not None:\n            info.append('pid=%s' % self._popen.pid)\n        info.append('parent=%s' % self._parent_pid)\n        info.append(status)\n        if exitcode is not None:\n            exitcode = _exitcode_to_name.get(exitcode, exitcode)\n            info.append('exitcode=%s' % exitcode)\n        if self.daemon:\n            info.append('daemon')\n        return '<%s>' % ' '.join(info)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.BaseProcess._bootstrap": {
        "API_name": "multiprocessing.process.BaseProcess._bootstrap",
        "loc_name": "multiprocessing.process.BaseProcess._bootstrap",
        "args": "self;parent_sentinel",
        "args_default": 1,
        "filepath": "multiprocessing.process",
        "lineno": 290,
        "namespace": "BaseProcess",
        "body": "    def _bootstrap(self, parent_sentinel=None):\n        from . import util, context\n        global _current_process, _parent_process, _process_counter, _children\n\n        try:\n            if self._start_method is not None:\n                context._force_start_method(self._start_method)\n            _process_counter = itertools.count(1)\n            _children = set()\n            util._close_stdin()\n            old_process = _current_process\n            _current_process = self\n            _parent_process = _ParentProcess(\n                self._parent_name, self._parent_pid, parent_sentinel)\n            if threading._HAVE_THREAD_NATIVE_ID:\n                threading.main_thread()._set_native_id()\n            try:\n                util._finalizer_registry.clear()\n                util._run_after_forkers()\n            finally:\n                # delay finalization of the old process object until after\n                # _run_after_forkers() is executed\n                del old_process\n            util.info('child process calling self.run()')\n            try:\n                self.run()\n                exitcode = 0\n            finally:\n                util._exit_function()\n        except SystemExit as e:\n            if e.code is None:\n                exitcode = 0\n            elif isinstance(e.code, int):\n                exitcode = e.code\n            else:\n                sys.stderr.write(str(e.code) + '\\n')\n                exitcode = 1\n        except:\n            exitcode = 1\n            import traceback\n            sys.stderr.write('Process %s:\\n' % self.name)\n            traceback.print_exc()\n        finally:\n            threading._shutdown()\n            util.info('process exiting with exitcode %d' % exitcode)\n            util._flush_std_streams()\n\n        return exitcode",
        "name_type": "stdlib"
    },
    "multiprocessing.process.AuthenticationString.__reduce__": {
        "API_name": "multiprocessing.process.AuthenticationString.__reduce__",
        "loc_name": "multiprocessing.process.AuthenticationString.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 344,
        "namespace": "AuthenticationString",
        "body": "    def __reduce__(self):\n        from .context import get_spawning_popen\n        if get_spawning_popen() is None:\n            raise TypeError(\n                'Pickling an AuthenticationString object is '\n                'disallowed for security reasons'\n                )\n        return AuthenticationString, (bytes(self),)",
        "name_type": "stdlib"
    },
    "multiprocessing.process.AuthenticationString": {
        "API_name": "multiprocessing.process.AuthenticationString",
        "loc_name": "multiprocessing.process.AuthenticationString",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.process",
        "lineno": 343,
        "namespace": "AuthenticationString",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.process._ParentProcess": {
        "API_name": "multiprocessing.process._ParentProcess",
        "loc_name": "multiprocessing.process._ParentProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.process",
        "lineno": 358,
        "namespace": "_ParentProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.process._ParentProcess.__init__": {
        "API_name": "multiprocessing.process._ParentProcess.__init__",
        "loc_name": "multiprocessing.process._ParentProcess.__init__",
        "args": "self;name;pid;sentinel",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 360,
        "namespace": "_ParentProcess",
        "body": "    def __init__(self, name, pid, sentinel):\n        self._identity = ()\n        self._name = name\n        self._pid = pid\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._sentinel = sentinel\n        self._config = {}",
        "name_type": "stdlib"
    },
    "multiprocessing.process._ParentProcess.is_alive": {
        "API_name": "multiprocessing.process._ParentProcess.is_alive",
        "loc_name": "multiprocessing.process._ParentProcess.is_alive",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 370,
        "namespace": "_ParentProcess",
        "body": "    def is_alive(self):\n        from multiprocessing.connection import wait\n        return not wait([self._sentinel], timeout=0)",
        "name_type": "stdlib"
    },
    "multiprocessing.process._ParentProcess.ident": {
        "API_name": "multiprocessing.process._ParentProcess.ident",
        "loc_name": "multiprocessing.process._ParentProcess.ident",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 375,
        "namespace": "_ParentProcess",
        "body": "    def ident(self):\n        return self._pid",
        "name_type": "stdlib"
    },
    "multiprocessing.process._ParentProcess.join": {
        "API_name": "multiprocessing.process._ParentProcess.join",
        "loc_name": "multiprocessing.process._ParentProcess.join",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.process",
        "lineno": 378,
        "namespace": "_ParentProcess",
        "body": "    def join(self, timeout=None):\n        '''\n        Wait until parent process terminates\n        '''\n        from multiprocessing.connection import wait\n        wait([self._sentinel], timeout=timeout)",
        "name_type": "stdlib"
    },
    "multiprocessing.process._MainProcess": {
        "API_name": "multiprocessing.process._MainProcess",
        "loc_name": "multiprocessing.process._MainProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.process",
        "lineno": 391,
        "namespace": "_MainProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.process._MainProcess.__init__": {
        "API_name": "multiprocessing.process._MainProcess.__init__",
        "loc_name": "multiprocessing.process._MainProcess.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 393,
        "namespace": "_MainProcess",
        "body": "    def __init__(self):\n        self._identity = ()\n        self._name = 'MainProcess'\n        self._parent_pid = None\n        self._popen = None\n        self._closed = False\n        self._config = {'authkey': AuthenticationString(os.urandom(32)),\n                        'semprefix': '/mp'}",
        "name_type": "stdlib"
    },
    "multiprocessing.process._MainProcess.close": {
        "API_name": "multiprocessing.process._MainProcess.close",
        "loc_name": "multiprocessing.process._MainProcess.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.process",
        "lineno": 411,
        "namespace": "_MainProcess",
        "body": "    def close(self):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.queues": {
        "API_name": "multiprocessing.queues",
        "loc_name": "multiprocessing.queues",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.queues",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['Queue', 'SimpleQueue', 'JoinableQueue']\n_ForkingPickler = context.reduction.ForkingPickler\n_sentinel = object()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue": {
        "API_name": "multiprocessing.queues.Queue",
        "loc_name": "multiprocessing.queues.Queue",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.queues",
        "lineno": 35,
        "namespace": "Queue",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.__init__": {
        "API_name": "multiprocessing.queues.Queue.__init__",
        "loc_name": "multiprocessing.queues.Queue.__init__",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "multiprocessing.queues",
        "lineno": 37,
        "namespace": "Queue",
        "body": "    def __init__(self, maxsize=0, *, ctx):\n        if maxsize <= 0:\n            # Can raise ImportError (see issues #3770 and #23400)\n            from .synchronize import SEM_VALUE_MAX as maxsize\n        self._maxsize = maxsize\n        self._reader, self._writer = connection.Pipe(duplex=False)\n        self._rlock = ctx.Lock()\n        self._opid = os.getpid()\n        if sys.platform == 'win32':\n            self._wlock = None\n        else:\n            self._wlock = ctx.Lock()\n        self._sem = ctx.BoundedSemaphore(maxsize)\n        # For use by concurrent.futures\n        self._ignore_epipe = False\n        self._reset()\n\n        if sys.platform != 'win32':\n            register_after_fork(self, Queue._after_fork)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.__getstate__": {
        "API_name": "multiprocessing.queues.Queue.__getstate__",
        "loc_name": "multiprocessing.queues.Queue.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 57,
        "namespace": "Queue",
        "body": "    def __getstate__(self):\n        context.assert_spawning(self)\n        return (self._ignore_epipe, self._maxsize, self._reader, self._writer,\n                self._rlock, self._wlock, self._sem, self._opid)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.__setstate__": {
        "API_name": "multiprocessing.queues.Queue.__setstate__",
        "loc_name": "multiprocessing.queues.Queue.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 62,
        "namespace": "Queue",
        "body": "    def __setstate__(self, state):\n        (self._ignore_epipe, self._maxsize, self._reader, self._writer,\n         self._rlock, self._wlock, self._sem, self._opid) = state\n        self._reset()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._after_fork": {
        "API_name": "multiprocessing.queues.Queue._after_fork",
        "loc_name": "multiprocessing.queues.Queue._after_fork",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 67,
        "namespace": "Queue",
        "body": "    def _after_fork(self):\n        debug('Queue._after_fork()')\n        self._reset(after_fork=True)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._reset": {
        "API_name": "multiprocessing.queues.Queue._reset",
        "loc_name": "multiprocessing.queues.Queue._reset",
        "args": "self;after_fork",
        "args_default": 1,
        "filepath": "multiprocessing.queues",
        "lineno": 71,
        "namespace": "Queue",
        "body": "    def _reset(self, after_fork=False):\n        if after_fork:\n            self._notempty._at_fork_reinit()\n        else:\n            self._notempty = threading.Condition(threading.Lock())\n        self._buffer = collections.deque()\n        self._thread = None\n        self._jointhread = None\n        self._joincancelled = False\n        self._closed = False\n        self._close = None\n        self._send_bytes = self._writer.send_bytes\n        self._recv_bytes = self._reader.recv_bytes\n        self._poll = self._reader.poll",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.put": {
        "API_name": "multiprocessing.queues.Queue.put",
        "loc_name": "multiprocessing.queues.Queue.put",
        "args": "self;obj;block;timeout",
        "args_default": 2,
        "filepath": "multiprocessing.queues",
        "lineno": 86,
        "namespace": "Queue",
        "body": "    def put(self, obj, block=True, timeout=None):\n        if self._closed:\n            raise ValueError(f\"Queue {self!r} is closed\")\n        if not self._sem.acquire(block, timeout):\n            raise Full\n\n        with self._notempty:\n            if self._thread is None:\n                self._start_thread()\n            self._buffer.append(obj)\n            self._notempty.notify()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.get": {
        "API_name": "multiprocessing.queues.Queue.get",
        "loc_name": "multiprocessing.queues.Queue.get",
        "args": "self;block;timeout",
        "args_default": 2,
        "filepath": "multiprocessing.queues",
        "lineno": 98,
        "namespace": "Queue",
        "body": "    def get(self, block=True, timeout=None):\n        if self._closed:\n            raise ValueError(f\"Queue {self!r} is closed\")\n        if block and timeout is None:\n            with self._rlock:\n                res = self._recv_bytes()\n            self._sem.release()\n        else:\n            if block:\n                deadline = time.monotonic() + timeout\n            if not self._rlock.acquire(block, timeout):\n                raise Empty\n            try:\n                if block:\n                    timeout = deadline - time.monotonic()\n                    if not self._poll(timeout):\n                        raise Empty\n                elif not self._poll():\n                    raise Empty\n                res = self._recv_bytes()\n                self._sem.release()\n            finally:\n                self._rlock.release()\n        # unserialize the data after having released the lock\n        return _ForkingPickler.loads(res)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.qsize": {
        "API_name": "multiprocessing.queues.Queue.qsize",
        "loc_name": "multiprocessing.queues.Queue.qsize",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 124,
        "namespace": "Queue",
        "body": "    def qsize(self):\n        # Raises NotImplementedError on Mac OSX because of broken sem_getvalue()\n        return self._maxsize - self._sem._semlock._get_value()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.empty": {
        "API_name": "multiprocessing.queues.Queue.empty",
        "loc_name": "multiprocessing.queues.Queue.empty",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 128,
        "namespace": "Queue",
        "body": "    def empty(self):\n        return not self._poll()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.full": {
        "API_name": "multiprocessing.queues.Queue.full",
        "loc_name": "multiprocessing.queues.Queue.full",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 131,
        "namespace": "Queue",
        "body": "    def full(self):\n        return self._sem._semlock._is_zero()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.get_nowait": {
        "API_name": "multiprocessing.queues.Queue.get_nowait",
        "loc_name": "multiprocessing.queues.Queue.get_nowait",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 134,
        "namespace": "Queue",
        "body": "    def get_nowait(self):\n        return self.get(False)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.put_nowait": {
        "API_name": "multiprocessing.queues.Queue.put_nowait",
        "loc_name": "multiprocessing.queues.Queue.put_nowait",
        "args": "self;obj",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 137,
        "namespace": "Queue",
        "body": "    def put_nowait(self, obj):\n        return self.put(obj, False)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.close": {
        "API_name": "multiprocessing.queues.Queue.close",
        "loc_name": "multiprocessing.queues.Queue.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 140,
        "namespace": "Queue",
        "body": "    def close(self):\n        self._closed = True\n        close = self._close\n        if close:\n            self._close = None\n            close()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.join_thread": {
        "API_name": "multiprocessing.queues.Queue.join_thread",
        "loc_name": "multiprocessing.queues.Queue.join_thread",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 147,
        "namespace": "Queue",
        "body": "    def join_thread(self):\n        debug('Queue.join_thread()')\n        assert self._closed, \"Queue {0!r} not closed\".format(self)\n        if self._jointhread:\n            self._jointhread()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue.cancel_join_thread": {
        "API_name": "multiprocessing.queues.Queue.cancel_join_thread",
        "loc_name": "multiprocessing.queues.Queue.cancel_join_thread",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 153,
        "namespace": "Queue",
        "body": "    def cancel_join_thread(self):\n        debug('Queue.cancel_join_thread()')\n        self._joincancelled = True\n        try:\n            self._jointhread.cancel()\n        except AttributeError:\n            pass",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._start_thread": {
        "API_name": "multiprocessing.queues.Queue._start_thread",
        "loc_name": "multiprocessing.queues.Queue._start_thread",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 161,
        "namespace": "Queue",
        "body": "    def _start_thread(self):\n        debug('Queue._start_thread()')\n\n        # Start thread which transfers data from buffer to pipe\n        self._buffer.clear()\n        self._thread = threading.Thread(\n            target=Queue._feed,\n            args=(self._buffer, self._notempty, self._send_bytes,\n                  self._wlock, self._reader.close, self._writer.close,\n                  self._ignore_epipe, self._on_queue_feeder_error,\n                  self._sem),\n            name='QueueFeederThread'\n        )\n        self._thread.daemon = True\n\n        debug('doing self._thread.start()')\n        self._thread.start()\n        debug('... done self._thread.start()')\n\n        if not self._joincancelled:\n            self._jointhread = Finalize(\n                self._thread, Queue._finalize_join,\n                [weakref.ref(self._thread)],\n                exitpriority=-5\n                )\n\n        # Send sentinel to the thread queue object when garbage collected\n        self._close = Finalize(\n            self, Queue._finalize_close,\n            [self._buffer, self._notempty],\n            exitpriority=10\n            )",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._finalize_join": {
        "API_name": "multiprocessing.queues.Queue._finalize_join",
        "loc_name": "multiprocessing.queues.Queue._finalize_join",
        "args": "twr",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 195,
        "namespace": "Queue",
        "body": "    def _finalize_join(twr):\n        debug('joining queue thread')\n        thread = twr()\n        if thread is not None:\n            thread.join()\n            debug('... queue thread joined')\n        else:\n            debug('... queue thread already dead')",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._finalize_close": {
        "API_name": "multiprocessing.queues.Queue._finalize_close",
        "loc_name": "multiprocessing.queues.Queue._finalize_close",
        "args": "buffer;notempty",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 205,
        "namespace": "Queue",
        "body": "    def _finalize_close(buffer, notempty):\n        debug('telling queue thread to quit')\n        with notempty:\n            buffer.append(_sentinel)\n            notempty.notify()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._feed": {
        "API_name": "multiprocessing.queues.Queue._feed",
        "loc_name": "multiprocessing.queues.Queue._feed",
        "args": "buffer;notempty;send_bytes;writelock;reader_close;writer_close;ignore_epipe;onerror;queue_sem",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 212,
        "namespace": "Queue",
        "body": "    def _feed(buffer, notempty, send_bytes, writelock, reader_close,\n              writer_close, ignore_epipe, onerror, queue_sem):\n        debug('starting thread to feed data to pipe')\n        nacquire = notempty.acquire\n        nrelease = notempty.release\n        nwait = notempty.wait\n        bpopleft = buffer.popleft\n        sentinel = _sentinel\n        if sys.platform != 'win32':\n            wacquire = writelock.acquire\n            wrelease = writelock.release\n        else:\n            wacquire = None\n\n        while 1:\n            try:\n                nacquire()\n                try:\n                    if not buffer:\n                        nwait()\n                finally:\n                    nrelease()\n                try:\n                    while 1:\n                        obj = bpopleft()\n                        if obj is sentinel:\n                            debug('feeder thread got sentinel -- exiting')\n                            reader_close()\n                            writer_close()\n                            return\n\n                        # serialize the data before acquiring the lock\n                        obj = _ForkingPickler.dumps(obj)\n                        if wacquire is None:\n                            send_bytes(obj)\n                        else:\n                            wacquire()\n                            try:\n                                send_bytes(obj)\n                            finally:\n                                wrelease()\n                except IndexError:\n                    pass\n            except Exception as e:\n                if ignore_epipe and getattr(e, 'errno', 0) == errno.EPIPE:\n                    return\n                # Since this runs in a daemon thread the resources it uses\n                # may be become unusable while the process is cleaning up.\n                # We ignore errors which happen after the process has\n                # started to cleanup.\n                if is_exiting():\n                    info('error in queue thread: %s', e)\n                    return\n                else:\n                    # Since the object has not been sent in the queue, we need\n                    # to decrease the size of the queue. The error acts as\n                    # if the object had been silently removed from the queue\n                    # and this step is necessary to have a properly working\n                    # queue.\n                    queue_sem.release()\n                    onerror(e, obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.Queue._on_queue_feeder_error": {
        "API_name": "multiprocessing.queues.Queue._on_queue_feeder_error",
        "loc_name": "multiprocessing.queues.Queue._on_queue_feeder_error",
        "args": "e;obj",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 275,
        "namespace": "Queue",
        "body": "    def _on_queue_feeder_error(e, obj):\n        \"\"\"\n        Private API hook called when feeding data in the background thread\n        raises an exception.  For overriding by concurrent.futures.\n        \"\"\"\n        import traceback\n        traceback.print_exc()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue": {
        "API_name": "multiprocessing.queues.JoinableQueue",
        "loc_name": "multiprocessing.queues.JoinableQueue",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.queues",
        "lineno": 294,
        "namespace": "JoinableQueue",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue.__init__": {
        "API_name": "multiprocessing.queues.JoinableQueue.__init__",
        "loc_name": "multiprocessing.queues.JoinableQueue.__init__",
        "args": "self;maxsize",
        "args_default": 1,
        "filepath": "multiprocessing.queues",
        "lineno": 296,
        "namespace": "JoinableQueue",
        "body": "    def __init__(self, maxsize=0, *, ctx):\n        Queue.__init__(self, maxsize, ctx=ctx)\n        self._unfinished_tasks = ctx.Semaphore(0)\n        self._cond = ctx.Condition()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue.__getstate__": {
        "API_name": "multiprocessing.queues.JoinableQueue.__getstate__",
        "loc_name": "multiprocessing.queues.JoinableQueue.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 301,
        "namespace": "JoinableQueue",
        "body": "    def __getstate__(self):\n        return Queue.__getstate__(self) + (self._cond, self._unfinished_tasks)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue.__setstate__": {
        "API_name": "multiprocessing.queues.JoinableQueue.__setstate__",
        "loc_name": "multiprocessing.queues.JoinableQueue.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 304,
        "namespace": "JoinableQueue",
        "body": "    def __setstate__(self, state):\n        Queue.__setstate__(self, state[:-2])\n        self._cond, self._unfinished_tasks = state[-2:]",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue.put": {
        "API_name": "multiprocessing.queues.JoinableQueue.put",
        "loc_name": "multiprocessing.queues.JoinableQueue.put",
        "args": "self;obj;block;timeout",
        "args_default": 2,
        "filepath": "multiprocessing.queues",
        "lineno": 308,
        "namespace": "JoinableQueue",
        "body": "    def put(self, obj, block=True, timeout=None):\n        if self._closed:\n            raise ValueError(f\"Queue {self!r} is closed\")\n        if not self._sem.acquire(block, timeout):\n            raise Full\n\n        with self._notempty, self._cond:\n            if self._thread is None:\n                self._start_thread()\n            self._buffer.append(obj)\n            self._unfinished_tasks.release()\n            self._notempty.notify()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue.task_done": {
        "API_name": "multiprocessing.queues.JoinableQueue.task_done",
        "loc_name": "multiprocessing.queues.JoinableQueue.task_done",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 321,
        "namespace": "JoinableQueue",
        "body": "    def task_done(self):\n        with self._cond:\n            if not self._unfinished_tasks.acquire(False):\n                raise ValueError('task_done() called too many times')\n            if self._unfinished_tasks._semlock._is_zero():\n                self._cond.notify_all()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.JoinableQueue.join": {
        "API_name": "multiprocessing.queues.JoinableQueue.join",
        "loc_name": "multiprocessing.queues.JoinableQueue.join",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 328,
        "namespace": "JoinableQueue",
        "body": "    def join(self):\n        with self._cond:\n            if not self._unfinished_tasks._semlock._is_zero():\n                self._cond.wait()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue": {
        "API_name": "multiprocessing.queues.SimpleQueue",
        "loc_name": "multiprocessing.queues.SimpleQueue",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.queues",
        "lineno": 337,
        "namespace": "SimpleQueue",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.__init__": {
        "API_name": "multiprocessing.queues.SimpleQueue.__init__",
        "loc_name": "multiprocessing.queues.SimpleQueue.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 339,
        "namespace": "SimpleQueue",
        "body": "    def __init__(self, *, ctx):\n        self._reader, self._writer = connection.Pipe(duplex=False)\n        self._rlock = ctx.Lock()\n        self._poll = self._reader.poll\n        if sys.platform == 'win32':\n            self._wlock = None\n        else:\n            self._wlock = ctx.Lock()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.close": {
        "API_name": "multiprocessing.queues.SimpleQueue.close",
        "loc_name": "multiprocessing.queues.SimpleQueue.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 348,
        "namespace": "SimpleQueue",
        "body": "    def close(self):\n        self._reader.close()\n        self._writer.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.empty": {
        "API_name": "multiprocessing.queues.SimpleQueue.empty",
        "loc_name": "multiprocessing.queues.SimpleQueue.empty",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 352,
        "namespace": "SimpleQueue",
        "body": "    def empty(self):\n        return not self._poll()",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.__getstate__": {
        "API_name": "multiprocessing.queues.SimpleQueue.__getstate__",
        "loc_name": "multiprocessing.queues.SimpleQueue.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 355,
        "namespace": "SimpleQueue",
        "body": "    def __getstate__(self):\n        context.assert_spawning(self)\n        return (self._reader, self._writer, self._rlock, self._wlock)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.__setstate__": {
        "API_name": "multiprocessing.queues.SimpleQueue.__setstate__",
        "loc_name": "multiprocessing.queues.SimpleQueue.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 359,
        "namespace": "SimpleQueue",
        "body": "    def __setstate__(self, state):\n        (self._reader, self._writer, self._rlock, self._wlock) = state\n        self._poll = self._reader.poll",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.get": {
        "API_name": "multiprocessing.queues.SimpleQueue.get",
        "loc_name": "multiprocessing.queues.SimpleQueue.get",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 363,
        "namespace": "SimpleQueue",
        "body": "    def get(self):\n        with self._rlock:\n            res = self._reader.recv_bytes()\n        # unserialize the data after having released the lock\n        return _ForkingPickler.loads(res)",
        "name_type": "stdlib"
    },
    "multiprocessing.queues.SimpleQueue.put": {
        "API_name": "multiprocessing.queues.SimpleQueue.put",
        "loc_name": "multiprocessing.queues.SimpleQueue.put",
        "args": "self;obj",
        "args_default": 0,
        "filepath": "multiprocessing.queues",
        "lineno": 369,
        "namespace": "SimpleQueue",
        "body": "    def put(self, obj):\n        # serialize the data before acquiring the lock\n        obj = _ForkingPickler.dumps(obj)\n        if self._wlock is None:\n            # writes to a message oriented win32 pipe are atomic\n            self._writer.send_bytes(obj)\n        else:\n            with self._wlock:\n                self._writer.send_bytes(obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction": {
        "API_name": "multiprocessing.reduction",
        "loc_name": "multiprocessing.reduction",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.reduction",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['send_handle', 'recv_handle', 'ForkingPickler', 'register', 'dump']\nHAVE_SEND_HANDLE = (sys.platform == 'win32' or\n                    (hasattr(socket, 'CMSG_LEN') and\n                     hasattr(socket, 'SCM_RIGHTS') and\n                     hasattr(socket.socket, 'sendmsg')))\nregister = ForkingPickler.register\nif sys.platform == 'win32':\n    # Windows\n    __all__ += ['DupHandle', 'duplicate', 'steal_handle']\n    import _winapi\n\n    def duplicate(handle, target_process=None, inheritable=False,\n                  *, source_process=None):\n        '''Duplicate a handle.  (target_process is a handle not a pid!)'''\n        current_process = _winapi.GetCurrentProcess()\n        if source_process is None:\n            source_process = current_process\n        if target_process is None:\n            target_process = current_process\n        return _winapi.DuplicateHandle(\n            source_process, handle, target_process,\n            0, inheritable, _winapi.DUPLICATE_SAME_ACCESS)\n\n    def steal_handle(source_pid, handle):\n        '''Steal a handle from process identified by source_pid.'''\n        source_process_handle = _winapi.OpenProcess(\n            _winapi.PROCESS_DUP_HANDLE, False, source_pid)\n        try:\n            return _winapi.DuplicateHandle(\n                source_process_handle, handle,\n                _winapi.GetCurrentProcess(), 0, False,\n                _winapi.DUPLICATE_SAME_ACCESS | _winapi.DUPLICATE_CLOSE_SOURCE)\n        finally:\n            _winapi.CloseHandle(source_process_handle)\n\n    def send_handle(conn, handle, destination_pid):\n        '''Send a handle over a local connection.'''\n        dh = DupHandle(handle, _winapi.DUPLICATE_SAME_ACCESS, destination_pid)\n        conn.send(dh)\n\n    def recv_handle(conn):\n        '''Receive a handle over a local connection.'''\n        return conn.recv().detach()\n\n    class DupHandle(object):\n        '''Picklable wrapper for a handle.'''\n        def __init__(self, handle, access, pid=None):\n            if pid is None:\n                # We just duplicate the handle in the current process and\n                # let the receiving process steal the handle.\n                pid = os.getpid()\n            proc = _winapi.OpenProcess(_winapi.PROCESS_DUP_HANDLE, False, pid)\n            try:\n                self._handle = _winapi.DuplicateHandle(\n                    _winapi.GetCurrentProcess(),\n                    handle, proc, access, False, 0)\n            finally:\n                _winapi.CloseHandle(proc)\n            self._access = access\n            self._pid = pid\n\n        def detach(self):\n            '''Get the handle.  This should only be called once.'''\n            # retrieve handle from process which currently owns it\n            if self._pid == os.getpid():\n                # The handle has already been duplicated for this process.\n                return self._handle\n            # We must steal the handle from the process whose pid is self._pid.\n            proc = _winapi.OpenProcess(_winapi.PROCESS_DUP_HANDLE, False,\n                                       self._pid)\n            try:\n                return _winapi.DuplicateHandle(\n                    proc, self._handle, _winapi.GetCurrentProcess(),\n                    self._access, False, _winapi.DUPLICATE_CLOSE_SOURCE)\n            finally:\n                _winapi.CloseHandle(proc)\n\nelse:\n    # Unix\n    __all__ += ['DupFd', 'sendfds', 'recvfds']\n    import array\n\n    # On MacOSX we should acknowledge receipt of fds -- see Issue14669\n    ACKNOWLEDGE = sys.platform == 'darwin'\n\n    def sendfds(sock, fds):\n        '''Send an array of fds over an AF_UNIX socket.'''\n        fds = array.array('i', fds)\n        msg = bytes([len(fds) % 256])\n        sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds)])\n        if ACKNOWLEDGE and sock.recv(1) != b'A':\n            raise RuntimeError('did not receive acknowledgement of fd')\n\n    def recvfds(sock, size):\n        '''Receive an array of fds over an AF_UNIX socket.'''\n        a = array.array('i')\n        bytes_size = a.itemsize * size\n        msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))\n        if not msg and not ancdata:\n            raise EOFError\n        try:\n            if ACKNOWLEDGE:\n                sock.send(b'A')\n            if len(ancdata) != 1:\n                raise RuntimeError('received %d items of ancdata' %\n                                   len(ancdata))\n            cmsg_level, cmsg_type, cmsg_data = ancdata[0]\n            if (cmsg_level == socket.SOL_SOCKET and\n                cmsg_type == socket.SCM_RIGHTS):\n                if len(cmsg_data) % a.itemsize != 0:\n                    raise ValueError\n                a.frombytes(cmsg_data)\n                if len(a) % 256 != msg[0]:\n                    raise AssertionError(\n                        \"Len is {0:n} but msg[0] is {1!r}\".format(\n                            len(a), msg[0]))\n                return list(a)\n        except (ValueError, IndexError):\n            pass\n        raise RuntimeError('Invalid data received')\n\n    def send_handle(conn, handle, destination_pid):\n        '''Send a handle over a local connection.'''\n        with socket.fromfd(conn.fileno(), socket.AF_UNIX, socket.SOCK_STREAM) as s:\n            sendfds(s, [handle])\n\n    def recv_handle(conn):\n        '''Receive a handle over a local connection.'''\n        with socket.fromfd(conn.fileno(), socket.AF_UNIX, socket.SOCK_STREAM) as s:\n            return recvfds(s, 1)[0]\n\n    def DupFd(fd):\n        '''Return a wrapper for an fd.'''\n        popen_obj = context.get_spawning_popen()\n        if popen_obj is not None:\n            return popen_obj.DupFd(popen_obj.duplicate_for_child(fd))\n        elif HAVE_SEND_HANDLE:\n            from . import resource_sharer\n            return resource_sharer.DupFd(fd)\n        else:\n            raise ValueError('SCM_RIGHTS appears not to be available')\nregister(type(_C().f), _reduce_method)\nregister(type(list.append), _reduce_method_descriptor)\nregister(type(int.__add__), _reduce_method_descriptor)\nregister(functools.partial, _reduce_partial)\nif sys.platform == 'win32':\n    def _reduce_socket(s):\n        from .resource_sharer import DupSocket\n        return _rebuild_socket, (DupSocket(s),)\n    def _rebuild_socket(ds):\n        return ds.detach()\n    register(socket.socket, _reduce_socket)\n\nelse:\n    def _reduce_socket(s):\n        df = DupFd(s.fileno())\n        return _rebuild_socket, (df, s.family, s.type, s.proto)\n    def _rebuild_socket(df, family, type, proto):\n        fd = df.detach()\n        return socket.socket(family, type, proto, fileno=fd)\n    register(socket.socket, _reduce_socket)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.ForkingPickler": {
        "API_name": "multiprocessing.reduction.ForkingPickler",
        "loc_name": "multiprocessing.reduction.ForkingPickler",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.reduction",
        "lineno": 33,
        "namespace": "ForkingPickler",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.ForkingPickler.__init__": {
        "API_name": "multiprocessing.reduction.ForkingPickler.__init__",
        "loc_name": "multiprocessing.reduction.ForkingPickler.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 38,
        "namespace": "ForkingPickler",
        "body": "    def __init__(self, *args):\n        super().__init__(*args)\n        self.dispatch_table = self._copyreg_dispatch_table.copy()\n        self.dispatch_table.update(self._extra_reducers)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.ForkingPickler.register": {
        "API_name": "multiprocessing.reduction.ForkingPickler.register",
        "loc_name": "multiprocessing.reduction.ForkingPickler.register",
        "args": "cls;type;reduce",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 44,
        "namespace": "ForkingPickler",
        "body": "    def register(cls, type, reduce):\n        '''Register a reduce function for a type.'''\n        cls._extra_reducers[type] = reduce",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.ForkingPickler.dumps": {
        "API_name": "multiprocessing.reduction.ForkingPickler.dumps",
        "loc_name": "multiprocessing.reduction.ForkingPickler.dumps",
        "args": "cls;obj;protocol",
        "args_default": 1,
        "filepath": "multiprocessing.reduction",
        "lineno": 49,
        "namespace": "ForkingPickler",
        "body": "    def dumps(cls, obj, protocol=None):\n        buf = io.BytesIO()\n        cls(buf, protocol).dump(obj)\n        return buf.getbuffer()",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.dump": {
        "API_name": "multiprocessing.reduction.dump",
        "loc_name": "multiprocessing.reduction.dump",
        "args": "obj;file;protocol",
        "args_default": 1,
        "filepath": "multiprocessing.reduction",
        "lineno": 58,
        "namespace": "*",
        "body": "def dump(obj, file, protocol=None):\n    '''Replacement for pickle.dump() using ForkingPickler.'''\n    ForkingPickler(file, protocol).dump(obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.duplicate": {
        "API_name": "multiprocessing.reduction.duplicate",
        "loc_name": "multiprocessing.reduction.duplicate",
        "args": "handle;target_process;inheritable",
        "args_default": 2,
        "filepath": "multiprocessing.reduction",
        "lineno": 71,
        "namespace": "*",
        "body": "    def duplicate(handle, target_process=None, inheritable=False,\n                  *, source_process=None):\n        '''Duplicate a handle.  (target_process is a handle not a pid!)'''\n        current_process = _winapi.GetCurrentProcess()\n        if source_process is None:\n            source_process = current_process\n        if target_process is None:\n            target_process = current_process\n        return _winapi.DuplicateHandle(\n            source_process, handle, target_process,\n            0, inheritable, _winapi.DUPLICATE_SAME_ACCESS)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.steal_handle": {
        "API_name": "multiprocessing.reduction.steal_handle",
        "loc_name": "multiprocessing.reduction.steal_handle",
        "args": "source_pid;handle",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 83,
        "namespace": "*",
        "body": "    def steal_handle(source_pid, handle):\n        '''Steal a handle from process identified by source_pid.'''\n        source_process_handle = _winapi.OpenProcess(\n            _winapi.PROCESS_DUP_HANDLE, False, source_pid)\n        try:\n            return _winapi.DuplicateHandle(\n                source_process_handle, handle,\n                _winapi.GetCurrentProcess(), 0, False,\n                _winapi.DUPLICATE_SAME_ACCESS | _winapi.DUPLICATE_CLOSE_SOURCE)\n        finally:\n            _winapi.CloseHandle(source_process_handle)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.send_handle": {
        "API_name": "multiprocessing.reduction.send_handle",
        "loc_name": "multiprocessing.reduction.send_handle",
        "args": "conn;handle;destination_pid",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 181,
        "namespace": "*",
        "body": "    def send_handle(conn, handle, destination_pid):\n        '''Send a handle over a local connection.'''\n        with socket.fromfd(conn.fileno(), socket.AF_UNIX, socket.SOCK_STREAM) as s:\n            sendfds(s, [handle])",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.recv_handle": {
        "API_name": "multiprocessing.reduction.recv_handle",
        "loc_name": "multiprocessing.reduction.recv_handle",
        "args": "conn",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 186,
        "namespace": "*",
        "body": "    def recv_handle(conn):\n        '''Receive a handle over a local connection.'''\n        with socket.fromfd(conn.fileno(), socket.AF_UNIX, socket.SOCK_STREAM) as s:\n            return recvfds(s, 1)[0]",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.DupHandle": {
        "API_name": "multiprocessing.reduction.DupHandle",
        "loc_name": "multiprocessing.reduction.DupHandle",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.reduction",
        "lineno": 104,
        "namespace": "DupHandle",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.DupHandle.__init__": {
        "API_name": "multiprocessing.reduction.DupHandle.__init__",
        "loc_name": "multiprocessing.reduction.DupHandle.__init__",
        "args": "self;handle;access;pid",
        "args_default": 1,
        "filepath": "multiprocessing.reduction",
        "lineno": 106,
        "namespace": "DupHandle",
        "body": "        def __init__(self, handle, access, pid=None):\n            if pid is None:\n                # We just duplicate the handle in the current process and\n                # let the receiving process steal the handle.\n                pid = os.getpid()\n            proc = _winapi.OpenProcess(_winapi.PROCESS_DUP_HANDLE, False, pid)\n            try:\n                self._handle = _winapi.DuplicateHandle(\n                    _winapi.GetCurrentProcess(),\n                    handle, proc, access, False, 0)\n            finally:\n                _winapi.CloseHandle(proc)\n            self._access = access\n            self._pid = pid",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.DupHandle.detach": {
        "API_name": "multiprocessing.reduction.DupHandle.detach",
        "loc_name": "multiprocessing.reduction.DupHandle.detach",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 121,
        "namespace": "DupHandle",
        "body": "        def detach(self):\n            '''Get the handle.  This should only be called once.'''\n            # retrieve handle from process which currently owns it\n            if self._pid == os.getpid():\n                # The handle has already been duplicated for this process.\n                return self._handle\n            # We must steal the handle from the process whose pid is self._pid.\n            proc = _winapi.OpenProcess(_winapi.PROCESS_DUP_HANDLE, False,\n                                       self._pid)\n            try:\n                return _winapi.DuplicateHandle(\n                    proc, self._handle, _winapi.GetCurrentProcess(),\n                    self._access, False, _winapi.DUPLICATE_CLOSE_SOURCE)\n            finally:\n                _winapi.CloseHandle(proc)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.sendfds": {
        "API_name": "multiprocessing.reduction.sendfds",
        "loc_name": "multiprocessing.reduction.sendfds",
        "args": "sock;fds",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 145,
        "namespace": "*",
        "body": "    def sendfds(sock, fds):\n        '''Send an array of fds over an AF_UNIX socket.'''\n        fds = array.array('i', fds)\n        msg = bytes([len(fds) % 256])\n        sock.sendmsg([msg], [(socket.SOL_SOCKET, socket.SCM_RIGHTS, fds)])\n        if ACKNOWLEDGE and sock.recv(1) != b'A':\n            raise RuntimeError('did not receive acknowledgement of fd')",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.recvfds": {
        "API_name": "multiprocessing.reduction.recvfds",
        "loc_name": "multiprocessing.reduction.recvfds",
        "args": "sock;size",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 153,
        "namespace": "*",
        "body": "    def recvfds(sock, size):\n        '''Receive an array of fds over an AF_UNIX socket.'''\n        a = array.array('i')\n        bytes_size = a.itemsize * size\n        msg, ancdata, flags, addr = sock.recvmsg(1, socket.CMSG_SPACE(bytes_size))\n        if not msg and not ancdata:\n            raise EOFError\n        try:\n            if ACKNOWLEDGE:\n                sock.send(b'A')\n            if len(ancdata) != 1:\n                raise RuntimeError('received %d items of ancdata' %\n                                   len(ancdata))\n            cmsg_level, cmsg_type, cmsg_data = ancdata[0]\n            if (cmsg_level == socket.SOL_SOCKET and\n                cmsg_type == socket.SCM_RIGHTS):\n                if len(cmsg_data) % a.itemsize != 0:\n                    raise ValueError\n                a.frombytes(cmsg_data)\n                if len(a) % 256 != msg[0]:\n                    raise AssertionError(\n                        \"Len is {0:n} but msg[0] is {1!r}\".format(\n                            len(a), msg[0]))\n                return list(a)\n        except (ValueError, IndexError):\n            pass\n        raise RuntimeError('Invalid data received')",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.DupFd": {
        "API_name": "multiprocessing.reduction.DupFd",
        "loc_name": "multiprocessing.reduction.DupFd",
        "args": "fd",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 191,
        "namespace": "*",
        "body": "    def DupFd(fd):\n        '''Return a wrapper for an fd.'''\n        popen_obj = context.get_spawning_popen()\n        if popen_obj is not None:\n            return popen_obj.DupFd(popen_obj.duplicate_for_child(fd))\n        elif HAVE_SEND_HANDLE:\n            from . import resource_sharer\n            return resource_sharer.DupFd(fd)\n        else:\n            raise ValueError('SCM_RIGHTS appears not to be available')",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._reduce_method": {
        "API_name": "multiprocessing.reduction._reduce_method",
        "loc_name": "multiprocessing.reduction._reduce_method",
        "args": "m",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 206,
        "namespace": "*",
        "body": "def _reduce_method(m):\n    if m.__self__ is None:\n        return getattr, (m.__class__, m.__func__.__name__)\n    else:\n        return getattr, (m.__self__, m.__func__.__name__)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._C.f": {
        "API_name": "multiprocessing.reduction._C.f",
        "loc_name": "multiprocessing.reduction._C.f",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 212,
        "namespace": "_C",
        "body": "    def f(self):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._C": {
        "API_name": "multiprocessing.reduction._C",
        "loc_name": "multiprocessing.reduction._C",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.reduction",
        "lineno": 211,
        "namespace": "_C",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._reduce_method_descriptor": {
        "API_name": "multiprocessing.reduction._reduce_method_descriptor",
        "loc_name": "multiprocessing.reduction._reduce_method_descriptor",
        "args": "m",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 217,
        "namespace": "*",
        "body": "def _reduce_method_descriptor(m):\n    return getattr, (m.__objclass__, m.__name__)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._reduce_partial": {
        "API_name": "multiprocessing.reduction._reduce_partial",
        "loc_name": "multiprocessing.reduction._reduce_partial",
        "args": "p",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 223,
        "namespace": "*",
        "body": "def _reduce_partial(p):\n    return _rebuild_partial, (p.func, p.args, p.keywords or {})",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._rebuild_partial": {
        "API_name": "multiprocessing.reduction._rebuild_partial",
        "loc_name": "multiprocessing.reduction._rebuild_partial",
        "args": "func;args;keywords",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 225,
        "namespace": "*",
        "body": "def _rebuild_partial(func, args, keywords):\n    return functools.partial(func, *args, **keywords)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._reduce_socket": {
        "API_name": "multiprocessing.reduction._reduce_socket",
        "loc_name": "multiprocessing.reduction._reduce_socket",
        "args": "s",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 242,
        "namespace": "*",
        "body": "    def _reduce_socket(s):\n        df = DupFd(s.fileno())\n        return _rebuild_socket, (df, s.family, s.type, s.proto)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction._rebuild_socket": {
        "API_name": "multiprocessing.reduction._rebuild_socket",
        "loc_name": "multiprocessing.reduction._rebuild_socket",
        "args": "df;family;type;proto",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 245,
        "namespace": "*",
        "body": "    def _rebuild_socket(df, family, type, proto):\n        fd = df.detach()\n        return socket.socket(family, type, proto, fileno=fd)",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.AbstractReducer": {
        "API_name": "multiprocessing.reduction.AbstractReducer",
        "loc_name": "multiprocessing.reduction.AbstractReducer",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.reduction",
        "lineno": 251,
        "namespace": "AbstractReducer",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.reduction.AbstractReducer.__init__": {
        "API_name": "multiprocessing.reduction.AbstractReducer.__init__",
        "loc_name": "multiprocessing.reduction.AbstractReducer.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.reduction",
        "lineno": 276,
        "namespace": "AbstractReducer",
        "body": "    def __init__(self, *args):\n        register(type(_C().f), _reduce_method)\n        register(type(list.append), _reduce_method_descriptor)\n        register(type(int.__add__), _reduce_method_descriptor)\n        register(functools.partial, _reduce_partial)\n        register(socket.socket, _reduce_socket)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer": {
        "API_name": "multiprocessing.resource_sharer",
        "loc_name": "multiprocessing.resource_sharer",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.resource_sharer",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['stop']\nif sys.platform == 'win32':\n    __all__ += ['DupSocket']\n\n    class DupSocket(object):\n        '''Picklable wrapper for a socket.'''\n        def __init__(self, sock):\n            new_sock = sock.dup()\n            def send(conn, pid):\n                share = new_sock.share(pid)\n                conn.send_bytes(share)\n            self._id = _resource_sharer.register(send, new_sock.close)\n\n        def detach(self):\n            '''Get the socket.  This should only be called once.'''\n            with _resource_sharer.get_connection(self._id) as conn:\n                share = conn.recv_bytes()\n                return socket.fromshare(share)\n\nelse:\n    __all__ += ['DupFd']\n\n    class DupFd(object):\n        '''Wrapper for fd which can be used at any time.'''\n        def __init__(self, fd):\n            new_fd = os.dup(fd)\n            def send(conn, pid):\n                reduction.send_handle(conn, new_fd, pid)\n            def close():\n                os.close(new_fd)\n            self._id = _resource_sharer.register(send, close)\n\n        def detach(self):\n            '''Get the fd.  This should only be called once.'''\n            with _resource_sharer.get_connection(self._id) as conn:\n                return reduction.recv_handle(conn)\n_resource_sharer = _ResourceSharer()\nstop = _resource_sharer.stop",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupSocket": {
        "API_name": "multiprocessing.resource_sharer.DupSocket",
        "loc_name": "multiprocessing.resource_sharer.DupSocket",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 27,
        "namespace": "DupSocket",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupSocket.__init__": {
        "API_name": "multiprocessing.resource_sharer.DupSocket.__init__",
        "loc_name": "multiprocessing.resource_sharer.DupSocket.__init__",
        "args": "self;sock",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 29,
        "namespace": "DupSocket",
        "body": "        def __init__(self, sock):\n            new_sock = sock.dup()\n            def send(conn, pid):\n                share = new_sock.share(pid)\n                conn.send_bytes(share)\n            self._id = _resource_sharer.register(send, new_sock.close)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupSocket.__init__.send": {
        "API_name": "multiprocessing.resource_sharer.DupSocket.__init__.send",
        "loc_name": "multiprocessing.resource_sharer.DupSocket.__init__.send",
        "args": "conn;pid",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 31,
        "namespace": "DupSocket",
        "body": "            def send(conn, pid):\n                share = new_sock.share(pid)\n                conn.send_bytes(share)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupSocket.detach": {
        "API_name": "multiprocessing.resource_sharer.DupSocket.detach",
        "loc_name": "multiprocessing.resource_sharer.DupSocket.detach",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 36,
        "namespace": "DupSocket",
        "body": "        def detach(self):\n            '''Get the socket.  This should only be called once.'''\n            with _resource_sharer.get_connection(self._id) as conn:\n                share = conn.recv_bytes()\n                return socket.fromshare(share)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupFd": {
        "API_name": "multiprocessing.resource_sharer.DupFd",
        "loc_name": "multiprocessing.resource_sharer.DupFd",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 45,
        "namespace": "DupFd",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupFd.__init__": {
        "API_name": "multiprocessing.resource_sharer.DupFd.__init__",
        "loc_name": "multiprocessing.resource_sharer.DupFd.__init__",
        "args": "self;fd",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 47,
        "namespace": "DupFd",
        "body": "        def __init__(self, fd):\n            new_fd = os.dup(fd)\n            def send(conn, pid):\n                reduction.send_handle(conn, new_fd, pid)\n            def close():\n                os.close(new_fd)\n            self._id = _resource_sharer.register(send, close)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupFd.__init__.send": {
        "API_name": "multiprocessing.resource_sharer.DupFd.__init__.send",
        "loc_name": "multiprocessing.resource_sharer.DupFd.__init__.send",
        "args": "conn;pid",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 49,
        "namespace": "DupFd",
        "body": "            def send(conn, pid):\n                reduction.send_handle(conn, new_fd, pid)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupFd.__init__.close": {
        "API_name": "multiprocessing.resource_sharer.DupFd.__init__.close",
        "loc_name": "multiprocessing.resource_sharer.DupFd.__init__.close",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 51,
        "namespace": "DupFd",
        "body": "            def close():\n                os.close(new_fd)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer.DupFd.detach": {
        "API_name": "multiprocessing.resource_sharer.DupFd.detach",
        "loc_name": "multiprocessing.resource_sharer.DupFd.detach",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 55,
        "namespace": "DupFd",
        "body": "        def detach(self):\n            '''Get the fd.  This should only be called once.'''\n            with _resource_sharer.get_connection(self._id) as conn:\n                return reduction.recv_handle(conn)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 61,
        "namespace": "_ResourceSharer",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer.__init__": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer.__init__",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 63,
        "namespace": "_ResourceSharer",
        "body": "    def __init__(self):\n        self._key = 0\n        self._cache = {}\n        self._lock = threading.Lock()\n        self._listener = None\n        self._address = None\n        self._thread = None\n        util.register_after_fork(self, _ResourceSharer._afterfork)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer.register": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer.register",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer.register",
        "args": "self;send;close",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 72,
        "namespace": "_ResourceSharer",
        "body": "    def register(self, send, close):\n        '''Register resource, returning an identifier.'''\n        with self._lock:\n            if self._address is None:\n                self._start()\n            self._key += 1\n            self._cache[self._key] = (send, close)\n            return (self._address, self._key)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer.get_connection": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer.get_connection",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer.get_connection",
        "args": "ident",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 82,
        "namespace": "_ResourceSharer",
        "body": "    def get_connection(ident):\n        '''Return connection from which to receive identified resource.'''\n        from .connection import Client\n        address, key = ident\n        c = Client(address, authkey=process.current_process().authkey)\n        c.send((key, os.getpid()))\n        return c",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer.stop": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer.stop",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer.stop",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 90,
        "namespace": "_ResourceSharer",
        "body": "    def stop(self, timeout=None):\n        '''Stop the background thread and clear registered resources.'''\n        from .connection import Client\n        with self._lock:\n            if self._address is not None:\n                c = Client(self._address,\n                           authkey=process.current_process().authkey)\n                c.send(None)\n                c.close()\n                self._thread.join(timeout)\n                if self._thread.is_alive():\n                    util.sub_warning('_ResourceSharer thread did '\n                                     'not stop when asked')\n                self._listener.close()\n                self._thread = None\n                self._address = None\n                self._listener = None\n                for key, (send, close) in self._cache.items():\n                    close()\n                self._cache.clear()",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer._afterfork": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer._afterfork",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer._afterfork",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 111,
        "namespace": "_ResourceSharer",
        "body": "    def _afterfork(self):\n        for key, (send, close) in self._cache.items():\n            close()\n        self._cache.clear()\n        self._lock._at_fork_reinit()\n        if self._listener is not None:\n            self._listener.close()\n        self._listener = None\n        self._address = None\n        self._thread = None",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer._start": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer._start",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer._start",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 122,
        "namespace": "_ResourceSharer",
        "body": "    def _start(self):\n        from .connection import Listener\n        assert self._listener is None, \"Already have Listener\"\n        util.debug('starting listener and thread for sending handles')\n        self._listener = Listener(authkey=process.current_process().authkey)\n        self._address = self._listener.address\n        t = threading.Thread(target=self._serve)\n        t.daemon = True\n        t.start()\n        self._thread = t",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_sharer._ResourceSharer._serve": {
        "API_name": "multiprocessing.resource_sharer._ResourceSharer._serve",
        "loc_name": "multiprocessing.resource_sharer._ResourceSharer._serve",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_sharer",
        "lineno": 133,
        "namespace": "_ResourceSharer",
        "body": "    def _serve(self):\n        if hasattr(signal, 'pthread_sigmask'):\n            signal.pthread_sigmask(signal.SIG_BLOCK, signal.valid_signals())\n        while 1:\n            try:\n                with self._listener.accept() as conn:\n                    msg = conn.recv()\n                    if msg is None:\n                        break\n                    key, destination_pid = msg\n                    send, close = self._cache.pop(key)\n                    try:\n                        send(conn, destination_pid)\n                    finally:\n                        close()\n            except:\n                if not util.is_exiting():\n                    sys.excepthook(*sys.exc_info())",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker": {
        "API_name": "multiprocessing.resource_tracker",
        "loc_name": "multiprocessing.resource_tracker",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.resource_tracker",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['ensure_running', 'register', 'unregister']\n_HAVE_SIGMASK = hasattr(signal, 'pthread_sigmask')\n_IGNORED_SIGNALS = (signal.SIGINT, signal.SIGTERM)\n_CLEANUP_FUNCS = {\n    'noop': lambda: None,\n}\nif os.name == 'posix':\n    import _multiprocessing\n    import _posixshmem\n\n    _CLEANUP_FUNCS.update({\n        'semaphore': _multiprocessing.sem_unlink,\n        'shared_memory': _posixshmem.shm_unlink,\n    })\n_resource_tracker = ResourceTracker()\nensure_running = _resource_tracker.ensure_running\nregister = _resource_tracker.register\nunregister = _resource_tracker.unregister\ngetfd = _resource_tracker.getfd",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 46,
        "namespace": "ResourceTracker",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker.__init__": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker.__init__",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 48,
        "namespace": "ResourceTracker",
        "body": "    def __init__(self):\n        self._lock = threading.Lock()\n        self._fd = None\n        self._pid = None",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker._stop": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker._stop",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker._stop",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 53,
        "namespace": "ResourceTracker",
        "body": "    def _stop(self):\n        with self._lock:\n            if self._fd is None:\n                # not running\n                return\n\n            # closing the \"alive\" file descriptor stops main()\n            os.close(self._fd)\n            self._fd = None\n\n            os.waitpid(self._pid, 0)\n            self._pid = None",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker.getfd": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker.getfd",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker.getfd",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 66,
        "namespace": "ResourceTracker",
        "body": "    def getfd(self):\n        self.ensure_running()\n        return self._fd",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker.ensure_running": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker.ensure_running",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker.ensure_running",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 70,
        "namespace": "ResourceTracker",
        "body": "    def ensure_running(self):\n        '''Make sure that resource tracker process is running.\n\n        This can be run from any process.  Usually a child process will use\n        the resource created by its parent.'''\n        with self._lock:\n            if self._fd is not None:\n                # resource tracker was launched before, is it still running?\n                if self._check_alive():\n                    # => still alive\n                    return\n                # => dead, launch it again\n                os.close(self._fd)\n\n                # Clean-up to avoid dangling processes.\n                try:\n                    # _pid can be None if this process is a child from another\n                    # python process, which has started the resource_tracker.\n                    if self._pid is not None:\n                        os.waitpid(self._pid, 0)\n                except ChildProcessError:\n                    # The resource_tracker has already been terminated.\n                    pass\n                self._fd = None\n                self._pid = None\n\n                warnings.warn('resource_tracker: process died unexpectedly, '\n                              'relaunching.  Some resources might leak.')\n\n            fds_to_pass = []\n            try:\n                fds_to_pass.append(sys.stderr.fileno())\n            except Exception:\n                pass\n            cmd = 'from multiprocessing.resource_tracker import main;main(%d)'\n            r, w = os.pipe()\n            try:\n                fds_to_pass.append(r)\n                # process will out live us, so no need to wait on pid\n                exe = spawn.get_executable()\n                args = [exe] + util._args_from_interpreter_flags()\n                args += ['-c', cmd % r]\n                # bpo-33613: Register a signal mask that will block the signals.\n                # This signal mask will be inherited by the child that is going\n                # to be spawned and will protect the child from a race condition\n                # that can make the child die before it registers signal handlers\n                # for SIGINT and SIGTERM. The mask is unregistered after spawning\n                # the child.\n                try:\n                    if _HAVE_SIGMASK:\n                        signal.pthread_sigmask(signal.SIG_BLOCK, _IGNORED_SIGNALS)\n                    pid = util.spawnv_passfds(exe, args, fds_to_pass)\n                finally:\n                    if _HAVE_SIGMASK:\n                        signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n            except:\n                os.close(w)\n                raise\n            else:\n                self._fd = w\n                self._pid = pid\n            finally:\n                os.close(r)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker._check_alive": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker._check_alive",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker._check_alive",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 134,
        "namespace": "ResourceTracker",
        "body": "    def _check_alive(self):\n        '''Check that the pipe has not been closed by sending a probe.'''\n        try:\n            # We cannot use send here as it calls ensure_running, creating\n            # a cycle.\n            os.write(self._fd, b'PROBE:0:noop\\n')\n        except OSError:\n            return False\n        else:\n            return True",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker.register": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker.register",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker.register",
        "args": "self;name;rtype",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 145,
        "namespace": "ResourceTracker",
        "body": "    def register(self, name, rtype):\n        '''Register name of resource with resource tracker.'''\n        self._send('REGISTER', name, rtype)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker.unregister": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker.unregister",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker.unregister",
        "args": "self;name;rtype",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 149,
        "namespace": "ResourceTracker",
        "body": "    def unregister(self, name, rtype):\n        '''Unregister name of resource with resource tracker.'''\n        self._send('UNREGISTER', name, rtype)",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.ResourceTracker._send": {
        "API_name": "multiprocessing.resource_tracker.ResourceTracker._send",
        "loc_name": "multiprocessing.resource_tracker.ResourceTracker._send",
        "args": "self;cmd;name;rtype",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 153,
        "namespace": "ResourceTracker",
        "body": "    def _send(self, cmd, name, rtype):\n        self.ensure_running()\n        msg = '{0}:{1}:{2}\\n'.format(cmd, name, rtype).encode('ascii')\n        if len(name) > 512:\n            # posix guarantees that writes to a pipe of less than PIPE_BUF\n            # bytes are atomic, and that PIPE_BUF >= 512\n            raise ValueError('name too long')\n        nbytes = os.write(self._fd, msg)\n        assert nbytes == len(msg), \"nbytes {0:n} but len(msg) {1:n}\".format(\n            nbytes, len(msg))",
        "name_type": "stdlib"
    },
    "multiprocessing.resource_tracker.main": {
        "API_name": "multiprocessing.resource_tracker.main",
        "loc_name": "multiprocessing.resource_tracker.main",
        "args": "fd",
        "args_default": 0,
        "filepath": "multiprocessing.resource_tracker",
        "lineno": 171,
        "namespace": "*",
        "body": "def main(fd):\n    '''Run resource tracker.'''\n    # protect the process from ^C and \"killall python\" etc\n    signal.signal(signal.SIGINT, signal.SIG_IGN)\n    signal.signal(signal.SIGTERM, signal.SIG_IGN)\n    if _HAVE_SIGMASK:\n        signal.pthread_sigmask(signal.SIG_UNBLOCK, _IGNORED_SIGNALS)\n\n    for f in (sys.stdin, sys.stdout):\n        try:\n            f.close()\n        except Exception:\n            pass\n\n    cache = {rtype: set() for rtype in _CLEANUP_FUNCS.keys()}\n    try:\n        # keep track of registered/unregistered resources\n        with open(fd, 'rb') as f:\n            for line in f:\n                try:\n                    cmd, name, rtype = line.strip().decode('ascii').split(':')\n                    cleanup_func = _CLEANUP_FUNCS.get(rtype, None)\n                    if cleanup_func is None:\n                        raise ValueError(\n                            f'Cannot register {name} for automatic cleanup: '\n                            f'unknown resource type {rtype}')\n\n                    if cmd == 'REGISTER':\n                        cache[rtype].add(name)\n                    elif cmd == 'UNREGISTER':\n                        cache[rtype].remove(name)\n                    elif cmd == 'PROBE':\n                        pass\n                    else:\n                        raise RuntimeError('unrecognized command %r' % cmd)\n                except Exception:\n                    try:\n                        sys.excepthook(*sys.exc_info())\n                    except:\n                        pass\n    finally:\n        # all processes have terminated; cleanup any remaining resources\n        for rtype, rtype_cache in cache.items():\n            if rtype_cache:\n                try:\n                    warnings.warn('resource_tracker: There appear to be %d '\n                                  'leaked %s objects to clean up at shutdown' %\n                                  (len(rtype_cache), rtype))\n                except Exception:\n                    pass\n            for name in rtype_cache:\n                # For some reason the process which created and registered this\n                # resource has failed to unregister it. Presumably it has\n                # died.  We therefore unlink it.\n                try:\n                    try:\n                        _CLEANUP_FUNCS[rtype](name)\n                    except Exception as e:\n                        warnings.warn('resource_tracker: %r: %s' % (name, e))\n                finally:\n                    pass",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes": {
        "API_name": "multiprocessing.sharedctypes",
        "loc_name": "multiprocessing.sharedctypes",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.sharedctypes",
        "lineno": "*",
        "namespace": "*",
        "body": "_ForkingPickler = reduction.ForkingPickler\n__all__ = ['RawValue', 'RawArray', 'Value', 'Array', 'copy', 'synchronized']\ntypecode_to_type = {\n    'c': ctypes.c_char,     'u': ctypes.c_wchar,\n    'b': ctypes.c_byte,     'B': ctypes.c_ubyte,\n    'h': ctypes.c_short,    'H': ctypes.c_ushort,\n    'i': ctypes.c_int,      'I': ctypes.c_uint,\n    'l': ctypes.c_long,     'L': ctypes.c_ulong,\n    'q': ctypes.c_longlong, 'Q': ctypes.c_ulonglong,\n    'f': ctypes.c_float,    'd': ctypes.c_double\n    }\ntemplate = '''\ndef get%s(self):\n    self.acquire()\n    try:\n        return self._obj.%s\n    finally:\n        self.release()\ndef set%s(self, value):\n    self.acquire()\n    try:\n        self._obj.%s = value\n    finally:\n        self.release()\n%s = property(get%s, set%s)\n'''\nprop_cache = {}\nclass_cache = weakref.WeakKeyDictionary()",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes._new_value": {
        "API_name": "multiprocessing.sharedctypes._new_value",
        "loc_name": "multiprocessing.sharedctypes._new_value",
        "args": "type_",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 39,
        "namespace": "*",
        "body": "def _new_value(type_):\n    size = ctypes.sizeof(type_)\n    wrapper = heap.BufferWrapper(size)\n    return rebuild_ctype(type_, wrapper, None)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.RawValue": {
        "API_name": "multiprocessing.sharedctypes.RawValue",
        "loc_name": "multiprocessing.sharedctypes.RawValue",
        "args": "typecode_or_type",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 44,
        "namespace": "*",
        "body": "def RawValue(typecode_or_type, *args):\n    '''\n    Returns a ctypes object allocated from shared memory\n    '''\n    type_ = typecode_to_type.get(typecode_or_type, typecode_or_type)\n    obj = _new_value(type_)\n    ctypes.memset(ctypes.addressof(obj), 0, ctypes.sizeof(obj))\n    obj.__init__(*args)\n    return obj",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.RawArray": {
        "API_name": "multiprocessing.sharedctypes.RawArray",
        "loc_name": "multiprocessing.sharedctypes.RawArray",
        "args": "typecode_or_type;size_or_initializer",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 54,
        "namespace": "*",
        "body": "def RawArray(typecode_or_type, size_or_initializer):\n    '''\n    Returns a ctypes array allocated from shared memory\n    '''\n    type_ = typecode_to_type.get(typecode_or_type, typecode_or_type)\n    if isinstance(size_or_initializer, int):\n        type_ = type_ * size_or_initializer\n        obj = _new_value(type_)\n        ctypes.memset(ctypes.addressof(obj), 0, ctypes.sizeof(obj))\n        return obj\n    else:\n        type_ = type_ * len(size_or_initializer)\n        result = _new_value(type_)\n        result.__init__(*size_or_initializer)\n        return result",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.Value": {
        "API_name": "multiprocessing.sharedctypes.Value",
        "loc_name": "multiprocessing.sharedctypes.Value",
        "args": "typecode_or_type",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 70,
        "namespace": "*",
        "body": "def Value(typecode_or_type, *args, lock=True, ctx=None):\n    '''\n    Return a synchronization wrapper for a Value\n    '''\n    obj = RawValue(typecode_or_type, *args)\n    if lock is False:\n        return obj\n    if lock in (True, None):\n        ctx = ctx or get_context()\n        lock = ctx.RLock()\n    if not hasattr(lock, 'acquire'):\n        raise AttributeError(\"%r has no method 'acquire'\" % lock)\n    return synchronized(obj, lock, ctx=ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.Array": {
        "API_name": "multiprocessing.sharedctypes.Array",
        "loc_name": "multiprocessing.sharedctypes.Array",
        "args": "typecode_or_type;size_or_initializer",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 84,
        "namespace": "*",
        "body": "def Array(typecode_or_type, size_or_initializer, *, lock=True, ctx=None):\n    '''\n    Return a synchronization wrapper for a RawArray\n    '''\n    obj = RawArray(typecode_or_type, size_or_initializer)\n    if lock is False:\n        return obj\n    if lock in (True, None):\n        ctx = ctx or get_context()\n        lock = ctx.RLock()\n    if not hasattr(lock, 'acquire'):\n        raise AttributeError(\"%r has no method 'acquire'\" % lock)\n    return synchronized(obj, lock, ctx=ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.copy": {
        "API_name": "multiprocessing.sharedctypes.copy",
        "loc_name": "multiprocessing.sharedctypes.copy",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 98,
        "namespace": "*",
        "body": "def copy(obj):\n    new_obj = _new_value(type(obj))\n    ctypes.pointer(new_obj)[0] = obj\n    return new_obj",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.synchronized": {
        "API_name": "multiprocessing.sharedctypes.synchronized",
        "loc_name": "multiprocessing.sharedctypes.synchronized",
        "args": "obj;lock;ctx",
        "args_default": 2,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 103,
        "namespace": "*",
        "body": "def synchronized(obj, lock=None, ctx=None):\n    assert not isinstance(obj, SynchronizedBase), 'object already synchronized'\n    ctx = ctx or get_context()\n\n    if isinstance(obj, ctypes._SimpleCData):\n        return Synchronized(obj, lock, ctx)\n    elif isinstance(obj, ctypes.Array):\n        if obj._type_ is ctypes.c_char:\n            return SynchronizedString(obj, lock, ctx)\n        return SynchronizedArray(obj, lock, ctx)\n    else:\n        cls = type(obj)\n        try:\n            scls = class_cache[cls]\n        except KeyError:\n            names = [field[0] for field in cls._fields_]\n            d = {name: make_property(name) for name in names}\n            classname = 'Synchronized' + cls.__name__\n            scls = class_cache[cls] = type(classname, (SynchronizedBase,), d)\n        return scls(obj, lock, ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.reduce_ctype": {
        "API_name": "multiprocessing.sharedctypes.reduce_ctype",
        "loc_name": "multiprocessing.sharedctypes.reduce_ctype",
        "args": "obj",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 128,
        "namespace": "*",
        "body": "def reduce_ctype(obj):\n    assert_spawning(obj)\n    if isinstance(obj, ctypes.Array):\n        return rebuild_ctype, (obj._type_, obj._wrapper, obj._length_)\n    else:\n        return rebuild_ctype, (type(obj), obj._wrapper, None)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.rebuild_ctype": {
        "API_name": "multiprocessing.sharedctypes.rebuild_ctype",
        "loc_name": "multiprocessing.sharedctypes.rebuild_ctype",
        "args": "type_;wrapper;length",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 135,
        "namespace": "*",
        "body": "def rebuild_ctype(type_, wrapper, length):\n    if length is not None:\n        type_ = type_ * length\n    _ForkingPickler.register(type_, reduce_ctype)\n    buf = wrapper.create_memoryview()\n    obj = type_.from_buffer(buf)\n    obj._wrapper = wrapper\n    return obj",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.make_property": {
        "API_name": "multiprocessing.sharedctypes.make_property",
        "loc_name": "multiprocessing.sharedctypes.make_property",
        "args": "name",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 148,
        "namespace": "*",
        "body": "def make_property(name):\n    try:\n        return prop_cache[name]\n    except KeyError:\n        d = {}\n        exec(template % ((name,)*7), d)\n        prop_cache[name] = d[name]\n        return d[name]",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 180,
        "namespace": "SynchronizedBase",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.__init__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.__init__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.__init__",
        "args": "self;obj;lock;ctx",
        "args_default": 2,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 182,
        "namespace": "SynchronizedBase",
        "body": "    def __init__(self, obj, lock=None, ctx=None):\n        self._obj = obj\n        if lock:\n            self._lock = lock\n        else:\n            ctx = ctx or get_context(force=True)\n            self._lock = ctx.RLock()\n        self.acquire = self._lock.acquire\n        self.release = self._lock.release",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.__enter__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.__enter__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 192,
        "namespace": "SynchronizedBase",
        "body": "    def __enter__(self):\n        return self._lock.__enter__()",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.__exit__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.__exit__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 195,
        "namespace": "SynchronizedBase",
        "body": "    def __exit__(self, *args):\n        return self._lock.__exit__(*args)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.__reduce__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.__reduce__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 198,
        "namespace": "SynchronizedBase",
        "body": "    def __reduce__(self):\n        assert_spawning(self)\n        return synchronized, (self._obj, self._lock)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.get_obj": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.get_obj",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.get_obj",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 202,
        "namespace": "SynchronizedBase",
        "body": "    def get_obj(self):\n        return self._obj",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.get_lock": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.get_lock",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.get_lock",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 205,
        "namespace": "SynchronizedBase",
        "body": "    def get_lock(self):\n        return self._lock",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedBase.__repr__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedBase.__repr__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedBase.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 208,
        "namespace": "SynchronizedBase",
        "body": "    def __repr__(self):\n        return '<%s wrapper for %s>' % (type(self).__name__, self._obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.Synchronized": {
        "API_name": "multiprocessing.sharedctypes.Synchronized",
        "loc_name": "multiprocessing.sharedctypes.Synchronized",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 212,
        "namespace": "Synchronized",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedArray.__len__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedArray.__len__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedArray.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 218,
        "namespace": "SynchronizedArray",
        "body": "    def __len__(self):\n        return len(self._obj)",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedArray.__getitem__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedArray.__getitem__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedArray.__getitem__",
        "args": "self;i",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 221,
        "namespace": "SynchronizedArray",
        "body": "    def __getitem__(self, i):\n        with self:\n            return self._obj[i]",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedArray.__setitem__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedArray.__setitem__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedArray.__setitem__",
        "args": "self;i;value",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 225,
        "namespace": "SynchronizedArray",
        "body": "    def __setitem__(self, i, value):\n        with self:\n            self._obj[i] = value",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedArray.__getslice__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedArray.__getslice__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedArray.__getslice__",
        "args": "self;start;stop",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 229,
        "namespace": "SynchronizedArray",
        "body": "    def __getslice__(self, start, stop):\n        with self:\n            return self._obj[start:stop]",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedArray.__setslice__": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedArray.__setslice__",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedArray.__setslice__",
        "args": "self;start;stop;values",
        "args_default": 0,
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 233,
        "namespace": "SynchronizedArray",
        "body": "    def __setslice__(self, start, stop, values):\n        with self:\n            self._obj[start:stop] = values",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedArray": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedArray",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedArray",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 216,
        "namespace": "SynchronizedArray",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.sharedctypes.SynchronizedString": {
        "API_name": "multiprocessing.sharedctypes.SynchronizedString",
        "loc_name": "multiprocessing.sharedctypes.SynchronizedString",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.sharedctypes",
        "lineno": 238,
        "namespace": "SynchronizedString",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory": {
        "API_name": "multiprocessing.shared_memory",
        "loc_name": "multiprocessing.shared_memory",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.shared_memory",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Provides shared memory for direct access across processes.\n\nThe API of this package is currently provisional. Refer to the\ndocumentation for details.\n\"\"\"\n__all__ = [ 'SharedMemory', 'ShareableList' ]\nif os.name == \"nt\":\n    import _winapi\n    _USE_POSIX = False\nelse:\n    import _posixshmem\n    _USE_POSIX = True\n_O_CREX = os.O_CREAT | os.O_EXCL\n_SHM_SAFE_NAME_LENGTH = 14\nif _USE_POSIX:\n    _SHM_NAME_PREFIX = '/psm_'\nelse:\n    _SHM_NAME_PREFIX = 'wnsm_'\n_encoding = \"utf8\"",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory._make_filename": {
        "API_name": "multiprocessing.shared_memory._make_filename",
        "loc_name": "multiprocessing.shared_memory._make_filename",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 39,
        "namespace": "*",
        "body": "def _make_filename():\n    \"Create a random filename for the shared memory object.\"\n    # number of random bytes to use for name\n    nbytes = (_SHM_SAFE_NAME_LENGTH - len(_SHM_NAME_PREFIX)) // 2\n    assert nbytes >= 2, '_SHM_NAME_PREFIX too long'\n    name = _SHM_NAME_PREFIX + secrets.token_hex(nbytes)\n    assert len(name) <= _SHM_SAFE_NAME_LENGTH\n    return name",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory": {
        "API_name": "multiprocessing.shared_memory.SharedMemory",
        "loc_name": "multiprocessing.shared_memory.SharedMemory",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.shared_memory",
        "lineno": 49,
        "namespace": "SharedMemory",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.__init__": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.__init__",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.__init__",
        "args": "self;name;create;size",
        "args_default": 3,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 74,
        "namespace": "SharedMemory",
        "body": "    def __init__(self, name=None, create=False, size=0):\n        if not size >= 0:\n            raise ValueError(\"'size' must be a positive integer\")\n        if create:\n            self._flags = _O_CREX | os.O_RDWR\n            if size == 0:\n                raise ValueError(\"'size' must be a positive number different from zero\")\n        if name is None and not self._flags & os.O_EXCL:\n            raise ValueError(\"'name' can only be None if create=True\")\n\n        if _USE_POSIX:\n\n            # POSIX Shared Memory\n\n            if name is None:\n                while True:\n                    name = _make_filename()\n                    try:\n                        self._fd = _posixshmem.shm_open(\n                            name,\n                            self._flags,\n                            mode=self._mode\n                        )\n                    except FileExistsError:\n                        continue\n                    self._name = name\n                    break\n            else:\n                name = \"/\" + name if self._prepend_leading_slash else name\n                self._fd = _posixshmem.shm_open(\n                    name,\n                    self._flags,\n                    mode=self._mode\n                )\n                self._name = name\n            try:\n                if create and size:\n                    os.ftruncate(self._fd, size)\n                stats = os.fstat(self._fd)\n                size = stats.st_size\n                self._mmap = mmap.mmap(self._fd, size)\n            except OSError:\n                self.unlink()\n                raise\n\n            from .resource_tracker import register\n            register(self._name, \"shared_memory\")\n\n        else:\n\n            # Windows Named Shared Memory\n\n            if create:\n                while True:\n                    temp_name = _make_filename() if name is None else name\n                    # Create and reserve shared memory block with this name\n                    # until it can be attached to by mmap.\n                    h_map = _winapi.CreateFileMapping(\n                        _winapi.INVALID_HANDLE_VALUE,\n                        _winapi.NULL,\n                        _winapi.PAGE_READWRITE,\n                        (size >> 32) & 0xFFFFFFFF,\n                        size & 0xFFFFFFFF,\n                        temp_name\n                    )\n                    try:\n                        last_error_code = _winapi.GetLastError()\n                        if last_error_code == _winapi.ERROR_ALREADY_EXISTS:\n                            if name is not None:\n                                raise FileExistsError(\n                                    errno.EEXIST,\n                                    os.strerror(errno.EEXIST),\n                                    name,\n                                    _winapi.ERROR_ALREADY_EXISTS\n                                )\n                            else:\n                                continue\n                        self._mmap = mmap.mmap(-1, size, tagname=temp_name)\n                    finally:\n                        _winapi.CloseHandle(h_map)\n                    self._name = temp_name\n                    break\n\n            else:\n                self._name = name\n                # Dynamically determine the existing named shared memory\n                # block's size which is likely a multiple of mmap.PAGESIZE.\n                h_map = _winapi.OpenFileMapping(\n                    _winapi.FILE_MAP_READ,\n                    False,\n                    name\n                )\n                try:\n                    p_buf = _winapi.MapViewOfFile(\n                        h_map,\n                        _winapi.FILE_MAP_READ,\n                        0,\n                        0,\n                        0\n                    )\n                finally:\n                    _winapi.CloseHandle(h_map)\n                size = _winapi.VirtualQuerySize(p_buf)\n                self._mmap = mmap.mmap(-1, size, tagname=name)\n\n        self._size = size\n        self._buf = memoryview(self._mmap)",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.__del__": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.__del__",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.__del__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 182,
        "namespace": "SharedMemory",
        "body": "    def __del__(self):\n        try:\n            self.close()\n        except OSError:\n            pass",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.__reduce__": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.__reduce__",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 188,
        "namespace": "SharedMemory",
        "body": "    def __reduce__(self):\n        return (\n            self.__class__,\n            (\n                self.name,\n                False,\n                self.size,\n            ),\n        )",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.__repr__": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.__repr__",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 198,
        "namespace": "SharedMemory",
        "body": "    def __repr__(self):\n        return f'{self.__class__.__name__}({self.name!r}, size={self.size})'",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.buf": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.buf",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.buf",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 202,
        "namespace": "SharedMemory",
        "body": "    def buf(self):\n        \"A memoryview of contents of the shared memory block.\"\n        return self._buf",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.name": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.name",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.name",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 207,
        "namespace": "SharedMemory",
        "body": "    def name(self):\n        \"Unique name that identifies the shared memory block.\"\n        reported_name = self._name\n        if _USE_POSIX and self._prepend_leading_slash:\n            if self._name.startswith(\"/\"):\n                reported_name = self._name[1:]\n        return reported_name",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.size": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.size",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.size",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 216,
        "namespace": "SharedMemory",
        "body": "    def size(self):\n        \"Size in bytes.\"\n        return self._size",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.close": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.close",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 220,
        "namespace": "SharedMemory",
        "body": "    def close(self):\n        \"\"\"Closes access to the shared memory from this instance but does\n        not destroy the shared memory block.\"\"\"\n        if self._buf is not None:\n            self._buf.release()\n            self._buf = None\n        if self._mmap is not None:\n            self._mmap.close()\n            self._mmap = None\n        if _USE_POSIX and self._fd >= 0:\n            os.close(self._fd)\n            self._fd = -1",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.SharedMemory.unlink": {
        "API_name": "multiprocessing.shared_memory.SharedMemory.unlink",
        "loc_name": "multiprocessing.shared_memory.SharedMemory.unlink",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 233,
        "namespace": "SharedMemory",
        "body": "    def unlink(self):\n        \"\"\"Requests that the underlying shared memory block be destroyed.\n\n        In order to ensure proper cleanup of resources, unlink should be\n        called once (and only once) across all processes which have access\n        to the shared memory block.\"\"\"\n        if _USE_POSIX and self._name:\n            from .resource_tracker import unregister\n            _posixshmem.shm_unlink(self._name)\n            unregister(self._name, \"shared_memory\")",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList": {
        "API_name": "multiprocessing.shared_memory.ShareableList",
        "loc_name": "multiprocessing.shared_memory.ShareableList",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.shared_memory",
        "lineno": 247,
        "namespace": "ShareableList",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._extract_recreation_code": {
        "API_name": "multiprocessing.shared_memory.ShareableList._extract_recreation_code",
        "loc_name": "multiprocessing.shared_memory.ShareableList._extract_recreation_code",
        "args": "value",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 283,
        "namespace": "ShareableList",
        "body": "    def _extract_recreation_code(value):\n        \"\"\"Used in concert with _back_transforms_mapping to convert values\n        into the appropriate Python objects when retrieving them from\n        the list as well as when storing them.\"\"\"\n        if not isinstance(value, (str, bytes, None.__class__)):\n            return 0\n        elif isinstance(value, str):\n            return 1\n        elif isinstance(value, bytes):\n            return 2\n        else:\n            return 3  # NoneType",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.__init__": {
        "API_name": "multiprocessing.shared_memory.ShareableList.__init__",
        "loc_name": "multiprocessing.shared_memory.ShareableList.__init__",
        "args": "self;sequence",
        "args_default": 1,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 296,
        "namespace": "ShareableList",
        "body": "    def __init__(self, sequence=None, *, name=None):\n        if name is None or sequence is not None:\n            sequence = sequence or ()\n            _formats = [\n                self._types_mapping[type(item)]\n                    if not isinstance(item, (str, bytes))\n                    else self._types_mapping[type(item)] % (\n                        self._alignment * (len(item) // self._alignment + 1),\n                    )\n                for item in sequence\n            ]\n            self._list_len = len(_formats)\n            assert sum(len(fmt) <= 8 for fmt in _formats) == self._list_len\n            offset = 0\n            # The offsets of each list element into the shared memory's\n            # data area (0 meaning the start of the data area, not the start\n            # of the shared memory area).\n            self._allocated_offsets = [0]\n            for fmt in _formats:\n                offset += self._alignment if fmt[-1] != \"s\" else int(fmt[:-1])\n                self._allocated_offsets.append(offset)\n            _recreation_codes = [\n                self._extract_recreation_code(item) for item in sequence\n            ]\n            requested_size = struct.calcsize(\n                \"q\" + self._format_size_metainfo +\n                \"\".join(_formats) +\n                self._format_packing_metainfo +\n                self._format_back_transform_codes\n            )\n\n            self.shm = SharedMemory(name, create=True, size=requested_size)\n        else:\n            self.shm = SharedMemory(name)\n\n        if sequence is not None:\n            _enc = _encoding\n            struct.pack_into(\n                \"q\" + self._format_size_metainfo,\n                self.shm.buf,\n                0,\n                self._list_len,\n                *(self._allocated_offsets)\n            )\n            struct.pack_into(\n                \"\".join(_formats),\n                self.shm.buf,\n                self._offset_data_start,\n                *(v.encode(_enc) if isinstance(v, str) else v for v in sequence)\n            )\n            struct.pack_into(\n                self._format_packing_metainfo,\n                self.shm.buf,\n                self._offset_packing_formats,\n                *(v.encode(_enc) for v in _formats)\n            )\n            struct.pack_into(\n                self._format_back_transform_codes,\n                self.shm.buf,\n                self._offset_back_transform_codes,\n                *(_recreation_codes)\n            )\n\n        else:\n            self._list_len = len(self)  # Obtains size from offset 0 in buffer.\n            self._allocated_offsets = list(\n                struct.unpack_from(\n                    self._format_size_metainfo,\n                    self.shm.buf,\n                    1 * 8\n                )\n            )",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._get_packing_format": {
        "API_name": "multiprocessing.shared_memory.ShareableList._get_packing_format",
        "loc_name": "multiprocessing.shared_memory.ShareableList._get_packing_format",
        "args": "self;position",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 369,
        "namespace": "ShareableList",
        "body": "    def _get_packing_format(self, position):\n        \"Gets the packing format for a single value stored in the list.\"\n        position = position if position >= 0 else position + self._list_len\n        if (position >= self._list_len) or (self._list_len < 0):\n            raise IndexError(\"Requested position out of range.\")\n\n        v = struct.unpack_from(\n            \"8s\",\n            self.shm.buf,\n            self._offset_packing_formats + position * 8\n        )[0]\n        fmt = v.rstrip(b'\\x00')\n        fmt_as_str = fmt.decode(_encoding)\n\n        return fmt_as_str",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._get_back_transform": {
        "API_name": "multiprocessing.shared_memory.ShareableList._get_back_transform",
        "loc_name": "multiprocessing.shared_memory.ShareableList._get_back_transform",
        "args": "self;position",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 385,
        "namespace": "ShareableList",
        "body": "    def _get_back_transform(self, position):\n        \"Gets the back transformation function for a single value.\"\n\n        if (position >= self._list_len) or (self._list_len < 0):\n            raise IndexError(\"Requested position out of range.\")\n\n        transform_code = struct.unpack_from(\n            \"b\",\n            self.shm.buf,\n            self._offset_back_transform_codes + position\n        )[0]\n        transform_function = self._back_transforms_mapping[transform_code]\n\n        return transform_function",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._set_packing_format_and_transform": {
        "API_name": "multiprocessing.shared_memory.ShareableList._set_packing_format_and_transform",
        "loc_name": "multiprocessing.shared_memory.ShareableList._set_packing_format_and_transform",
        "args": "self;position;fmt_as_str;value",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 400,
        "namespace": "ShareableList",
        "body": "    def _set_packing_format_and_transform(self, position, fmt_as_str, value):\n        \"\"\"Sets the packing format and back transformation code for a\n        single value in the list at the specified position.\"\"\"\n\n        if (position >= self._list_len) or (self._list_len < 0):\n            raise IndexError(\"Requested position out of range.\")\n\n        struct.pack_into(\n            \"8s\",\n            self.shm.buf,\n            self._offset_packing_formats + position * 8,\n            fmt_as_str.encode(_encoding)\n        )\n\n        transform_code = self._extract_recreation_code(value)\n        struct.pack_into(\n            \"b\",\n            self.shm.buf,\n            self._offset_back_transform_codes + position,\n            transform_code\n        )",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.__getitem__": {
        "API_name": "multiprocessing.shared_memory.ShareableList.__getitem__",
        "loc_name": "multiprocessing.shared_memory.ShareableList.__getitem__",
        "args": "self;position",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 422,
        "namespace": "ShareableList",
        "body": "    def __getitem__(self, position):\n        position = position if position >= 0 else position + self._list_len\n        try:\n            offset = self._offset_data_start + self._allocated_offsets[position]\n            (v,) = struct.unpack_from(\n                self._get_packing_format(position),\n                self.shm.buf,\n                offset\n            )\n        except IndexError:\n            raise IndexError(\"index out of range\")\n\n        back_transform = self._get_back_transform(position)\n        v = back_transform(v)\n\n        return v",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.__setitem__": {
        "API_name": "multiprocessing.shared_memory.ShareableList.__setitem__",
        "loc_name": "multiprocessing.shared_memory.ShareableList.__setitem__",
        "args": "self;position;value",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 439,
        "namespace": "ShareableList",
        "body": "    def __setitem__(self, position, value):\n        position = position if position >= 0 else position + self._list_len\n        try:\n            item_offset = self._allocated_offsets[position]\n            offset = self._offset_data_start + item_offset\n            current_format = self._get_packing_format(position)\n        except IndexError:\n            raise IndexError(\"assignment index out of range\")\n\n        if not isinstance(value, (str, bytes)):\n            new_format = self._types_mapping[type(value)]\n            encoded_value = value\n        else:\n            allocated_length = self._allocated_offsets[position + 1] - item_offset\n\n            encoded_value = (value.encode(_encoding)\n                             if isinstance(value, str) else value)\n            if len(encoded_value) > allocated_length:\n                raise ValueError(\"bytes/str item exceeds available storage\")\n            if current_format[-1] == \"s\":\n                new_format = current_format\n            else:\n                new_format = self._types_mapping[str] % (\n                    allocated_length,\n                )\n\n        self._set_packing_format_and_transform(\n            position,\n            new_format,\n            value\n        )\n        struct.pack_into(new_format, self.shm.buf, offset, encoded_value)",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.__reduce__": {
        "API_name": "multiprocessing.shared_memory.ShareableList.__reduce__",
        "loc_name": "multiprocessing.shared_memory.ShareableList.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 472,
        "namespace": "ShareableList",
        "body": "    def __reduce__(self):\n        return partial(self.__class__, name=self.shm.name), ()",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.__len__": {
        "API_name": "multiprocessing.shared_memory.ShareableList.__len__",
        "loc_name": "multiprocessing.shared_memory.ShareableList.__len__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 475,
        "namespace": "ShareableList",
        "body": "    def __len__(self):\n        return struct.unpack_from(\"q\", self.shm.buf, 0)[0]",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.__repr__": {
        "API_name": "multiprocessing.shared_memory.ShareableList.__repr__",
        "loc_name": "multiprocessing.shared_memory.ShareableList.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 478,
        "namespace": "ShareableList",
        "body": "    def __repr__(self):\n        return f'{self.__class__.__name__}({list(self)}, name={self.shm.name!r})'",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.format": {
        "API_name": "multiprocessing.shared_memory.ShareableList.format",
        "loc_name": "multiprocessing.shared_memory.ShareableList.format",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 482,
        "namespace": "ShareableList",
        "body": "    def format(self):\n        \"The struct packing format used by all currently stored items.\"\n        return \"\".join(\n            self._get_packing_format(i) for i in range(self._list_len)\n        )",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._format_size_metainfo": {
        "API_name": "multiprocessing.shared_memory.ShareableList._format_size_metainfo",
        "loc_name": "multiprocessing.shared_memory.ShareableList._format_size_metainfo",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 489,
        "namespace": "ShareableList",
        "body": "    def _format_size_metainfo(self):\n        \"The struct packing format used for the items' storage offsets.\"\n        return \"q\" * (self._list_len + 1)",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._format_packing_metainfo": {
        "API_name": "multiprocessing.shared_memory.ShareableList._format_packing_metainfo",
        "loc_name": "multiprocessing.shared_memory.ShareableList._format_packing_metainfo",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 494,
        "namespace": "ShareableList",
        "body": "    def _format_packing_metainfo(self):\n        \"The struct packing format used for the items' packing formats.\"\n        return \"8s\" * self._list_len",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._format_back_transform_codes": {
        "API_name": "multiprocessing.shared_memory.ShareableList._format_back_transform_codes",
        "loc_name": "multiprocessing.shared_memory.ShareableList._format_back_transform_codes",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 499,
        "namespace": "ShareableList",
        "body": "    def _format_back_transform_codes(self):\n        \"The struct packing format used for the items' back transforms.\"\n        return \"b\" * self._list_len",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._offset_data_start": {
        "API_name": "multiprocessing.shared_memory.ShareableList._offset_data_start",
        "loc_name": "multiprocessing.shared_memory.ShareableList._offset_data_start",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 504,
        "namespace": "ShareableList",
        "body": "    def _offset_data_start(self):\n        # - 8 bytes for the list length\n        # - (N + 1) * 8 bytes for the element offsets\n        return (self._list_len + 2) * 8",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._offset_packing_formats": {
        "API_name": "multiprocessing.shared_memory.ShareableList._offset_packing_formats",
        "loc_name": "multiprocessing.shared_memory.ShareableList._offset_packing_formats",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 510,
        "namespace": "ShareableList",
        "body": "    def _offset_packing_formats(self):\n        return self._offset_data_start + self._allocated_offsets[-1]",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList._offset_back_transform_codes": {
        "API_name": "multiprocessing.shared_memory.ShareableList._offset_back_transform_codes",
        "loc_name": "multiprocessing.shared_memory.ShareableList._offset_back_transform_codes",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 514,
        "namespace": "ShareableList",
        "body": "    def _offset_back_transform_codes(self):\n        return self._offset_packing_formats + self._list_len * 8",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.count": {
        "API_name": "multiprocessing.shared_memory.ShareableList.count",
        "loc_name": "multiprocessing.shared_memory.ShareableList.count",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 517,
        "namespace": "ShareableList",
        "body": "    def count(self, value):\n        \"L.count(value) -> integer -- return number of occurrences of value.\"\n\n        return sum(value == entry for entry in self)",
        "name_type": "stdlib"
    },
    "multiprocessing.shared_memory.ShareableList.index": {
        "API_name": "multiprocessing.shared_memory.ShareableList.index",
        "loc_name": "multiprocessing.shared_memory.ShareableList.index",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.shared_memory",
        "lineno": 522,
        "namespace": "ShareableList",
        "body": "    def index(self, value):\n        \"\"\"L.index(value) -> integer -- return first index of value.\n        Raises ValueError if the value is not present.\"\"\"\n\n        for position, entry in enumerate(self):\n            if value == entry:\n                return position\n        else:\n            raise ValueError(f\"{value!r} not in this container\")",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn": {
        "API_name": "multiprocessing.spawn",
        "loc_name": "multiprocessing.spawn",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.spawn",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = ['_main', 'freeze_support', 'set_executable', 'get_executable',\n           'get_preparation_data', 'get_command_line', 'import_main_path']\nif sys.platform != 'win32':\n    WINEXE = False\n    WINSERVICE = False\nelse:\n    WINEXE = getattr(sys, 'frozen', False)\n    WINSERVICE = sys.executable.lower().endswith(\"pythonservice.exe\")\nif WINSERVICE:\n    _python_exe = os.path.join(sys.exec_prefix, 'python.exe')\nelse:\n    _python_exe = sys.executable\nold_main_modules = []",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.set_executable": {
        "API_name": "multiprocessing.spawn.set_executable",
        "loc_name": "multiprocessing.spawn.set_executable",
        "args": "exe",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 41,
        "namespace": "*",
        "body": "def set_executable(exe):\n    global _python_exe\n    _python_exe = exe",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.get_executable": {
        "API_name": "multiprocessing.spawn.get_executable",
        "loc_name": "multiprocessing.spawn.get_executable",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 45,
        "namespace": "*",
        "body": "def get_executable():\n    return _python_exe",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.is_forking": {
        "API_name": "multiprocessing.spawn.is_forking",
        "loc_name": "multiprocessing.spawn.is_forking",
        "args": "argv",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 52,
        "namespace": "*",
        "body": "def is_forking(argv):\n    '''\n    Return whether commandline indicates we are forking\n    '''\n    if len(argv) >= 2 and argv[1] == '--multiprocessing-fork':\n        return True\n    else:\n        return False",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.freeze_support": {
        "API_name": "multiprocessing.spawn.freeze_support",
        "loc_name": "multiprocessing.spawn.freeze_support",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 62,
        "namespace": "*",
        "body": "def freeze_support():\n    '''\n    Run code for process object if this in not the main process\n    '''\n    if is_forking(sys.argv):\n        kwds = {}\n        for arg in sys.argv[2:]:\n            name, value = arg.split('=')\n            if value == 'None':\n                kwds[name] = None\n            else:\n                kwds[name] = int(value)\n        spawn_main(**kwds)\n        sys.exit()",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.get_command_line": {
        "API_name": "multiprocessing.spawn.get_command_line",
        "loc_name": "multiprocessing.spawn.get_command_line",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 78,
        "namespace": "*",
        "body": "def get_command_line(**kwds):\n    '''\n    Returns prefix of command line used for spawning a child process\n    '''\n    if getattr(sys, 'frozen', False):\n        return ([sys.executable, '--multiprocessing-fork'] +\n                ['%s=%r' % item for item in kwds.items()])\n    else:\n        prog = 'from multiprocessing.spawn import spawn_main; spawn_main(%s)'\n        prog %= ', '.join('%s=%r' % item for item in kwds.items())\n        opts = util._args_from_interpreter_flags()\n        return [_python_exe] + opts + ['-c', prog, '--multiprocessing-fork']",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.spawn_main": {
        "API_name": "multiprocessing.spawn.spawn_main",
        "loc_name": "multiprocessing.spawn.spawn_main",
        "args": "pipe_handle;parent_pid;tracker_fd",
        "args_default": 2,
        "filepath": "multiprocessing.spawn",
        "lineno": 92,
        "namespace": "*",
        "body": "def spawn_main(pipe_handle, parent_pid=None, tracker_fd=None):\n    '''\n    Run code specified by data received over pipe\n    '''\n    assert is_forking(sys.argv), \"Not forking\"\n    if sys.platform == 'win32':\n        import msvcrt\n        import _winapi\n\n        if parent_pid is not None:\n            source_process = _winapi.OpenProcess(\n                _winapi.SYNCHRONIZE | _winapi.PROCESS_DUP_HANDLE,\n                False, parent_pid)\n        else:\n            source_process = None\n        new_handle = reduction.duplicate(pipe_handle,\n                                         source_process=source_process)\n        fd = msvcrt.open_osfhandle(new_handle, os.O_RDONLY)\n        parent_sentinel = source_process\n    else:\n        from . import resource_tracker\n        resource_tracker._resource_tracker._fd = tracker_fd\n        fd = pipe_handle\n        parent_sentinel = os.dup(pipe_handle)\n    exitcode = _main(fd, parent_sentinel)\n    sys.exit(exitcode)",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn._main": {
        "API_name": "multiprocessing.spawn._main",
        "loc_name": "multiprocessing.spawn._main",
        "args": "fd;parent_sentinel",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 120,
        "namespace": "*",
        "body": "def _main(fd, parent_sentinel):\n    with os.fdopen(fd, 'rb', closefd=True) as from_parent:\n        process.current_process()._inheriting = True\n        try:\n            preparation_data = reduction.pickle.load(from_parent)\n            prepare(preparation_data)\n            self = reduction.pickle.load(from_parent)\n        finally:\n            del process.current_process()._inheriting\n    return self._bootstrap(parent_sentinel)",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn._check_not_importing_main": {
        "API_name": "multiprocessing.spawn._check_not_importing_main",
        "loc_name": "multiprocessing.spawn._check_not_importing_main",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 132,
        "namespace": "*",
        "body": "def _check_not_importing_main():\n    if getattr(process.current_process(), '_inheriting', False):\n        raise RuntimeError('''\n        An attempt has been made to start a new process before the\n        current process has finished its bootstrapping phase.\n\n        This probably means that you are not using fork to start your\n        child processes and you have forgotten to use the proper idiom\n        in the main module:\n\n            if __name__ == '__main__':\n                freeze_support()\n                ...\n\n        The \"freeze_support()\" line can be omitted if the program\n        is not going to be frozen to produce an executable.''')",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.get_preparation_data": {
        "API_name": "multiprocessing.spawn.get_preparation_data",
        "loc_name": "multiprocessing.spawn.get_preparation_data",
        "args": "name",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 150,
        "namespace": "*",
        "body": "def get_preparation_data(name):\n    '''\n    Return info about parent needed by child to unpickle process object\n    '''\n    _check_not_importing_main()\n    d = dict(\n        log_to_stderr=util._log_to_stderr,\n        authkey=process.current_process().authkey,\n        )\n\n    if util._logger is not None:\n        d['log_level'] = util._logger.getEffectiveLevel()\n\n    sys_path=sys.path.copy()\n    try:\n        i = sys_path.index('')\n    except ValueError:\n        pass\n    else:\n        sys_path[i] = process.ORIGINAL_DIR\n\n    d.update(\n        name=name,\n        sys_path=sys_path,\n        sys_argv=sys.argv,\n        orig_dir=process.ORIGINAL_DIR,\n        dir=os.getcwd(),\n        start_method=get_start_method(),\n        )\n\n    # Figure out whether to initialise main in the subprocess as a module\n    # or through direct execution (or to leave it alone entirely)\n    main_module = sys.modules['__main__']\n    main_mod_name = getattr(main_module.__spec__, \"name\", None)\n    if main_mod_name is not None:\n        d['init_main_from_name'] = main_mod_name\n    elif sys.platform != 'win32' or (not WINEXE and not WINSERVICE):\n        main_path = getattr(main_module, '__file__', None)\n        if main_path is not None:\n            if (not os.path.isabs(main_path) and\n                        process.ORIGINAL_DIR is not None):\n                main_path = os.path.join(process.ORIGINAL_DIR, main_path)\n            d['init_main_from_path'] = os.path.normpath(main_path)\n\n    return d",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.prepare": {
        "API_name": "multiprocessing.spawn.prepare",
        "loc_name": "multiprocessing.spawn.prepare",
        "args": "data",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 202,
        "namespace": "*",
        "body": "def prepare(data):\n    '''\n    Try to get current process ready to unpickle process object\n    '''\n    if 'name' in data:\n        process.current_process().name = data['name']\n\n    if 'authkey' in data:\n        process.current_process().authkey = data['authkey']\n\n    if 'log_to_stderr' in data and data['log_to_stderr']:\n        util.log_to_stderr()\n\n    if 'log_level' in data:\n        util.get_logger().setLevel(data['log_level'])\n\n    if 'sys_path' in data:\n        sys.path = data['sys_path']\n\n    if 'sys_argv' in data:\n        sys.argv = data['sys_argv']\n\n    if 'dir' in data:\n        os.chdir(data['dir'])\n\n    if 'orig_dir' in data:\n        process.ORIGINAL_DIR = data['orig_dir']\n\n    if 'start_method' in data:\n        set_start_method(data['start_method'], force=True)\n\n    if 'init_main_from_name' in data:\n        _fixup_main_from_name(data['init_main_from_name'])\n    elif 'init_main_from_path' in data:\n        _fixup_main_from_path(data['init_main_from_path'])",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn._fixup_main_from_name": {
        "API_name": "multiprocessing.spawn._fixup_main_from_name",
        "loc_name": "multiprocessing.spawn._fixup_main_from_name",
        "args": "mod_name",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 240,
        "namespace": "*",
        "body": "def _fixup_main_from_name(mod_name):\n    # __main__.py files for packages, directories, zip archives, etc, run\n    # their \"main only\" code unconditionally, so we don't even try to\n    # populate anything in __main__, nor do we make any changes to\n    # __main__ attributes\n    current_main = sys.modules['__main__']\n    if mod_name == \"__main__\" or mod_name.endswith(\".__main__\"):\n        return\n\n    # If this process was forked, __main__ may already be populated\n    if getattr(current_main.__spec__, \"name\", None) == mod_name:\n        return\n\n    # Otherwise, __main__ may contain some non-main code where we need to\n    # support unpickling it properly. We rerun it as __mp_main__ and make\n    # the normal __main__ an alias to that\n    old_main_modules.append(current_main)\n    main_module = types.ModuleType(\"__mp_main__\")\n    main_content = runpy.run_module(mod_name,\n                                    run_name=\"__mp_main__\",\n                                    alter_sys=True)\n    main_module.__dict__.update(main_content)\n    sys.modules['__main__'] = sys.modules['__mp_main__'] = main_module",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn._fixup_main_from_path": {
        "API_name": "multiprocessing.spawn._fixup_main_from_path",
        "loc_name": "multiprocessing.spawn._fixup_main_from_path",
        "args": "main_path",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 265,
        "namespace": "*",
        "body": "def _fixup_main_from_path(main_path):\n    # If this process was forked, __main__ may already be populated\n    current_main = sys.modules['__main__']\n\n    # Unfortunately, the main ipython launch script historically had no\n    # \"if __name__ == '__main__'\" guard, so we work around that\n    # by treating it like a __main__.py file\n    # See https://github.com/ipython/ipython/issues/4698\n    main_name = os.path.splitext(os.path.basename(main_path))[0]\n    if main_name == 'ipython':\n        return\n\n    # Otherwise, if __file__ already has the setting we expect,\n    # there's nothing more to do\n    if getattr(current_main, '__file__', None) == main_path:\n        return\n\n    # If the parent process has sent a path through rather than a module\n    # name we assume it is an executable script that may contain\n    # non-main code that needs to be executed\n    old_main_modules.append(current_main)\n    main_module = types.ModuleType(\"__mp_main__\")\n    main_content = runpy.run_path(main_path,\n                                  run_name=\"__mp_main__\")\n    main_module.__dict__.update(main_content)\n    sys.modules['__main__'] = sys.modules['__mp_main__'] = main_module",
        "name_type": "stdlib"
    },
    "multiprocessing.spawn.import_main_path": {
        "API_name": "multiprocessing.spawn.import_main_path",
        "loc_name": "multiprocessing.spawn.import_main_path",
        "args": "main_path",
        "args_default": 0,
        "filepath": "multiprocessing.spawn",
        "lineno": 293,
        "namespace": "*",
        "body": "def import_main_path(main_path):\n    '''\n    Set sys.modules['__main__'] to module at main_path\n    '''\n    _fixup_main_from_path(main_path)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize": {
        "API_name": "multiprocessing.synchronize",
        "loc_name": "multiprocessing.synchronize",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [\n    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition', 'Event'\n    ]\ntry:\n    from _multiprocessing import SemLock, sem_unlink\nexcept (ImportError):\n    raise ImportError(\"This platform lacks a functioning sem_open\" +\n                      \" implementation, therefore, the required\" +\n                      \" synchronization primitives needed will not\" +\n                      \" function, see issue 3770.\")\nRECURSIVE_MUTEX, SEMAPHORE = list(range(2))\nSEM_VALUE_MAX = _multiprocessing.SemLock.SEM_VALUE_MAX",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock": {
        "API_name": "multiprocessing.synchronize.SemLock",
        "loc_name": "multiprocessing.synchronize.SemLock",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 46,
        "namespace": "SemLock",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock.__init__": {
        "API_name": "multiprocessing.synchronize.SemLock.__init__",
        "loc_name": "multiprocessing.synchronize.SemLock.__init__",
        "args": "self;kind;value;maxvalue",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 50,
        "namespace": "SemLock",
        "body": "    def __init__(self, kind, value, maxvalue, *, ctx):\n        if ctx is None:\n            ctx = context._default_context.get_context()\n        name = ctx.get_start_method()\n        unlink_now = sys.platform == 'win32' or name == 'fork'\n        for i in range(100):\n            try:\n                sl = self._semlock = _multiprocessing.SemLock(\n                    kind, value, maxvalue, self._make_name(),\n                    unlink_now)\n            except FileExistsError:\n                pass\n            else:\n                break\n        else:\n            raise FileExistsError('cannot find name for semaphore')\n\n        util.debug('created semlock with handle %s' % sl.handle)\n        self._make_methods()\n\n        if sys.platform != 'win32':\n            def _after_fork(obj):\n                obj._semlock._after_fork()\n            util.register_after_fork(self, _after_fork)\n\n        if self._semlock.name is not None:\n            # We only get here if we are on Unix with forking\n            # disabled.  When the object is garbage collected or the\n            # process shuts down we unlink the semaphore name\n            from .resource_tracker import register\n            register(self._semlock.name, \"semaphore\")\n            util.Finalize(self, SemLock._cleanup, (self._semlock.name,),\n                          exitpriority=0)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock._cleanup": {
        "API_name": "multiprocessing.synchronize.SemLock._cleanup",
        "loc_name": "multiprocessing.synchronize.SemLock._cleanup",
        "args": "name",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 85,
        "namespace": "SemLock",
        "body": "    def _cleanup(name):\n        from .resource_tracker import unregister\n        sem_unlink(name)\n        unregister(name, \"semaphore\")",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock._make_methods": {
        "API_name": "multiprocessing.synchronize.SemLock._make_methods",
        "loc_name": "multiprocessing.synchronize.SemLock._make_methods",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 90,
        "namespace": "SemLock",
        "body": "    def _make_methods(self):\n        self.acquire = self._semlock.acquire\n        self.release = self._semlock.release",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock.__enter__": {
        "API_name": "multiprocessing.synchronize.SemLock.__enter__",
        "loc_name": "multiprocessing.synchronize.SemLock.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 94,
        "namespace": "SemLock",
        "body": "    def __enter__(self):\n        return self._semlock.__enter__()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock.__exit__": {
        "API_name": "multiprocessing.synchronize.SemLock.__exit__",
        "loc_name": "multiprocessing.synchronize.SemLock.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 97,
        "namespace": "SemLock",
        "body": "    def __exit__(self, *args):\n        return self._semlock.__exit__(*args)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock.__getstate__": {
        "API_name": "multiprocessing.synchronize.SemLock.__getstate__",
        "loc_name": "multiprocessing.synchronize.SemLock.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 100,
        "namespace": "SemLock",
        "body": "    def __getstate__(self):\n        context.assert_spawning(self)\n        sl = self._semlock\n        if sys.platform == 'win32':\n            h = context.get_spawning_popen().duplicate_for_child(sl.handle)\n        else:\n            h = sl.handle\n        return (h, sl.kind, sl.maxvalue, sl.name)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock.__setstate__": {
        "API_name": "multiprocessing.synchronize.SemLock.__setstate__",
        "loc_name": "multiprocessing.synchronize.SemLock.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 109,
        "namespace": "SemLock",
        "body": "    def __setstate__(self, state):\n        self._semlock = _multiprocessing.SemLock._rebuild(*state)\n        util.debug('recreated blocker with handle %r' % state[0])\n        self._make_methods()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.SemLock._make_name": {
        "API_name": "multiprocessing.synchronize.SemLock._make_name",
        "loc_name": "multiprocessing.synchronize.SemLock._make_name",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 115,
        "namespace": "SemLock",
        "body": "    def _make_name():\n        return '%s-%s' % (process.current_process()._config['semprefix'],\n                          next(SemLock._rand))",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Semaphore": {
        "API_name": "multiprocessing.synchronize.Semaphore",
        "loc_name": "multiprocessing.synchronize.Semaphore",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 123,
        "namespace": "Semaphore",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Semaphore.__init__": {
        "API_name": "multiprocessing.synchronize.Semaphore.__init__",
        "loc_name": "multiprocessing.synchronize.Semaphore.__init__",
        "args": "self;value",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 125,
        "namespace": "Semaphore",
        "body": "    def __init__(self, value=1, *, ctx):\n        SemLock.__init__(self, SEMAPHORE, value, SEM_VALUE_MAX, ctx=ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Semaphore.get_value": {
        "API_name": "multiprocessing.synchronize.Semaphore.get_value",
        "loc_name": "multiprocessing.synchronize.Semaphore.get_value",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 128,
        "namespace": "Semaphore",
        "body": "    def get_value(self):\n        return self._semlock._get_value()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Semaphore.__repr__": {
        "API_name": "multiprocessing.synchronize.Semaphore.__repr__",
        "loc_name": "multiprocessing.synchronize.Semaphore.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 131,
        "namespace": "Semaphore",
        "body": "    def __repr__(self):\n        try:\n            value = self._semlock._get_value()\n        except Exception:\n            value = 'unknown'\n        return '<%s(value=%s)>' % (self.__class__.__name__, value)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.BoundedSemaphore": {
        "API_name": "multiprocessing.synchronize.BoundedSemaphore",
        "loc_name": "multiprocessing.synchronize.BoundedSemaphore",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 142,
        "namespace": "BoundedSemaphore",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.BoundedSemaphore.__init__": {
        "API_name": "multiprocessing.synchronize.BoundedSemaphore.__init__",
        "loc_name": "multiprocessing.synchronize.BoundedSemaphore.__init__",
        "args": "self;value",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 144,
        "namespace": "BoundedSemaphore",
        "body": "    def __init__(self, value=1, *, ctx):\n        SemLock.__init__(self, SEMAPHORE, value, value, ctx=ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.BoundedSemaphore.__repr__": {
        "API_name": "multiprocessing.synchronize.BoundedSemaphore.__repr__",
        "loc_name": "multiprocessing.synchronize.BoundedSemaphore.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 147,
        "namespace": "BoundedSemaphore",
        "body": "    def __repr__(self):\n        try:\n            value = self._semlock._get_value()\n        except Exception:\n            value = 'unknown'\n        return '<%s(value=%s, maxvalue=%s)>' % \\\n               (self.__class__.__name__, value, self._semlock.maxvalue)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Lock": {
        "API_name": "multiprocessing.synchronize.Lock",
        "loc_name": "multiprocessing.synchronize.Lock",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 159,
        "namespace": "Lock",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Lock.__init__": {
        "API_name": "multiprocessing.synchronize.Lock.__init__",
        "loc_name": "multiprocessing.synchronize.Lock.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 161,
        "namespace": "Lock",
        "body": "    def __init__(self, *, ctx):\n        SemLock.__init__(self, SEMAPHORE, 1, 1, ctx=ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Lock.__repr__": {
        "API_name": "multiprocessing.synchronize.Lock.__repr__",
        "loc_name": "multiprocessing.synchronize.Lock.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 164,
        "namespace": "Lock",
        "body": "    def __repr__(self):\n        try:\n            if self._semlock._is_mine():\n                name = process.current_process().name\n                if threading.current_thread().name != 'MainThread':\n                    name += '|' + threading.current_thread().name\n            elif self._semlock._get_value() == 1:\n                name = 'None'\n            elif self._semlock._count() > 0:\n                name = 'SomeOtherThread'\n            else:\n                name = 'SomeOtherProcess'\n        except Exception:\n            name = 'unknown'\n        return '<%s(owner=%s)>' % (self.__class__.__name__, name)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.RLock": {
        "API_name": "multiprocessing.synchronize.RLock",
        "loc_name": "multiprocessing.synchronize.RLock",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 184,
        "namespace": "RLock",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.RLock.__init__": {
        "API_name": "multiprocessing.synchronize.RLock.__init__",
        "loc_name": "multiprocessing.synchronize.RLock.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 186,
        "namespace": "RLock",
        "body": "    def __init__(self, *, ctx):\n        SemLock.__init__(self, RECURSIVE_MUTEX, 1, 1, ctx=ctx)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.RLock.__repr__": {
        "API_name": "multiprocessing.synchronize.RLock.__repr__",
        "loc_name": "multiprocessing.synchronize.RLock.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 189,
        "namespace": "RLock",
        "body": "    def __repr__(self):\n        try:\n            if self._semlock._is_mine():\n                name = process.current_process().name\n                if threading.current_thread().name != 'MainThread':\n                    name += '|' + threading.current_thread().name\n                count = self._semlock._count()\n            elif self._semlock._get_value() == 1:\n                name, count = 'None', 0\n            elif self._semlock._count() > 0:\n                name, count = 'SomeOtherThread', 'nonzero'\n            else:\n                name, count = 'SomeOtherProcess', 'nonzero'\n        except Exception:\n            name, count = 'unknown', 'unknown'\n        return '<%s(%s, %s)>' % (self.__class__.__name__, name, count)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition": {
        "API_name": "multiprocessing.synchronize.Condition",
        "loc_name": "multiprocessing.synchronize.Condition",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 210,
        "namespace": "Condition",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.__init__": {
        "API_name": "multiprocessing.synchronize.Condition.__init__",
        "loc_name": "multiprocessing.synchronize.Condition.__init__",
        "args": "self;lock",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 212,
        "namespace": "Condition",
        "body": "    def __init__(self, lock=None, *, ctx):\n        self._lock = lock or ctx.RLock()\n        self._sleeping_count = ctx.Semaphore(0)\n        self._woken_count = ctx.Semaphore(0)\n        self._wait_semaphore = ctx.Semaphore(0)\n        self._make_methods()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.__getstate__": {
        "API_name": "multiprocessing.synchronize.Condition.__getstate__",
        "loc_name": "multiprocessing.synchronize.Condition.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 219,
        "namespace": "Condition",
        "body": "    def __getstate__(self):\n        context.assert_spawning(self)\n        return (self._lock, self._sleeping_count,\n                self._woken_count, self._wait_semaphore)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.__setstate__": {
        "API_name": "multiprocessing.synchronize.Condition.__setstate__",
        "loc_name": "multiprocessing.synchronize.Condition.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 224,
        "namespace": "Condition",
        "body": "    def __setstate__(self, state):\n        (self._lock, self._sleeping_count,\n         self._woken_count, self._wait_semaphore) = state\n        self._make_methods()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.__enter__": {
        "API_name": "multiprocessing.synchronize.Condition.__enter__",
        "loc_name": "multiprocessing.synchronize.Condition.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 229,
        "namespace": "Condition",
        "body": "    def __enter__(self):\n        return self._lock.__enter__()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.__exit__": {
        "API_name": "multiprocessing.synchronize.Condition.__exit__",
        "loc_name": "multiprocessing.synchronize.Condition.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 232,
        "namespace": "Condition",
        "body": "    def __exit__(self, *args):\n        return self._lock.__exit__(*args)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition._make_methods": {
        "API_name": "multiprocessing.synchronize.Condition._make_methods",
        "loc_name": "multiprocessing.synchronize.Condition._make_methods",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 235,
        "namespace": "Condition",
        "body": "    def _make_methods(self):\n        self.acquire = self._lock.acquire\n        self.release = self._lock.release",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.__repr__": {
        "API_name": "multiprocessing.synchronize.Condition.__repr__",
        "loc_name": "multiprocessing.synchronize.Condition.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 239,
        "namespace": "Condition",
        "body": "    def __repr__(self):\n        try:\n            num_waiters = (self._sleeping_count._semlock._get_value() -\n                           self._woken_count._semlock._get_value())\n        except Exception:\n            num_waiters = 'unknown'\n        return '<%s(%s, %s)>' % (self.__class__.__name__, self._lock, num_waiters)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.wait": {
        "API_name": "multiprocessing.synchronize.Condition.wait",
        "loc_name": "multiprocessing.synchronize.Condition.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 247,
        "namespace": "Condition",
        "body": "    def wait(self, timeout=None):\n        assert self._lock._semlock._is_mine(), \\\n               'must acquire() condition before using wait()'\n\n        # indicate that this thread is going to sleep\n        self._sleeping_count.release()\n\n        # release lock\n        count = self._lock._semlock._count()\n        for i in range(count):\n            self._lock.release()\n\n        try:\n            # wait for notification or timeout\n            return self._wait_semaphore.acquire(True, timeout)\n        finally:\n            # indicate that this thread has woken\n            self._woken_count.release()\n\n            # reacquire lock\n            for i in range(count):\n                self._lock.acquire()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.notify": {
        "API_name": "multiprocessing.synchronize.Condition.notify",
        "loc_name": "multiprocessing.synchronize.Condition.notify",
        "args": "self;n",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 270,
        "namespace": "Condition",
        "body": "    def notify(self, n=1):\n        assert self._lock._semlock._is_mine(), 'lock is not owned'\n        assert not self._wait_semaphore.acquire(\n            False), ('notify: Should not have been able to acquire '\n                     + '_wait_semaphore')\n\n        # to take account of timeouts since last notify*() we subtract\n        # woken_count from sleeping_count and rezero woken_count\n        while self._woken_count.acquire(False):\n            res = self._sleeping_count.acquire(False)\n            assert res, ('notify: Bug in sleeping_count.acquire'\n                         + '- res should not be False')\n\n        sleepers = 0\n        while sleepers < n and self._sleeping_count.acquire(False):\n            self._wait_semaphore.release()        # wake up one sleeper\n            sleepers += 1\n\n        if sleepers:\n            for i in range(sleepers):\n                self._woken_count.acquire()       # wait for a sleeper to wake\n\n            # rezero wait_semaphore in case some timeouts just happened\n            while self._wait_semaphore.acquire(False):\n                pass",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.notify_all": {
        "API_name": "multiprocessing.synchronize.Condition.notify_all",
        "loc_name": "multiprocessing.synchronize.Condition.notify_all",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 296,
        "namespace": "Condition",
        "body": "    def notify_all(self):\n        self.notify(n=sys.maxsize)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Condition.wait_for": {
        "API_name": "multiprocessing.synchronize.Condition.wait_for",
        "loc_name": "multiprocessing.synchronize.Condition.wait_for",
        "args": "self;predicate;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 299,
        "namespace": "Condition",
        "body": "    def wait_for(self, predicate, timeout=None):\n        result = predicate()\n        if result:\n            return result\n        if timeout is not None:\n            endtime = time.monotonic() + timeout\n        else:\n            endtime = None\n            waittime = None\n        while not result:\n            if endtime is not None:\n                waittime = endtime - time.monotonic()\n                if waittime <= 0:\n                    break\n            self.wait(waittime)\n            result = predicate()\n        return result",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Event": {
        "API_name": "multiprocessing.synchronize.Event",
        "loc_name": "multiprocessing.synchronize.Event",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 321,
        "namespace": "Event",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Event.__init__": {
        "API_name": "multiprocessing.synchronize.Event.__init__",
        "loc_name": "multiprocessing.synchronize.Event.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 323,
        "namespace": "Event",
        "body": "    def __init__(self, *, ctx):\n        self._cond = ctx.Condition(ctx.Lock())\n        self._flag = ctx.Semaphore(0)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Event.is_set": {
        "API_name": "multiprocessing.synchronize.Event.is_set",
        "loc_name": "multiprocessing.synchronize.Event.is_set",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 327,
        "namespace": "Event",
        "body": "    def is_set(self):\n        with self._cond:\n            if self._flag.acquire(False):\n                self._flag.release()\n                return True\n            return False",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Event.set": {
        "API_name": "multiprocessing.synchronize.Event.set",
        "loc_name": "multiprocessing.synchronize.Event.set",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 334,
        "namespace": "Event",
        "body": "    def set(self):\n        with self._cond:\n            self._flag.acquire(False)\n            self._flag.release()\n            self._cond.notify_all()",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Event.clear": {
        "API_name": "multiprocessing.synchronize.Event.clear",
        "loc_name": "multiprocessing.synchronize.Event.clear",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 340,
        "namespace": "Event",
        "body": "    def clear(self):\n        with self._cond:\n            self._flag.acquire(False)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Event.wait": {
        "API_name": "multiprocessing.synchronize.Event.wait",
        "loc_name": "multiprocessing.synchronize.Event.wait",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.synchronize",
        "lineno": 344,
        "namespace": "Event",
        "body": "    def wait(self, timeout=None):\n        with self._cond:\n            if self._flag.acquire(False):\n                self._flag.release()\n            else:\n                self._cond.wait(timeout)\n\n            if self._flag.acquire(False):\n                self._flag.release()\n                return True\n            return False",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Barrier": {
        "API_name": "multiprocessing.synchronize.Barrier",
        "loc_name": "multiprocessing.synchronize.Barrier",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.synchronize",
        "lineno": 360,
        "namespace": "Barrier",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Barrier.__init__": {
        "API_name": "multiprocessing.synchronize.Barrier.__init__",
        "loc_name": "multiprocessing.synchronize.Barrier.__init__",
        "args": "self;parties;action;timeout",
        "args_default": 2,
        "filepath": "multiprocessing.synchronize",
        "lineno": 362,
        "namespace": "Barrier",
        "body": "    def __init__(self, parties, action=None, timeout=None, *, ctx):\n        import struct\n        from .heap import BufferWrapper\n        wrapper = BufferWrapper(struct.calcsize('i') * 2)\n        cond = ctx.Condition()\n        self.__setstate__((parties, action, timeout, cond, wrapper))\n        self._state = 0\n        self._count = 0",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Barrier.__setstate__": {
        "API_name": "multiprocessing.synchronize.Barrier.__setstate__",
        "loc_name": "multiprocessing.synchronize.Barrier.__setstate__",
        "args": "self;state",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 371,
        "namespace": "Barrier",
        "body": "    def __setstate__(self, state):\n        (self._parties, self._action, self._timeout,\n         self._cond, self._wrapper) = state\n        self._array = self._wrapper.create_memoryview().cast('i')",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Barrier.__getstate__": {
        "API_name": "multiprocessing.synchronize.Barrier.__getstate__",
        "loc_name": "multiprocessing.synchronize.Barrier.__getstate__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 376,
        "namespace": "Barrier",
        "body": "    def __getstate__(self):\n        return (self._parties, self._action, self._timeout,\n                self._cond, self._wrapper)",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Barrier._state": {
        "API_name": "multiprocessing.synchronize.Barrier._state",
        "loc_name": "multiprocessing.synchronize.Barrier._state",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 385,
        "namespace": "Barrier",
        "body": "    def _state(self, value):\n        self._array[0] = value",
        "name_type": "stdlib"
    },
    "multiprocessing.synchronize.Barrier._count": {
        "API_name": "multiprocessing.synchronize.Barrier._count",
        "loc_name": "multiprocessing.synchronize.Barrier._count",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.synchronize",
        "lineno": 393,
        "namespace": "Barrier",
        "body": "    def _count(self, value):\n        self._array[1] = value",
        "name_type": "stdlib"
    },
    "multiprocessing.util": {
        "API_name": "multiprocessing.util",
        "loc_name": "multiprocessing.util",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.util",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [\n    'sub_debug', 'debug', 'info', 'sub_warning', 'get_logger',\n    'log_to_stderr', 'get_temp_dir', 'register_after_fork',\n    'is_exiting', 'Finalize', 'ForkAwareThreadLock', 'ForkAwareLocal',\n    'close_all_fds_except', 'SUBDEBUG', 'SUBWARNING',\n    ]\nNOTSET = 0\nSUBDEBUG = 5\nDEBUG = 10\nINFO = 20\nSUBWARNING = 25\nLOGGER_NAME = 'multiprocessing'\nDEFAULT_LOGGING_FORMAT = '[%(levelname)s/%(processName)s] %(message)s'\n_logger = None\n_log_to_stderr = False\nabstract_sockets_supported = _platform_supports_abstract_sockets()\n_afterfork_registry = weakref.WeakValueDictionary()\n_afterfork_counter = itertools.count()\n_finalizer_registry = {}\n_finalizer_counter = itertools.count()\n_exiting = False\natexit.register(_exit_function)\ntry:\n    MAXFD = os.sysconf(\"SC_OPEN_MAX\")\nexcept Exception:\n    MAXFD = 256",
        "name_type": "stdlib"
    },
    "multiprocessing.util.sub_debug": {
        "API_name": "multiprocessing.util.sub_debug",
        "loc_name": "multiprocessing.util.sub_debug",
        "args": "msg",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 44,
        "namespace": "*",
        "body": "def sub_debug(msg, *args):\n    if _logger:\n        _logger.log(SUBDEBUG, msg, *args)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.debug": {
        "API_name": "multiprocessing.util.debug",
        "loc_name": "multiprocessing.util.debug",
        "args": "msg",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 48,
        "namespace": "*",
        "body": "def debug(msg, *args):\n    if _logger:\n        _logger.log(DEBUG, msg, *args)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.info": {
        "API_name": "multiprocessing.util.info",
        "loc_name": "multiprocessing.util.info",
        "args": "msg",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 52,
        "namespace": "*",
        "body": "def info(msg, *args):\n    if _logger:\n        _logger.log(INFO, msg, *args)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.sub_warning": {
        "API_name": "multiprocessing.util.sub_warning",
        "loc_name": "multiprocessing.util.sub_warning",
        "args": "msg",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 56,
        "namespace": "*",
        "body": "def sub_warning(msg, *args):\n    if _logger:\n        _logger.log(SUBWARNING, msg, *args)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.get_logger": {
        "API_name": "multiprocessing.util.get_logger",
        "loc_name": "multiprocessing.util.get_logger",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 60,
        "namespace": "*",
        "body": "def get_logger():\n    '''\n    Returns logger used by multiprocessing\n    '''\n    global _logger\n    import logging\n\n    logging._acquireLock()\n    try:\n        if not _logger:\n\n            _logger = logging.getLogger(LOGGER_NAME)\n            _logger.propagate = 0\n\n            # XXX multiprocessing should cleanup before logging\n            if hasattr(atexit, 'unregister'):\n                atexit.unregister(_exit_function)\n                atexit.register(_exit_function)\n            else:\n                atexit._exithandlers.remove((_exit_function, (), {}))\n                atexit._exithandlers.append((_exit_function, (), {}))\n\n    finally:\n        logging._releaseLock()\n\n    return _logger",
        "name_type": "stdlib"
    },
    "multiprocessing.util.log_to_stderr": {
        "API_name": "multiprocessing.util.log_to_stderr",
        "loc_name": "multiprocessing.util.log_to_stderr",
        "args": "level",
        "args_default": 1,
        "filepath": "multiprocessing.util",
        "lineno": 87,
        "namespace": "*",
        "body": "def log_to_stderr(level=None):\n    '''\n    Turn on logging and add a handler which prints to stderr\n    '''\n    global _log_to_stderr\n    import logging\n\n    logger = get_logger()\n    formatter = logging.Formatter(DEFAULT_LOGGING_FORMAT)\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    logger.addHandler(handler)\n\n    if level:\n        logger.setLevel(level)\n    _log_to_stderr = True\n    return _logger",
        "name_type": "stdlib"
    },
    "multiprocessing.util._platform_supports_abstract_sockets": {
        "API_name": "multiprocessing.util._platform_supports_abstract_sockets",
        "loc_name": "multiprocessing.util._platform_supports_abstract_sockets",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 108,
        "namespace": "*",
        "body": "def _platform_supports_abstract_sockets():\n    if sys.platform == \"linux\":\n        return True\n    if hasattr(sys, 'getandroidapilevel'):\n        return True\n    return False",
        "name_type": "stdlib"
    },
    "multiprocessing.util.is_abstract_socket_namespace": {
        "API_name": "multiprocessing.util.is_abstract_socket_namespace",
        "loc_name": "multiprocessing.util.is_abstract_socket_namespace",
        "args": "address",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 116,
        "namespace": "*",
        "body": "def is_abstract_socket_namespace(address):\n    if not address:\n        return False\n    if isinstance(address, bytes):\n        return address[0] == 0\n    elif isinstance(address, str):\n        return address[0] == \"\\0\"\n    raise TypeError(f'address type of {address!r} unrecognized')",
        "name_type": "stdlib"
    },
    "multiprocessing.util._remove_temp_dir": {
        "API_name": "multiprocessing.util._remove_temp_dir",
        "loc_name": "multiprocessing.util._remove_temp_dir",
        "args": "rmtree;tempdir",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 132,
        "namespace": "*",
        "body": "def _remove_temp_dir(rmtree, tempdir):\n    rmtree(tempdir)\n\n    current_process = process.current_process()\n    # current_process() can be None if the finalizer is called\n    # late during Python finalization\n    if current_process is not None:\n        current_process._config['tempdir'] = None",
        "name_type": "stdlib"
    },
    "multiprocessing.util.get_temp_dir": {
        "API_name": "multiprocessing.util.get_temp_dir",
        "loc_name": "multiprocessing.util.get_temp_dir",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 141,
        "namespace": "*",
        "body": "def get_temp_dir():\n    # get name of a temp directory which will be automatically cleaned up\n    tempdir = process.current_process()._config.get('tempdir')\n    if tempdir is None:\n        import shutil, tempfile\n        tempdir = tempfile.mkdtemp(prefix='pymp-')\n        info('created temp directory %s', tempdir)\n        # keep a strong reference to shutil.rmtree(), since the finalizer\n        # can be called late during Python shutdown\n        Finalize(None, _remove_temp_dir, args=(shutil.rmtree, tempdir),\n                 exitpriority=-100)\n        process.current_process()._config['tempdir'] = tempdir\n    return tempdir",
        "name_type": "stdlib"
    },
    "multiprocessing.util._run_after_forkers": {
        "API_name": "multiprocessing.util._run_after_forkers",
        "loc_name": "multiprocessing.util._run_after_forkers",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 162,
        "namespace": "*",
        "body": "def _run_after_forkers():\n    items = list(_afterfork_registry.items())\n    items.sort()\n    for (index, ident, func), obj in items:\n        try:\n            func(obj)\n        except Exception as e:\n            info('after forker raised exception %s', e)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.register_after_fork": {
        "API_name": "multiprocessing.util.register_after_fork",
        "loc_name": "multiprocessing.util.register_after_fork",
        "args": "obj;func",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 171,
        "namespace": "*",
        "body": "def register_after_fork(obj, func):\n    _afterfork_registry[(next(_afterfork_counter), id(obj), func)] = obj",
        "name_type": "stdlib"
    },
    "multiprocessing.util.Finalize": {
        "API_name": "multiprocessing.util.Finalize",
        "loc_name": "multiprocessing.util.Finalize",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.util",
        "lineno": 182,
        "namespace": "Finalize",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.util.Finalize.__init__": {
        "API_name": "multiprocessing.util.Finalize.__init__",
        "loc_name": "multiprocessing.util.Finalize.__init__",
        "args": "self;obj;callback;args;kwargs;exitpriority",
        "args_default": 3,
        "filepath": "multiprocessing.util",
        "lineno": 186,
        "namespace": "Finalize",
        "body": "    def __init__(self, obj, callback, args=(), kwargs=None, exitpriority=None):\n        if (exitpriority is not None) and not isinstance(exitpriority,int):\n            raise TypeError(\n                \"Exitpriority ({0!r}) must be None or int, not {1!s}\".format(\n                    exitpriority, type(exitpriority)))\n\n        if obj is not None:\n            self._weakref = weakref.ref(obj, self)\n        elif exitpriority is None:\n            raise ValueError(\"Without object, exitpriority cannot be None\")\n\n        self._callback = callback\n        self._args = args\n        self._kwargs = kwargs or {}\n        self._key = (exitpriority, next(_finalizer_counter))\n        self._pid = os.getpid()\n\n        _finalizer_registry[self._key] = self",
        "name_type": "stdlib"
    },
    "multiprocessing.util.Finalize.__call__": {
        "API_name": "multiprocessing.util.Finalize.__call__",
        "loc_name": "multiprocessing.util.Finalize.__call__",
        "args": "self;wr;_finalizer_registry;sub_debug;getpid",
        "args_default": 4,
        "filepath": "multiprocessing.util",
        "lineno": 205,
        "namespace": "Finalize",
        "body": "    def __call__(self, wr=None,\n                 # Need to bind these locally because the globals can have\n                 # been cleared at shutdown\n                 _finalizer_registry=_finalizer_registry,\n                 sub_debug=sub_debug, getpid=os.getpid):\n        '''\n        Run the callback unless it has already been called or cancelled\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            sub_debug('finalizer no longer registered')\n        else:\n            if self._pid != getpid():\n                sub_debug('finalizer ignored because different process')\n                res = None\n            else:\n                sub_debug('finalizer calling %s with args %s and kwargs %s',\n                          self._callback, self._args, self._kwargs)\n                res = self._callback(*self._args, **self._kwargs)\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None\n            return res",
        "name_type": "stdlib"
    },
    "multiprocessing.util.Finalize.cancel": {
        "API_name": "multiprocessing.util.Finalize.cancel",
        "loc_name": "multiprocessing.util.Finalize.cancel",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 229,
        "namespace": "Finalize",
        "body": "    def cancel(self):\n        '''\n        Cancel finalization of the object\n        '''\n        try:\n            del _finalizer_registry[self._key]\n        except KeyError:\n            pass\n        else:\n            self._weakref = self._callback = self._args = \\\n                            self._kwargs = self._key = None",
        "name_type": "stdlib"
    },
    "multiprocessing.util.Finalize.still_active": {
        "API_name": "multiprocessing.util.Finalize.still_active",
        "loc_name": "multiprocessing.util.Finalize.still_active",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 241,
        "namespace": "Finalize",
        "body": "    def still_active(self):\n        '''\n        Return whether this finalizer is still waiting to invoke callback\n        '''\n        return self._key in _finalizer_registry",
        "name_type": "stdlib"
    },
    "multiprocessing.util.Finalize.__repr__": {
        "API_name": "multiprocessing.util.Finalize.__repr__",
        "loc_name": "multiprocessing.util.Finalize.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 247,
        "namespace": "Finalize",
        "body": "    def __repr__(self):\n        try:\n            obj = self._weakref()\n        except (AttributeError, TypeError):\n            obj = None\n\n        if obj is None:\n            return '<%s object, dead>' % self.__class__.__name__\n\n        x = '<%s object, callback=%s' % (\n                self.__class__.__name__,\n                getattr(self._callback, '__name__', self._callback))\n        if self._args:\n            x += ', args=' + str(self._args)\n        if self._kwargs:\n            x += ', kwargs=' + str(self._kwargs)\n        if self._key[0] is not None:\n            x += ', exitpriority=' + str(self._key[0])\n        return x + '>'",
        "name_type": "stdlib"
    },
    "multiprocessing.util._run_finalizers": {
        "API_name": "multiprocessing.util._run_finalizers",
        "loc_name": "multiprocessing.util._run_finalizers",
        "args": "minpriority",
        "args_default": 1,
        "filepath": "multiprocessing.util",
        "lineno": 268,
        "namespace": "*",
        "body": "def _run_finalizers(minpriority=None):\n    '''\n    Run all finalizers whose exit priority is not None and at least minpriority\n\n    Finalizers with highest priority are called first; finalizers with\n    the same priority will be called in reverse order of creation.\n    '''\n    if _finalizer_registry is None:\n        # This function may be called after this module's globals are\n        # destroyed.  See the _exit_function function in this module for more\n        # notes.\n        return\n\n    if minpriority is None:\n        f = lambda p : p[0] is not None\n    else:\n        f = lambda p : p[0] is not None and p[0] >= minpriority\n\n    # Careful: _finalizer_registry may be mutated while this function\n    # is running (either by a GC run or by another thread).\n\n    # list(_finalizer_registry) should be atomic, while\n    # list(_finalizer_registry.items()) is not.\n    keys = [key for key in list(_finalizer_registry) if f(key)]\n    keys.sort(reverse=True)\n\n    for key in keys:\n        finalizer = _finalizer_registry.get(key)\n        # key may have been removed from the registry\n        if finalizer is not None:\n            sub_debug('calling %s', finalizer)\n            try:\n                finalizer()\n            except Exception:\n                import traceback\n                traceback.print_exc()\n\n    if minpriority is None:\n        _finalizer_registry.clear()",
        "name_type": "stdlib"
    },
    "multiprocessing.util.is_exiting": {
        "API_name": "multiprocessing.util.is_exiting",
        "loc_name": "multiprocessing.util.is_exiting",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 312,
        "namespace": "*",
        "body": "def is_exiting():\n    '''\n    Returns true if the process is shutting down\n    '''\n    return _exiting or _exiting is None",
        "name_type": "stdlib"
    },
    "multiprocessing.util._exit_function": {
        "API_name": "multiprocessing.util._exit_function",
        "loc_name": "multiprocessing.util._exit_function",
        "args": "info;debug;_run_finalizers;active_children;current_process",
        "args_default": 5,
        "filepath": "multiprocessing.util",
        "lineno": 320,
        "namespace": "*",
        "body": "def _exit_function(info=info, debug=debug, _run_finalizers=_run_finalizers,\n                   active_children=process.active_children,\n                   current_process=process.current_process):\n    # We hold on to references to functions in the arglist due to the\n    # situation described below, where this function is called after this\n    # module's globals are destroyed.\n\n    global _exiting\n\n    if not _exiting:\n        _exiting = True\n\n        info('process shutting down')\n        debug('running all \"atexit\" finalizers with priority >= 0')\n        _run_finalizers(0)\n\n        if current_process() is not None:\n            # We check if the current process is None here because if\n            # it's None, any call to ``active_children()`` will raise\n            # an AttributeError (active_children winds up trying to\n            # get attributes from util._current_process).  One\n            # situation where this can happen is if someone has\n            # manipulated sys.modules, causing this module to be\n            # garbage collected.  The destructor for the module type\n            # then replaces all values in the module dict with None.\n            # For instance, after setuptools runs a test it replaces\n            # sys.modules with a copy created earlier.  See issues\n            # #9775 and #15881.  Also related: #4106, #9205, and\n            # #9207.\n\n            for p in active_children():\n                if p.daemon:\n                    info('calling terminate() for daemon %s', p.name)\n                    p._popen.terminate()\n\n            for p in active_children():\n                info('calling join() for process %s', p.name)\n                p.join()\n\n        debug('running the remaining \"atexit\" finalizers')\n        _run_finalizers()",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareThreadLock": {
        "API_name": "multiprocessing.util.ForkAwareThreadLock",
        "loc_name": "multiprocessing.util.ForkAwareThreadLock",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.util",
        "lineno": 368,
        "namespace": "ForkAwareThreadLock",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareThreadLock.__init__": {
        "API_name": "multiprocessing.util.ForkAwareThreadLock.__init__",
        "loc_name": "multiprocessing.util.ForkAwareThreadLock.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 369,
        "namespace": "ForkAwareThreadLock",
        "body": "    def __init__(self):\n        self._lock = threading.Lock()\n        self.acquire = self._lock.acquire\n        self.release = self._lock.release\n        register_after_fork(self, ForkAwareThreadLock._at_fork_reinit)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareThreadLock._at_fork_reinit": {
        "API_name": "multiprocessing.util.ForkAwareThreadLock._at_fork_reinit",
        "loc_name": "multiprocessing.util.ForkAwareThreadLock._at_fork_reinit",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 375,
        "namespace": "ForkAwareThreadLock",
        "body": "    def _at_fork_reinit(self):\n        self._lock._at_fork_reinit()",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareThreadLock.__enter__": {
        "API_name": "multiprocessing.util.ForkAwareThreadLock.__enter__",
        "loc_name": "multiprocessing.util.ForkAwareThreadLock.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 378,
        "namespace": "ForkAwareThreadLock",
        "body": "    def __enter__(self):\n        return self._lock.__enter__()",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareThreadLock.__exit__": {
        "API_name": "multiprocessing.util.ForkAwareThreadLock.__exit__",
        "loc_name": "multiprocessing.util.ForkAwareThreadLock.__exit__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 381,
        "namespace": "ForkAwareThreadLock",
        "body": "    def __exit__(self, *args):\n        return self._lock.__exit__(*args)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareLocal": {
        "API_name": "multiprocessing.util.ForkAwareLocal",
        "loc_name": "multiprocessing.util.ForkAwareLocal",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.util",
        "lineno": 385,
        "namespace": "ForkAwareLocal",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareLocal.__init__": {
        "API_name": "multiprocessing.util.ForkAwareLocal.__init__",
        "loc_name": "multiprocessing.util.ForkAwareLocal.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 386,
        "namespace": "ForkAwareLocal",
        "body": "    def __init__(self):\n        register_after_fork(self, lambda obj : obj.__dict__.clear())",
        "name_type": "stdlib"
    },
    "multiprocessing.util.ForkAwareLocal.__reduce__": {
        "API_name": "multiprocessing.util.ForkAwareLocal.__reduce__",
        "loc_name": "multiprocessing.util.ForkAwareLocal.__reduce__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 388,
        "namespace": "ForkAwareLocal",
        "body": "    def __reduce__(self):\n        return type(self), ()",
        "name_type": "stdlib"
    },
    "multiprocessing.util.close_all_fds_except": {
        "API_name": "multiprocessing.util.close_all_fds_except",
        "loc_name": "multiprocessing.util.close_all_fds_except",
        "args": "fds",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 400,
        "namespace": "*",
        "body": "def close_all_fds_except(fds):\n    fds = list(fds) + [-1, MAXFD]\n    fds.sort()\n    assert fds[-1] == MAXFD, 'fd too large'\n    for i in range(len(fds) - 1):\n        os.closerange(fds[i]+1, fds[i+1])",
        "name_type": "stdlib"
    },
    "multiprocessing.util._close_stdin": {
        "API_name": "multiprocessing.util._close_stdin",
        "loc_name": "multiprocessing.util._close_stdin",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 410,
        "namespace": "*",
        "body": "def _close_stdin():\n    if sys.stdin is None:\n        return\n\n    try:\n        sys.stdin.close()\n    except (OSError, ValueError):\n        pass\n\n    try:\n        fd = os.open(os.devnull, os.O_RDONLY)\n        try:\n            sys.stdin = open(fd, closefd=False)\n        except:\n            os.close(fd)\n            raise\n    except (OSError, ValueError):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.util._flush_std_streams": {
        "API_name": "multiprocessing.util._flush_std_streams",
        "loc_name": "multiprocessing.util._flush_std_streams",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 433,
        "namespace": "*",
        "body": "def _flush_std_streams():\n    try:\n        sys.stdout.flush()\n    except (AttributeError, ValueError):\n        pass\n    try:\n        sys.stderr.flush()\n    except (AttributeError, ValueError):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.util.spawnv_passfds": {
        "API_name": "multiprocessing.util.spawnv_passfds",
        "loc_name": "multiprocessing.util.spawnv_passfds",
        "args": "path;args;passfds",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 447,
        "namespace": "*",
        "body": "def spawnv_passfds(path, args, passfds):\n    import _posixsubprocess\n    passfds = tuple(sorted(map(int, passfds)))\n    errpipe_read, errpipe_write = os.pipe()\n    try:\n        return _posixsubprocess.fork_exec(\n            args, [os.fsencode(path)], True, passfds, None, None,\n            -1, -1, -1, -1, -1, -1, errpipe_read, errpipe_write,\n            False, False, None, None, None, -1, None)\n    finally:\n        os.close(errpipe_read)\n        os.close(errpipe_write)",
        "name_type": "stdlib"
    },
    "multiprocessing.util.close_fds": {
        "API_name": "multiprocessing.util.close_fds",
        "loc_name": "multiprocessing.util.close_fds",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 461,
        "namespace": "*",
        "body": "def close_fds(*fds):\n    \"\"\"Close each file descriptor given as an argument\"\"\"\n    for fd in fds:\n        os.close(fd)",
        "name_type": "stdlib"
    },
    "multiprocessing.util._cleanup_tests": {
        "API_name": "multiprocessing.util._cleanup_tests",
        "loc_name": "multiprocessing.util._cleanup_tests",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.util",
        "lineno": 467,
        "namespace": "*",
        "body": "def _cleanup_tests():\n    \"\"\"Cleanup multiprocessing resources when multiprocessing tests\n    completed.\"\"\"\n\n    from test import support\n\n    # cleanup multiprocessing\n    process._cleanup()\n\n    # Stop the ForkServer process if it's running\n    from multiprocessing import forkserver\n    forkserver._forkserver._stop()\n\n    # Stop the ResourceTracker process if it's running\n    from multiprocessing import resource_tracker\n    resource_tracker._resource_tracker._stop()\n\n    # bpo-37421: Explicitly call _run_finalizers() to remove immediately\n    # temporary directories created by multiprocessing.util.get_temp_dir().\n    _run_finalizers()\n    support.gc_collect()\n\n    support.reap_children()",
        "name_type": "stdlib"
    },
    "multiprocessing": {
        "API_name": "multiprocessing",
        "loc_name": "multiprocessing",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [x for x in dir(context._default_context) if not x.startswith('_')]\nglobals().update((name, getattr(context._default_context, name)) for name in __all__)\nSUBDEBUG = 5\nSUBWARNING = 25\nif '__main__' in sys.modules:\n    sys.modules['__mp_main__'] = sys.modules['__main__']",
        "name_type": "stdlib"
    },
    "urllib.error": {
        "API_name": "urllib.error",
        "loc_name": "urllib.error",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.error",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Exception classes raised by urllib.\n\nThe base exception class is URLError, which inherits from OSError.  It\ndoesn't define any behavior of its own, but is the base class for all\nexceptions defined in this package.\n\nHTTPError is an exception class that is also a valid HTTP response\ninstance.  It behaves this way because HTTP protocol errors are valid\nresponses, with a status code, headers, and a body.  In some contexts,\nan application may want to handle an exception like a regular\nresponse.\n\"\"\"\n__all__ = ['URLError', 'HTTPError', 'ContentTooShortError']",
        "name_type": "stdlib"
    },
    "urllib.error.URLError": {
        "API_name": "urllib.error.URLError",
        "loc_name": "urllib.error.URLError",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.error",
        "lineno": 19,
        "namespace": "URLError",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.error.URLError.__init__": {
        "API_name": "urllib.error.URLError.__init__",
        "loc_name": "urllib.error.URLError.__init__",
        "args": "self;reason;filename",
        "args_default": 1,
        "filepath": "urllib.error",
        "lineno": 25,
        "namespace": "URLError",
        "body": "    def __init__(self, reason, filename=None):\n        self.args = reason,\n        self.reason = reason\n        if filename is not None:\n            self.filename = filename",
        "name_type": "stdlib"
    },
    "urllib.error.URLError.__str__": {
        "API_name": "urllib.error.URLError.__str__",
        "loc_name": "urllib.error.URLError.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 31,
        "namespace": "URLError",
        "body": "    def __str__(self):\n        return '<urlopen error %s>' % self.reason",
        "name_type": "stdlib"
    },
    "urllib.error.HTTPError": {
        "API_name": "urllib.error.HTTPError",
        "loc_name": "urllib.error.HTTPError",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.error",
        "lineno": 35,
        "namespace": "HTTPError",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.error.HTTPError.__init__": {
        "API_name": "urllib.error.HTTPError.__init__",
        "loc_name": "urllib.error.HTTPError.__init__",
        "args": "self;url;code;msg;hdrs;fp",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 39,
        "namespace": "HTTPError",
        "body": "    def __init__(self, url, code, msg, hdrs, fp):\n        self.code = code\n        self.msg = msg\n        self.hdrs = hdrs\n        self.fp = fp\n        self.filename = url\n        # The addinfourl classes depend on fp being a valid file\n        # object.  In some cases, the HTTPError may not have a valid\n        # file object.  If this happens, the simplest workaround is to\n        # not initialize the base classes.\n        if fp is not None:\n            self.__super_init(fp, hdrs, url, code)",
        "name_type": "stdlib"
    },
    "urllib.error.HTTPError.__str__": {
        "API_name": "urllib.error.HTTPError.__str__",
        "loc_name": "urllib.error.HTTPError.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 52,
        "namespace": "HTTPError",
        "body": "    def __str__(self):\n        return 'HTTP Error %s: %s' % (self.code, self.msg)",
        "name_type": "stdlib"
    },
    "urllib.error.HTTPError.__repr__": {
        "API_name": "urllib.error.HTTPError.__repr__",
        "loc_name": "urllib.error.HTTPError.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 55,
        "namespace": "HTTPError",
        "body": "    def __repr__(self):\n        return '<HTTPError %s: %r>' % (self.code, self.msg)",
        "name_type": "stdlib"
    },
    "urllib.error.HTTPError.reason": {
        "API_name": "urllib.error.HTTPError.reason",
        "loc_name": "urllib.error.HTTPError.reason",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 61,
        "namespace": "HTTPError",
        "body": "    def reason(self):\n        return self.msg",
        "name_type": "stdlib"
    },
    "urllib.error.HTTPError.headers": {
        "API_name": "urllib.error.HTTPError.headers",
        "loc_name": "urllib.error.HTTPError.headers",
        "args": "self;headers",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 69,
        "namespace": "HTTPError",
        "body": "    def headers(self, headers):\n        self.hdrs = headers",
        "name_type": "stdlib"
    },
    "urllib.error.ContentTooShortError": {
        "API_name": "urllib.error.ContentTooShortError",
        "loc_name": "urllib.error.ContentTooShortError",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.error",
        "lineno": 73,
        "namespace": "ContentTooShortError",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.error.ContentTooShortError.__init__": {
        "API_name": "urllib.error.ContentTooShortError.__init__",
        "loc_name": "urllib.error.ContentTooShortError.__init__",
        "args": "self;message;content",
        "args_default": 0,
        "filepath": "urllib.error",
        "lineno": 75,
        "namespace": "ContentTooShortError",
        "body": "    def __init__(self, message, content):\n        URLError.__init__(self, message)\n        self.content = content",
        "name_type": "stdlib"
    },
    "urllib.parse": {
        "API_name": "urllib.parse",
        "loc_name": "urllib.parse",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Parse (absolute and relative) URLs.\n\nurlparse module is based upon the following RFC specifications.\n\nRFC 3986 (STD66): \"Uniform Resource Identifiers\" by T. Berners-Lee, R. Fielding\nand L.  Masinter, January 2005.\n\nRFC 2732 : \"Format for Literal IPv6 Addresses in URL's by R.Hinden, B.Carpenter\nand L.Masinter, December 1999.\n\nRFC 2396:  \"Uniform Resource Identifiers (URI)\": Generic Syntax by T.\nBerners-Lee, R. Fielding, and L. Masinter, August 1998.\n\nRFC 2368: \"The mailto URL scheme\", by P.Hoffman , L Masinter, J. Zawinski, July 1998.\n\nRFC 1808: \"Relative Uniform Resource Locators\", by R. Fielding, UC Irvine, June\n1995.\n\nRFC 1738: \"Uniform Resource Locators (URL)\" by T. Berners-Lee, L. Masinter, M.\nMcCahill, December 1994\n\nRFC 3986 is considered the current standard and any future changes to\nurlparse module should conform with it.  The urlparse module is\ncurrently not entirely compliant with this RFC due to defacto\nscenarios for parsing, and for backward compatibility purposes, some\nparsing quirks from older RFCs are retained. The testcases in\ntest_urlparse.py provides a good indicator of parsing behavior.\n\"\"\"\n__all__ = [\"urlparse\", \"urlunparse\", \"urljoin\", \"urldefrag\",\n           \"urlsplit\", \"urlunsplit\", \"urlencode\", \"parse_qs\",\n           \"parse_qsl\", \"quote\", \"quote_plus\", \"quote_from_bytes\",\n           \"unquote\", \"unquote_plus\", \"unquote_to_bytes\",\n           \"DefragResult\", \"ParseResult\", \"SplitResult\",\n           \"DefragResultBytes\", \"ParseResultBytes\", \"SplitResultBytes\"]\nuses_relative = ['', 'ftp', 'http', 'gopher', 'nntp', 'imap',\n                 'wais', 'file', 'https', 'shttp', 'mms',\n                 'prospero', 'rtsp', 'rtspu', 'sftp',\n                 'svn', 'svn+ssh', 'ws', 'wss']\nuses_netloc = ['', 'ftp', 'http', 'gopher', 'nntp', 'telnet',\n               'imap', 'wais', 'file', 'mms', 'https', 'shttp',\n               'snews', 'prospero', 'rtsp', 'rtspu', 'rsync',\n               'svn', 'svn+ssh', 'sftp', 'nfs', 'git', 'git+ssh',\n               'ws', 'wss']\nuses_params = ['', 'ftp', 'hdl', 'prospero', 'http', 'imap',\n               'https', 'shttp', 'rtsp', 'rtspu', 'sip', 'sips',\n               'mms', 'sftp', 'tel']\nnon_hierarchical = ['gopher', 'hdl', 'mailto', 'news',\n                    'telnet', 'wais', 'imap', 'snews', 'sip', 'sips']\nuses_query = ['', 'http', 'wais', 'imap', 'https', 'shttp', 'mms',\n              'gopher', 'rtsp', 'rtspu', 'sip', 'sips']\nuses_fragment = ['', 'ftp', 'hdl', 'http', 'gopher', 'news',\n                 'nntp', 'wais', 'https', 'shttp', 'snews',\n                 'file', 'prospero']\nscheme_chars = ('abcdefghijklmnopqrstuvwxyz'\n                'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                '0123456789'\n                '+-.')\n_UNSAFE_URL_BYTES_TO_REMOVE = ['\\t', '\\r', '\\n']\nMAX_CACHE_SIZE = 20\n_parse_cache = {}\n_implicit_encoding = 'ascii'\n_implicit_errors = 'strict'\n_DefragResultBase = namedtuple('DefragResult', 'url fragment')\n_SplitResultBase = namedtuple(\n    'SplitResult', 'scheme netloc path query fragment')\n_ParseResultBase = namedtuple(\n    'ParseResult', 'scheme netloc path params query fragment')\n_DefragResultBase.__doc__ = \"\"\"\nDefragResult(url, fragment)\n\nA 2-tuple that contains the url without fragment identifier and the fragment\nidentifier as a separate argument.\n\"\"\"\n_DefragResultBase.url.__doc__ = \"\"\"The URL with no fragment identifier.\"\"\"\n_DefragResultBase.fragment.__doc__ = \"\"\"\nFragment identifier separated from URL, that allows indirect identification of a\nsecondary resource by reference to a primary resource and additional identifying\ninformation.\n\"\"\"\n_SplitResultBase.__doc__ = \"\"\"\nSplitResult(scheme, netloc, path, query, fragment)\n\nA 5-tuple that contains the different components of a URL. Similar to\nParseResult, but does not split params.\n\"\"\"\n_SplitResultBase.scheme.__doc__ = \"\"\"Specifies URL scheme for the request.\"\"\"\n_SplitResultBase.netloc.__doc__ = \"\"\"\nNetwork location where the request is made to.\n\"\"\"\n_SplitResultBase.path.__doc__ = \"\"\"\nThe hierarchical path, such as the path to a file to download.\n\"\"\"\n_SplitResultBase.query.__doc__ = \"\"\"\nThe query component, that contains non-hierarchical data, that along with data\nin path component, identifies a resource in the scope of URI's scheme and\nnetwork location.\n\"\"\"\n_SplitResultBase.fragment.__doc__ = \"\"\"\nFragment identifier, that allows indirect identification of a secondary resource\nby reference to a primary resource and additional identifying information.\n\"\"\"\n_ParseResultBase.__doc__ = \"\"\"\nParseResult(scheme, netloc, path, params, query, fragment)\n\nA 6-tuple that contains components of a parsed URL.\n\"\"\"\n_ParseResultBase.scheme.__doc__ = _SplitResultBase.scheme.__doc__\n_ParseResultBase.netloc.__doc__ = _SplitResultBase.netloc.__doc__\n_ParseResultBase.path.__doc__ = _SplitResultBase.path.__doc__\n_ParseResultBase.params.__doc__ = \"\"\"\nParameters for last path element used to dereference the URI in order to provide\naccess to perform some operation on the resource.\n\"\"\"\n_ParseResultBase.query.__doc__ = _SplitResultBase.query.__doc__\n_ParseResultBase.fragment.__doc__ = _SplitResultBase.fragment.__doc__\nResultBase = _NetlocResultMixinStr\n_fix_result_transcoding()\ndel _fix_result_transcoding\n_hexdig = '0123456789ABCDEFabcdef'\n_hextobyte = None\n_asciire = re.compile('([\\x00-\\x7f]+)')\n_ALWAYS_SAFE = frozenset(b'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n                         b'abcdefghijklmnopqrstuvwxyz'\n                         b'0123456789'\n                         b'_.-~')\n_ALWAYS_SAFE_BYTES = bytes(_ALWAYS_SAFE)\n_safe_quoters = {}\n_typeprog = None\n_hostprog = None\n_portprog = None",
        "name_type": "stdlib"
    },
    "urllib.parse.clear_cache": {
        "API_name": "urllib.parse.clear_cache",
        "loc_name": "urllib.parse.clear_cache",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 88,
        "namespace": "*",
        "body": "def clear_cache():\n    \"\"\"Clear the parse cache and the quoters cache.\"\"\"\n    _parse_cache.clear()\n    _safe_quoters.clear()",
        "name_type": "stdlib"
    },
    "urllib.parse._noop": {
        "API_name": "urllib.parse._noop",
        "loc_name": "urllib.parse._noop",
        "args": "obj",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 103,
        "namespace": "*",
        "body": "def _noop(obj):\n    return obj",
        "name_type": "stdlib"
    },
    "urllib.parse._encode_result": {
        "API_name": "urllib.parse._encode_result",
        "loc_name": "urllib.parse._encode_result",
        "args": "obj;encoding;errors",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 106,
        "namespace": "*",
        "body": "def _encode_result(obj, encoding=_implicit_encoding,\n                        errors=_implicit_errors):\n    return obj.encode(encoding, errors)",
        "name_type": "stdlib"
    },
    "urllib.parse._decode_args": {
        "API_name": "urllib.parse._decode_args",
        "loc_name": "urllib.parse._decode_args",
        "args": "args;encoding;errors",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 110,
        "namespace": "*",
        "body": "def _decode_args(args, encoding=_implicit_encoding,\n                       errors=_implicit_errors):\n    return tuple(x.decode(encoding, errors) if x else '' for x in args)",
        "name_type": "stdlib"
    },
    "urllib.parse._coerce_args": {
        "API_name": "urllib.parse._coerce_args",
        "loc_name": "urllib.parse._coerce_args",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 114,
        "namespace": "*",
        "body": "def _coerce_args(*args):\n    # Invokes decode if necessary to create str args\n    # and returns the coerced inputs along with\n    # an appropriate result coercion function\n    #   - noop for str inputs\n    #   - encoding function otherwise\n    str_input = isinstance(args[0], str)\n    for arg in args[1:]:\n        # We special-case the empty string to support the\n        # \"scheme=''\" default argument to some functions\n        if arg and isinstance(arg, str) != str_input:\n            raise TypeError(\"Cannot mix str and non-str arguments\")\n    if str_input:\n        return args + (_noop,)\n    return _decode_args(args) + (_encode_result,)",
        "name_type": "stdlib"
    },
    "urllib.parse._ResultMixinStr.encode": {
        "API_name": "urllib.parse._ResultMixinStr.encode",
        "loc_name": "urllib.parse._ResultMixinStr.encode",
        "args": "self;encoding;errors",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 135,
        "namespace": "_ResultMixinStr",
        "body": "    def encode(self, encoding='ascii', errors='strict'):\n        return self._encoded_counterpart(*(x.encode(encoding, errors) for x in self))",
        "name_type": "stdlib"
    },
    "urllib.parse._ResultMixinStr": {
        "API_name": "urllib.parse._ResultMixinStr",
        "loc_name": "urllib.parse._ResultMixinStr",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 131,
        "namespace": "_ResultMixinStr",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse._ResultMixinBytes.decode": {
        "API_name": "urllib.parse._ResultMixinBytes.decode",
        "loc_name": "urllib.parse._ResultMixinBytes.decode",
        "args": "self;encoding;errors",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 143,
        "namespace": "_ResultMixinBytes",
        "body": "    def decode(self, encoding='ascii', errors='strict'):\n        return self._decoded_counterpart(*(x.decode(encoding, errors) for x in self))",
        "name_type": "stdlib"
    },
    "urllib.parse._ResultMixinBytes": {
        "API_name": "urllib.parse._ResultMixinBytes",
        "loc_name": "urllib.parse._ResultMixinBytes",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 139,
        "namespace": "_ResultMixinBytes",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBase.username": {
        "API_name": "urllib.parse._NetlocResultMixinBase.username",
        "loc_name": "urllib.parse._NetlocResultMixinBase.username",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 152,
        "namespace": "_NetlocResultMixinBase",
        "body": "    def username(self):\n        return self._userinfo[0]",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBase.password": {
        "API_name": "urllib.parse._NetlocResultMixinBase.password",
        "loc_name": "urllib.parse._NetlocResultMixinBase.password",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 156,
        "namespace": "_NetlocResultMixinBase",
        "body": "    def password(self):\n        return self._userinfo[1]",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBase.hostname": {
        "API_name": "urllib.parse._NetlocResultMixinBase.hostname",
        "loc_name": "urllib.parse._NetlocResultMixinBase.hostname",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 160,
        "namespace": "_NetlocResultMixinBase",
        "body": "    def hostname(self):\n        hostname = self._hostinfo[0]\n        if not hostname:\n            return None\n        # Scoped IPv6 address may have zone info, which must not be lowercased\n        # like http://[fe80::822a:a8ff:fe49:470c%tESt]:1234/keys\n        separator = '%' if isinstance(hostname, str) else b'%'\n        hostname, percent, zone = hostname.partition(separator)\n        return hostname.lower() + percent + zone",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBase.port": {
        "API_name": "urllib.parse._NetlocResultMixinBase.port",
        "loc_name": "urllib.parse._NetlocResultMixinBase.port",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 171,
        "namespace": "_NetlocResultMixinBase",
        "body": "    def port(self):\n        port = self._hostinfo[1]\n        if port is not None:\n            try:\n                port = int(port, 10)\n            except ValueError:\n                message = f'Port could not be cast to integer value as {port!r}'\n                raise ValueError(message) from None\n            if not ( 0 <= port <= 65535):\n                raise ValueError(\"Port out of range 0-65535\")\n        return port",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBase": {
        "API_name": "urllib.parse._NetlocResultMixinBase",
        "loc_name": "urllib.parse._NetlocResultMixinBase",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 147,
        "namespace": "_NetlocResultMixinBase",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinStr._userinfo": {
        "API_name": "urllib.parse._NetlocResultMixinStr._userinfo",
        "loc_name": "urllib.parse._NetlocResultMixinStr._userinfo",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 190,
        "namespace": "_NetlocResultMixinStr",
        "body": "    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition('@')\n        if have_info:\n            username, have_password, password = userinfo.partition(':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinStr._hostinfo": {
        "API_name": "urllib.parse._NetlocResultMixinStr._hostinfo",
        "loc_name": "urllib.parse._NetlocResultMixinStr._hostinfo",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 202,
        "namespace": "_NetlocResultMixinStr",
        "body": "    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition('@')\n        _, have_open_br, bracketed = hostinfo.partition('[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(']')\n            _, _, port = port.partition(':')\n        else:\n            hostname, _, port = hostinfo.partition(':')\n        if not port:\n            port = None\n        return hostname, port",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinStr": {
        "API_name": "urllib.parse._NetlocResultMixinStr",
        "loc_name": "urllib.parse._NetlocResultMixinStr",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 186,
        "namespace": "_NetlocResultMixinStr",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBytes._userinfo": {
        "API_name": "urllib.parse._NetlocResultMixinBytes._userinfo",
        "loc_name": "urllib.parse._NetlocResultMixinBytes._userinfo",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 220,
        "namespace": "_NetlocResultMixinBytes",
        "body": "    def _userinfo(self):\n        netloc = self.netloc\n        userinfo, have_info, hostinfo = netloc.rpartition(b'@')\n        if have_info:\n            username, have_password, password = userinfo.partition(b':')\n            if not have_password:\n                password = None\n        else:\n            username = password = None\n        return username, password",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBytes._hostinfo": {
        "API_name": "urllib.parse._NetlocResultMixinBytes._hostinfo",
        "loc_name": "urllib.parse._NetlocResultMixinBytes._hostinfo",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 232,
        "namespace": "_NetlocResultMixinBytes",
        "body": "    def _hostinfo(self):\n        netloc = self.netloc\n        _, _, hostinfo = netloc.rpartition(b'@')\n        _, have_open_br, bracketed = hostinfo.partition(b'[')\n        if have_open_br:\n            hostname, _, port = bracketed.partition(b']')\n            _, _, port = port.partition(b':')\n        else:\n            hostname, _, port = hostinfo.partition(b':')\n        if not port:\n            port = None\n        return hostname, port",
        "name_type": "stdlib"
    },
    "urllib.parse._NetlocResultMixinBytes": {
        "API_name": "urllib.parse._NetlocResultMixinBytes",
        "loc_name": "urllib.parse._NetlocResultMixinBytes",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 216,
        "namespace": "_NetlocResultMixinBytes",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.DefragResult.geturl": {
        "API_name": "urllib.parse.DefragResult.geturl",
        "loc_name": "urllib.parse.DefragResult.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 323,
        "namespace": "DefragResult",
        "body": "    def geturl(self):\n        if self.fragment:\n            return self.url + '#' + self.fragment\n        else:\n            return self.url",
        "name_type": "stdlib"
    },
    "urllib.parse.DefragResult": {
        "API_name": "urllib.parse.DefragResult",
        "loc_name": "urllib.parse.DefragResult",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 321,
        "namespace": "DefragResult",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.SplitResult.geturl": {
        "API_name": "urllib.parse.SplitResult.geturl",
        "loc_name": "urllib.parse.SplitResult.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 331,
        "namespace": "SplitResult",
        "body": "    def geturl(self):\n        return urlunsplit(self)",
        "name_type": "stdlib"
    },
    "urllib.parse.SplitResult": {
        "API_name": "urllib.parse.SplitResult",
        "loc_name": "urllib.parse.SplitResult",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 329,
        "namespace": "SplitResult",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.ParseResult.geturl": {
        "API_name": "urllib.parse.ParseResult.geturl",
        "loc_name": "urllib.parse.ParseResult.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 336,
        "namespace": "ParseResult",
        "body": "    def geturl(self):\n        return urlunparse(self)",
        "name_type": "stdlib"
    },
    "urllib.parse.ParseResult": {
        "API_name": "urllib.parse.ParseResult",
        "loc_name": "urllib.parse.ParseResult",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 334,
        "namespace": "ParseResult",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.DefragResultBytes.geturl": {
        "API_name": "urllib.parse.DefragResultBytes.geturl",
        "loc_name": "urllib.parse.DefragResultBytes.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 342,
        "namespace": "DefragResultBytes",
        "body": "    def geturl(self):\n        if self.fragment:\n            return self.url + b'#' + self.fragment\n        else:\n            return self.url",
        "name_type": "stdlib"
    },
    "urllib.parse.DefragResultBytes": {
        "API_name": "urllib.parse.DefragResultBytes",
        "loc_name": "urllib.parse.DefragResultBytes",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 340,
        "namespace": "DefragResultBytes",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.SplitResultBytes.geturl": {
        "API_name": "urllib.parse.SplitResultBytes.geturl",
        "loc_name": "urllib.parse.SplitResultBytes.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 350,
        "namespace": "SplitResultBytes",
        "body": "    def geturl(self):\n        return urlunsplit(self)",
        "name_type": "stdlib"
    },
    "urllib.parse.SplitResultBytes": {
        "API_name": "urllib.parse.SplitResultBytes",
        "loc_name": "urllib.parse.SplitResultBytes",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 348,
        "namespace": "SplitResultBytes",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.ParseResultBytes.geturl": {
        "API_name": "urllib.parse.ParseResultBytes.geturl",
        "loc_name": "urllib.parse.ParseResultBytes.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 355,
        "namespace": "ParseResultBytes",
        "body": "    def geturl(self):\n        return urlunparse(self)",
        "name_type": "stdlib"
    },
    "urllib.parse.ParseResultBytes": {
        "API_name": "urllib.parse.ParseResultBytes",
        "loc_name": "urllib.parse.ParseResultBytes",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 353,
        "namespace": "ParseResultBytes",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse._fix_result_transcoding": {
        "API_name": "urllib.parse._fix_result_transcoding",
        "loc_name": "urllib.parse._fix_result_transcoding",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 359,
        "namespace": "*",
        "body": "def _fix_result_transcoding():\n    _result_pairs = (\n        (DefragResult, DefragResultBytes),\n        (SplitResult, SplitResultBytes),\n        (ParseResult, ParseResultBytes),\n    )\n    for _decoded, _encoded in _result_pairs:\n        _decoded._encoded_counterpart = _encoded\n        _encoded._decoded_counterpart = _decoded",
        "name_type": "stdlib"
    },
    "urllib.parse.urlparse": {
        "API_name": "urllib.parse.urlparse",
        "loc_name": "urllib.parse.urlparse",
        "args": "url;scheme;allow_fragments",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 372,
        "namespace": "*",
        "body": "def urlparse(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 6 components:\n    <scheme>://<netloc>/<path>;<params>?<query>#<fragment>\n\n    The result is a named 6-tuple with fields corresponding to the\n    above. It is either a ParseResult or ParseResultBytes object,\n    depending on the type of the url parameter.\n\n    The username, password, hostname, and port sub-components of netloc\n    can also be accessed as attributes of the returned object.\n\n    The scheme argument provides the default value of the scheme\n    component when no scheme is found in url.\n\n    If allow_fragments is False, no attempt is made to separate the\n    fragment component from the previous component, which can be either\n    path or query.\n\n    Note that % escapes are not expanded.\n    \"\"\"\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n    splitresult = urlsplit(url, scheme, allow_fragments)\n    scheme, netloc, url, query, fragment = splitresult\n    if scheme in uses_params and ';' in url:\n        url, params = _splitparams(url)\n    else:\n        params = ''\n    result = ParseResult(scheme, netloc, url, params, query, fragment)\n    return _coerce_result(result)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitparams": {
        "API_name": "urllib.parse._splitparams",
        "loc_name": "urllib.parse._splitparams",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 402,
        "namespace": "*",
        "body": "def _splitparams(url):\n    if '/'  in url:\n        i = url.find(';', url.rfind('/'))\n        if i < 0:\n            return url, ''\n    else:\n        i = url.find(';')\n    return url[:i], url[i+1:]",
        "name_type": "stdlib"
    },
    "urllib.parse._splitnetloc": {
        "API_name": "urllib.parse._splitnetloc",
        "loc_name": "urllib.parse._splitnetloc",
        "args": "url;start",
        "args_default": 1,
        "filepath": "urllib.parse",
        "lineno": 411,
        "namespace": "*",
        "body": "def _splitnetloc(url, start=0):\n    delim = len(url)   # position of end of domain part of url, default is end\n    for c in '/?#':    # look for delimiters; the order is NOT important\n        wdelim = url.find(c, start)        # find first of this delim\n        if wdelim >= 0:                    # if found\n            delim = min(delim, wdelim)     # use earliest delim position\n    return url[start:delim], url[delim:]   # return (domain, rest)",
        "name_type": "stdlib"
    },
    "urllib.parse._checknetloc": {
        "API_name": "urllib.parse._checknetloc",
        "loc_name": "urllib.parse._checknetloc",
        "args": "netloc",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 419,
        "namespace": "*",
        "body": "def _checknetloc(netloc):\n    if not netloc or netloc.isascii():\n        return\n    # looking for characters like \\u2100 that expand to 'a/c'\n    # IDNA uses NFKC equivalence, so normalize for this check\n    import unicodedata\n    n = netloc.replace('@', '')   # ignore characters already included\n    n = n.replace(':', '')        # but not the surrounding text\n    n = n.replace('#', '')\n    n = n.replace('?', '')\n    netloc2 = unicodedata.normalize('NFKC', n)\n    if n == netloc2:\n        return\n    for c in '/?#@:':\n        if c in netloc2:\n            raise ValueError(\"netloc '\" + netloc + \"' contains invalid \" +\n                             \"characters under NFKC normalization\")",
        "name_type": "stdlib"
    },
    "urllib.parse.urlsplit": {
        "API_name": "urllib.parse.urlsplit",
        "loc_name": "urllib.parse.urlsplit",
        "args": "url;scheme;allow_fragments",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 437,
        "namespace": "*",
        "body": "def urlsplit(url, scheme='', allow_fragments=True):\n    \"\"\"Parse a URL into 5 components:\n    <scheme>://<netloc>/<path>?<query>#<fragment>\n\n    The result is a named 5-tuple with fields corresponding to the\n    above. It is either a SplitResult or SplitResultBytes object,\n    depending on the type of the url parameter.\n\n    The username, password, hostname, and port sub-components of netloc\n    can also be accessed as attributes of the returned object.\n\n    The scheme argument provides the default value of the scheme\n    component when no scheme is found in url.\n\n    If allow_fragments is False, no attempt is made to separate the\n    fragment component from the previous component, which can be either\n    path or query.\n\n    Note that % escapes are not expanded.\n    \"\"\"\n\n    url, scheme, _coerce_result = _coerce_args(url, scheme)\n\n    for b in _UNSAFE_URL_BYTES_TO_REMOVE:\n        url = url.replace(b, \"\")\n        scheme = scheme.replace(b, \"\")\n\n    allow_fragments = bool(allow_fragments)\n    key = url, scheme, allow_fragments, type(url), type(scheme)\n    cached = _parse_cache.get(key, None)\n    if cached:\n        return _coerce_result(cached)\n    if len(_parse_cache) >= MAX_CACHE_SIZE: # avoid runaway growth\n        clear_cache()\n    netloc = query = fragment = ''\n    i = url.find(':')\n    if i > 0:\n        for c in url[:i]:\n            if c not in scheme_chars:\n                break\n        else:\n            scheme, url = url[:i].lower(), url[i+1:]\n\n    if url[:2] == '//':\n        netloc, url = _splitnetloc(url, 2)\n        if (('[' in netloc and ']' not in netloc) or\n                (']' in netloc and '[' not in netloc)):\n            raise ValueError(\"Invalid IPv6 URL\")\n    if allow_fragments and '#' in url:\n        url, fragment = url.split('#', 1)\n    if '?' in url:\n        url, query = url.split('?', 1)\n    _checknetloc(netloc)\n    v = SplitResult(scheme, netloc, url, query, fragment)\n    _parse_cache[key] = v\n    return _coerce_result(v)",
        "name_type": "stdlib"
    },
    "urllib.parse.urlunparse": {
        "API_name": "urllib.parse.urlunparse",
        "loc_name": "urllib.parse.urlunparse",
        "args": "components",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 494,
        "namespace": "*",
        "body": "def urlunparse(components):\n    \"\"\"Put a parsed URL back together again.  This may result in a\n    slightly different, but equivalent URL, if the URL that was parsed\n    originally had redundant delimiters, e.g. a ? with an empty query\n    (the draft states that these are equivalent).\"\"\"\n    scheme, netloc, url, params, query, fragment, _coerce_result = (\n                                                  _coerce_args(*components))\n    if params:\n        url = \"%s;%s\" % (url, params)\n    return _coerce_result(urlunsplit((scheme, netloc, url, query, fragment)))",
        "name_type": "stdlib"
    },
    "urllib.parse.urlunsplit": {
        "API_name": "urllib.parse.urlunsplit",
        "loc_name": "urllib.parse.urlunsplit",
        "args": "components",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 505,
        "namespace": "*",
        "body": "def urlunsplit(components):\n    \"\"\"Combine the elements of a tuple as returned by urlsplit() into a\n    complete URL as a string. The data argument can be any five-item iterable.\n    This may result in a slightly different, but equivalent URL, if the URL that\n    was parsed originally had unnecessary delimiters (for example, a ? with an\n    empty query; the RFC states that these are equivalent).\"\"\"\n    scheme, netloc, url, query, fragment, _coerce_result = (\n                                          _coerce_args(*components))\n    if netloc or (scheme and scheme in uses_netloc and url[:2] != '//'):\n        if url and url[:1] != '/': url = '/' + url\n        url = '//' + (netloc or '') + url\n    if scheme:\n        url = scheme + ':' + url\n    if query:\n        url = url + '?' + query\n    if fragment:\n        url = url + '#' + fragment\n    return _coerce_result(url)",
        "name_type": "stdlib"
    },
    "urllib.parse.urljoin": {
        "API_name": "urllib.parse.urljoin",
        "loc_name": "urllib.parse.urljoin",
        "args": "base;url;allow_fragments",
        "args_default": 1,
        "filepath": "urllib.parse",
        "lineno": 524,
        "namespace": "*",
        "body": "def urljoin(base, url, allow_fragments=True):\n    \"\"\"Join a base URL and a possibly relative URL to form an absolute\n    interpretation of the latter.\"\"\"\n    if not base:\n        return url\n    if not url:\n        return base\n\n    base, url, _coerce_result = _coerce_args(base, url)\n    bscheme, bnetloc, bpath, bparams, bquery, bfragment = \\\n            urlparse(base, '', allow_fragments)\n    scheme, netloc, path, params, query, fragment = \\\n            urlparse(url, bscheme, allow_fragments)\n\n    if scheme != bscheme or scheme not in uses_relative:\n        return _coerce_result(url)\n    if scheme in uses_netloc:\n        if netloc:\n            return _coerce_result(urlunparse((scheme, netloc, path,\n                                              params, query, fragment)))\n        netloc = bnetloc\n\n    if not path and not params:\n        path = bpath\n        params = bparams\n        if not query:\n            query = bquery\n        return _coerce_result(urlunparse((scheme, netloc, path,\n                                          params, query, fragment)))\n\n    base_parts = bpath.split('/')\n    if base_parts[-1] != '':\n        # the last item is not a directory, so will not be taken into account\n        # in resolving the relative path\n        del base_parts[-1]\n\n    # for rfc3986, ignore all base path should the first character be root.\n    if path[:1] == '/':\n        segments = path.split('/')\n    else:\n        segments = base_parts + path.split('/')\n        # filter out elements that would cause redundant slashes on re-joining\n        # the resolved_path\n        segments[1:-1] = filter(None, segments[1:-1])\n\n    resolved_path = []\n\n    for seg in segments:\n        if seg == '..':\n            try:\n                resolved_path.pop()\n            except IndexError:\n                # ignore any .. segments that would otherwise cause an IndexError\n                # when popped from resolved_path if resolving for rfc3986\n                pass\n        elif seg == '.':\n            continue\n        else:\n            resolved_path.append(seg)\n\n    if segments[-1] in ('.', '..'):\n        # do some post-processing here. if the last segment was a relative dir,\n        # then we need to append the trailing '/'\n        resolved_path.append('')\n\n    return _coerce_result(urlunparse((scheme, netloc, '/'.join(\n        resolved_path) or '/', params, query, fragment)))",
        "name_type": "stdlib"
    },
    "urllib.parse.urldefrag": {
        "API_name": "urllib.parse.urldefrag",
        "loc_name": "urllib.parse.urldefrag",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 593,
        "namespace": "*",
        "body": "def urldefrag(url):\n    \"\"\"Removes any existing fragment from URL.\n\n    Returns a tuple of the defragmented URL and the fragment.  If\n    the URL contained no fragments, the second element is the\n    empty string.\n    \"\"\"\n    url, _coerce_result = _coerce_args(url)\n    if '#' in url:\n        s, n, p, a, q, frag = urlparse(url)\n        defrag = urlunparse((s, n, p, a, q, ''))\n    else:\n        frag = ''\n        defrag = url\n    return _coerce_result(DefragResult(defrag, frag))",
        "name_type": "stdlib"
    },
    "urllib.parse.unquote_to_bytes": {
        "API_name": "urllib.parse.unquote_to_bytes",
        "loc_name": "urllib.parse.unquote_to_bytes",
        "args": "string",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 612,
        "namespace": "*",
        "body": "def unquote_to_bytes(string):\n    \"\"\"unquote_to_bytes('abc%20def') -> b'abc def'.\"\"\"\n    # Note: strings are encoded as UTF-8. This is only an issue if it contains\n    # unescaped non-ASCII characters, which URIs should not.\n    if not string:\n        # Is it a string-like object?\n        string.split\n        return b''\n    if isinstance(string, str):\n        string = string.encode('utf-8')\n    bits = string.split(b'%')\n    if len(bits) == 1:\n        return string\n    res = [bits[0]]\n    append = res.append\n    # Delay the initialization of the table to not waste memory\n    # if the function is never called\n    global _hextobyte\n    if _hextobyte is None:\n        _hextobyte = {(a + b).encode(): bytes.fromhex(a + b)\n                      for a in _hexdig for b in _hexdig}\n    for item in bits[1:]:\n        try:\n            append(_hextobyte[item[:2]])\n            append(item[2:])\n        except KeyError:\n            append(b'%')\n            append(item)\n    return b''.join(res)",
        "name_type": "stdlib"
    },
    "urllib.parse.unquote": {
        "API_name": "urllib.parse.unquote",
        "loc_name": "urllib.parse.unquote",
        "args": "string;encoding;errors",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 644,
        "namespace": "*",
        "body": "def unquote(string, encoding='utf-8', errors='replace'):\n    \"\"\"Replace %xx escapes by their single-character equivalent. The optional\n    encoding and errors parameters specify how to decode percent-encoded\n    sequences into Unicode characters, as accepted by the bytes.decode()\n    method.\n    By default, percent-encoded sequences are decoded with UTF-8, and invalid\n    sequences are replaced by a placeholder character.\n\n    unquote('abc%20def') -> 'abc def'.\n    \"\"\"\n    if isinstance(string, bytes):\n        return unquote_to_bytes(string).decode(encoding, errors)\n    if '%' not in string:\n        string.split\n        return string\n    if encoding is None:\n        encoding = 'utf-8'\n    if errors is None:\n        errors = 'replace'\n    bits = _asciire.split(string)\n    res = [bits[0]]\n    append = res.append\n    for i in range(1, len(bits), 2):\n        append(unquote_to_bytes(bits[i]).decode(encoding, errors))\n        append(bits[i + 1])\n    return ''.join(res)",
        "name_type": "stdlib"
    },
    "urllib.parse.parse_qs": {
        "API_name": "urllib.parse.parse_qs",
        "loc_name": "urllib.parse.parse_qs",
        "args": "qs;keep_blank_values;strict_parsing;encoding;errors;max_num_fields;separator",
        "args_default": 6,
        "filepath": "urllib.parse",
        "lineno": 672,
        "namespace": "*",
        "body": "def parse_qs(qs, keep_blank_values=False, strict_parsing=False,\n             encoding='utf-8', errors='replace', max_num_fields=None, separator='&'):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as\n            blank strings.  The default false value indicates that\n            blank values are to be ignored and treated as if they were\n            not included.\n\n        strict_parsing: flag indicating what to do with parsing errors.\n            If false (the default), errors are silently ignored.\n            If true, errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n\n        max_num_fields: int. If set, then throws a ValueError if there\n            are more than n fields read by parse_qsl().\n\n        separator: str. The symbol to use for separating the query arguments.\n            Defaults to &.\n\n        Returns a dictionary.\n    \"\"\"\n    parsed_result = {}\n    pairs = parse_qsl(qs, keep_blank_values, strict_parsing,\n                      encoding=encoding, errors=errors,\n                      max_num_fields=max_num_fields, separator=separator)\n    for name, value in pairs:\n        if name in parsed_result:\n            parsed_result[name].append(value)\n        else:\n            parsed_result[name] = [value]\n    return parsed_result",
        "name_type": "stdlib"
    },
    "urllib.parse.parse_qsl": {
        "API_name": "urllib.parse.parse_qsl",
        "loc_name": "urllib.parse.parse_qsl",
        "args": "qs;keep_blank_values;strict_parsing;encoding;errors;max_num_fields;separator",
        "args_default": 6,
        "filepath": "urllib.parse",
        "lineno": 714,
        "namespace": "*",
        "body": "def parse_qsl(qs, keep_blank_values=False, strict_parsing=False,\n              encoding='utf-8', errors='replace', max_num_fields=None, separator='&'):\n    \"\"\"Parse a query given as a string argument.\n\n        Arguments:\n\n        qs: percent-encoded query string to be parsed\n\n        keep_blank_values: flag indicating whether blank values in\n            percent-encoded queries should be treated as blank strings.\n            A true value indicates that blanks should be retained as blank\n            strings.  The default false value indicates that blank values\n            are to be ignored and treated as if they were  not included.\n\n        strict_parsing: flag indicating what to do with parsing errors. If\n            false (the default), errors are silently ignored. If true,\n            errors raise a ValueError exception.\n\n        encoding and errors: specify how to decode percent-encoded sequences\n            into Unicode characters, as accepted by the bytes.decode() method.\n\n        max_num_fields: int. If set, then throws a ValueError\n            if there are more than n fields read by parse_qsl().\n\n        separator: str. The symbol to use for separating the query arguments.\n            Defaults to &.\n\n        Returns a list, as G-d intended.\n    \"\"\"\n    qs, _coerce_result = _coerce_args(qs)\n    separator, _ = _coerce_args(separator)\n\n    if not separator or (not isinstance(separator, (str, bytes))):\n        raise ValueError(\"Separator must be of type string or bytes.\")\n\n    # If max_num_fields is defined then check that the number of fields\n    # is less than max_num_fields. This prevents a memory exhaustion DOS\n    # attack via post bodies with many fields.\n    if max_num_fields is not None:\n        num_fields = 1 + qs.count(separator)\n        if max_num_fields < num_fields:\n            raise ValueError('Max number of fields exceeded')\n\n    pairs = [s1 for s1 in qs.split(separator)]\n    r = []\n    for name_value in pairs:\n        if not name_value and not strict_parsing:\n            continue\n        nv = name_value.split('=', 1)\n        if len(nv) != 2:\n            if strict_parsing:\n                raise ValueError(\"bad query field: %r\" % (name_value,))\n            # Handle case of a control-name with no equal sign\n            if keep_blank_values:\n                nv.append('')\n            else:\n                continue\n        if len(nv[1]) or keep_blank_values:\n            name = nv[0].replace('+', ' ')\n            name = unquote(name, encoding=encoding, errors=errors)\n            name = _coerce_result(name)\n            value = nv[1].replace('+', ' ')\n            value = unquote(value, encoding=encoding, errors=errors)\n            value = _coerce_result(value)\n            r.append((name, value))\n    return r",
        "name_type": "stdlib"
    },
    "urllib.parse.unquote_plus": {
        "API_name": "urllib.parse.unquote_plus",
        "loc_name": "urllib.parse.unquote_plus",
        "args": "string;encoding;errors",
        "args_default": 2,
        "filepath": "urllib.parse",
        "lineno": 781,
        "namespace": "*",
        "body": "def unquote_plus(string, encoding='utf-8', errors='replace'):\n    \"\"\"Like unquote(), but also replace plus signs by spaces, as required for\n    unquoting HTML form values.\n\n    unquote_plus('%7e/abc+def') -> '~/abc def'\n    \"\"\"\n    string = string.replace('+', ' ')\n    return unquote(string, encoding, errors)",
        "name_type": "stdlib"
    },
    "urllib.parse.Quoter": {
        "API_name": "urllib.parse.Quoter",
        "loc_name": "urllib.parse.Quoter",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.parse",
        "lineno": 797,
        "namespace": "Quoter",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.parse.Quoter.__init__": {
        "API_name": "urllib.parse.Quoter.__init__",
        "loc_name": "urllib.parse.Quoter.__init__",
        "args": "self;safe",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 805,
        "namespace": "Quoter",
        "body": "    def __init__(self, safe):\n        \"\"\"safe: bytes object.\"\"\"\n        self.safe = _ALWAYS_SAFE.union(safe)",
        "name_type": "stdlib"
    },
    "urllib.parse.Quoter.__repr__": {
        "API_name": "urllib.parse.Quoter.__repr__",
        "loc_name": "urllib.parse.Quoter.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 809,
        "namespace": "Quoter",
        "body": "    def __repr__(self):\n        # Without this, will just display as a defaultdict\n        return \"<%s %r>\" % (self.__class__.__name__, dict(self))",
        "name_type": "stdlib"
    },
    "urllib.parse.Quoter.__missing__": {
        "API_name": "urllib.parse.Quoter.__missing__",
        "loc_name": "urllib.parse.Quoter.__missing__",
        "args": "self;b",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 813,
        "namespace": "Quoter",
        "body": "    def __missing__(self, b):\n        # Handle a cache miss. Store quoted string in cache and return.\n        res = chr(b) if b in self.safe else '%{:02X}'.format(b)\n        self[b] = res\n        return res",
        "name_type": "stdlib"
    },
    "urllib.parse.quote": {
        "API_name": "urllib.parse.quote",
        "loc_name": "urllib.parse.quote",
        "args": "string;safe;encoding;errors",
        "args_default": 3,
        "filepath": "urllib.parse",
        "lineno": 819,
        "namespace": "*",
        "body": "def quote(string, safe='/', encoding=None, errors=None):\n    \"\"\"quote('abc def') -> 'abc%20def'\n\n    Each part of a URL, e.g. the path info, the query, etc., has a\n    different set of reserved characters that must be quoted. The\n    quote function offers a cautious (not minimal) way to quote a\n    string for most of these parts.\n\n    RFC 3986 Uniform Resource Identifier (URI): Generic Syntax lists\n    the following (un)reserved characters.\n\n    unreserved    = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\n    reserved      = gen-delims / sub-delims\n    gen-delims    = \":\" / \"/\" / \"?\" / \"#\" / \"[\" / \"]\" / \"@\"\n    sub-delims    = \"!\" / \"$\" / \"&\" / \"'\" / \"(\" / \")\"\n                  / \"*\" / \"+\" / \",\" / \";\" / \"=\"\n\n    Each of the reserved characters is reserved in some component of a URL,\n    but not necessarily in all of them.\n\n    The quote function %-escapes all characters that are neither in the\n    unreserved chars (\"always safe\") nor the additional chars set via the\n    safe arg.\n\n    The default for the safe arg is '/'. The character is reserved, but in\n    typical usage the quote function is being called on a path where the\n    existing slash characters are to be preserved.\n\n    Python 3.7 updates from using RFC 2396 to RFC 3986 to quote URL strings.\n    Now, \"~\" is included in the set of unreserved characters.\n\n    string and safe may be either str or bytes objects. encoding and errors\n    must not be specified if string is a bytes object.\n\n    The optional encoding and errors parameters specify how to deal with\n    non-ASCII characters, as accepted by the str.encode method.\n    By default, encoding='utf-8' (characters are encoded with UTF-8), and\n    errors='strict' (unsupported characters raise a UnicodeEncodeError).\n    \"\"\"\n    if isinstance(string, str):\n        if not string:\n            return string\n        if encoding is None:\n            encoding = 'utf-8'\n        if errors is None:\n            errors = 'strict'\n        string = string.encode(encoding, errors)\n    else:\n        if encoding is not None:\n            raise TypeError(\"quote() doesn't support 'encoding' for bytes\")\n        if errors is not None:\n            raise TypeError(\"quote() doesn't support 'errors' for bytes\")\n    return quote_from_bytes(string, safe)",
        "name_type": "stdlib"
    },
    "urllib.parse.quote_plus": {
        "API_name": "urllib.parse.quote_plus",
        "loc_name": "urllib.parse.quote_plus",
        "args": "string;safe;encoding;errors",
        "args_default": 3,
        "filepath": "urllib.parse",
        "lineno": 873,
        "namespace": "*",
        "body": "def quote_plus(string, safe='', encoding=None, errors=None):\n    \"\"\"Like quote(), but also replace ' ' with '+', as required for quoting\n    HTML form values. Plus signs in the original string are escaped unless\n    they are included in safe. It also does not have safe default to '/'.\n    \"\"\"\n    # Check if ' ' in string, where string may either be a str or bytes.  If\n    # there are no spaces, the regular quote will produce the right answer.\n    if ((isinstance(string, str) and ' ' not in string) or\n        (isinstance(string, bytes) and b' ' not in string)):\n        return quote(string, safe, encoding, errors)\n    if isinstance(safe, str):\n        space = ' '\n    else:\n        space = b' '\n    string = quote(string, safe + space, encoding, errors)\n    return string.replace(' ', '+')",
        "name_type": "stdlib"
    },
    "urllib.parse.quote_from_bytes": {
        "API_name": "urllib.parse.quote_from_bytes",
        "loc_name": "urllib.parse.quote_from_bytes",
        "args": "bs;safe",
        "args_default": 1,
        "filepath": "urllib.parse",
        "lineno": 890,
        "namespace": "*",
        "body": "def quote_from_bytes(bs, safe='/'):\n    \"\"\"Like quote(), but accepts a bytes object rather than a str, and does\n    not perform string-to-bytes encoding.  It always returns an ASCII string.\n    quote_from_bytes(b'abc def\\x3f') -> 'abc%20def%3f'\n    \"\"\"\n    if not isinstance(bs, (bytes, bytearray)):\n        raise TypeError(\"quote_from_bytes() expected bytes\")\n    if not bs:\n        return ''\n    if isinstance(safe, str):\n        # Normalize 'safe' by converting to bytes and removing non-ASCII chars\n        safe = safe.encode('ascii', 'ignore')\n    else:\n        safe = bytes([c for c in safe if c < 128])\n    if not bs.rstrip(_ALWAYS_SAFE_BYTES + safe):\n        return bs.decode()\n    try:\n        quoter = _safe_quoters[safe]\n    except KeyError:\n        _safe_quoters[safe] = quoter = Quoter(safe).__getitem__\n    return ''.join([quoter(char) for char in bs])",
        "name_type": "stdlib"
    },
    "urllib.parse.urlencode": {
        "API_name": "urllib.parse.urlencode",
        "loc_name": "urllib.parse.urlencode",
        "args": "query;doseq;safe;encoding;errors;quote_via",
        "args_default": 5,
        "filepath": "urllib.parse",
        "lineno": 912,
        "namespace": "*",
        "body": "def urlencode(query, doseq=False, safe='', encoding=None, errors=None,\n              quote_via=quote_plus):\n    \"\"\"Encode a dict or sequence of two-element tuples into a URL query string.\n\n    If any values in the query arg are sequences and doseq is true, each\n    sequence element is converted to a separate parameter.\n\n    If the query arg is a sequence of two-element tuples, the order of the\n    parameters in the output will match the order of parameters in the\n    input.\n\n    The components of a query arg may each be either a string or a bytes type.\n\n    The safe, encoding, and errors parameters are passed down to the function\n    specified by quote_via (encoding and errors only if a component is a str).\n    \"\"\"\n\n    if hasattr(query, \"items\"):\n        query = query.items()\n    else:\n        # It's a bother at times that strings and string-like objects are\n        # sequences.\n        try:\n            # non-sequence items should not work with len()\n            # non-empty strings will fail this\n            if len(query) and not isinstance(query[0], tuple):\n                raise TypeError\n            # Zero-length sequences of all types will get here and succeed,\n            # but that's a minor nit.  Since the original implementation\n            # allowed empty dicts that type of behavior probably should be\n            # preserved for consistency\n        except TypeError:\n            ty, va, tb = sys.exc_info()\n            raise TypeError(\"not a valid non-string sequence \"\n                            \"or mapping object\").with_traceback(tb)\n\n    l = []\n    if not doseq:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_via(k, safe)\n            else:\n                k = quote_via(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_via(v, safe)\n            else:\n                v = quote_via(str(v), safe, encoding, errors)\n            l.append(k + '=' + v)\n    else:\n        for k, v in query:\n            if isinstance(k, bytes):\n                k = quote_via(k, safe)\n            else:\n                k = quote_via(str(k), safe, encoding, errors)\n\n            if isinstance(v, bytes):\n                v = quote_via(v, safe)\n                l.append(k + '=' + v)\n            elif isinstance(v, str):\n                v = quote_via(v, safe, encoding, errors)\n                l.append(k + '=' + v)\n            else:\n                try:\n                    # Is this a sufficient test for sequence-ness?\n                    x = len(v)\n                except TypeError:\n                    # not a sequence\n                    v = quote_via(str(v), safe, encoding, errors)\n                    l.append(k + '=' + v)\n                else:\n                    # loop over the sequence\n                    for elt in v:\n                        if isinstance(elt, bytes):\n                            elt = quote_via(elt, safe)\n                        else:\n                            elt = quote_via(str(elt), safe, encoding, errors)\n                        l.append(k + '=' + elt)\n    return '&'.join(l)",
        "name_type": "stdlib"
    },
    "urllib.parse.to_bytes": {
        "API_name": "urllib.parse.to_bytes",
        "loc_name": "urllib.parse.to_bytes",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 993,
        "namespace": "*",
        "body": "def to_bytes(url):\n    warnings.warn(\"urllib.parse.to_bytes() is deprecated as of 3.8\",\n                  DeprecationWarning, stacklevel=2)\n    return _to_bytes(url)",
        "name_type": "stdlib"
    },
    "urllib.parse._to_bytes": {
        "API_name": "urllib.parse._to_bytes",
        "loc_name": "urllib.parse._to_bytes",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 999,
        "namespace": "*",
        "body": "def _to_bytes(url):\n    \"\"\"to_bytes(u\"URL\") --> 'URL'.\"\"\"\n    # Most URL schemes require ASCII. If that changes, the conversion\n    # can be relaxed.\n    # XXX get rid of to_bytes()\n    if isinstance(url, str):\n        try:\n            url = url.encode(\"ASCII\").decode()\n        except UnicodeError:\n            raise UnicodeError(\"URL \" + repr(url) +\n                               \" contains non-ASCII characters\")\n    return url",
        "name_type": "stdlib"
    },
    "urllib.parse.unwrap": {
        "API_name": "urllib.parse.unwrap",
        "loc_name": "urllib.parse.unwrap",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1013,
        "namespace": "*",
        "body": "def unwrap(url):\n    \"\"\"Transform a string like '<URL:scheme://host/path>' into 'scheme://host/path'.\n\n    The string is returned unchanged if it's not a wrapped URL.\n    \"\"\"\n    url = str(url).strip()\n    if url[:1] == '<' and url[-1:] == '>':\n        url = url[1:-1].strip()\n    if url[:4] == 'URL:':\n        url = url[4:].strip()\n    return url",
        "name_type": "stdlib"
    },
    "urllib.parse.splittype": {
        "API_name": "urllib.parse.splittype",
        "loc_name": "urllib.parse.splittype",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1026,
        "namespace": "*",
        "body": "def splittype(url):\n    warnings.warn(\"urllib.parse.splittype() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splittype(url)",
        "name_type": "stdlib"
    },
    "urllib.parse._splittype": {
        "API_name": "urllib.parse._splittype",
        "loc_name": "urllib.parse._splittype",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1034,
        "namespace": "*",
        "body": "def _splittype(url):\n    \"\"\"splittype('type:opaquestring') --> 'type', 'opaquestring'.\"\"\"\n    global _typeprog\n    if _typeprog is None:\n        _typeprog = re.compile('([^/:]+):(.*)', re.DOTALL)\n\n    match = _typeprog.match(url)\n    if match:\n        scheme, data = match.groups()\n        return scheme.lower(), data\n    return None, url",
        "name_type": "stdlib"
    },
    "urllib.parse.splithost": {
        "API_name": "urllib.parse.splithost",
        "loc_name": "urllib.parse.splithost",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1047,
        "namespace": "*",
        "body": "def splithost(url):\n    warnings.warn(\"urllib.parse.splithost() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splithost(url)",
        "name_type": "stdlib"
    },
    "urllib.parse._splithost": {
        "API_name": "urllib.parse._splithost",
        "loc_name": "urllib.parse._splithost",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1055,
        "namespace": "*",
        "body": "def _splithost(url):\n    \"\"\"splithost('//host[:port]/path') --> 'host[:port]', '/path'.\"\"\"\n    global _hostprog\n    if _hostprog is None:\n        _hostprog = re.compile('//([^/#?]*)(.*)', re.DOTALL)\n\n    match = _hostprog.match(url)\n    if match:\n        host_port, path = match.groups()\n        if path and path[0] != '/':\n            path = '/' + path\n        return host_port, path\n    return None, url",
        "name_type": "stdlib"
    },
    "urllib.parse.splituser": {
        "API_name": "urllib.parse.splituser",
        "loc_name": "urllib.parse.splituser",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1070,
        "namespace": "*",
        "body": "def splituser(host):\n    warnings.warn(\"urllib.parse.splituser() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splituser(host)",
        "name_type": "stdlib"
    },
    "urllib.parse._splituser": {
        "API_name": "urllib.parse._splituser",
        "loc_name": "urllib.parse._splituser",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1077,
        "namespace": "*",
        "body": "def _splituser(host):\n    \"\"\"splituser('user[:passwd]@host[:port]') --> 'user[:passwd]', 'host[:port]'.\"\"\"\n    user, delim, host = host.rpartition('@')\n    return (user if delim else None), host",
        "name_type": "stdlib"
    },
    "urllib.parse.splitpasswd": {
        "API_name": "urllib.parse.splitpasswd",
        "loc_name": "urllib.parse.splitpasswd",
        "args": "user",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1083,
        "namespace": "*",
        "body": "def splitpasswd(user):\n    warnings.warn(\"urllib.parse.splitpasswd() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splitpasswd(user)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitpasswd": {
        "API_name": "urllib.parse._splitpasswd",
        "loc_name": "urllib.parse._splitpasswd",
        "args": "user",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1090,
        "namespace": "*",
        "body": "def _splitpasswd(user):\n    \"\"\"splitpasswd('user:passwd') -> 'user', 'passwd'.\"\"\"\n    user, delim, passwd = user.partition(':')\n    return user, (passwd if delim else None)",
        "name_type": "stdlib"
    },
    "urllib.parse.splitport": {
        "API_name": "urllib.parse.splitport",
        "loc_name": "urllib.parse.splitport",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1096,
        "namespace": "*",
        "body": "def splitport(host):\n    warnings.warn(\"urllib.parse.splitport() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splitport(host)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitport": {
        "API_name": "urllib.parse._splitport",
        "loc_name": "urllib.parse._splitport",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1105,
        "namespace": "*",
        "body": "def _splitport(host):\n    \"\"\"splitport('host:port') --> 'host', 'port'.\"\"\"\n    global _portprog\n    if _portprog is None:\n        _portprog = re.compile('(.*):([0-9]*)', re.DOTALL)\n\n    match = _portprog.fullmatch(host)\n    if match:\n        host, port = match.groups()\n        if port:\n            return host, port\n    return host, None",
        "name_type": "stdlib"
    },
    "urllib.parse.splitnport": {
        "API_name": "urllib.parse.splitnport",
        "loc_name": "urllib.parse.splitnport",
        "args": "host;defport",
        "args_default": 1,
        "filepath": "urllib.parse",
        "lineno": 1119,
        "namespace": "*",
        "body": "def splitnport(host, defport=-1):\n    warnings.warn(\"urllib.parse.splitnport() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splitnport(host, defport)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitnport": {
        "API_name": "urllib.parse._splitnport",
        "loc_name": "urllib.parse._splitnport",
        "args": "host;defport",
        "args_default": 1,
        "filepath": "urllib.parse",
        "lineno": 1126,
        "namespace": "*",
        "body": "def _splitnport(host, defport=-1):\n    \"\"\"Split host and port, returning numeric port.\n    Return given default port if no ':' found; defaults to -1.\n    Return numerical port if a valid number are found after ':'.\n    Return None if ':' but not a valid number.\"\"\"\n    host, delim, port = host.rpartition(':')\n    if not delim:\n        host = port\n    elif port:\n        try:\n            nport = int(port)\n        except ValueError:\n            nport = None\n        return host, nport\n    return host, defport",
        "name_type": "stdlib"
    },
    "urllib.parse.splitquery": {
        "API_name": "urllib.parse.splitquery",
        "loc_name": "urllib.parse.splitquery",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1143,
        "namespace": "*",
        "body": "def splitquery(url):\n    warnings.warn(\"urllib.parse.splitquery() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splitquery(url)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitquery": {
        "API_name": "urllib.parse._splitquery",
        "loc_name": "urllib.parse._splitquery",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1150,
        "namespace": "*",
        "body": "def _splitquery(url):\n    \"\"\"splitquery('/path?query') --> '/path', 'query'.\"\"\"\n    path, delim, query = url.rpartition('?')\n    if delim:\n        return path, query\n    return url, None",
        "name_type": "stdlib"
    },
    "urllib.parse.splittag": {
        "API_name": "urllib.parse.splittag",
        "loc_name": "urllib.parse.splittag",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1158,
        "namespace": "*",
        "body": "def splittag(url):\n    warnings.warn(\"urllib.parse.splittag() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splittag(url)",
        "name_type": "stdlib"
    },
    "urllib.parse._splittag": {
        "API_name": "urllib.parse._splittag",
        "loc_name": "urllib.parse._splittag",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1165,
        "namespace": "*",
        "body": "def _splittag(url):\n    \"\"\"splittag('/path#tag') --> '/path', 'tag'.\"\"\"\n    path, delim, tag = url.rpartition('#')\n    if delim:\n        return path, tag\n    return url, None",
        "name_type": "stdlib"
    },
    "urllib.parse.splitattr": {
        "API_name": "urllib.parse.splitattr",
        "loc_name": "urllib.parse.splitattr",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1173,
        "namespace": "*",
        "body": "def splitattr(url):\n    warnings.warn(\"urllib.parse.splitattr() is deprecated as of 3.8, \"\n                  \"use urllib.parse.urlparse() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splitattr(url)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitattr": {
        "API_name": "urllib.parse._splitattr",
        "loc_name": "urllib.parse._splitattr",
        "args": "url",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1180,
        "namespace": "*",
        "body": "def _splitattr(url):\n    \"\"\"splitattr('/path;attr1=value1;attr2=value2;...') ->\n        '/path', ['attr1=value1', 'attr2=value2', ...].\"\"\"\n    words = url.split(';')\n    return words[0], words[1:]",
        "name_type": "stdlib"
    },
    "urllib.parse.splitvalue": {
        "API_name": "urllib.parse.splitvalue",
        "loc_name": "urllib.parse.splitvalue",
        "args": "attr",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1187,
        "namespace": "*",
        "body": "def splitvalue(attr):\n    warnings.warn(\"urllib.parse.splitvalue() is deprecated as of 3.8, \"\n                  \"use urllib.parse.parse_qsl() instead\",\n                  DeprecationWarning, stacklevel=2)\n    return _splitvalue(attr)",
        "name_type": "stdlib"
    },
    "urllib.parse._splitvalue": {
        "API_name": "urllib.parse._splitvalue",
        "loc_name": "urllib.parse._splitvalue",
        "args": "attr",
        "args_default": 0,
        "filepath": "urllib.parse",
        "lineno": 1194,
        "namespace": "*",
        "body": "def _splitvalue(attr):\n    \"\"\"splitvalue('attr=value') --> 'attr', 'value'.\"\"\"\n    attr, delim, value = attr.partition('=')\n    return attr, (value if delim else None)",
        "name_type": "stdlib"
    },
    "urllib.request": {
        "API_name": "urllib.request",
        "loc_name": "urllib.request",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"An extensible library for opening URLs using a variety of protocols\n\nThe simplest way to use this module is to call the urlopen function,\nwhich accepts a string containing a URL or a Request object (described\nbelow).  It opens the URL and returns the results as file-like\nobject; the returned object has some extra methods described below.\n\nThe OpenerDirector manages a collection of Handler objects that do\nall the actual work.  Each Handler implements a particular protocol or\noption.  The OpenerDirector is a composite object that invokes the\nHandlers needed to open the requested URL.  For example, the\nHTTPHandler performs HTTP GET and POST requests and deals with\nnon-error returns.  The HTTPRedirectHandler automatically deals with\nHTTP 301, 302, 303 and 307 redirect errors, and the HTTPDigestAuthHandler\ndeals with digest authentication.\n\nurlopen(url, data=None) -- Basic usage is the same as original\nurllib.  pass the url and optionally data to post to an HTTP URL, and\nget a file-like object back.  One difference is that you can also pass\na Request instance instead of URL.  Raises a URLError (subclass of\nOSError); for HTTP errors, raises an HTTPError, which can also be\ntreated as a valid response.\n\nbuild_opener -- Function that creates a new OpenerDirector instance.\nWill install the default handlers.  Accepts one or more Handlers as\narguments, either instances or Handler classes that it will\ninstantiate.  If one of the argument is a subclass of the default\nhandler, the argument will be installed instead of the default.\n\ninstall_opener -- Installs a new opener as the default opener.\n\nobjects of interest:\n\nOpenerDirector -- Sets up the User Agent as the Python-urllib client and manages\nthe Handler classes, while dealing with requests and responses.\n\nRequest -- An object that encapsulates the state of a request.  The\nstate can be as simple as the URL.  It can also include extra HTTP\nheaders, e.g. a User-Agent.\n\nBaseHandler --\n\ninternals:\nBaseHandler and parent\n_call_chain conventions\n\nExample usage:\n\nimport urllib.request\n\n# set up authentication info\nauthinfo = urllib.request.HTTPBasicAuthHandler()\nauthinfo.add_password(realm='PDQ Application',\n                      uri='https://mahler:8092/site-updates.py',\n                      user='klem',\n                      passwd='geheim$parole')\n\nproxy_support = urllib.request.ProxyHandler({\"http\" : \"http://ahad-haam:3128\"})\n\n# build a new opener that adds authentication and caching FTP handlers\nopener = urllib.request.build_opener(proxy_support, authinfo,\n                                     urllib.request.CacheFTPHandler)\n\n# install it\nurllib.request.install_opener(opener)\n\nf = urllib.request.urlopen('https://www.python.org/')\n\"\"\"\ntry:\n    import ssl\nexcept ImportError:\n    _have_ssl = False\nelse:\n    _have_ssl = True\n__all__ = [\n    # Classes\n    'Request', 'OpenerDirector', 'BaseHandler', 'HTTPDefaultErrorHandler',\n    'HTTPRedirectHandler', 'HTTPCookieProcessor', 'ProxyHandler',\n    'HTTPPasswordMgr', 'HTTPPasswordMgrWithDefaultRealm',\n    'HTTPPasswordMgrWithPriorAuth', 'AbstractBasicAuthHandler',\n    'HTTPBasicAuthHandler', 'ProxyBasicAuthHandler', 'AbstractDigestAuthHandler',\n    'HTTPDigestAuthHandler', 'ProxyDigestAuthHandler', 'HTTPHandler',\n    'FileHandler', 'FTPHandler', 'CacheFTPHandler', 'DataHandler',\n    'UnknownHandler', 'HTTPErrorProcessor',\n    # Functions\n    'urlopen', 'install_opener', 'build_opener',\n    'pathname2url', 'url2pathname', 'getproxies',\n    # Legacy interface\n    'urlretrieve', 'urlcleanup', 'URLopener', 'FancyURLopener',\n]\n__version__ = '%d.%d' % sys.version_info[:2]\n_opener = None\n_url_tempfiles = []\n_cut_port_re = re.compile(r\":\\d+$\", re.ASCII)\n_randombytes = os.urandom\nif hasattr(http.client, 'HTTPSConnection'):\n\n    class HTTPSHandler(AbstractHTTPHandler):\n\n        def __init__(self, debuglevel=0, context=None, check_hostname=None):\n            AbstractHTTPHandler.__init__(self, debuglevel)\n            self._context = context\n            self._check_hostname = check_hostname\n\n        def https_open(self, req):\n            return self.do_open(http.client.HTTPSConnection, req,\n                context=self._context, check_hostname=self._check_hostname)\n\n        https_request = AbstractHTTPHandler.do_request_\n\n    __all__.append('HTTPSHandler')\nMAXFTPCACHE = 10        # Trim the ftp cache beyond this size\nif os.name == 'nt':\n    from nturl2path import url2pathname, pathname2url\nelse:\n    def url2pathname(pathname):\n        \"\"\"OS-specific conversion from a relative URL of the 'file' scheme\n        to a file system path; not recommended for general use.\"\"\"\n        return unquote(pathname)\n\n    def pathname2url(pathname):\n        \"\"\"OS-specific conversion from a file system path to a relative URL\n        of the 'file' scheme; not recommended for general use.\"\"\"\n        return quote(pathname)\nftpcache = {}\n_localhost = None\n_thishost = None\n_ftperrors = None\n_noheaders = None\nif sys.platform == 'darwin':\n    from _scproxy import _get_proxy_settings, _get_proxies\n\n    def proxy_bypass_macosx_sysconf(host):\n        proxy_settings = _get_proxy_settings()\n        return _proxy_bypass_macosx_sysconf(host, proxy_settings)\n\n    def getproxies_macosx_sysconf():\n        \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n        This function uses the MacOSX framework SystemConfiguration\n        to fetch the proxy information.\n        \"\"\"\n        return _get_proxies()\n\n\n\n    def proxy_bypass(host):\n        \"\"\"Return True, if host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or from the MacOSX framework SystemConfiguration.\n\n        \"\"\"\n        proxies = getproxies_environment()\n        if proxies:\n            return proxy_bypass_environment(host, proxies)\n        else:\n            return proxy_bypass_macosx_sysconf(host)\n\n    def getproxies():\n        return getproxies_environment() or getproxies_macosx_sysconf()\n\n\nelif os.name == 'nt':\n    def getproxies_registry():\n        \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n        Win32 uses the registry to store proxies.\n\n        \"\"\"\n        proxies = {}\n        try:\n            import winreg\n        except ImportError:\n            # Std module, so should be around - but you never know!\n            return proxies\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            proxyEnable = winreg.QueryValueEx(internetSettings,\n                                               'ProxyEnable')[0]\n            if proxyEnable:\n                # Returned as Unicode but problems if not converted to ASCII\n                proxyServer = str(winreg.QueryValueEx(internetSettings,\n                                                       'ProxyServer')[0])\n                if '=' not in proxyServer and ';' not in proxyServer:\n                    # Use one setting for all protocols.\n                    proxyServer = 'http={0};https={0};ftp={0}'.format(proxyServer)\n                for p in proxyServer.split(';'):\n                    protocol, address = p.split('=', 1)\n                    # See if address has a type:// prefix\n                    if not re.match('(?:[^/:]+)://', address):\n                        # Add type:// prefix to address without specifying type\n                        if protocol in ('http', 'https', 'ftp'):\n                            # The default proxy type of Windows is HTTP\n                            address = 'http://' + address\n                        elif protocol == 'socks':\n                            address = 'socks://' + address\n                    proxies[protocol] = address\n                # Use SOCKS proxy for HTTP(S) protocols\n                if proxies.get('socks'):\n                    # The default SOCKS proxy type of Windows is SOCKS4\n                    address = re.sub(r'^socks://', 'socks4://', proxies['socks'])\n                    proxies['http'] = proxies.get('http') or address\n                    proxies['https'] = proxies.get('https') or address\n            internetSettings.Close()\n        except (OSError, ValueError, TypeError):\n            # Either registry key not found etc, or the value in an\n            # unexpected format.\n            # proxies already set up to be empty so nothing to do\n            pass\n        return proxies\n\n    def getproxies():\n        \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n        Returns settings gathered from the environment, if specified,\n        or the registry.\n\n        \"\"\"\n        return getproxies_environment() or getproxies_registry()\n\n    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            # Std modules, so should be around - but you never know!\n            return 0\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            proxyEnable = winreg.QueryValueEx(internetSettings,\n                                               'ProxyEnable')[0]\n            proxyOverride = str(winreg.QueryValueEx(internetSettings,\n                                                     'ProxyOverride')[0])\n            # ^^^^ Returned as Unicode but problems if not converted to ASCII\n        except OSError:\n            return 0\n        if not proxyEnable or not proxyOverride:\n            return 0\n        # try to make a host list from name and IP address.\n        rawHost, port = _splitport(host)\n        host = [rawHost]\n        try:\n            addr = socket.gethostbyname(rawHost)\n            if addr != rawHost:\n                host.append(addr)\n        except OSError:\n            pass\n        try:\n            fqdn = socket.getfqdn(rawHost)\n            if fqdn != rawHost:\n                host.append(fqdn)\n        except OSError:\n            pass\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(';')\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == '<local>':\n                if '.' not in rawHost:\n                    return 1\n            test = test.replace(\".\", r\"\\.\")     # mask dots\n            test = test.replace(\"*\", r\".*\")     # change glob sequence\n            test = test.replace(\"?\", r\".\")      # change glob char\n            for val in host:\n                if re.match(test, val, re.I):\n                    return 1\n        return 0\n\n    def proxy_bypass(host):\n        \"\"\"Return True, if host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n\n        \"\"\"\n        proxies = getproxies_environment()\n        if proxies:\n            return proxy_bypass_environment(host, proxies)\n        else:\n            return proxy_bypass_registry(host)\n\nelse:\n    # By default use environment variables\n    getproxies = getproxies_environment\n    proxy_bypass = proxy_bypass_environment",
        "name_type": "stdlib"
    },
    "urllib.request.urlopen": {
        "API_name": "urllib.request.urlopen",
        "loc_name": "urllib.request.urlopen",
        "args": "url;data;timeout",
        "args_default": 2,
        "filepath": "urllib.request",
        "lineno": 139,
        "namespace": "*",
        "body": "def urlopen(url, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT,\n            *, cafile=None, capath=None, cadefault=False, context=None):\n    '''Open the URL url, which can be either a string or a Request object.\n\n    *data* must be an object specifying additional data to be sent to\n    the server, or None if no such data is needed.  See Request for\n    details.\n\n    urllib.request module uses HTTP/1.1 and includes a \"Connection:close\"\n    header in its HTTP requests.\n\n    The optional *timeout* parameter specifies a timeout in seconds for\n    blocking operations like the connection attempt (if not specified, the\n    global default timeout setting will be used). This only works for HTTP,\n    HTTPS and FTP connections.\n\n    If *context* is specified, it must be a ssl.SSLContext instance describing\n    the various SSL options. See HTTPSConnection for more details.\n\n    The optional *cafile* and *capath* parameters specify a set of trusted CA\n    certificates for HTTPS requests. cafile should point to a single file\n    containing a bundle of CA certificates, whereas capath should point to a\n    directory of hashed certificate files. More information can be found in\n    ssl.SSLContext.load_verify_locations().\n\n    The *cadefault* parameter is ignored.\n\n\n    This function always returns an object which can work as a\n    context manager and has the properties url, headers, and status.\n    See urllib.response.addinfourl for more detail on these properties.\n\n    For HTTP and HTTPS URLs, this function returns a http.client.HTTPResponse\n    object slightly modified. In addition to the three new methods above, the\n    msg attribute contains the same information as the reason attribute ---\n    the reason phrase returned by the server --- instead of the response\n    headers as it is specified in the documentation for HTTPResponse.\n\n    For FTP, file, and data URLs and requests explicitly handled by legacy\n    URLopener and FancyURLopener classes, this function returns a\n    urllib.response.addinfourl object.\n\n    Note that None may be returned if no handler handles the request (though\n    the default installed global OpenerDirector uses UnknownHandler to ensure\n    this never happens).\n\n    In addition, if proxy settings are detected (for example, when a *_proxy\n    environment variable like http_proxy is set), ProxyHandler is default\n    installed and makes sure the requests are handled through the proxy.\n\n    '''\n    global _opener\n    if cafile or capath or cadefault:\n        import warnings\n        warnings.warn(\"cafile, capath and cadefault are deprecated, use a \"\n                      \"custom context instead.\", DeprecationWarning, 2)\n        if context is not None:\n            raise ValueError(\n                \"You can't pass both context and any of cafile, capath, and \"\n                \"cadefault\"\n            )\n        if not _have_ssl:\n            raise ValueError('SSL support not available')\n        context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH,\n                                             cafile=cafile,\n                                             capath=capath)\n        https_handler = HTTPSHandler(context=context)\n        opener = build_opener(https_handler)\n    elif context:\n        https_handler = HTTPSHandler(context=context)\n        opener = build_opener(https_handler)\n    elif _opener is None:\n        _opener = opener = build_opener()\n    else:\n        opener = _opener\n    return opener.open(url, data, timeout)",
        "name_type": "stdlib"
    },
    "urllib.request.install_opener": {
        "API_name": "urllib.request.install_opener",
        "loc_name": "urllib.request.install_opener",
        "args": "opener",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 216,
        "namespace": "*",
        "body": "def install_opener(opener):\n    global _opener\n    _opener = opener",
        "name_type": "stdlib"
    },
    "urllib.request.urlretrieve": {
        "API_name": "urllib.request.urlretrieve",
        "loc_name": "urllib.request.urlretrieve",
        "args": "url;filename;reporthook;data",
        "args_default": 3,
        "filepath": "urllib.request",
        "lineno": 221,
        "namespace": "*",
        "body": "def urlretrieve(url, filename=None, reporthook=None, data=None):\n    \"\"\"\n    Retrieve a URL into a temporary location on disk.\n\n    Requires a URL argument. If a filename is passed, it is used as\n    the temporary file location. The reporthook argument should be\n    a callable that accepts a block number, a read size, and the\n    total file size of the URL target. The data argument should be\n    valid URL encoded data.\n\n    If a filename is passed and the URL points to a local resource,\n    the result is a copy from local file to new file.\n\n    Returns a tuple containing the path to the newly created\n    data file as well as the resulting HTTPMessage object.\n    \"\"\"\n    url_type, path = _splittype(url)\n\n    with contextlib.closing(urlopen(url, data)) as fp:\n        headers = fp.info()\n\n        # Just return the local path and the \"headers\" for file://\n        # URLs. No sense in performing a copy unless requested.\n        if url_type == \"file\" and not filename:\n            return os.path.normpath(path), headers\n\n        # Handle temporary file setup.\n        if filename:\n            tfp = open(filename, 'wb')\n        else:\n            tfp = tempfile.NamedTemporaryFile(delete=False)\n            filename = tfp.name\n            _url_tempfiles.append(filename)\n\n        with tfp:\n            result = filename, headers\n            bs = 1024*8\n            size = -1\n            read = 0\n            blocknum = 0\n            if \"content-length\" in headers:\n                size = int(headers[\"Content-Length\"])\n\n            if reporthook:\n                reporthook(blocknum, bs, size)\n\n            while True:\n                block = fp.read(bs)\n                if not block:\n                    break\n                read += len(block)\n                tfp.write(block)\n                blocknum += 1\n                if reporthook:\n                    reporthook(blocknum, bs, size)\n\n    if size >= 0 and read < size:\n        raise ContentTooShortError(\n            \"retrieval incomplete: got only %i out of %i bytes\"\n            % (read, size), result)\n\n    return result",
        "name_type": "stdlib"
    },
    "urllib.request.urlcleanup": {
        "API_name": "urllib.request.urlcleanup",
        "loc_name": "urllib.request.urlcleanup",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 284,
        "namespace": "*",
        "body": "def urlcleanup():\n    \"\"\"Clean up temporary files from urlretrieve calls.\"\"\"\n    for temp_file in _url_tempfiles:\n        try:\n            os.unlink(temp_file)\n        except OSError:\n            pass\n\n    del _url_tempfiles[:]\n    global _opener\n    if _opener:\n        _opener = None",
        "name_type": "stdlib"
    },
    "urllib.request.request_host": {
        "API_name": "urllib.request.request_host",
        "loc_name": "urllib.request.request_host",
        "args": "request",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 299,
        "namespace": "*",
        "body": "def request_host(request):\n    \"\"\"Return request-host, as defined by RFC 2965.\n\n    Variation from RFC: returned value is lowercased, for convenient\n    comparison.\n\n    \"\"\"\n    url = request.full_url\n    host = urlparse(url)[1]\n    if host == \"\":\n        host = request.get_header(\"Host\", \"\")\n\n    # remove port, if present\n    host = _cut_port_re.sub(\"\", host, 1)\n    return host.lower()",
        "name_type": "stdlib"
    },
    "urllib.request.Request": {
        "API_name": "urllib.request.Request",
        "loc_name": "urllib.request.Request",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 315,
        "namespace": "Request",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.Request.__init__": {
        "API_name": "urllib.request.Request.__init__",
        "loc_name": "urllib.request.Request.__init__",
        "args": "self;url;data;headers;origin_req_host;unverifiable;method",
        "args_default": 5,
        "filepath": "urllib.request",
        "lineno": 317,
        "namespace": "Request",
        "body": "    def __init__(self, url, data=None, headers={},\n                 origin_req_host=None, unverifiable=False,\n                 method=None):\n        self.full_url = url\n        self.headers = {}\n        self.unredirected_hdrs = {}\n        self._data = None\n        self.data = data\n        self._tunnel_host = None\n        for key, value in headers.items():\n            self.add_header(key, value)\n        if origin_req_host is None:\n            origin_req_host = request_host(self)\n        self.origin_req_host = origin_req_host\n        self.unverifiable = unverifiable\n        if method:\n            self.method = method",
        "name_type": "stdlib"
    },
    "urllib.request.Request.full_url": {
        "API_name": "urllib.request.Request.full_url",
        "loc_name": "urllib.request.Request.full_url",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 349,
        "namespace": "Request",
        "body": "    def full_url(self):\n        self._full_url = None\n        self.fragment = None\n        self.selector = ''",
        "name_type": "stdlib"
    },
    "urllib.request.Request.data": {
        "API_name": "urllib.request.Request.data",
        "loc_name": "urllib.request.Request.data",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 369,
        "namespace": "Request",
        "body": "    def data(self):\n        self.data = None",
        "name_type": "stdlib"
    },
    "urllib.request.Request._parse": {
        "API_name": "urllib.request.Request._parse",
        "loc_name": "urllib.request.Request._parse",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 372,
        "namespace": "Request",
        "body": "    def _parse(self):\n        self.type, rest = _splittype(self._full_url)\n        if self.type is None:\n            raise ValueError(\"unknown url type: %r\" % self.full_url)\n        self.host, self.selector = _splithost(rest)\n        if self.host:\n            self.host = unquote(self.host)",
        "name_type": "stdlib"
    },
    "urllib.request.Request.get_method": {
        "API_name": "urllib.request.Request.get_method",
        "loc_name": "urllib.request.Request.get_method",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 380,
        "namespace": "Request",
        "body": "    def get_method(self):\n        \"\"\"Return a string indicating the HTTP request method.\"\"\"\n        default_method = \"POST\" if self.data is not None else \"GET\"\n        return getattr(self, 'method', default_method)",
        "name_type": "stdlib"
    },
    "urllib.request.Request.get_full_url": {
        "API_name": "urllib.request.Request.get_full_url",
        "loc_name": "urllib.request.Request.get_full_url",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 385,
        "namespace": "Request",
        "body": "    def get_full_url(self):\n        return self.full_url",
        "name_type": "stdlib"
    },
    "urllib.request.Request.set_proxy": {
        "API_name": "urllib.request.Request.set_proxy",
        "loc_name": "urllib.request.Request.set_proxy",
        "args": "self;host;type",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 388,
        "namespace": "Request",
        "body": "    def set_proxy(self, host, type):\n        if self.type == 'https' and not self._tunnel_host:\n            self._tunnel_host = self.host\n        else:\n            self.type= type\n            self.selector = self.full_url\n        self.host = host",
        "name_type": "stdlib"
    },
    "urllib.request.Request.has_proxy": {
        "API_name": "urllib.request.Request.has_proxy",
        "loc_name": "urllib.request.Request.has_proxy",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 396,
        "namespace": "Request",
        "body": "    def has_proxy(self):\n        return self.selector == self.full_url",
        "name_type": "stdlib"
    },
    "urllib.request.Request.add_header": {
        "API_name": "urllib.request.Request.add_header",
        "loc_name": "urllib.request.Request.add_header",
        "args": "self;key;val",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 399,
        "namespace": "Request",
        "body": "    def add_header(self, key, val):\n        # useful for something like authentication\n        self.headers[key.capitalize()] = val",
        "name_type": "stdlib"
    },
    "urllib.request.Request.add_unredirected_header": {
        "API_name": "urllib.request.Request.add_unredirected_header",
        "loc_name": "urllib.request.Request.add_unredirected_header",
        "args": "self;key;val",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 403,
        "namespace": "Request",
        "body": "    def add_unredirected_header(self, key, val):\n        # will not be added to a redirected request\n        self.unredirected_hdrs[key.capitalize()] = val",
        "name_type": "stdlib"
    },
    "urllib.request.Request.has_header": {
        "API_name": "urllib.request.Request.has_header",
        "loc_name": "urllib.request.Request.has_header",
        "args": "self;header_name",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 407,
        "namespace": "Request",
        "body": "    def has_header(self, header_name):\n        return (header_name in self.headers or\n                header_name in self.unredirected_hdrs)",
        "name_type": "stdlib"
    },
    "urllib.request.Request.get_header": {
        "API_name": "urllib.request.Request.get_header",
        "loc_name": "urllib.request.Request.get_header",
        "args": "self;header_name;default",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 411,
        "namespace": "Request",
        "body": "    def get_header(self, header_name, default=None):\n        return self.headers.get(\n            header_name,\n            self.unredirected_hdrs.get(header_name, default))",
        "name_type": "stdlib"
    },
    "urllib.request.Request.remove_header": {
        "API_name": "urllib.request.Request.remove_header",
        "loc_name": "urllib.request.Request.remove_header",
        "args": "self;header_name",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 416,
        "namespace": "Request",
        "body": "    def remove_header(self, header_name):\n        self.headers.pop(header_name, None)\n        self.unredirected_hdrs.pop(header_name, None)",
        "name_type": "stdlib"
    },
    "urllib.request.Request.header_items": {
        "API_name": "urllib.request.Request.header_items",
        "loc_name": "urllib.request.Request.header_items",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 420,
        "namespace": "Request",
        "body": "    def header_items(self):\n        hdrs = {**self.unredirected_hdrs, **self.headers}\n        return list(hdrs.items())",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector": {
        "API_name": "urllib.request.OpenerDirector",
        "loc_name": "urllib.request.OpenerDirector",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 424,
        "namespace": "OpenerDirector",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector.__init__": {
        "API_name": "urllib.request.OpenerDirector.__init__",
        "loc_name": "urllib.request.OpenerDirector.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 425,
        "namespace": "OpenerDirector",
        "body": "    def __init__(self):\n        client_version = \"Python-urllib/%s\" % __version__\n        self.addheaders = [('User-agent', client_version)]\n        # self.handlers is retained only for backward compatibility\n        self.handlers = []\n        # manage the individual handlers\n        self.handle_open = {}\n        self.handle_error = {}\n        self.process_response = {}\n        self.process_request = {}",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector.add_handler": {
        "API_name": "urllib.request.OpenerDirector.add_handler",
        "loc_name": "urllib.request.OpenerDirector.add_handler",
        "args": "self;handler",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 436,
        "namespace": "OpenerDirector",
        "body": "    def add_handler(self, handler):\n        if not hasattr(handler, \"add_parent\"):\n            raise TypeError(\"expected BaseHandler instance, got %r\" %\n                            type(handler))\n\n        added = False\n        for meth in dir(handler):\n            if meth in [\"redirect_request\", \"do_open\", \"proxy_open\"]:\n                # oops, coincidental match\n                continue\n\n            i = meth.find(\"_\")\n            protocol = meth[:i]\n            condition = meth[i+1:]\n\n            if condition.startswith(\"error\"):\n                j = condition.find(\"_\") + i + 1\n                kind = meth[j+1:]\n                try:\n                    kind = int(kind)\n                except ValueError:\n                    pass\n                lookup = self.handle_error.get(protocol, {})\n                self.handle_error[protocol] = lookup\n            elif condition == \"open\":\n                kind = protocol\n                lookup = self.handle_open\n            elif condition == \"response\":\n                kind = protocol\n                lookup = self.process_response\n            elif condition == \"request\":\n                kind = protocol\n                lookup = self.process_request\n            else:\n                continue\n\n            handlers = lookup.setdefault(kind, [])\n            if handlers:\n                bisect.insort(handlers, handler)\n            else:\n                handlers.append(handler)\n            added = True\n\n        if added:\n            bisect.insort(self.handlers, handler)\n            handler.add_parent(self)",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector.close": {
        "API_name": "urllib.request.OpenerDirector.close",
        "loc_name": "urllib.request.OpenerDirector.close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 483,
        "namespace": "OpenerDirector",
        "body": "    def close(self):\n        # Only exists for backwards compatibility.\n        pass",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector._call_chain": {
        "API_name": "urllib.request.OpenerDirector._call_chain",
        "loc_name": "urllib.request.OpenerDirector._call_chain",
        "args": "self;chain;kind;meth_name",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 487,
        "namespace": "OpenerDirector",
        "body": "    def _call_chain(self, chain, kind, meth_name, *args):\n        # Handlers raise an exception if no one else should try to handle\n        # the request, or return None if they can't but another handler\n        # could.  Otherwise, they return the response.\n        handlers = chain.get(kind, ())\n        for handler in handlers:\n            func = getattr(handler, meth_name)\n            result = func(*args)\n            if result is not None:\n                return result",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector.open": {
        "API_name": "urllib.request.OpenerDirector.open",
        "loc_name": "urllib.request.OpenerDirector.open",
        "args": "self;fullurl;data;timeout",
        "args_default": 2,
        "filepath": "urllib.request",
        "lineno": 498,
        "namespace": "OpenerDirector",
        "body": "    def open(self, fullurl, data=None, timeout=socket._GLOBAL_DEFAULT_TIMEOUT):\n        # accept a URL or a Request object\n        if isinstance(fullurl, str):\n            req = Request(fullurl, data)\n        else:\n            req = fullurl\n            if data is not None:\n                req.data = data\n\n        req.timeout = timeout\n        protocol = req.type\n\n        # pre-process request\n        meth_name = protocol+\"_request\"\n        for processor in self.process_request.get(protocol, []):\n            meth = getattr(processor, meth_name)\n            req = meth(req)\n\n        sys.audit('urllib.Request', req.full_url, req.data, req.headers, req.get_method())\n        response = self._open(req, data)\n\n        # post-process response\n        meth_name = protocol+\"_response\"\n        for processor in self.process_response.get(protocol, []):\n            meth = getattr(processor, meth_name)\n            response = meth(req, response)\n\n        return response",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector._open": {
        "API_name": "urllib.request.OpenerDirector._open",
        "loc_name": "urllib.request.OpenerDirector._open",
        "args": "self;req;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 527,
        "namespace": "OpenerDirector",
        "body": "    def _open(self, req, data=None):\n        result = self._call_chain(self.handle_open, 'default',\n                                  'default_open', req)\n        if result:\n            return result\n\n        protocol = req.type\n        result = self._call_chain(self.handle_open, protocol, protocol +\n                                  '_open', req)\n        if result:\n            return result\n\n        return self._call_chain(self.handle_open, 'unknown',\n                                'unknown_open', req)",
        "name_type": "stdlib"
    },
    "urllib.request.OpenerDirector.error": {
        "API_name": "urllib.request.OpenerDirector.error",
        "loc_name": "urllib.request.OpenerDirector.error",
        "args": "self;proto",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 542,
        "namespace": "OpenerDirector",
        "body": "    def error(self, proto, *args):\n        if proto in ('http', 'https'):\n            # XXX http[s] protocols are special-cased\n            dict = self.handle_error['http'] # https is not different than http\n            proto = args[2]  # YUCK!\n            meth_name = 'http_error_%s' % proto\n            http_err = 1\n            orig_args = args\n        else:\n            dict = self.handle_error\n            meth_name = proto + '_error'\n            http_err = 0\n        args = (dict, proto, meth_name) + args\n        result = self._call_chain(*args)\n        if result:\n            return result\n\n        if http_err:\n            args = (dict, 'default', 'http_error_default') + orig_args\n            return self._call_chain(*args)",
        "name_type": "stdlib"
    },
    "urllib.request.build_opener": {
        "API_name": "urllib.request.build_opener",
        "loc_name": "urllib.request.build_opener",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 567,
        "namespace": "*",
        "body": "def build_opener(*handlers):\n    \"\"\"Create an opener object from a list of handlers.\n\n    The opener will use several default handlers, including support\n    for HTTP, FTP and when applicable HTTPS.\n\n    If any of the handlers passed as arguments are subclasses of the\n    default handlers, the default handlers will not be used.\n    \"\"\"\n    opener = OpenerDirector()\n    default_classes = [ProxyHandler, UnknownHandler, HTTPHandler,\n                       HTTPDefaultErrorHandler, HTTPRedirectHandler,\n                       FTPHandler, FileHandler, HTTPErrorProcessor,\n                       DataHandler]\n    if hasattr(http.client, \"HTTPSConnection\"):\n        default_classes.append(HTTPSHandler)\n    skip = set()\n    for klass in default_classes:\n        for check in handlers:\n            if isinstance(check, type):\n                if issubclass(check, klass):\n                    skip.add(klass)\n            elif isinstance(check, klass):\n                skip.add(klass)\n    for klass in skip:\n        default_classes.remove(klass)\n\n    for klass in default_classes:\n        opener.add_handler(klass())\n\n    for h in handlers:\n        if isinstance(h, type):\n            h = h()\n        opener.add_handler(h)\n    return opener",
        "name_type": "stdlib"
    },
    "urllib.request.BaseHandler.add_parent": {
        "API_name": "urllib.request.BaseHandler.add_parent",
        "loc_name": "urllib.request.BaseHandler.add_parent",
        "args": "self;parent",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 606,
        "namespace": "BaseHandler",
        "body": "    def add_parent(self, parent):\n        self.parent = parent",
        "name_type": "stdlib"
    },
    "urllib.request.BaseHandler.close": {
        "API_name": "urllib.request.BaseHandler.close",
        "loc_name": "urllib.request.BaseHandler.close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 609,
        "namespace": "BaseHandler",
        "body": "    def close(self):\n        # Only exists for backwards compatibility\n        pass",
        "name_type": "stdlib"
    },
    "urllib.request.BaseHandler.__lt__": {
        "API_name": "urllib.request.BaseHandler.__lt__",
        "loc_name": "urllib.request.BaseHandler.__lt__",
        "args": "self;other",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 613,
        "namespace": "BaseHandler",
        "body": "    def __lt__(self, other):\n        if not hasattr(other, \"handler_order\"):\n            # Try to preserve the old behavior of having custom classes\n            # inserted after default ones (works only for custom user\n            # classes which are not aware of handler_order).\n            return True\n        return self.handler_order < other.handler_order",
        "name_type": "stdlib"
    },
    "urllib.request.BaseHandler": {
        "API_name": "urllib.request.BaseHandler",
        "loc_name": "urllib.request.BaseHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 603,
        "namespace": "BaseHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPErrorProcessor.http_response": {
        "API_name": "urllib.request.HTTPErrorProcessor.http_response",
        "loc_name": "urllib.request.HTTPErrorProcessor.http_response",
        "args": "self;request;response",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 626,
        "namespace": "HTTPErrorProcessor",
        "body": "    def http_response(self, request, response):\n        code, msg, hdrs = response.code, response.msg, response.info()\n\n        # According to RFC 2616, \"2xx\" code indicates that the client's\n        # request was successfully received, understood, and accepted.\n        if not (200 <= code < 300):\n            response = self.parent.error(\n                'http', request, response, code, msg, hdrs)\n\n        return response",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPErrorProcessor": {
        "API_name": "urllib.request.HTTPErrorProcessor",
        "loc_name": "urllib.request.HTTPErrorProcessor",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 622,
        "namespace": "HTTPErrorProcessor",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPDefaultErrorHandler.http_error_default": {
        "API_name": "urllib.request.HTTPDefaultErrorHandler.http_error_default",
        "loc_name": "urllib.request.HTTPDefaultErrorHandler.http_error_default",
        "args": "self;req;fp;code;msg;hdrs",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 640,
        "namespace": "HTTPDefaultErrorHandler",
        "body": "    def http_error_default(self, req, fp, code, msg, hdrs):\n        raise HTTPError(req.full_url, code, msg, hdrs, fp)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPDefaultErrorHandler": {
        "API_name": "urllib.request.HTTPDefaultErrorHandler",
        "loc_name": "urllib.request.HTTPDefaultErrorHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 639,
        "namespace": "HTTPDefaultErrorHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPRedirectHandler.redirect_request": {
        "API_name": "urllib.request.HTTPRedirectHandler.redirect_request",
        "loc_name": "urllib.request.HTTPRedirectHandler.redirect_request",
        "args": "self;req;fp;code;msg;headers;newurl",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 651,
        "namespace": "HTTPRedirectHandler",
        "body": "    def redirect_request(self, req, fp, code, msg, headers, newurl):\n        \"\"\"Return a Request or None in response to a redirect.\n\n        This is called by the http_error_30x methods when a\n        redirection response is received.  If a redirection should\n        take place, return a new Request to allow http_error_30x to\n        perform the redirect.  Otherwise, raise HTTPError if no-one\n        else should try to handle this url.  Return None if you can't\n        but another Handler might.\n        \"\"\"\n        m = req.get_method()\n        if (not (code in (301, 302, 303, 307) and m in (\"GET\", \"HEAD\")\n            or code in (301, 302, 303) and m == \"POST\")):\n            raise HTTPError(req.full_url, code, msg, headers, fp)\n\n        # Strictly (according to RFC 2616), 301 or 302 in response to\n        # a POST MUST NOT cause a redirection without confirmation\n        # from the user (of urllib.request, in this case).  In practice,\n        # essentially all clients do redirect in this case, so we do\n        # the same.\n\n        # Be conciliant with URIs containing a space.  This is mainly\n        # redundant with the more complete encoding done in http_error_302(),\n        # but it is kept for compatibility with other callers.\n        newurl = newurl.replace(' ', '%20')\n\n        CONTENT_HEADERS = (\"content-length\", \"content-type\")\n        newheaders = {k: v for k, v in req.headers.items()\n                      if k.lower() not in CONTENT_HEADERS}\n        return Request(newurl,\n                       headers=newheaders,\n                       origin_req_host=req.origin_req_host,\n                       unverifiable=True)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPRedirectHandler.http_error_302": {
        "API_name": "urllib.request.HTTPRedirectHandler.http_error_302",
        "loc_name": "urllib.request.HTTPRedirectHandler.http_error_302",
        "args": "self;req;fp;code;msg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 689,
        "namespace": "HTTPRedirectHandler",
        "body": "    def http_error_302(self, req, fp, code, msg, headers):\n        # Some servers (incorrectly) return multiple Location headers\n        # (so probably same goes for URI).  Use first header.\n        if \"location\" in headers:\n            newurl = headers[\"location\"]\n        elif \"uri\" in headers:\n            newurl = headers[\"uri\"]\n        else:\n            return\n\n        # fix a possible malformed URL\n        urlparts = urlparse(newurl)\n\n        # For security reasons we don't allow redirection to anything other\n        # than http, https or ftp.\n\n        if urlparts.scheme not in ('http', 'https', 'ftp', ''):\n            raise HTTPError(\n                newurl, code,\n                \"%s - Redirection to url '%s' is not allowed\" % (msg, newurl),\n                headers, fp)\n\n        if not urlparts.path and urlparts.netloc:\n            urlparts = list(urlparts)\n            urlparts[2] = \"/\"\n        newurl = urlunparse(urlparts)\n\n        # http.client.parse_headers() decodes as ISO-8859-1.  Recover the\n        # original bytes and percent-encode non-ASCII bytes, and any special\n        # characters such as the space.\n        newurl = quote(\n            newurl, encoding=\"iso-8859-1\", safe=string.punctuation)\n        newurl = urljoin(req.full_url, newurl)\n\n        # XXX Probably want to forget about the state of the current\n        # request, although that might interact poorly with other\n        # handlers that also use handler-specific request attributes\n        new = self.redirect_request(req, fp, code, msg, headers, newurl)\n        if new is None:\n            return\n\n        # loop detection\n        # .redirect_dict has a key url if url was previously visited.\n        if hasattr(req, 'redirect_dict'):\n            visited = new.redirect_dict = req.redirect_dict\n            if (visited.get(newurl, 0) >= self.max_repeats or\n                len(visited) >= self.max_redirections):\n                raise HTTPError(req.full_url, code,\n                                self.inf_msg + msg, headers, fp)\n        else:\n            visited = new.redirect_dict = req.redirect_dict = {}\n        visited[newurl] = visited.get(newurl, 0) + 1\n\n        # Don't close the fp until we are sure that we won't use it\n        # with HTTPError.\n        fp.read()\n        fp.close()\n\n        return self.parent.open(new, timeout=req.timeout)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPRedirectHandler": {
        "API_name": "urllib.request.HTTPRedirectHandler",
        "loc_name": "urllib.request.HTTPRedirectHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 643,
        "namespace": "HTTPRedirectHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request._parse_proxy": {
        "API_name": "urllib.request._parse_proxy",
        "loc_name": "urllib.request._parse_proxy",
        "args": "proxy",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 756,
        "namespace": "*",
        "body": "def _parse_proxy(proxy):\n    \"\"\"Return (scheme, user, password, host/port) given a URL or an authority.\n\n    If a URL is supplied, it must have an authority (host:port) component.\n    According to RFC 3986, having an authority component means the URL must\n    have two slashes after the scheme.\n    \"\"\"\n    scheme, r_scheme = _splittype(proxy)\n    if not r_scheme.startswith(\"/\"):\n        # authority\n        scheme = None\n        authority = proxy\n    else:\n        # URL\n        if not r_scheme.startswith(\"//\"):\n            raise ValueError(\"proxy URL with no authority: %r\" % proxy)\n        # We have an authority, so for RFC 3986-compliant URLs (by ss 3.\n        # and 3.3.), path is empty or starts with '/'\n        if '@' in r_scheme:\n            host_separator = r_scheme.find('@')\n            end = r_scheme.find(\"/\", host_separator)\n        else:\n            end = r_scheme.find(\"/\", 2)\n        if end == -1:\n            end = None\n        authority = r_scheme[2:end]\n    userinfo, hostport = _splituser(authority)\n    if userinfo is not None:\n        user, password = _splitpasswd(userinfo)\n    else:\n        user = password = None\n    return scheme, user, password, hostport",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyHandler": {
        "API_name": "urllib.request.ProxyHandler",
        "loc_name": "urllib.request.ProxyHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 789,
        "namespace": "ProxyHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyHandler.__init__": {
        "API_name": "urllib.request.ProxyHandler.__init__",
        "loc_name": "urllib.request.ProxyHandler.__init__",
        "args": "self;proxies",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 793,
        "namespace": "ProxyHandler",
        "body": "    def __init__(self, proxies=None):\n        if proxies is None:\n            proxies = getproxies()\n        assert hasattr(proxies, 'keys'), \"proxies must be a mapping\"\n        self.proxies = proxies\n        for type, url in proxies.items():\n            type = type.lower()\n            setattr(self, '%s_open' % type,\n                    lambda r, proxy=url, type=type, meth=self.proxy_open:\n                        meth(r, proxy, type))",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyHandler.proxy_open": {
        "API_name": "urllib.request.ProxyHandler.proxy_open",
        "loc_name": "urllib.request.ProxyHandler.proxy_open",
        "args": "self;req;proxy;type",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 804,
        "namespace": "ProxyHandler",
        "body": "    def proxy_open(self, req, proxy, type):\n        orig_type = req.type\n        proxy_type, user, password, hostport = _parse_proxy(proxy)\n        if proxy_type is None:\n            proxy_type = orig_type\n\n        if req.host and proxy_bypass(req.host):\n            return None\n\n        if user and password:\n            user_pass = '%s:%s' % (unquote(user),\n                                   unquote(password))\n            creds = base64.b64encode(user_pass.encode()).decode(\"ascii\")\n            req.add_header('Proxy-authorization', 'Basic ' + creds)\n        hostport = unquote(hostport)\n        req.set_proxy(hostport, proxy_type)\n        if orig_type == proxy_type or orig_type == 'https':\n            # let other handlers take care of it\n            return None\n        else:\n            # need to start over, because the other handlers don't\n            # grok the proxy's URL type\n            # e.g. if we have a constructor arg proxies like so:\n            # {'http': 'ftp://proxy.example.com'}, we may end up turning\n            # a request for http://acme.example.com/a into one for\n            # ftp://proxy.example.com/a\n            return self.parent.open(req, timeout=req.timeout)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgr": {
        "API_name": "urllib.request.HTTPPasswordMgr",
        "loc_name": "urllib.request.HTTPPasswordMgr",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 832,
        "namespace": "HTTPPasswordMgr",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgr.__init__": {
        "API_name": "urllib.request.HTTPPasswordMgr.__init__",
        "loc_name": "urllib.request.HTTPPasswordMgr.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 834,
        "namespace": "HTTPPasswordMgr",
        "body": "    def __init__(self):\n        self.passwd = {}",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgr.add_password": {
        "API_name": "urllib.request.HTTPPasswordMgr.add_password",
        "loc_name": "urllib.request.HTTPPasswordMgr.add_password",
        "args": "self;realm;uri;user;passwd",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 837,
        "namespace": "HTTPPasswordMgr",
        "body": "    def add_password(self, realm, uri, user, passwd):\n        # uri could be a single URI or a sequence\n        if isinstance(uri, str):\n            uri = [uri]\n        if realm not in self.passwd:\n            self.passwd[realm] = {}\n        for default_port in True, False:\n            reduced_uri = tuple(\n                self.reduce_uri(u, default_port) for u in uri)\n            self.passwd[realm][reduced_uri] = (user, passwd)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgr.find_user_password": {
        "API_name": "urllib.request.HTTPPasswordMgr.find_user_password",
        "loc_name": "urllib.request.HTTPPasswordMgr.find_user_password",
        "args": "self;realm;authuri",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 848,
        "namespace": "HTTPPasswordMgr",
        "body": "    def find_user_password(self, realm, authuri):\n        domains = self.passwd.get(realm, {})\n        for default_port in True, False:\n            reduced_authuri = self.reduce_uri(authuri, default_port)\n            for uris, authinfo in domains.items():\n                for uri in uris:\n                    if self.is_suburi(uri, reduced_authuri):\n                        return authinfo\n        return None, None",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgr.reduce_uri": {
        "API_name": "urllib.request.HTTPPasswordMgr.reduce_uri",
        "loc_name": "urllib.request.HTTPPasswordMgr.reduce_uri",
        "args": "self;uri;default_port",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 858,
        "namespace": "HTTPPasswordMgr",
        "body": "    def reduce_uri(self, uri, default_port=True):\n        \"\"\"Accept authority or URI and extract only the authority and path.\"\"\"\n        # note HTTP URLs do not have a userinfo component\n        parts = urlsplit(uri)\n        if parts[1]:\n            # URI\n            scheme = parts[0]\n            authority = parts[1]\n            path = parts[2] or '/'\n        else:\n            # host or host:port\n            scheme = None\n            authority = uri\n            path = '/'\n        host, port = _splitport(authority)\n        if default_port and port is None and scheme is not None:\n            dport = {\"http\": 80,\n                     \"https\": 443,\n                     }.get(scheme)\n            if dport is not None:\n                authority = \"%s:%d\" % (host, dport)\n        return authority, path",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgr.is_suburi": {
        "API_name": "urllib.request.HTTPPasswordMgr.is_suburi",
        "loc_name": "urllib.request.HTTPPasswordMgr.is_suburi",
        "args": "self;base;test",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 881,
        "namespace": "HTTPPasswordMgr",
        "body": "    def is_suburi(self, base, test):\n        \"\"\"Check if test is below base in a URI tree\n\n        Both args must be URIs in reduced form.\n        \"\"\"\n        if base == test:\n            return True\n        if base[0] != test[0]:\n            return False\n        prefix = base[1]\n        if prefix[-1:] != '/':\n            prefix += '/'\n        return test[1].startswith(prefix)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithDefaultRealm.find_user_password": {
        "API_name": "urllib.request.HTTPPasswordMgrWithDefaultRealm.find_user_password",
        "loc_name": "urllib.request.HTTPPasswordMgrWithDefaultRealm.find_user_password",
        "args": "self;realm;authuri",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 898,
        "namespace": "HTTPPasswordMgrWithDefaultRealm",
        "body": "    def find_user_password(self, realm, authuri):\n        user, password = HTTPPasswordMgr.find_user_password(self, realm,\n                                                            authuri)\n        if user is not None:\n            return user, password\n        return HTTPPasswordMgr.find_user_password(self, None, authuri)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithDefaultRealm": {
        "API_name": "urllib.request.HTTPPasswordMgrWithDefaultRealm",
        "loc_name": "urllib.request.HTTPPasswordMgrWithDefaultRealm",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 896,
        "namespace": "HTTPPasswordMgrWithDefaultRealm",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithPriorAuth": {
        "API_name": "urllib.request.HTTPPasswordMgrWithPriorAuth",
        "loc_name": "urllib.request.HTTPPasswordMgrWithPriorAuth",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 906,
        "namespace": "HTTPPasswordMgrWithPriorAuth",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithPriorAuth.__init__": {
        "API_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.__init__",
        "loc_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 908,
        "namespace": "HTTPPasswordMgrWithPriorAuth",
        "body": "    def __init__(self, *args, **kwargs):\n        self.authenticated = {}\n        super().__init__(*args, **kwargs)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithPriorAuth.add_password": {
        "API_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.add_password",
        "loc_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.add_password",
        "args": "self;realm;uri;user;passwd;is_authenticated",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 912,
        "namespace": "HTTPPasswordMgrWithPriorAuth",
        "body": "    def add_password(self, realm, uri, user, passwd, is_authenticated=False):\n        self.update_authenticated(uri, is_authenticated)\n        # Add a default for prior auth requests\n        if realm is not None:\n            super().add_password(None, uri, user, passwd)\n        super().add_password(realm, uri, user, passwd)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithPriorAuth.update_authenticated": {
        "API_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.update_authenticated",
        "loc_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.update_authenticated",
        "args": "self;uri;is_authenticated",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 919,
        "namespace": "HTTPPasswordMgrWithPriorAuth",
        "body": "    def update_authenticated(self, uri, is_authenticated=False):\n        # uri could be a single URI or a sequence\n        if isinstance(uri, str):\n            uri = [uri]\n\n        for default_port in True, False:\n            for u in uri:\n                reduced_uri = self.reduce_uri(u, default_port)\n                self.authenticated[reduced_uri] = is_authenticated",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPPasswordMgrWithPriorAuth.is_authenticated": {
        "API_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.is_authenticated",
        "loc_name": "urllib.request.HTTPPasswordMgrWithPriorAuth.is_authenticated",
        "args": "self;authuri",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 929,
        "namespace": "HTTPPasswordMgrWithPriorAuth",
        "body": "    def is_authenticated(self, authuri):\n        for default_port in True, False:\n            reduced_authuri = self.reduce_uri(authuri, default_port)\n            for uri in self.authenticated:\n                if self.is_suburi(uri, reduced_authuri):\n                    return self.authenticated[uri]",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler": {
        "API_name": "urllib.request.AbstractBasicAuthHandler",
        "loc_name": "urllib.request.AbstractBasicAuthHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 937,
        "namespace": "AbstractBasicAuthHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler.__init__": {
        "API_name": "urllib.request.AbstractBasicAuthHandler.__init__",
        "loc_name": "urllib.request.AbstractBasicAuthHandler.__init__",
        "args": "self;password_mgr",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 958,
        "namespace": "AbstractBasicAuthHandler",
        "body": "    def __init__(self, password_mgr=None):\n        if password_mgr is None:\n            password_mgr = HTTPPasswordMgr()\n        self.passwd = password_mgr\n        self.add_password = self.passwd.add_password",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler._parse_realm": {
        "API_name": "urllib.request.AbstractBasicAuthHandler._parse_realm",
        "loc_name": "urllib.request.AbstractBasicAuthHandler._parse_realm",
        "args": "self;header",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 964,
        "namespace": "AbstractBasicAuthHandler",
        "body": "    def _parse_realm(self, header):\n        # parse WWW-Authenticate header: accept multiple challenges per header\n        found_challenge = False\n        for mo in AbstractBasicAuthHandler.rx.finditer(header):\n            scheme, quote, realm = mo.groups()\n            if quote not in ['\"', \"'\"]:\n                warnings.warn(\"Basic Auth Realm was unquoted\",\n                              UserWarning, 3)\n\n            yield (scheme, realm)\n\n            found_challenge = True\n\n        if not found_challenge:\n            if header:\n                scheme = header.split()[0]\n            else:\n                scheme = ''\n            yield (scheme, None)",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler.http_error_auth_reqed": {
        "API_name": "urllib.request.AbstractBasicAuthHandler.http_error_auth_reqed",
        "loc_name": "urllib.request.AbstractBasicAuthHandler.http_error_auth_reqed",
        "args": "self;authreq;host;req;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 984,
        "namespace": "AbstractBasicAuthHandler",
        "body": "    def http_error_auth_reqed(self, authreq, host, req, headers):\n        # host may be an authority (without userinfo) or a URL with an\n        # authority\n        headers = headers.get_all(authreq)\n        if not headers:\n            # no header found\n            return\n\n        unsupported = None\n        for header in headers:\n            for scheme, realm in self._parse_realm(header):\n                if scheme.lower() != 'basic':\n                    unsupported = scheme\n                    continue\n\n                if realm is not None:\n                    # Use the first matching Basic challenge.\n                    # Ignore following challenges even if they use the Basic\n                    # scheme.\n                    return self.retry_http_basic_auth(host, req, realm)\n\n        if unsupported is not None:\n            raise ValueError(\"AbstractBasicAuthHandler does not \"\n                             \"support the following scheme: %r\"\n                             % (scheme,))",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler.retry_http_basic_auth": {
        "API_name": "urllib.request.AbstractBasicAuthHandler.retry_http_basic_auth",
        "loc_name": "urllib.request.AbstractBasicAuthHandler.retry_http_basic_auth",
        "args": "self;host;req;realm",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1010,
        "namespace": "AbstractBasicAuthHandler",
        "body": "    def retry_http_basic_auth(self, host, req, realm):\n        user, pw = self.passwd.find_user_password(realm, host)\n        if pw is not None:\n            raw = \"%s:%s\" % (user, pw)\n            auth = \"Basic \" + base64.b64encode(raw.encode()).decode(\"ascii\")\n            if req.get_header(self.auth_header, None) == auth:\n                return None\n            req.add_unredirected_header(self.auth_header, auth)\n            return self.parent.open(req, timeout=req.timeout)\n        else:\n            return None",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler.http_request": {
        "API_name": "urllib.request.AbstractBasicAuthHandler.http_request",
        "loc_name": "urllib.request.AbstractBasicAuthHandler.http_request",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1022,
        "namespace": "AbstractBasicAuthHandler",
        "body": "    def http_request(self, req):\n        if (not hasattr(self.passwd, 'is_authenticated') or\n           not self.passwd.is_authenticated(req.full_url)):\n            return req\n\n        if not req.has_header('Authorization'):\n            user, passwd = self.passwd.find_user_password(None, req.full_url)\n            credentials = '{0}:{1}'.format(user, passwd).encode()\n            auth_str = base64.standard_b64encode(credentials).decode()\n            req.add_unredirected_header('Authorization',\n                                        'Basic {}'.format(auth_str.strip()))\n        return req",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractBasicAuthHandler.http_response": {
        "API_name": "urllib.request.AbstractBasicAuthHandler.http_response",
        "loc_name": "urllib.request.AbstractBasicAuthHandler.http_response",
        "args": "self;req;response",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1035,
        "namespace": "AbstractBasicAuthHandler",
        "body": "    def http_response(self, req, response):\n        if hasattr(self.passwd, 'is_authenticated'):\n            if 200 <= response.code < 300:\n                self.passwd.update_authenticated(req.full_url, True)\n            else:\n                self.passwd.update_authenticated(req.full_url, False)\n        return response",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPBasicAuthHandler.http_error_401": {
        "API_name": "urllib.request.HTTPBasicAuthHandler.http_error_401",
        "loc_name": "urllib.request.HTTPBasicAuthHandler.http_error_401",
        "args": "self;req;fp;code;msg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1052,
        "namespace": "HTTPBasicAuthHandler",
        "body": "    def http_error_401(self, req, fp, code, msg, headers):\n        url = req.full_url\n        response = self.http_error_auth_reqed('www-authenticate',\n                                          url, req, headers)\n        return response",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPBasicAuthHandler": {
        "API_name": "urllib.request.HTTPBasicAuthHandler",
        "loc_name": "urllib.request.HTTPBasicAuthHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1048,
        "namespace": "HTTPBasicAuthHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyBasicAuthHandler.http_error_407": {
        "API_name": "urllib.request.ProxyBasicAuthHandler.http_error_407",
        "loc_name": "urllib.request.ProxyBasicAuthHandler.http_error_407",
        "args": "self;req;fp;code;msg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1063,
        "namespace": "ProxyBasicAuthHandler",
        "body": "    def http_error_407(self, req, fp, code, msg, headers):\n        # http_error_auth_reqed requires that there is no userinfo component in\n        # authority.  Assume there isn't one, since urllib.request does not (and\n        # should not, RFC 3986 s. 3.2.1) support requests for URLs containing\n        # userinfo.\n        authority = req.host\n        response = self.http_error_auth_reqed('proxy-authenticate',\n                                          authority, req, headers)\n        return response",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyBasicAuthHandler": {
        "API_name": "urllib.request.ProxyBasicAuthHandler",
        "loc_name": "urllib.request.ProxyBasicAuthHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1059,
        "namespace": "ProxyBasicAuthHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler": {
        "API_name": "urllib.request.AbstractDigestAuthHandler",
        "loc_name": "urllib.request.AbstractDigestAuthHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1078,
        "namespace": "AbstractDigestAuthHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.__init__": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.__init__",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.__init__",
        "args": "self;passwd",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1089,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def __init__(self, passwd=None):\n        if passwd is None:\n            passwd = HTTPPasswordMgr()\n        self.passwd = passwd\n        self.add_password = self.passwd.add_password\n        self.retried = 0\n        self.nonce_count = 0\n        self.last_nonce = None",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.reset_retry_count": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.reset_retry_count",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.reset_retry_count",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1098,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def reset_retry_count(self):\n        self.retried = 0",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.http_error_auth_reqed": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.http_error_auth_reqed",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.http_error_auth_reqed",
        "args": "self;auth_header;host;req;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1101,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def http_error_auth_reqed(self, auth_header, host, req, headers):\n        authreq = headers.get(auth_header, None)\n        if self.retried > 5:\n            # Don't fail endlessly - if we failed once, we'll probably\n            # fail a second time. Hm. Unless the Password Manager is\n            # prompting for the information. Crap. This isn't great\n            # but it's better than the current 'repeat until recursion\n            # depth exceeded' approach <wink>\n            raise HTTPError(req.full_url, 401, \"digest auth failed\",\n                            headers, None)\n        else:\n            self.retried += 1\n        if authreq:\n            scheme = authreq.split()[0]\n            if scheme.lower() == 'digest':\n                return self.retry_http_digest_auth(req, authreq)\n            elif scheme.lower() != 'basic':\n                raise ValueError(\"AbstractDigestAuthHandler does not support\"\n                                 \" the following scheme: '%s'\" % scheme)",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.retry_http_digest_auth": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.retry_http_digest_auth",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.retry_http_digest_auth",
        "args": "self;req;auth",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1121,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def retry_http_digest_auth(self, req, auth):\n        token, challenge = auth.split(' ', 1)\n        chal = parse_keqv_list(filter(None, parse_http_list(challenge)))\n        auth = self.get_authorization(req, chal)\n        if auth:\n            auth_val = 'Digest %s' % auth\n            if req.headers.get(self.auth_header, None) == auth_val:\n                return None\n            req.add_unredirected_header(self.auth_header, auth_val)\n            resp = self.parent.open(req, timeout=req.timeout)\n            return resp",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.get_cnonce": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.get_cnonce",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.get_cnonce",
        "args": "self;nonce",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1133,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def get_cnonce(self, nonce):\n        # The cnonce-value is an opaque\n        # quoted string value provided by the client and used by both client\n        # and server to avoid chosen plaintext attacks, to provide mutual\n        # authentication, and to provide some message integrity protection.\n        # This isn't a fabulous effort, but it's probably Good Enough.\n        s = \"%s:%s:%s:\" % (self.nonce_count, nonce, time.ctime())\n        b = s.encode(\"ascii\") + _randombytes(8)\n        dig = hashlib.sha1(b).hexdigest()\n        return dig[:16]",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.get_authorization": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.get_authorization",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.get_authorization",
        "args": "self;req;chal",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1144,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def get_authorization(self, req, chal):\n        try:\n            realm = chal['realm']\n            nonce = chal['nonce']\n            qop = chal.get('qop')\n            algorithm = chal.get('algorithm', 'MD5')\n            # mod_digest doesn't send an opaque, even though it isn't\n            # supposed to be optional\n            opaque = chal.get('opaque', None)\n        except KeyError:\n            return None\n\n        H, KD = self.get_algorithm_impls(algorithm)\n        if H is None:\n            return None\n\n        user, pw = self.passwd.find_user_password(realm, req.full_url)\n        if user is None:\n            return None\n\n        # XXX not implemented yet\n        if req.data is not None:\n            entdig = self.get_entity_digest(req.data, chal)\n        else:\n            entdig = None\n\n        A1 = \"%s:%s:%s\" % (user, realm, pw)\n        A2 = \"%s:%s\" % (req.get_method(),\n                        # XXX selector: what about proxies and full urls\n                        req.selector)\n        # NOTE: As per  RFC 2617, when server sends \"auth,auth-int\", the client could use either `auth`\n        #     or `auth-int` to the response back. we use `auth` to send the response back.\n        if qop is None:\n            respdig = KD(H(A1), \"%s:%s\" % (nonce, H(A2)))\n        elif 'auth' in qop.split(','):\n            if nonce == self.last_nonce:\n                self.nonce_count += 1\n            else:\n                self.nonce_count = 1\n                self.last_nonce = nonce\n            ncvalue = '%08x' % self.nonce_count\n            cnonce = self.get_cnonce(nonce)\n            noncebit = \"%s:%s:%s:%s:%s\" % (nonce, ncvalue, cnonce, 'auth', H(A2))\n            respdig = KD(H(A1), noncebit)\n        else:\n            # XXX handle auth-int.\n            raise URLError(\"qop '%s' is not supported.\" % qop)\n\n        # XXX should the partial digests be encoded too?\n\n        base = 'username=\"%s\", realm=\"%s\", nonce=\"%s\", uri=\"%s\", ' \\\n               'response=\"%s\"' % (user, realm, nonce, req.selector,\n                                  respdig)\n        if opaque:\n            base += ', opaque=\"%s\"' % opaque\n        if entdig:\n            base += ', digest=\"%s\"' % entdig\n        base += ', algorithm=\"%s\"' % algorithm\n        if qop:\n            base += ', qop=auth, nc=%s, cnonce=\"%s\"' % (ncvalue, cnonce)\n        return base",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.get_algorithm_impls": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.get_algorithm_impls",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.get_algorithm_impls",
        "args": "self;algorithm",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1206,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def get_algorithm_impls(self, algorithm):\n        # lambdas assume digest modules are imported at the top level\n        if algorithm == 'MD5':\n            H = lambda x: hashlib.md5(x.encode(\"ascii\")).hexdigest()\n        elif algorithm == 'SHA':\n            H = lambda x: hashlib.sha1(x.encode(\"ascii\")).hexdigest()\n        # XXX MD5-sess\n        else:\n            raise ValueError(\"Unsupported digest authentication \"\n                             \"algorithm %r\" % algorithm)\n        KD = lambda s, d: H(\"%s:%s\" % (s, d))\n        return H, KD",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractDigestAuthHandler.get_entity_digest": {
        "API_name": "urllib.request.AbstractDigestAuthHandler.get_entity_digest",
        "loc_name": "urllib.request.AbstractDigestAuthHandler.get_entity_digest",
        "args": "self;data;chal",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1219,
        "namespace": "AbstractDigestAuthHandler",
        "body": "    def get_entity_digest(self, data, chal):\n        # XXX not implemented yet\n        return None",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPDigestAuthHandler.http_error_401": {
        "API_name": "urllib.request.HTTPDigestAuthHandler.http_error_401",
        "loc_name": "urllib.request.HTTPDigestAuthHandler.http_error_401",
        "args": "self;req;fp;code;msg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1234,
        "namespace": "HTTPDigestAuthHandler",
        "body": "    def http_error_401(self, req, fp, code, msg, headers):\n        host = urlparse(req.full_url)[1]\n        retry = self.http_error_auth_reqed('www-authenticate',\n                                           host, req, headers)\n        self.reset_retry_count()\n        return retry",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPDigestAuthHandler": {
        "API_name": "urllib.request.HTTPDigestAuthHandler",
        "loc_name": "urllib.request.HTTPDigestAuthHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1224,
        "namespace": "HTTPDigestAuthHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyDigestAuthHandler.http_error_407": {
        "API_name": "urllib.request.ProxyDigestAuthHandler.http_error_407",
        "loc_name": "urllib.request.ProxyDigestAuthHandler.http_error_407",
        "args": "self;req;fp;code;msg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1247,
        "namespace": "ProxyDigestAuthHandler",
        "body": "    def http_error_407(self, req, fp, code, msg, headers):\n        host = req.host\n        retry = self.http_error_auth_reqed('proxy-authenticate',\n                                           host, req, headers)\n        self.reset_retry_count()\n        return retry",
        "name_type": "stdlib"
    },
    "urllib.request.ProxyDigestAuthHandler": {
        "API_name": "urllib.request.ProxyDigestAuthHandler",
        "loc_name": "urllib.request.ProxyDigestAuthHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1242,
        "namespace": "ProxyDigestAuthHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractHTTPHandler": {
        "API_name": "urllib.request.AbstractHTTPHandler",
        "loc_name": "urllib.request.AbstractHTTPHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1254,
        "namespace": "AbstractHTTPHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractHTTPHandler.__init__": {
        "API_name": "urllib.request.AbstractHTTPHandler.__init__",
        "loc_name": "urllib.request.AbstractHTTPHandler.__init__",
        "args": "self;debuglevel",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1256,
        "namespace": "AbstractHTTPHandler",
        "body": "    def __init__(self, debuglevel=0):\n        self._debuglevel = debuglevel",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractHTTPHandler.set_http_debuglevel": {
        "API_name": "urllib.request.AbstractHTTPHandler.set_http_debuglevel",
        "loc_name": "urllib.request.AbstractHTTPHandler.set_http_debuglevel",
        "args": "self;level",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1259,
        "namespace": "AbstractHTTPHandler",
        "body": "    def set_http_debuglevel(self, level):\n        self._debuglevel = level",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractHTTPHandler._get_content_length": {
        "API_name": "urllib.request.AbstractHTTPHandler._get_content_length",
        "loc_name": "urllib.request.AbstractHTTPHandler._get_content_length",
        "args": "self;request",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1262,
        "namespace": "AbstractHTTPHandler",
        "body": "    def _get_content_length(self, request):\n        return http.client.HTTPConnection._get_content_length(\n            request.data,\n            request.get_method())",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractHTTPHandler.do_request_": {
        "API_name": "urllib.request.AbstractHTTPHandler.do_request_",
        "loc_name": "urllib.request.AbstractHTTPHandler.do_request_",
        "args": "self;request",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1267,
        "namespace": "AbstractHTTPHandler",
        "body": "    def do_request_(self, request):\n        host = request.host\n        if not host:\n            raise URLError('no host given')\n\n        if request.data is not None:  # POST\n            data = request.data\n            if isinstance(data, str):\n                msg = \"POST data should be bytes, an iterable of bytes, \" \\\n                      \"or a file object. It cannot be of type str.\"\n                raise TypeError(msg)\n            if not request.has_header('Content-type'):\n                request.add_unredirected_header(\n                    'Content-type',\n                    'application/x-www-form-urlencoded')\n            if (not request.has_header('Content-length')\n                    and not request.has_header('Transfer-encoding')):\n                content_length = self._get_content_length(request)\n                if content_length is not None:\n                    request.add_unredirected_header(\n                            'Content-length', str(content_length))\n                else:\n                    request.add_unredirected_header(\n                            'Transfer-encoding', 'chunked')\n\n        sel_host = host\n        if request.has_proxy():\n            scheme, sel = _splittype(request.selector)\n            sel_host, sel_path = _splithost(sel)\n        if not request.has_header('Host'):\n            request.add_unredirected_header('Host', sel_host)\n        for name, value in self.parent.addheaders:\n            name = name.capitalize()\n            if not request.has_header(name):\n                request.add_unredirected_header(name, value)\n\n        return request",
        "name_type": "stdlib"
    },
    "urllib.request.AbstractHTTPHandler.do_open": {
        "API_name": "urllib.request.AbstractHTTPHandler.do_open",
        "loc_name": "urllib.request.AbstractHTTPHandler.do_open",
        "args": "self;http_class;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1305,
        "namespace": "AbstractHTTPHandler",
        "body": "    def do_open(self, http_class, req, **http_conn_args):\n        \"\"\"Return an HTTPResponse object for the request, using http_class.\n\n        http_class must implement the HTTPConnection API from http.client.\n        \"\"\"\n        host = req.host\n        if not host:\n            raise URLError('no host given')\n\n        # will parse host:port\n        h = http_class(host, timeout=req.timeout, **http_conn_args)\n        h.set_debuglevel(self._debuglevel)\n\n        headers = dict(req.unredirected_hdrs)\n        headers.update({k: v for k, v in req.headers.items()\n                        if k not in headers})\n\n        # TODO(jhylton): Should this be redesigned to handle\n        # persistent connections?\n\n        # We want to make an HTTP/1.1 request, but the addinfourl\n        # class isn't prepared to deal with a persistent connection.\n        # It will try to read all remaining data from the socket,\n        # which will block while the server waits for the next request.\n        # So make sure the connection gets closed after the (only)\n        # request.\n        headers[\"Connection\"] = \"close\"\n        headers = {name.title(): val for name, val in headers.items()}\n\n        if req._tunnel_host:\n            tunnel_headers = {}\n            proxy_auth_hdr = \"Proxy-Authorization\"\n            if proxy_auth_hdr in headers:\n                tunnel_headers[proxy_auth_hdr] = headers[proxy_auth_hdr]\n                # Proxy-Authorization should not be sent to origin\n                # server.\n                del headers[proxy_auth_hdr]\n            h.set_tunnel(req._tunnel_host, headers=tunnel_headers)\n\n        try:\n            try:\n                h.request(req.get_method(), req.selector, req.data, headers,\n                          encode_chunked=req.has_header('Transfer-encoding'))\n            except OSError as err: # timeout error\n                raise URLError(err)\n            r = h.getresponse()\n        except:\n            h.close()\n            raise\n\n        # If the server does not send us a 'Connection: close' header,\n        # HTTPConnection assumes the socket should be left open. Manually\n        # mark the socket to be closed when this response object goes away.\n        if h.sock:\n            h.sock.close()\n            h.sock = None\n\n        r.url = req.get_full_url()\n        # This line replaces the .msg attribute of the HTTPResponse\n        # with .headers, because urllib clients expect the response to\n        # have the reason in .msg.  It would be good to mark this\n        # attribute is deprecated and get then to use info() or\n        # .headers.\n        r.msg = r.reason\n        return r",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPHandler.http_open": {
        "API_name": "urllib.request.HTTPHandler.http_open",
        "loc_name": "urllib.request.HTTPHandler.http_open",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1374,
        "namespace": "HTTPHandler",
        "body": "    def http_open(self, req):\n        return self.do_open(http.client.HTTPConnection, req)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPHandler": {
        "API_name": "urllib.request.HTTPHandler",
        "loc_name": "urllib.request.HTTPHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1372,
        "namespace": "HTTPHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPSHandler": {
        "API_name": "urllib.request.HTTPSHandler",
        "loc_name": "urllib.request.HTTPSHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1381,
        "namespace": "HTTPSHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPSHandler.__init__": {
        "API_name": "urllib.request.HTTPSHandler.__init__",
        "loc_name": "urllib.request.HTTPSHandler.__init__",
        "args": "self;debuglevel;context;check_hostname",
        "args_default": 3,
        "filepath": "urllib.request",
        "lineno": 1383,
        "namespace": "HTTPSHandler",
        "body": "        def __init__(self, debuglevel=0, context=None, check_hostname=None):\n            AbstractHTTPHandler.__init__(self, debuglevel)\n            self._context = context\n            self._check_hostname = check_hostname",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPSHandler.https_open": {
        "API_name": "urllib.request.HTTPSHandler.https_open",
        "loc_name": "urllib.request.HTTPSHandler.https_open",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1388,
        "namespace": "HTTPSHandler",
        "body": "        def https_open(self, req):\n            return self.do_open(http.client.HTTPSConnection, req,\n                context=self._context, check_hostname=self._check_hostname)",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPCookieProcessor": {
        "API_name": "urllib.request.HTTPCookieProcessor",
        "loc_name": "urllib.request.HTTPCookieProcessor",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1396,
        "namespace": "HTTPCookieProcessor",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPCookieProcessor.__init__": {
        "API_name": "urllib.request.HTTPCookieProcessor.__init__",
        "loc_name": "urllib.request.HTTPCookieProcessor.__init__",
        "args": "self;cookiejar",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1397,
        "namespace": "HTTPCookieProcessor",
        "body": "    def __init__(self, cookiejar=None):\n        import http.cookiejar\n        if cookiejar is None:\n            cookiejar = http.cookiejar.CookieJar()\n        self.cookiejar = cookiejar",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPCookieProcessor.http_request": {
        "API_name": "urllib.request.HTTPCookieProcessor.http_request",
        "loc_name": "urllib.request.HTTPCookieProcessor.http_request",
        "args": "self;request",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1403,
        "namespace": "HTTPCookieProcessor",
        "body": "    def http_request(self, request):\n        self.cookiejar.add_cookie_header(request)\n        return request",
        "name_type": "stdlib"
    },
    "urllib.request.HTTPCookieProcessor.http_response": {
        "API_name": "urllib.request.HTTPCookieProcessor.http_response",
        "loc_name": "urllib.request.HTTPCookieProcessor.http_response",
        "args": "self;request;response",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1407,
        "namespace": "HTTPCookieProcessor",
        "body": "    def http_response(self, request, response):\n        self.cookiejar.extract_cookies(response, request)\n        return response",
        "name_type": "stdlib"
    },
    "urllib.request.UnknownHandler.unknown_open": {
        "API_name": "urllib.request.UnknownHandler.unknown_open",
        "loc_name": "urllib.request.UnknownHandler.unknown_open",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1415,
        "namespace": "UnknownHandler",
        "body": "    def unknown_open(self, req):\n        type = req.type\n        raise URLError('unknown url type: %s' % type)",
        "name_type": "stdlib"
    },
    "urllib.request.UnknownHandler": {
        "API_name": "urllib.request.UnknownHandler",
        "loc_name": "urllib.request.UnknownHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1414,
        "namespace": "UnknownHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.parse_keqv_list": {
        "API_name": "urllib.request.parse_keqv_list",
        "loc_name": "urllib.request.parse_keqv_list",
        "args": "l",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1419,
        "namespace": "*",
        "body": "def parse_keqv_list(l):\n    \"\"\"Parse list of key=value strings where keys are not duplicated.\"\"\"\n    parsed = {}\n    for elt in l:\n        k, v = elt.split('=', 1)\n        if v[0] == '\"' and v[-1] == '\"':\n            v = v[1:-1]\n        parsed[k] = v\n    return parsed",
        "name_type": "stdlib"
    },
    "urllib.request.parse_http_list": {
        "API_name": "urllib.request.parse_http_list",
        "loc_name": "urllib.request.parse_http_list",
        "args": "s",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1429,
        "namespace": "*",
        "body": "def parse_http_list(s):\n    \"\"\"Parse lists as described by RFC 2068 Section 2.\n\n    In particular, parse comma-separated lists where the elements of\n    the list may include quoted-strings.  A quoted-string could\n    contain a comma.  A non-quoted string could have quotes in the\n    middle.  Neither commas nor quotes count if they are escaped.\n    Only double-quotes count, not single-quotes.\n    \"\"\"\n    res = []\n    part = ''\n\n    escape = quote = False\n    for cur in s:\n        if escape:\n            part += cur\n            escape = False\n            continue\n        if quote:\n            if cur == '\\\\':\n                escape = True\n                continue\n            elif cur == '\"':\n                quote = False\n            part += cur\n            continue\n\n        if cur == ',':\n            res.append(part)\n            part = ''\n            continue\n\n        if cur == '\"':\n            quote = True\n\n        part += cur\n\n    # append last part\n    if part:\n        res.append(part)\n\n    return [part.strip() for part in res]",
        "name_type": "stdlib"
    },
    "urllib.request.FileHandler.file_open": {
        "API_name": "urllib.request.FileHandler.file_open",
        "loc_name": "urllib.request.FileHandler.file_open",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1474,
        "namespace": "FileHandler",
        "body": "    def file_open(self, req):\n        url = req.selector\n        if url[:2] == '//' and url[2:3] != '/' and (req.host and\n                req.host != 'localhost'):\n            if not req.host in self.get_names():\n                raise URLError(\"file:// scheme is supported only on localhost\")\n        else:\n            return self.open_local_file(req)",
        "name_type": "stdlib"
    },
    "urllib.request.FileHandler.get_names": {
        "API_name": "urllib.request.FileHandler.get_names",
        "loc_name": "urllib.request.FileHandler.get_names",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1485,
        "namespace": "FileHandler",
        "body": "    def get_names(self):\n        if FileHandler.names is None:\n            try:\n                FileHandler.names = tuple(\n                    socket.gethostbyname_ex('localhost')[2] +\n                    socket.gethostbyname_ex(socket.gethostname())[2])\n            except socket.gaierror:\n                FileHandler.names = (socket.gethostbyname('localhost'),)\n        return FileHandler.names",
        "name_type": "stdlib"
    },
    "urllib.request.FileHandler.open_local_file": {
        "API_name": "urllib.request.FileHandler.open_local_file",
        "loc_name": "urllib.request.FileHandler.open_local_file",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1496,
        "namespace": "FileHandler",
        "body": "    def open_local_file(self, req):\n        import email.utils\n        import mimetypes\n        host = req.host\n        filename = req.selector\n        localfile = url2pathname(filename)\n        try:\n            stats = os.stat(localfile)\n            size = stats.st_size\n            modified = email.utils.formatdate(stats.st_mtime, usegmt=True)\n            mtype = mimetypes.guess_type(filename)[0]\n            headers = email.message_from_string(\n                'Content-type: %s\\nContent-length: %d\\nLast-modified: %s\\n' %\n                (mtype or 'text/plain', size, modified))\n            if host:\n                host, port = _splitport(host)\n            if not host or \\\n                (not port and _safe_gethostbyname(host) in self.get_names()):\n                if host:\n                    origurl = 'file://' + host + filename\n                else:\n                    origurl = 'file://' + filename\n                return addinfourl(open(localfile, 'rb'), headers, origurl)\n        except OSError as exp:\n            raise URLError(exp)\n        raise URLError('file not on local host')",
        "name_type": "stdlib"
    },
    "urllib.request.FileHandler": {
        "API_name": "urllib.request.FileHandler",
        "loc_name": "urllib.request.FileHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1472,
        "namespace": "FileHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request._safe_gethostbyname": {
        "API_name": "urllib.request._safe_gethostbyname",
        "loc_name": "urllib.request._safe_gethostbyname",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1523,
        "namespace": "*",
        "body": "def _safe_gethostbyname(host):\n    try:\n        return socket.gethostbyname(host)\n    except socket.gaierror:\n        return None",
        "name_type": "stdlib"
    },
    "urllib.request.FTPHandler.ftp_open": {
        "API_name": "urllib.request.FTPHandler.ftp_open",
        "loc_name": "urllib.request.FTPHandler.ftp_open",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1530,
        "namespace": "FTPHandler",
        "body": "    def ftp_open(self, req):\n        import ftplib\n        import mimetypes\n        host = req.host\n        if not host:\n            raise URLError('ftp error: no host given')\n        host, port = _splitport(host)\n        if port is None:\n            port = ftplib.FTP_PORT\n        else:\n            port = int(port)\n\n        # username/password handling\n        user, host = _splituser(host)\n        if user:\n            user, passwd = _splitpasswd(user)\n        else:\n            passwd = None\n        host = unquote(host)\n        user = user or ''\n        passwd = passwd or ''\n\n        try:\n            host = socket.gethostbyname(host)\n        except OSError as msg:\n            raise URLError(msg)\n        path, attrs = _splitattr(req.selector)\n        dirs = path.split('/')\n        dirs = list(map(unquote, dirs))\n        dirs, file = dirs[:-1], dirs[-1]\n        if dirs and not dirs[0]:\n            dirs = dirs[1:]\n        try:\n            fw = self.connect_ftp(user, passwd, host, port, dirs, req.timeout)\n            type = file and 'I' or 'D'\n            for attr in attrs:\n                attr, value = _splitvalue(attr)\n                if attr.lower() == 'type' and \\\n                   value in ('a', 'A', 'i', 'I', 'd', 'D'):\n                    type = value.upper()\n            fp, retrlen = fw.retrfile(file, type)\n            headers = \"\"\n            mtype = mimetypes.guess_type(req.full_url)[0]\n            if mtype:\n                headers += \"Content-type: %s\\n\" % mtype\n            if retrlen is not None and retrlen >= 0:\n                headers += \"Content-length: %d\\n\" % retrlen\n            headers = email.message_from_string(headers)\n            return addinfourl(fp, headers, req.full_url)\n        except ftplib.all_errors as exp:\n            exc = URLError('ftp error: %r' % exp)\n            raise exc.with_traceback(sys.exc_info()[2])",
        "name_type": "stdlib"
    },
    "urllib.request.FTPHandler.connect_ftp": {
        "API_name": "urllib.request.FTPHandler.connect_ftp",
        "loc_name": "urllib.request.FTPHandler.connect_ftp",
        "args": "self;user;passwd;host;port;dirs;timeout",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1583,
        "namespace": "FTPHandler",
        "body": "    def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n        return ftpwrapper(user, passwd, host, port, dirs, timeout,\n                          persistent=False)",
        "name_type": "stdlib"
    },
    "urllib.request.FTPHandler": {
        "API_name": "urllib.request.FTPHandler",
        "loc_name": "urllib.request.FTPHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1529,
        "namespace": "FTPHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler": {
        "API_name": "urllib.request.CacheFTPHandler",
        "loc_name": "urllib.request.CacheFTPHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1587,
        "namespace": "CacheFTPHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler.__init__": {
        "API_name": "urllib.request.CacheFTPHandler.__init__",
        "loc_name": "urllib.request.CacheFTPHandler.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1590,
        "namespace": "CacheFTPHandler",
        "body": "    def __init__(self):\n        self.cache = {}\n        self.timeout = {}\n        self.soonest = 0\n        self.delay = 60\n        self.max_conns = 16",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler.setTimeout": {
        "API_name": "urllib.request.CacheFTPHandler.setTimeout",
        "loc_name": "urllib.request.CacheFTPHandler.setTimeout",
        "args": "self;t",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1597,
        "namespace": "CacheFTPHandler",
        "body": "    def setTimeout(self, t):\n        self.delay = t",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler.setMaxConns": {
        "API_name": "urllib.request.CacheFTPHandler.setMaxConns",
        "loc_name": "urllib.request.CacheFTPHandler.setMaxConns",
        "args": "self;m",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1600,
        "namespace": "CacheFTPHandler",
        "body": "    def setMaxConns(self, m):\n        self.max_conns = m",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler.connect_ftp": {
        "API_name": "urllib.request.CacheFTPHandler.connect_ftp",
        "loc_name": "urllib.request.CacheFTPHandler.connect_ftp",
        "args": "self;user;passwd;host;port;dirs;timeout",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1603,
        "namespace": "CacheFTPHandler",
        "body": "    def connect_ftp(self, user, passwd, host, port, dirs, timeout):\n        key = user, host, port, '/'.join(dirs), timeout\n        if key in self.cache:\n            self.timeout[key] = time.time() + self.delay\n        else:\n            self.cache[key] = ftpwrapper(user, passwd, host, port,\n                                         dirs, timeout)\n            self.timeout[key] = time.time() + self.delay\n        self.check_cache()\n        return self.cache[key]",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler.check_cache": {
        "API_name": "urllib.request.CacheFTPHandler.check_cache",
        "loc_name": "urllib.request.CacheFTPHandler.check_cache",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1614,
        "namespace": "CacheFTPHandler",
        "body": "    def check_cache(self):\n        # first check for old ones\n        t = time.time()\n        if self.soonest <= t:\n            for k, v in list(self.timeout.items()):\n                if v < t:\n                    self.cache[k].close()\n                    del self.cache[k]\n                    del self.timeout[k]\n        self.soonest = min(list(self.timeout.values()))\n\n        # then check the size\n        if len(self.cache) == self.max_conns:\n            for k, v in list(self.timeout.items()):\n                if v == self.soonest:\n                    del self.cache[k]\n                    del self.timeout[k]\n                    break\n            self.soonest = min(list(self.timeout.values()))",
        "name_type": "stdlib"
    },
    "urllib.request.CacheFTPHandler.clear_cache": {
        "API_name": "urllib.request.CacheFTPHandler.clear_cache",
        "loc_name": "urllib.request.CacheFTPHandler.clear_cache",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1634,
        "namespace": "CacheFTPHandler",
        "body": "    def clear_cache(self):\n        for conn in self.cache.values():\n            conn.close()\n        self.cache.clear()\n        self.timeout.clear()",
        "name_type": "stdlib"
    },
    "urllib.request.DataHandler.data_open": {
        "API_name": "urllib.request.DataHandler.data_open",
        "loc_name": "urllib.request.DataHandler.data_open",
        "args": "self;req",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1641,
        "namespace": "DataHandler",
        "body": "    def data_open(self, req):\n        # data URLs as specified in RFC 2397.\n        #\n        # ignores POSTed data\n        #\n        # syntax:\n        # dataurl   := \"data:\" [ mediatype ] [ \";base64\" ] \",\" data\n        # mediatype := [ type \"/\" subtype ] *( \";\" parameter )\n        # data      := *urlchar\n        # parameter := attribute \"=\" value\n        url = req.full_url\n\n        scheme, data = url.split(\":\",1)\n        mediatype, data = data.split(\",\",1)\n\n        # even base64 encoded data URLs might be quoted so unquote in any case:\n        data = unquote_to_bytes(data)\n        if mediatype.endswith(\";base64\"):\n            data = base64.decodebytes(data)\n            mediatype = mediatype[:-7]\n\n        if not mediatype:\n            mediatype = \"text/plain;charset=US-ASCII\"\n\n        headers = email.message_from_string(\"Content-type: %s\\nContent-length: %d\\n\" %\n            (mediatype, len(data)))\n\n        return addinfourl(io.BytesIO(data), headers, url)",
        "name_type": "stdlib"
    },
    "urllib.request.DataHandler": {
        "API_name": "urllib.request.DataHandler",
        "loc_name": "urllib.request.DataHandler",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1640,
        "namespace": "DataHandler",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.url2pathname": {
        "API_name": "urllib.request.url2pathname",
        "loc_name": "urllib.request.url2pathname",
        "args": "pathname",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1679,
        "namespace": "*",
        "body": "    def url2pathname(pathname):\n        \"\"\"OS-specific conversion from a relative URL of the 'file' scheme\n        to a file system path; not recommended for general use.\"\"\"\n        return unquote(pathname)",
        "name_type": "stdlib"
    },
    "urllib.request.pathname2url": {
        "API_name": "urllib.request.pathname2url",
        "loc_name": "urllib.request.pathname2url",
        "args": "pathname",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1684,
        "namespace": "*",
        "body": "    def pathname2url(pathname):\n        \"\"\"OS-specific conversion from a file system path to a relative URL\n        of the 'file' scheme; not recommended for general use.\"\"\"\n        return quote(pathname)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener": {
        "API_name": "urllib.request.URLopener",
        "loc_name": "urllib.request.URLopener",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 1693,
        "namespace": "URLopener",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.__init__": {
        "API_name": "urllib.request.URLopener.__init__",
        "loc_name": "urllib.request.URLopener.__init__",
        "args": "self;proxies",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1706,
        "namespace": "URLopener",
        "body": "    def __init__(self, proxies=None, **x509):\n        msg = \"%(class)s style of invoking requests is deprecated. \" \\\n              \"Use newer urlopen functions/methods\" % {'class': self.__class__.__name__}\n        warnings.warn(msg, DeprecationWarning, stacklevel=3)\n        if proxies is None:\n            proxies = getproxies()\n        assert hasattr(proxies, 'keys'), \"proxies must be a mapping\"\n        self.proxies = proxies\n        self.key_file = x509.get('key_file')\n        self.cert_file = x509.get('cert_file')\n        self.addheaders = [('User-Agent', self.version), ('Accept', '*/*')]\n        self.__tempfiles = []\n        self.__unlink = os.unlink # See cleanup()\n        self.tempcache = None\n        # Undocumented feature: if you assign {} to tempcache,\n        # it is used to cache files retrieved with\n        # self.retrieve().  This is not enabled by default\n        # since it does not work for changing documents (and I\n        # haven't got the logic to check expiration headers\n        # yet).\n        self.ftpcache = ftpcache",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.__del__": {
        "API_name": "urllib.request.URLopener.__del__",
        "loc_name": "urllib.request.URLopener.__del__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1732,
        "namespace": "URLopener",
        "body": "    def __del__(self):\n        self.close()",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.close": {
        "API_name": "urllib.request.URLopener.close",
        "loc_name": "urllib.request.URLopener.close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1735,
        "namespace": "URLopener",
        "body": "    def close(self):\n        self.cleanup()",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.cleanup": {
        "API_name": "urllib.request.URLopener.cleanup",
        "loc_name": "urllib.request.URLopener.cleanup",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1738,
        "namespace": "URLopener",
        "body": "    def cleanup(self):\n        # This code sometimes runs when the rest of this module\n        # has already been deleted, so it can't use any globals\n        # or import anything.\n        if self.__tempfiles:\n            for file in self.__tempfiles:\n                try:\n                    self.__unlink(file)\n                except OSError:\n                    pass\n            del self.__tempfiles[:]\n        if self.tempcache:\n            self.tempcache.clear()",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.addheader": {
        "API_name": "urllib.request.URLopener.addheader",
        "loc_name": "urllib.request.URLopener.addheader",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1752,
        "namespace": "URLopener",
        "body": "    def addheader(self, *args):\n        \"\"\"Add a header to be used by the HTTP interface only\n        e.g. u.addheader('Accept', 'sound/basic')\"\"\"\n        self.addheaders.append(args)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open": {
        "API_name": "urllib.request.URLopener.open",
        "loc_name": "urllib.request.URLopener.open",
        "args": "self;fullurl;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1758,
        "namespace": "URLopener",
        "body": "    def open(self, fullurl, data=None):\n        \"\"\"Use URLopener().open(file) instead of open(file, 'r').\"\"\"\n        fullurl = unwrap(_to_bytes(fullurl))\n        fullurl = quote(fullurl, safe=\"%/:=&?~#+!$,;'@()*[]|\")\n        if self.tempcache and fullurl in self.tempcache:\n            filename, headers = self.tempcache[fullurl]\n            fp = open(filename, 'rb')\n            return addinfourl(fp, headers, fullurl)\n        urltype, url = _splittype(fullurl)\n        if not urltype:\n            urltype = 'file'\n        if urltype in self.proxies:\n            proxy = self.proxies[urltype]\n            urltype, proxyhost = _splittype(proxy)\n            host, selector = _splithost(proxyhost)\n            url = (host, fullurl) # Signal special case to open_*()\n        else:\n            proxy = None\n        name = 'open_' + urltype\n        self.type = urltype\n        name = name.replace('-', '_')\n        if not hasattr(self, name) or name == 'open_local_file':\n            if proxy:\n                return self.open_unknown_proxy(proxy, fullurl, data)\n            else:\n                return self.open_unknown(fullurl, data)\n        try:\n            if data is None:\n                return getattr(self, name)(url)\n            else:\n                return getattr(self, name)(url, data)\n        except (HTTPError, URLError):\n            raise\n        except OSError as msg:\n            raise OSError('socket error', msg).with_traceback(sys.exc_info()[2])",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_unknown": {
        "API_name": "urllib.request.URLopener.open_unknown",
        "loc_name": "urllib.request.URLopener.open_unknown",
        "args": "self;fullurl;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1794,
        "namespace": "URLopener",
        "body": "    def open_unknown(self, fullurl, data=None):\n        \"\"\"Overridable interface to open unknown URL type.\"\"\"\n        type, url = _splittype(fullurl)\n        raise OSError('url error', 'unknown url type', type)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_unknown_proxy": {
        "API_name": "urllib.request.URLopener.open_unknown_proxy",
        "loc_name": "urllib.request.URLopener.open_unknown_proxy",
        "args": "self;proxy;fullurl;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1799,
        "namespace": "URLopener",
        "body": "    def open_unknown_proxy(self, proxy, fullurl, data=None):\n        \"\"\"Overridable interface to open unknown URL type.\"\"\"\n        type, url = _splittype(fullurl)\n        raise OSError('url error', 'invalid proxy for %s' % type, proxy)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.retrieve": {
        "API_name": "urllib.request.URLopener.retrieve",
        "loc_name": "urllib.request.URLopener.retrieve",
        "args": "self;url;filename;reporthook;data",
        "args_default": 3,
        "filepath": "urllib.request",
        "lineno": 1805,
        "namespace": "URLopener",
        "body": "    def retrieve(self, url, filename=None, reporthook=None, data=None):\n        \"\"\"retrieve(url) returns (filename, headers) for a local object\n        or (tempfilename, headers) for a remote object.\"\"\"\n        url = unwrap(_to_bytes(url))\n        if self.tempcache and url in self.tempcache:\n            return self.tempcache[url]\n        type, url1 = _splittype(url)\n        if filename is None and (not type or type == 'file'):\n            try:\n                fp = self.open_local_file(url1)\n                hdrs = fp.info()\n                fp.close()\n                return url2pathname(_splithost(url1)[1]), hdrs\n            except OSError:\n                pass\n        fp = self.open(url, data)\n        try:\n            headers = fp.info()\n            if filename:\n                tfp = open(filename, 'wb')\n            else:\n                garbage, path = _splittype(url)\n                garbage, path = _splithost(path or \"\")\n                path, garbage = _splitquery(path or \"\")\n                path, garbage = _splitattr(path or \"\")\n                suffix = os.path.splitext(path)[1]\n                (fd, filename) = tempfile.mkstemp(suffix)\n                self.__tempfiles.append(filename)\n                tfp = os.fdopen(fd, 'wb')\n            try:\n                result = filename, headers\n                if self.tempcache is not None:\n                    self.tempcache[url] = result\n                bs = 1024*8\n                size = -1\n                read = 0\n                blocknum = 0\n                if \"content-length\" in headers:\n                    size = int(headers[\"Content-Length\"])\n                if reporthook:\n                    reporthook(blocknum, bs, size)\n                while 1:\n                    block = fp.read(bs)\n                    if not block:\n                        break\n                    read += len(block)\n                    tfp.write(block)\n                    blocknum += 1\n                    if reporthook:\n                        reporthook(blocknum, bs, size)\n            finally:\n                tfp.close()\n        finally:\n            fp.close()\n\n        # raise exception if actual size does not match content-length header\n        if size >= 0 and read < size:\n            raise ContentTooShortError(\n                \"retrieval incomplete: got only %i out of %i bytes\"\n                % (read, size), result)\n\n        return result",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener._open_generic_http": {
        "API_name": "urllib.request.URLopener._open_generic_http",
        "loc_name": "urllib.request.URLopener._open_generic_http",
        "args": "self;connection_factory;url;data",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1870,
        "namespace": "URLopener",
        "body": "    def _open_generic_http(self, connection_factory, url, data):\n        \"\"\"Make an HTTP connection using connection_class.\n\n        This is an internal method that should be called from\n        open_http() or open_https().\n\n        Arguments:\n        - connection_factory should take a host name and return an\n          HTTPConnection instance.\n        - url is the url to retrieval or a host, relative-path pair.\n        - data is payload for a POST request or None.\n        \"\"\"\n\n        user_passwd = None\n        proxy_passwd= None\n        if isinstance(url, str):\n            host, selector = _splithost(url)\n            if host:\n                user_passwd, host = _splituser(host)\n                host = unquote(host)\n            realhost = host\n        else:\n            host, selector = url\n            # check whether the proxy contains authorization information\n            proxy_passwd, host = _splituser(host)\n            # now we proceed with the url we want to obtain\n            urltype, rest = _splittype(selector)\n            url = rest\n            user_passwd = None\n            if urltype.lower() != 'http':\n                realhost = None\n            else:\n                realhost, rest = _splithost(rest)\n                if realhost:\n                    user_passwd, realhost = _splituser(realhost)\n                if user_passwd:\n                    selector = \"%s://%s%s\" % (urltype, realhost, rest)\n                if proxy_bypass(realhost):\n                    host = realhost\n\n        if not host: raise OSError('http error', 'no host given')\n\n        if proxy_passwd:\n            proxy_passwd = unquote(proxy_passwd)\n            proxy_auth = base64.b64encode(proxy_passwd.encode()).decode('ascii')\n        else:\n            proxy_auth = None\n\n        if user_passwd:\n            user_passwd = unquote(user_passwd)\n            auth = base64.b64encode(user_passwd.encode()).decode('ascii')\n        else:\n            auth = None\n        http_conn = connection_factory(host)\n        headers = {}\n        if proxy_auth:\n            headers[\"Proxy-Authorization\"] = \"Basic %s\" % proxy_auth\n        if auth:\n            headers[\"Authorization\"] =  \"Basic %s\" % auth\n        if realhost:\n            headers[\"Host\"] = realhost\n\n        # Add Connection:close as we don't support persistent connections yet.\n        # This helps in closing the socket and avoiding ResourceWarning\n\n        headers[\"Connection\"] = \"close\"\n\n        for header, value in self.addheaders:\n            headers[header] = value\n\n        if data is not None:\n            headers[\"Content-Type\"] = \"application/x-www-form-urlencoded\"\n            http_conn.request(\"POST\", selector, data, headers)\n        else:\n            http_conn.request(\"GET\", selector, headers=headers)\n\n        try:\n            response = http_conn.getresponse()\n        except http.client.BadStatusLine:\n            # something went wrong with the HTTP status line\n            raise URLError(\"http protocol error: bad status line\")\n\n        # According to RFC 2616, \"2xx\" code indicates that the client's\n        # request was successfully received, understood, and accepted.\n        if 200 <= response.status < 300:\n            return addinfourl(response, response.msg, \"http:\" + url,\n                              response.status)\n        else:\n            return self.http_error(\n                url, response.fp,\n                response.status, response.reason, response.msg, data)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_http": {
        "API_name": "urllib.request.URLopener.open_http",
        "loc_name": "urllib.request.URLopener.open_http",
        "args": "self;url;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1962,
        "namespace": "URLopener",
        "body": "    def open_http(self, url, data=None):\n        \"\"\"Use HTTP protocol.\"\"\"\n        return self._open_generic_http(http.client.HTTPConnection, url, data)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.http_error": {
        "API_name": "urllib.request.URLopener.http_error",
        "loc_name": "urllib.request.URLopener.http_error",
        "args": "self;url;fp;errcode;errmsg;headers;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 1966,
        "namespace": "URLopener",
        "body": "    def http_error(self, url, fp, errcode, errmsg, headers, data=None):\n        \"\"\"Handle http errors.\n\n        Derived class can override this, or provide specific handlers\n        named http_error_DDD where DDD is the 3-digit error code.\"\"\"\n        # First check if there's a specific handler for this error\n        name = 'http_error_%d' % errcode\n        if hasattr(self, name):\n            method = getattr(self, name)\n            if data is None:\n                result = method(url, fp, errcode, errmsg, headers)\n            else:\n                result = method(url, fp, errcode, errmsg, headers, data)\n            if result: return result\n        return self.http_error_default(url, fp, errcode, errmsg, headers)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.http_error_default": {
        "API_name": "urllib.request.URLopener.http_error_default",
        "loc_name": "urllib.request.URLopener.http_error_default",
        "args": "self;url;fp;errcode;errmsg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1982,
        "namespace": "URLopener",
        "body": "    def http_error_default(self, url, fp, errcode, errmsg, headers):\n        \"\"\"Default error handler: close the connection and raise OSError.\"\"\"\n        fp.close()\n        raise HTTPError(url, errcode, errmsg, headers, None)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_file": {
        "API_name": "urllib.request.URLopener.open_file",
        "loc_name": "urllib.request.URLopener.open_file",
        "args": "self;url",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 1997,
        "namespace": "URLopener",
        "body": "    def open_file(self, url):\n        \"\"\"Use local file or FTP depending on form of URL.\"\"\"\n        if not isinstance(url, str):\n            raise URLError('file error: proxy support for file protocol currently not implemented')\n        if url[:2] == '//' and url[2:3] != '/' and url[2:12].lower() != 'localhost/':\n            raise ValueError(\"file:// scheme is supported only on localhost\")\n        else:\n            return self.open_local_file(url)",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_local_file": {
        "API_name": "urllib.request.URLopener.open_local_file",
        "loc_name": "urllib.request.URLopener.open_local_file",
        "args": "self;url",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2006,
        "namespace": "URLopener",
        "body": "    def open_local_file(self, url):\n        \"\"\"Use local file.\"\"\"\n        import email.utils\n        import mimetypes\n        host, file = _splithost(url)\n        localname = url2pathname(file)\n        try:\n            stats = os.stat(localname)\n        except OSError as e:\n            raise URLError(e.strerror, e.filename)\n        size = stats.st_size\n        modified = email.utils.formatdate(stats.st_mtime, usegmt=True)\n        mtype = mimetypes.guess_type(url)[0]\n        headers = email.message_from_string(\n            'Content-Type: %s\\nContent-Length: %d\\nLast-modified: %s\\n' %\n            (mtype or 'text/plain', size, modified))\n        if not host:\n            urlfile = file\n            if file[:1] == '/':\n                urlfile = 'file://' + file\n            return addinfourl(open(localname, 'rb'), headers, urlfile)\n        host, port = _splitport(host)\n        if (not port\n           and socket.gethostbyname(host) in ((localhost(),) + thishost())):\n            urlfile = file\n            if file[:1] == '/':\n                urlfile = 'file://' + file\n            elif file[:2] == './':\n                raise ValueError(\"local file url may start with / or file:. Unknown url of type: %s\" % url)\n            return addinfourl(open(localname, 'rb'), headers, urlfile)\n        raise URLError('local file error: not on local host')",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_ftp": {
        "API_name": "urllib.request.URLopener.open_ftp",
        "loc_name": "urllib.request.URLopener.open_ftp",
        "args": "self;url",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2038,
        "namespace": "URLopener",
        "body": "    def open_ftp(self, url):\n        \"\"\"Use FTP protocol.\"\"\"\n        if not isinstance(url, str):\n            raise URLError('ftp error: proxy support for ftp protocol currently not implemented')\n        import mimetypes\n        host, path = _splithost(url)\n        if not host: raise URLError('ftp error: no host given')\n        host, port = _splitport(host)\n        user, host = _splituser(host)\n        if user: user, passwd = _splitpasswd(user)\n        else: passwd = None\n        host = unquote(host)\n        user = unquote(user or '')\n        passwd = unquote(passwd or '')\n        host = socket.gethostbyname(host)\n        if not port:\n            import ftplib\n            port = ftplib.FTP_PORT\n        else:\n            port = int(port)\n        path, attrs = _splitattr(path)\n        path = unquote(path)\n        dirs = path.split('/')\n        dirs, file = dirs[:-1], dirs[-1]\n        if dirs and not dirs[0]: dirs = dirs[1:]\n        if dirs and not dirs[0]: dirs[0] = '/'\n        key = user, host, port, '/'.join(dirs)\n        # XXX thread unsafe!\n        if len(self.ftpcache) > MAXFTPCACHE:\n            # Prune the cache, rather arbitrarily\n            for k in list(self.ftpcache):\n                if k != key:\n                    v = self.ftpcache[k]\n                    del self.ftpcache[k]\n                    v.close()\n        try:\n            if key not in self.ftpcache:\n                self.ftpcache[key] = \\\n                    ftpwrapper(user, passwd, host, port, dirs)\n            if not file: type = 'D'\n            else: type = 'I'\n            for attr in attrs:\n                attr, value = _splitvalue(attr)\n                if attr.lower() == 'type' and \\\n                   value in ('a', 'A', 'i', 'I', 'd', 'D'):\n                    type = value.upper()\n            (fp, retrlen) = self.ftpcache[key].retrfile(file, type)\n            mtype = mimetypes.guess_type(\"ftp:\" + url)[0]\n            headers = \"\"\n            if mtype:\n                headers += \"Content-Type: %s\\n\" % mtype\n            if retrlen is not None and retrlen >= 0:\n                headers += \"Content-Length: %d\\n\" % retrlen\n            headers = email.message_from_string(headers)\n            return addinfourl(fp, headers, \"ftp:\" + url)\n        except ftperrors() as exp:\n            raise URLError('ftp error %r' % exp).with_traceback(sys.exc_info()[2])",
        "name_type": "stdlib"
    },
    "urllib.request.URLopener.open_data": {
        "API_name": "urllib.request.URLopener.open_data",
        "loc_name": "urllib.request.URLopener.open_data",
        "args": "self;url;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2096,
        "namespace": "URLopener",
        "body": "    def open_data(self, url, data=None):\n        \"\"\"Use \"data\" URL.\"\"\"\n        if not isinstance(url, str):\n            raise URLError('data error: proxy support for data protocol currently not implemented')\n        # ignore POSTed data\n        #\n        # syntax of data URLs:\n        # dataurl   := \"data:\" [ mediatype ] [ \";base64\" ] \",\" data\n        # mediatype := [ type \"/\" subtype ] *( \";\" parameter )\n        # data      := *urlchar\n        # parameter := attribute \"=\" value\n        try:\n            [type, data] = url.split(',', 1)\n        except ValueError:\n            raise OSError('data error', 'bad data URL')\n        if not type:\n            type = 'text/plain;charset=US-ASCII'\n        semi = type.rfind(';')\n        if semi >= 0 and '=' not in type[semi:]:\n            encoding = type[semi+1:]\n            type = type[:semi]\n        else:\n            encoding = ''\n        msg = []\n        msg.append('Date: %s'%time.strftime('%a, %d %b %Y %H:%M:%S GMT',\n                                            time.gmtime(time.time())))\n        msg.append('Content-type: %s' % type)\n        if encoding == 'base64':\n            # XXX is this encoding/decoding ok?\n            data = base64.decodebytes(data.encode('ascii')).decode('latin-1')\n        else:\n            data = unquote(data)\n        msg.append('Content-Length: %d' % len(data))\n        msg.append('')\n        msg.append(data)\n        msg = '\\n'.join(msg)\n        headers = email.message_from_string(msg)\n        f = io.StringIO(msg)\n        #f.fileno = None     # needed for addinfourl\n        return addinfourl(f, headers, url)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener": {
        "API_name": "urllib.request.FancyURLopener",
        "loc_name": "urllib.request.FancyURLopener",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 2138,
        "namespace": "FancyURLopener",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.__init__": {
        "API_name": "urllib.request.FancyURLopener.__init__",
        "loc_name": "urllib.request.FancyURLopener.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2141,
        "namespace": "FancyURLopener",
        "body": "    def __init__(self, *args, **kwargs):\n        URLopener.__init__(self, *args, **kwargs)\n        self.auth_cache = {}\n        self.tries = 0\n        self.maxtries = 10",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_default": {
        "API_name": "urllib.request.FancyURLopener.http_error_default",
        "loc_name": "urllib.request.FancyURLopener.http_error_default",
        "args": "self;url;fp;errcode;errmsg;headers",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2147,
        "namespace": "FancyURLopener",
        "body": "    def http_error_default(self, url, fp, errcode, errmsg, headers):\n        \"\"\"Default error handling -- don't raise an exception.\"\"\"\n        return addinfourl(fp, headers, \"http:\" + url, errcode)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_302": {
        "API_name": "urllib.request.FancyURLopener.http_error_302",
        "loc_name": "urllib.request.FancyURLopener.http_error_302",
        "args": "self;url;fp;errcode;errmsg;headers;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2151,
        "namespace": "FancyURLopener",
        "body": "    def http_error_302(self, url, fp, errcode, errmsg, headers, data=None):\n        \"\"\"Error 302 -- relocated (temporarily).\"\"\"\n        self.tries += 1\n        try:\n            if self.maxtries and self.tries >= self.maxtries:\n                if hasattr(self, \"http_error_500\"):\n                    meth = self.http_error_500\n                else:\n                    meth = self.http_error_default\n                return meth(url, fp, 500,\n                            \"Internal Server Error: Redirect Recursion\",\n                            headers)\n            result = self.redirect_internal(url, fp, errcode, errmsg,\n                                            headers, data)\n            return result\n        finally:\n            self.tries = 0",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.redirect_internal": {
        "API_name": "urllib.request.FancyURLopener.redirect_internal",
        "loc_name": "urllib.request.FancyURLopener.redirect_internal",
        "args": "self;url;fp;errcode;errmsg;headers;data",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2169,
        "namespace": "FancyURLopener",
        "body": "    def redirect_internal(self, url, fp, errcode, errmsg, headers, data):\n        if 'location' in headers:\n            newurl = headers['location']\n        elif 'uri' in headers:\n            newurl = headers['uri']\n        else:\n            return\n        fp.close()\n\n        # In case the server sent a relative URL, join with original:\n        newurl = urljoin(self.type + \":\" + url, newurl)\n\n        urlparts = urlparse(newurl)\n\n        # For security reasons, we don't allow redirection to anything other\n        # than http, https and ftp.\n\n        # We are using newer HTTPError with older redirect_internal method\n        # This older method will get deprecated in 3.3\n\n        if urlparts.scheme not in ('http', 'https', 'ftp', ''):\n            raise HTTPError(newurl, errcode,\n                            errmsg +\n                            \" Redirection to url '%s' is not allowed.\" % newurl,\n                            headers, fp)\n\n        return self.open(newurl)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_301": {
        "API_name": "urllib.request.FancyURLopener.http_error_301",
        "loc_name": "urllib.request.FancyURLopener.http_error_301",
        "args": "self;url;fp;errcode;errmsg;headers;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2197,
        "namespace": "FancyURLopener",
        "body": "    def http_error_301(self, url, fp, errcode, errmsg, headers, data=None):\n        \"\"\"Error 301 -- also relocated (permanently).\"\"\"\n        return self.http_error_302(url, fp, errcode, errmsg, headers, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_303": {
        "API_name": "urllib.request.FancyURLopener.http_error_303",
        "loc_name": "urllib.request.FancyURLopener.http_error_303",
        "args": "self;url;fp;errcode;errmsg;headers;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2201,
        "namespace": "FancyURLopener",
        "body": "    def http_error_303(self, url, fp, errcode, errmsg, headers, data=None):\n        \"\"\"Error 303 -- also relocated (essentially identical to 302).\"\"\"\n        return self.http_error_302(url, fp, errcode, errmsg, headers, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_307": {
        "API_name": "urllib.request.FancyURLopener.http_error_307",
        "loc_name": "urllib.request.FancyURLopener.http_error_307",
        "args": "self;url;fp;errcode;errmsg;headers;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2205,
        "namespace": "FancyURLopener",
        "body": "    def http_error_307(self, url, fp, errcode, errmsg, headers, data=None):\n        \"\"\"Error 307 -- relocated, but turn POST into error.\"\"\"\n        if data is None:\n            return self.http_error_302(url, fp, errcode, errmsg, headers, data)\n        else:\n            return self.http_error_default(url, fp, errcode, errmsg, headers)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_401": {
        "API_name": "urllib.request.FancyURLopener.http_error_401",
        "loc_name": "urllib.request.FancyURLopener.http_error_401",
        "args": "self;url;fp;errcode;errmsg;headers;data;retry",
        "args_default": 2,
        "filepath": "urllib.request",
        "lineno": 2212,
        "namespace": "FancyURLopener",
        "body": "    def http_error_401(self, url, fp, errcode, errmsg, headers, data=None,\n            retry=False):\n        \"\"\"Error 401 -- authentication required.\n        This function supports Basic authentication only.\"\"\"\n        if 'www-authenticate' not in headers:\n            URLopener.http_error_default(self, url, fp,\n                                         errcode, errmsg, headers)\n        stuff = headers['www-authenticate']\n        match = re.match('[ \\t]*([^ \\t]+)[ \\t]+realm=\"([^\"]*)\"', stuff)\n        if not match:\n            URLopener.http_error_default(self, url, fp,\n                                         errcode, errmsg, headers)\n        scheme, realm = match.groups()\n        if scheme.lower() != 'basic':\n            URLopener.http_error_default(self, url, fp,\n                                         errcode, errmsg, headers)\n        if not retry:\n            URLopener.http_error_default(self, url, fp, errcode, errmsg,\n                    headers)\n        name = 'retry_' + self.type + '_basic_auth'\n        if data is None:\n            return getattr(self,name)(url, realm)\n        else:\n            return getattr(self,name)(url, realm, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.http_error_407": {
        "API_name": "urllib.request.FancyURLopener.http_error_407",
        "loc_name": "urllib.request.FancyURLopener.http_error_407",
        "args": "self;url;fp;errcode;errmsg;headers;data;retry",
        "args_default": 2,
        "filepath": "urllib.request",
        "lineno": 2237,
        "namespace": "FancyURLopener",
        "body": "    def http_error_407(self, url, fp, errcode, errmsg, headers, data=None,\n            retry=False):\n        \"\"\"Error 407 -- proxy authentication required.\n        This function supports Basic authentication only.\"\"\"\n        if 'proxy-authenticate' not in headers:\n            URLopener.http_error_default(self, url, fp,\n                                         errcode, errmsg, headers)\n        stuff = headers['proxy-authenticate']\n        match = re.match('[ \\t]*([^ \\t]+)[ \\t]+realm=\"([^\"]*)\"', stuff)\n        if not match:\n            URLopener.http_error_default(self, url, fp,\n                                         errcode, errmsg, headers)\n        scheme, realm = match.groups()\n        if scheme.lower() != 'basic':\n            URLopener.http_error_default(self, url, fp,\n                                         errcode, errmsg, headers)\n        if not retry:\n            URLopener.http_error_default(self, url, fp, errcode, errmsg,\n                    headers)\n        name = 'retry_proxy_' + self.type + '_basic_auth'\n        if data is None:\n            return getattr(self,name)(url, realm)\n        else:\n            return getattr(self,name)(url, realm, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.retry_proxy_http_basic_auth": {
        "API_name": "urllib.request.FancyURLopener.retry_proxy_http_basic_auth",
        "loc_name": "urllib.request.FancyURLopener.retry_proxy_http_basic_auth",
        "args": "self;url;realm;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2262,
        "namespace": "FancyURLopener",
        "body": "    def retry_proxy_http_basic_auth(self, url, realm, data=None):\n        host, selector = _splithost(url)\n        newurl = 'http://' + host + selector\n        proxy = self.proxies['http']\n        urltype, proxyhost = _splittype(proxy)\n        proxyhost, proxyselector = _splithost(proxyhost)\n        i = proxyhost.find('@') + 1\n        proxyhost = proxyhost[i:]\n        user, passwd = self.get_user_passwd(proxyhost, realm, i)\n        if not (user or passwd): return None\n        proxyhost = \"%s:%s@%s\" % (quote(user, safe=''),\n                                  quote(passwd, safe=''), proxyhost)\n        self.proxies['http'] = 'http://' + proxyhost + proxyselector\n        if data is None:\n            return self.open(newurl)\n        else:\n            return self.open(newurl, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.retry_proxy_https_basic_auth": {
        "API_name": "urllib.request.FancyURLopener.retry_proxy_https_basic_auth",
        "loc_name": "urllib.request.FancyURLopener.retry_proxy_https_basic_auth",
        "args": "self;url;realm;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2280,
        "namespace": "FancyURLopener",
        "body": "    def retry_proxy_https_basic_auth(self, url, realm, data=None):\n        host, selector = _splithost(url)\n        newurl = 'https://' + host + selector\n        proxy = self.proxies['https']\n        urltype, proxyhost = _splittype(proxy)\n        proxyhost, proxyselector = _splithost(proxyhost)\n        i = proxyhost.find('@') + 1\n        proxyhost = proxyhost[i:]\n        user, passwd = self.get_user_passwd(proxyhost, realm, i)\n        if not (user or passwd): return None\n        proxyhost = \"%s:%s@%s\" % (quote(user, safe=''),\n                                  quote(passwd, safe=''), proxyhost)\n        self.proxies['https'] = 'https://' + proxyhost + proxyselector\n        if data is None:\n            return self.open(newurl)\n        else:\n            return self.open(newurl, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.retry_http_basic_auth": {
        "API_name": "urllib.request.FancyURLopener.retry_http_basic_auth",
        "loc_name": "urllib.request.FancyURLopener.retry_http_basic_auth",
        "args": "self;url;realm;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2298,
        "namespace": "FancyURLopener",
        "body": "    def retry_http_basic_auth(self, url, realm, data=None):\n        host, selector = _splithost(url)\n        i = host.find('@') + 1\n        host = host[i:]\n        user, passwd = self.get_user_passwd(host, realm, i)\n        if not (user or passwd): return None\n        host = \"%s:%s@%s\" % (quote(user, safe=''),\n                             quote(passwd, safe=''), host)\n        newurl = 'http://' + host + selector\n        if data is None:\n            return self.open(newurl)\n        else:\n            return self.open(newurl, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.retry_https_basic_auth": {
        "API_name": "urllib.request.FancyURLopener.retry_https_basic_auth",
        "loc_name": "urllib.request.FancyURLopener.retry_https_basic_auth",
        "args": "self;url;realm;data",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2312,
        "namespace": "FancyURLopener",
        "body": "    def retry_https_basic_auth(self, url, realm, data=None):\n        host, selector = _splithost(url)\n        i = host.find('@') + 1\n        host = host[i:]\n        user, passwd = self.get_user_passwd(host, realm, i)\n        if not (user or passwd): return None\n        host = \"%s:%s@%s\" % (quote(user, safe=''),\n                             quote(passwd, safe=''), host)\n        newurl = 'https://' + host + selector\n        if data is None:\n            return self.open(newurl)\n        else:\n            return self.open(newurl, data)",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.get_user_passwd": {
        "API_name": "urllib.request.FancyURLopener.get_user_passwd",
        "loc_name": "urllib.request.FancyURLopener.get_user_passwd",
        "args": "self;host;realm;clear_cache",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2326,
        "namespace": "FancyURLopener",
        "body": "    def get_user_passwd(self, host, realm, clear_cache=0):\n        key = realm + '@' + host.lower()\n        if key in self.auth_cache:\n            if clear_cache:\n                del self.auth_cache[key]\n            else:\n                return self.auth_cache[key]\n        user, passwd = self.prompt_user_passwd(host, realm)\n        if user or passwd: self.auth_cache[key] = (user, passwd)\n        return user, passwd",
        "name_type": "stdlib"
    },
    "urllib.request.FancyURLopener.prompt_user_passwd": {
        "API_name": "urllib.request.FancyURLopener.prompt_user_passwd",
        "loc_name": "urllib.request.FancyURLopener.prompt_user_passwd",
        "args": "self;host;realm",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2337,
        "namespace": "FancyURLopener",
        "body": "    def prompt_user_passwd(self, host, realm):\n        \"\"\"Override this in a GUI environment!\"\"\"\n        import getpass\n        try:\n            user = input(\"Enter username for %s at %s: \" % (realm, host))\n            passwd = getpass.getpass(\"Enter password for %s in %s at %s: \" %\n                (user, realm, host))\n            return user, passwd\n        except KeyboardInterrupt:\n            print()\n            return None, None",
        "name_type": "stdlib"
    },
    "urllib.request.localhost": {
        "API_name": "urllib.request.localhost",
        "loc_name": "urllib.request.localhost",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2353,
        "namespace": "*",
        "body": "def localhost():\n    \"\"\"Return the IP address of the magic hostname 'localhost'.\"\"\"\n    global _localhost\n    if _localhost is None:\n        _localhost = socket.gethostbyname('localhost')\n    return _localhost",
        "name_type": "stdlib"
    },
    "urllib.request.thishost": {
        "API_name": "urllib.request.thishost",
        "loc_name": "urllib.request.thishost",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2361,
        "namespace": "*",
        "body": "def thishost():\n    \"\"\"Return the IP addresses of the current host.\"\"\"\n    global _thishost\n    if _thishost is None:\n        try:\n            _thishost = tuple(socket.gethostbyname_ex(socket.gethostname())[2])\n        except socket.gaierror:\n            _thishost = tuple(socket.gethostbyname_ex('localhost')[2])\n    return _thishost",
        "name_type": "stdlib"
    },
    "urllib.request.ftperrors": {
        "API_name": "urllib.request.ftperrors",
        "loc_name": "urllib.request.ftperrors",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2372,
        "namespace": "*",
        "body": "def ftperrors():\n    \"\"\"Return the set of errors raised by the FTP class.\"\"\"\n    global _ftperrors\n    if _ftperrors is None:\n        import ftplib\n        _ftperrors = ftplib.all_errors\n    return _ftperrors",
        "name_type": "stdlib"
    },
    "urllib.request.noheaders": {
        "API_name": "urllib.request.noheaders",
        "loc_name": "urllib.request.noheaders",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2381,
        "namespace": "*",
        "body": "def noheaders():\n    \"\"\"Return an empty email Message object.\"\"\"\n    global _noheaders\n    if _noheaders is None:\n        _noheaders = email.message_from_string(\"\")\n    return _noheaders",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper": {
        "API_name": "urllib.request.ftpwrapper",
        "loc_name": "urllib.request.ftpwrapper",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.request",
        "lineno": 2391,
        "namespace": "ftpwrapper",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.__init__": {
        "API_name": "urllib.request.ftpwrapper.__init__",
        "loc_name": "urllib.request.ftpwrapper.__init__",
        "args": "self;user;passwd;host;port;dirs;timeout;persistent",
        "args_default": 2,
        "filepath": "urllib.request",
        "lineno": 2394,
        "namespace": "ftpwrapper",
        "body": "    def __init__(self, user, passwd, host, port, dirs, timeout=None,\n                 persistent=True):\n        self.user = user\n        self.passwd = passwd\n        self.host = host\n        self.port = port\n        self.dirs = dirs\n        self.timeout = timeout\n        self.refcount = 0\n        self.keepalive = persistent\n        try:\n            self.init()\n        except:\n            self.close()\n            raise",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.init": {
        "API_name": "urllib.request.ftpwrapper.init",
        "loc_name": "urllib.request.ftpwrapper.init",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2410,
        "namespace": "ftpwrapper",
        "body": "    def init(self):\n        import ftplib\n        self.busy = 0\n        self.ftp = ftplib.FTP()\n        self.ftp.connect(self.host, self.port, self.timeout)\n        self.ftp.login(self.user, self.passwd)\n        _target = '/'.join(self.dirs)\n        self.ftp.cwd(_target)",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.retrfile": {
        "API_name": "urllib.request.ftpwrapper.retrfile",
        "loc_name": "urllib.request.ftpwrapper.retrfile",
        "args": "self;file;type",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2419,
        "namespace": "ftpwrapper",
        "body": "    def retrfile(self, file, type):\n        import ftplib\n        self.endtransfer()\n        if type in ('d', 'D'): cmd = 'TYPE A'; isdir = 1\n        else: cmd = 'TYPE ' + type; isdir = 0\n        try:\n            self.ftp.voidcmd(cmd)\n        except ftplib.all_errors:\n            self.init()\n            self.ftp.voidcmd(cmd)\n        conn = None\n        if file and not isdir:\n            # Try to retrieve as a file\n            try:\n                cmd = 'RETR ' + file\n                conn, retrlen = self.ftp.ntransfercmd(cmd)\n            except ftplib.error_perm as reason:\n                if str(reason)[:3] != '550':\n                    raise URLError('ftp error: %r' % reason).with_traceback(\n                        sys.exc_info()[2])\n        if not conn:\n            # Set transfer mode to ASCII!\n            self.ftp.voidcmd('TYPE A')\n            # Try a directory listing. Verify that directory exists.\n            if file:\n                pwd = self.ftp.pwd()\n                try:\n                    try:\n                        self.ftp.cwd(file)\n                    except ftplib.error_perm as reason:\n                        raise URLError('ftp error: %r' % reason) from reason\n                finally:\n                    self.ftp.cwd(pwd)\n                cmd = 'LIST ' + file\n            else:\n                cmd = 'LIST'\n            conn, retrlen = self.ftp.ntransfercmd(cmd)\n        self.busy = 1\n\n        ftpobj = addclosehook(conn.makefile('rb'), self.file_close)\n        self.refcount += 1\n        conn.close()\n        # Pass back both a suitably decorated object and a retrieval length\n        return (ftpobj, retrlen)",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.endtransfer": {
        "API_name": "urllib.request.ftpwrapper.endtransfer",
        "loc_name": "urllib.request.ftpwrapper.endtransfer",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2464,
        "namespace": "ftpwrapper",
        "body": "    def endtransfer(self):\n        self.busy = 0",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.close": {
        "API_name": "urllib.request.ftpwrapper.close",
        "loc_name": "urllib.request.ftpwrapper.close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2467,
        "namespace": "ftpwrapper",
        "body": "    def close(self):\n        self.keepalive = False\n        if self.refcount <= 0:\n            self.real_close()",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.file_close": {
        "API_name": "urllib.request.ftpwrapper.file_close",
        "loc_name": "urllib.request.ftpwrapper.file_close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2472,
        "namespace": "ftpwrapper",
        "body": "    def file_close(self):\n        self.endtransfer()\n        self.refcount -= 1\n        if self.refcount <= 0 and not self.keepalive:\n            self.real_close()",
        "name_type": "stdlib"
    },
    "urllib.request.ftpwrapper.real_close": {
        "API_name": "urllib.request.ftpwrapper.real_close",
        "loc_name": "urllib.request.ftpwrapper.real_close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2478,
        "namespace": "ftpwrapper",
        "body": "    def real_close(self):\n        self.endtransfer()\n        try:\n            self.ftp.close()\n        except ftperrors():\n            pass",
        "name_type": "stdlib"
    },
    "urllib.request.getproxies_environment": {
        "API_name": "urllib.request.getproxies_environment",
        "loc_name": "urllib.request.getproxies_environment",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2486,
        "namespace": "*",
        "body": "def getproxies_environment():\n    \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n    Scan the environment for variables named <scheme>_proxy;\n    this seems to be the standard convention.  If you need a\n    different way, you can pass a proxies dictionary to the\n    [Fancy]URLopener constructor.\n\n    \"\"\"\n    proxies = {}\n    # in order to prefer lowercase variables, process environment in\n    # two passes: first matches any, second pass matches lowercase only\n    for name, value in os.environ.items():\n        name = name.lower()\n        if value and name[-6:] == '_proxy':\n            proxies[name[:-6]] = value\n    # CVE-2016-1000110 - If we are running as CGI script, forget HTTP_PROXY\n    # (non-all-lowercase) as it may be set from the web server by a \"Proxy:\"\n    # header from the client\n    # If \"proxy\" is lowercase, it will still be used thanks to the next block\n    if 'REQUEST_METHOD' in os.environ:\n        proxies.pop('http', None)\n    for name, value in os.environ.items():\n        if name[-6:] == '_proxy':\n            name = name.lower()\n            if value:\n                proxies[name[:-6]] = value\n            else:\n                proxies.pop(name[:-6], None)\n    return proxies",
        "name_type": "stdlib"
    },
    "urllib.request.proxy_bypass_environment": {
        "API_name": "urllib.request.proxy_bypass_environment",
        "loc_name": "urllib.request.proxy_bypass_environment",
        "args": "host;proxies",
        "args_default": 1,
        "filepath": "urllib.request",
        "lineno": 2517,
        "namespace": "*",
        "body": "def proxy_bypass_environment(host, proxies=None):\n    \"\"\"Test if proxies should not be used for a particular host.\n\n    Checks the proxy dict for the value of no_proxy, which should\n    be a list of comma separated DNS suffixes, or '*' for all hosts.\n\n    \"\"\"\n    if proxies is None:\n        proxies = getproxies_environment()\n    # don't bypass, if no_proxy isn't specified\n    try:\n        no_proxy = proxies['no']\n    except KeyError:\n        return False\n    # '*' is special case for always bypass\n    if no_proxy == '*':\n        return True\n    host = host.lower()\n    # strip port off host\n    hostonly, port = _splitport(host)\n    # check if the host ends with any of the DNS suffixes\n    for name in no_proxy.split(','):\n        name = name.strip()\n        if name:\n            name = name.lstrip('.')  # ignore leading dots\n            name = name.lower()\n            if hostonly == name or host == name:\n                return True\n            name = '.' + name\n            if hostonly.endswith(name) or host.endswith(name):\n                return True\n    # otherwise, don't bypass\n    return False",
        "name_type": "stdlib"
    },
    "urllib.request._proxy_bypass_macosx_sysconf": {
        "API_name": "urllib.request._proxy_bypass_macosx_sysconf",
        "loc_name": "urllib.request._proxy_bypass_macosx_sysconf",
        "args": "host;proxy_settings",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2554,
        "namespace": "*",
        "body": "def _proxy_bypass_macosx_sysconf(host, proxy_settings):\n    \"\"\"\n    Return True iff this host shouldn't be accessed using a proxy\n\n    This function uses the MacOSX framework SystemConfiguration\n    to fetch the proxy information.\n\n    proxy_settings come from _scproxy._get_proxy_settings or get mocked ie:\n    { 'exclude_simple': bool,\n      'exceptions': ['foo.bar', '*.bar.com', '127.0.0.1', '10.1', '10.0/16']\n    }\n    \"\"\"\n    from fnmatch import fnmatch\n\n    hostonly, port = _splitport(host)\n\n    def ip2num(ipAddr):\n        parts = ipAddr.split('.')\n        parts = list(map(int, parts))\n        if len(parts) != 4:\n            parts = (parts + [0, 0, 0, 0])[:4]\n        return (parts[0] << 24) | (parts[1] << 16) | (parts[2] << 8) | parts[3]\n\n    # Check for simple host names:\n    if '.' not in host:\n        if proxy_settings['exclude_simple']:\n            return True\n\n    hostIP = None\n\n    for value in proxy_settings.get('exceptions', ()):\n        # Items in the list are strings like these: *.local, 169.254/16\n        if not value: continue\n\n        m = re.match(r\"(\\d+(?:\\.\\d+)*)(/\\d+)?\", value)\n        if m is not None:\n            if hostIP is None:\n                try:\n                    hostIP = socket.gethostbyname(hostonly)\n                    hostIP = ip2num(hostIP)\n                except OSError:\n                    continue\n\n            base = ip2num(m.group(1))\n            mask = m.group(2)\n            if mask is None:\n                mask = 8 * (m.group(1).count('.') + 1)\n            else:\n                mask = int(mask[1:])\n\n            if mask < 0 or mask > 32:\n                # System libraries ignore invalid prefix lengths\n                continue\n\n            mask = 32 - mask\n\n            if (hostIP >> mask) == (base >> mask):\n                return True\n\n        elif fnmatch(host, value):\n            return True\n\n    return False",
        "name_type": "stdlib"
    },
    "urllib.request._proxy_bypass_macosx_sysconf.ip2num": {
        "API_name": "urllib.request._proxy_bypass_macosx_sysconf.ip2num",
        "loc_name": "urllib.request._proxy_bypass_macosx_sysconf.ip2num",
        "args": "ipAddr",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2570,
        "namespace": "*",
        "body": "    def ip2num(ipAddr):\n        parts = ipAddr.split('.')\n        parts = list(map(int, parts))\n        if len(parts) != 4:\n            parts = (parts + [0, 0, 0, 0])[:4]\n        return (parts[0] << 24) | (parts[1] << 16) | (parts[2] << 8) | parts[3]",
        "name_type": "stdlib"
    },
    "urllib.request.proxy_bypass_macosx_sysconf": {
        "API_name": "urllib.request.proxy_bypass_macosx_sysconf",
        "loc_name": "urllib.request.proxy_bypass_macosx_sysconf",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2622,
        "namespace": "*",
        "body": "    def proxy_bypass_macosx_sysconf(host):\n        proxy_settings = _get_proxy_settings()\n        return _proxy_bypass_macosx_sysconf(host, proxy_settings)",
        "name_type": "stdlib"
    },
    "urllib.request.getproxies_macosx_sysconf": {
        "API_name": "urllib.request.getproxies_macosx_sysconf",
        "loc_name": "urllib.request.getproxies_macosx_sysconf",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2626,
        "namespace": "*",
        "body": "    def getproxies_macosx_sysconf():\n        \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n        This function uses the MacOSX framework SystemConfiguration\n        to fetch the proxy information.\n        \"\"\"\n        return _get_proxies()",
        "name_type": "stdlib"
    },
    "urllib.request.proxy_bypass": {
        "API_name": "urllib.request.proxy_bypass",
        "loc_name": "urllib.request.proxy_bypass",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2762,
        "namespace": "*",
        "body": "    def proxy_bypass(host):\n        \"\"\"Return True, if host should be bypassed.\n\n        Checks proxy settings gathered from the environment, if specified,\n        or the registry.\n\n        \"\"\"\n        proxies = getproxies_environment()\n        if proxies:\n            return proxy_bypass_environment(host, proxies)\n        else:\n            return proxy_bypass_registry(host)",
        "name_type": "stdlib"
    },
    "urllib.request.getproxies": {
        "API_name": "urllib.request.getproxies",
        "loc_name": "urllib.request.getproxies",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2703,
        "namespace": "*",
        "body": "    def getproxies():\n        \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n        Returns settings gathered from the environment, if specified,\n        or the registry.\n\n        \"\"\"\n        return getproxies_environment() or getproxies_registry()",
        "name_type": "stdlib"
    },
    "urllib.request.getproxies_registry": {
        "API_name": "urllib.request.getproxies_registry",
        "loc_name": "urllib.request.getproxies_registry",
        "args": "",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2654,
        "namespace": "*",
        "body": "    def getproxies_registry():\n        \"\"\"Return a dictionary of scheme -> proxy server URL mappings.\n\n        Win32 uses the registry to store proxies.\n\n        \"\"\"\n        proxies = {}\n        try:\n            import winreg\n        except ImportError:\n            # Std module, so should be around - but you never know!\n            return proxies\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            proxyEnable = winreg.QueryValueEx(internetSettings,\n                                               'ProxyEnable')[0]\n            if proxyEnable:\n                # Returned as Unicode but problems if not converted to ASCII\n                proxyServer = str(winreg.QueryValueEx(internetSettings,\n                                                       'ProxyServer')[0])\n                if '=' not in proxyServer and ';' not in proxyServer:\n                    # Use one setting for all protocols.\n                    proxyServer = 'http={0};https={0};ftp={0}'.format(proxyServer)\n                for p in proxyServer.split(';'):\n                    protocol, address = p.split('=', 1)\n                    # See if address has a type:// prefix\n                    if not re.match('(?:[^/:]+)://', address):\n                        # Add type:// prefix to address without specifying type\n                        if protocol in ('http', 'https', 'ftp'):\n                            # The default proxy type of Windows is HTTP\n                            address = 'http://' + address\n                        elif protocol == 'socks':\n                            address = 'socks://' + address\n                    proxies[protocol] = address\n                # Use SOCKS proxy for HTTP(S) protocols\n                if proxies.get('socks'):\n                    # The default SOCKS proxy type of Windows is SOCKS4\n                    address = re.sub(r'^socks://', 'socks4://', proxies['socks'])\n                    proxies['http'] = proxies.get('http') or address\n                    proxies['https'] = proxies.get('https') or address\n            internetSettings.Close()\n        except (OSError, ValueError, TypeError):\n            # Either registry key not found etc, or the value in an\n            # unexpected format.\n            # proxies already set up to be empty so nothing to do\n            pass\n        return proxies",
        "name_type": "stdlib"
    },
    "urllib.request.proxy_bypass_registry": {
        "API_name": "urllib.request.proxy_bypass_registry",
        "loc_name": "urllib.request.proxy_bypass_registry",
        "args": "host",
        "args_default": 0,
        "filepath": "urllib.request",
        "lineno": 2712,
        "namespace": "*",
        "body": "    def proxy_bypass_registry(host):\n        try:\n            import winreg\n        except ImportError:\n            # Std modules, so should be around - but you never know!\n            return 0\n        try:\n            internetSettings = winreg.OpenKey(winreg.HKEY_CURRENT_USER,\n                r'Software\\Microsoft\\Windows\\CurrentVersion\\Internet Settings')\n            proxyEnable = winreg.QueryValueEx(internetSettings,\n                                               'ProxyEnable')[0]\n            proxyOverride = str(winreg.QueryValueEx(internetSettings,\n                                                     'ProxyOverride')[0])\n            # ^^^^ Returned as Unicode but problems if not converted to ASCII\n        except OSError:\n            return 0\n        if not proxyEnable or not proxyOverride:\n            return 0\n        # try to make a host list from name and IP address.\n        rawHost, port = _splitport(host)\n        host = [rawHost]\n        try:\n            addr = socket.gethostbyname(rawHost)\n            if addr != rawHost:\n                host.append(addr)\n        except OSError:\n            pass\n        try:\n            fqdn = socket.getfqdn(rawHost)\n            if fqdn != rawHost:\n                host.append(fqdn)\n        except OSError:\n            pass\n        # make a check value list from the registry entry: replace the\n        # '<local>' string by the localhost entry and the corresponding\n        # canonical entry.\n        proxyOverride = proxyOverride.split(';')\n        # now check if we match one of the registry values.\n        for test in proxyOverride:\n            if test == '<local>':\n                if '.' not in rawHost:\n                    return 1\n            test = test.replace(\".\", r\"\\.\")     # mask dots\n            test = test.replace(\"*\", r\".*\")     # change glob sequence\n            test = test.replace(\"?\", r\".\")      # change glob char\n            for val in host:\n                if re.match(test, val, re.I):\n                    return 1\n        return 0",
        "name_type": "stdlib"
    },
    "urllib.response": {
        "API_name": "urllib.response",
        "loc_name": "urllib.response",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.response",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\"Response classes used by urllib.\n\nThe base class, addbase, defines a minimal file-like interface,\nincluding read() and readline().  The typical response object is an\naddinfourl instance, which defines an info() method that returns\nheaders and a geturl() method that returns the url.\n\"\"\"\n__all__ = ['addbase', 'addclosehook', 'addinfo', 'addinfourl']",
        "name_type": "stdlib"
    },
    "urllib.response.addbase": {
        "API_name": "urllib.response.addbase",
        "loc_name": "urllib.response.addbase",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.response",
        "lineno": 14,
        "namespace": "addbase",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.response.addbase.__init__": {
        "API_name": "urllib.response.addbase.__init__",
        "loc_name": "urllib.response.addbase.__init__",
        "args": "self;fp",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 19,
        "namespace": "addbase",
        "body": "    def __init__(self, fp):\n        super(addbase,  self).__init__(fp, '<urllib response>', delete=False)\n        # Keep reference around as this was part of the original API.\n        self.fp = fp",
        "name_type": "stdlib"
    },
    "urllib.response.addbase.__repr__": {
        "API_name": "urllib.response.addbase.__repr__",
        "loc_name": "urllib.response.addbase.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 24,
        "namespace": "addbase",
        "body": "    def __repr__(self):\n        return '<%s at %r whose fp = %r>' % (self.__class__.__name__,\n                                             id(self), self.file)",
        "name_type": "stdlib"
    },
    "urllib.response.addbase.__enter__": {
        "API_name": "urllib.response.addbase.__enter__",
        "loc_name": "urllib.response.addbase.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 28,
        "namespace": "addbase",
        "body": "    def __enter__(self):\n        if self.fp.closed:\n            raise ValueError(\"I/O operation on closed file\")\n        return self",
        "name_type": "stdlib"
    },
    "urllib.response.addbase.__exit__": {
        "API_name": "urllib.response.addbase.__exit__",
        "loc_name": "urllib.response.addbase.__exit__",
        "args": "self;type;value;traceback",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 33,
        "namespace": "addbase",
        "body": "    def __exit__(self, type, value, traceback):\n        self.close()",
        "name_type": "stdlib"
    },
    "urllib.response.addclosehook": {
        "API_name": "urllib.response.addclosehook",
        "loc_name": "urllib.response.addclosehook",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.response",
        "lineno": 37,
        "namespace": "addclosehook",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.response.addclosehook.__init__": {
        "API_name": "urllib.response.addclosehook.__init__",
        "loc_name": "urllib.response.addclosehook.__init__",
        "args": "self;fp;closehook",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 40,
        "namespace": "addclosehook",
        "body": "    def __init__(self, fp, closehook, *hookargs):\n        super(addclosehook, self).__init__(fp)\n        self.closehook = closehook\n        self.hookargs = hookargs",
        "name_type": "stdlib"
    },
    "urllib.response.addclosehook.close": {
        "API_name": "urllib.response.addclosehook.close",
        "loc_name": "urllib.response.addclosehook.close",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 45,
        "namespace": "addclosehook",
        "body": "    def close(self):\n        try:\n            closehook = self.closehook\n            hookargs = self.hookargs\n            if closehook:\n                self.closehook = None\n                self.hookargs = None\n                closehook(*hookargs)\n        finally:\n            super(addclosehook, self).close()",
        "name_type": "stdlib"
    },
    "urllib.response.addinfo": {
        "API_name": "urllib.response.addinfo",
        "loc_name": "urllib.response.addinfo",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.response",
        "lineno": 57,
        "namespace": "addinfo",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.response.addinfo.__init__": {
        "API_name": "urllib.response.addinfo.__init__",
        "loc_name": "urllib.response.addinfo.__init__",
        "args": "self;fp;headers",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 60,
        "namespace": "addinfo",
        "body": "    def __init__(self, fp, headers):\n        super(addinfo, self).__init__(fp)\n        self.headers = headers",
        "name_type": "stdlib"
    },
    "urllib.response.addinfo.info": {
        "API_name": "urllib.response.addinfo.info",
        "loc_name": "urllib.response.addinfo.info",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 64,
        "namespace": "addinfo",
        "body": "    def info(self):\n        return self.headers",
        "name_type": "stdlib"
    },
    "urllib.response.addinfourl": {
        "API_name": "urllib.response.addinfourl",
        "loc_name": "urllib.response.addinfourl",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.response",
        "lineno": 68,
        "namespace": "addinfourl",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.response.addinfourl.__init__": {
        "API_name": "urllib.response.addinfourl.__init__",
        "loc_name": "urllib.response.addinfourl.__init__",
        "args": "self;fp;headers;url;code",
        "args_default": 1,
        "filepath": "urllib.response",
        "lineno": 71,
        "namespace": "addinfourl",
        "body": "    def __init__(self, fp, headers, url, code=None):\n        super(addinfourl, self).__init__(fp, headers)\n        self.url = url\n        self.code = code",
        "name_type": "stdlib"
    },
    "urllib.response.addinfourl.status": {
        "API_name": "urllib.response.addinfourl.status",
        "loc_name": "urllib.response.addinfourl.status",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 77,
        "namespace": "addinfourl",
        "body": "    def status(self):\n        return self.code",
        "name_type": "stdlib"
    },
    "urllib.response.addinfourl.getcode": {
        "API_name": "urllib.response.addinfourl.getcode",
        "loc_name": "urllib.response.addinfourl.getcode",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 80,
        "namespace": "addinfourl",
        "body": "    def getcode(self):\n        return self.code",
        "name_type": "stdlib"
    },
    "urllib.response.addinfourl.geturl": {
        "API_name": "urllib.response.addinfourl.geturl",
        "loc_name": "urllib.response.addinfourl.geturl",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.response",
        "lineno": 83,
        "namespace": "addinfourl",
        "body": "    def geturl(self):\n        return self.url",
        "name_type": "stdlib"
    },
    "urllib.robotparser": {
        "API_name": "urllib.robotparser",
        "loc_name": "urllib.robotparser",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.robotparser",
        "lineno": "*",
        "namespace": "*",
        "body": "\"\"\" robotparser.py\n\n    Copyright (C) 2000  Bastian Kleineidam\n\n    You can choose between two licenses when using this package:\n    1) GNU GPLv2\n    2) PSF license for Python 2.2\n\n    The robots.txt Exclusion Protocol is implemented as specified in\n    http://www.robotstxt.org/norobots-rfc.txt\n\"\"\"\n__all__ = [\"RobotFileParser\"]\nRequestRate = collections.namedtuple(\"RequestRate\", \"requests seconds\")",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser": {
        "API_name": "urllib.robotparser.RobotFileParser",
        "loc_name": "urllib.robotparser.RobotFileParser",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.robotparser",
        "lineno": 22,
        "namespace": "RobotFileParser",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.__init__": {
        "API_name": "urllib.robotparser.RobotFileParser.__init__",
        "loc_name": "urllib.robotparser.RobotFileParser.__init__",
        "args": "self;url",
        "args_default": 1,
        "filepath": "urllib.robotparser",
        "lineno": 28,
        "namespace": "RobotFileParser",
        "body": "    def __init__(self, url=''):\n        self.entries = []\n        self.sitemaps = []\n        self.default_entry = None\n        self.disallow_all = False\n        self.allow_all = False\n        self.set_url(url)\n        self.last_checked = 0",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.mtime": {
        "API_name": "urllib.robotparser.RobotFileParser.mtime",
        "loc_name": "urllib.robotparser.RobotFileParser.mtime",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 37,
        "namespace": "RobotFileParser",
        "body": "    def mtime(self):\n        \"\"\"Returns the time the robots.txt file was last fetched.\n\n        This is useful for long-running web spiders that need to\n        check for new robots.txt files periodically.\n\n        \"\"\"\n        return self.last_checked",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.modified": {
        "API_name": "urllib.robotparser.RobotFileParser.modified",
        "loc_name": "urllib.robotparser.RobotFileParser.modified",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 46,
        "namespace": "RobotFileParser",
        "body": "    def modified(self):\n        \"\"\"Sets the time the robots.txt file was last fetched to the\n        current time.\n\n        \"\"\"\n        import time\n        self.last_checked = time.time()",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.set_url": {
        "API_name": "urllib.robotparser.RobotFileParser.set_url",
        "loc_name": "urllib.robotparser.RobotFileParser.set_url",
        "args": "self;url",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 54,
        "namespace": "RobotFileParser",
        "body": "    def set_url(self, url):\n        \"\"\"Sets the URL referring to a robots.txt file.\"\"\"\n        self.url = url\n        self.host, self.path = urllib.parse.urlparse(url)[1:3]",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.read": {
        "API_name": "urllib.robotparser.RobotFileParser.read",
        "loc_name": "urllib.robotparser.RobotFileParser.read",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 59,
        "namespace": "RobotFileParser",
        "body": "    def read(self):\n        \"\"\"Reads the robots.txt URL and feeds it to the parser.\"\"\"\n        try:\n            f = urllib.request.urlopen(self.url)\n        except urllib.error.HTTPError as err:\n            if err.code in (401, 403):\n                self.disallow_all = True\n            elif err.code >= 400 and err.code < 500:\n                self.allow_all = True\n        else:\n            raw = f.read()\n            self.parse(raw.decode(\"utf-8\").splitlines())",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser._add_entry": {
        "API_name": "urllib.robotparser.RobotFileParser._add_entry",
        "loc_name": "urllib.robotparser.RobotFileParser._add_entry",
        "args": "self;entry",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 72,
        "namespace": "RobotFileParser",
        "body": "    def _add_entry(self, entry):\n        if \"*\" in entry.useragents:\n            # the default entry is considered last\n            if self.default_entry is None:\n                # the first default entry wins\n                self.default_entry = entry\n        else:\n            self.entries.append(entry)",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.parse": {
        "API_name": "urllib.robotparser.RobotFileParser.parse",
        "loc_name": "urllib.robotparser.RobotFileParser.parse",
        "args": "self;lines",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 81,
        "namespace": "RobotFileParser",
        "body": "    def parse(self, lines):\n        \"\"\"Parse the input lines from a robots.txt file.\n\n        We allow that a user-agent: line is not preceded by\n        one or more blank lines.\n        \"\"\"\n        # states:\n        #   0: start state\n        #   1: saw user-agent line\n        #   2: saw an allow or disallow line\n        state = 0\n        entry = Entry()\n\n        self.modified()\n        for line in lines:\n            if not line:\n                if state == 1:\n                    entry = Entry()\n                    state = 0\n                elif state == 2:\n                    self._add_entry(entry)\n                    entry = Entry()\n                    state = 0\n            # remove optional comment and strip line\n            i = line.find('#')\n            if i >= 0:\n                line = line[:i]\n            line = line.strip()\n            if not line:\n                continue\n            line = line.split(':', 1)\n            if len(line) == 2:\n                line[0] = line[0].strip().lower()\n                line[1] = urllib.parse.unquote(line[1].strip())\n                if line[0] == \"user-agent\":\n                    if state == 2:\n                        self._add_entry(entry)\n                        entry = Entry()\n                    entry.useragents.append(line[1])\n                    state = 1\n                elif line[0] == \"disallow\":\n                    if state != 0:\n                        entry.rulelines.append(RuleLine(line[1], False))\n                        state = 2\n                elif line[0] == \"allow\":\n                    if state != 0:\n                        entry.rulelines.append(RuleLine(line[1], True))\n                        state = 2\n                elif line[0] == \"crawl-delay\":\n                    if state != 0:\n                        # before trying to convert to int we need to make\n                        # sure that robots.txt has valid syntax otherwise\n                        # it will crash\n                        if line[1].strip().isdigit():\n                            entry.delay = int(line[1])\n                        state = 2\n                elif line[0] == \"request-rate\":\n                    if state != 0:\n                        numbers = line[1].split('/')\n                        # check if all values are sane\n                        if (len(numbers) == 2 and numbers[0].strip().isdigit()\n                            and numbers[1].strip().isdigit()):\n                            entry.req_rate = RequestRate(int(numbers[0]), int(numbers[1]))\n                        state = 2\n                elif line[0] == \"sitemap\":\n                    # According to http://www.sitemaps.org/protocol.html\n                    # \"This directive is independent of the user-agent line,\n                    #  so it doesn't matter where you place it in your file.\"\n                    # Therefore we do not change the state of the parser.\n                    self.sitemaps.append(line[1])\n        if state == 2:\n            self._add_entry(entry)",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.can_fetch": {
        "API_name": "urllib.robotparser.RobotFileParser.can_fetch",
        "loc_name": "urllib.robotparser.RobotFileParser.can_fetch",
        "args": "self;useragent;url",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 154,
        "namespace": "RobotFileParser",
        "body": "    def can_fetch(self, useragent, url):\n        \"\"\"using the parsed robots.txt decide if useragent can fetch url\"\"\"\n        if self.disallow_all:\n            return False\n        if self.allow_all:\n            return True\n        # Until the robots.txt file has been read or found not\n        # to exist, we must assume that no url is allowable.\n        # This prevents false positives when a user erroneously\n        # calls can_fetch() before calling read().\n        if not self.last_checked:\n            return False\n        # search for given user agent matches\n        # the first match counts\n        parsed_url = urllib.parse.urlparse(urllib.parse.unquote(url))\n        url = urllib.parse.urlunparse(('','',parsed_url.path,\n            parsed_url.params,parsed_url.query, parsed_url.fragment))\n        url = urllib.parse.quote(url)\n        if not url:\n            url = \"/\"\n        for entry in self.entries:\n            if entry.applies_to(useragent):\n                return entry.allowance(url)\n        # try the default entry last\n        if self.default_entry:\n            return self.default_entry.allowance(url)\n        # agent not found ==> access granted\n        return True",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.crawl_delay": {
        "API_name": "urllib.robotparser.RobotFileParser.crawl_delay",
        "loc_name": "urllib.robotparser.RobotFileParser.crawl_delay",
        "args": "self;useragent",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 183,
        "namespace": "RobotFileParser",
        "body": "    def crawl_delay(self, useragent):\n        if not self.mtime():\n            return None\n        for entry in self.entries:\n            if entry.applies_to(useragent):\n                return entry.delay\n        if self.default_entry:\n            return self.default_entry.delay\n        return None",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.request_rate": {
        "API_name": "urllib.robotparser.RobotFileParser.request_rate",
        "loc_name": "urllib.robotparser.RobotFileParser.request_rate",
        "args": "self;useragent",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 193,
        "namespace": "RobotFileParser",
        "body": "    def request_rate(self, useragent):\n        if not self.mtime():\n            return None\n        for entry in self.entries:\n            if entry.applies_to(useragent):\n                return entry.req_rate\n        if self.default_entry:\n            return self.default_entry.req_rate\n        return None",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.site_maps": {
        "API_name": "urllib.robotparser.RobotFileParser.site_maps",
        "loc_name": "urllib.robotparser.RobotFileParser.site_maps",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 203,
        "namespace": "RobotFileParser",
        "body": "    def site_maps(self):\n        if not self.sitemaps:\n            return None\n        return self.sitemaps",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RobotFileParser.__str__": {
        "API_name": "urllib.robotparser.RobotFileParser.__str__",
        "loc_name": "urllib.robotparser.RobotFileParser.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 208,
        "namespace": "RobotFileParser",
        "body": "    def __str__(self):\n        entries = self.entries\n        if self.default_entry is not None:\n            entries = entries + [self.default_entry]\n        return '\\n\\n'.join(map(str, entries))",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RuleLine": {
        "API_name": "urllib.robotparser.RuleLine",
        "loc_name": "urllib.robotparser.RuleLine",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.robotparser",
        "lineno": 215,
        "namespace": "RuleLine",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RuleLine.__init__": {
        "API_name": "urllib.robotparser.RuleLine.__init__",
        "loc_name": "urllib.robotparser.RuleLine.__init__",
        "args": "self;path;allowance",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 218,
        "namespace": "RuleLine",
        "body": "    def __init__(self, path, allowance):\n        if path == '' and not allowance:\n            # an empty value means allow all\n            allowance = True\n        path = urllib.parse.urlunparse(urllib.parse.urlparse(path))\n        self.path = urllib.parse.quote(path)\n        self.allowance = allowance",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RuleLine.applies_to": {
        "API_name": "urllib.robotparser.RuleLine.applies_to",
        "loc_name": "urllib.robotparser.RuleLine.applies_to",
        "args": "self;filename",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 226,
        "namespace": "RuleLine",
        "body": "    def applies_to(self, filename):\n        return self.path == \"*\" or filename.startswith(self.path)",
        "name_type": "stdlib"
    },
    "urllib.robotparser.RuleLine.__str__": {
        "API_name": "urllib.robotparser.RuleLine.__str__",
        "loc_name": "urllib.robotparser.RuleLine.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 229,
        "namespace": "RuleLine",
        "body": "    def __str__(self):\n        return (\"Allow\" if self.allowance else \"Disallow\") + \": \" + self.path",
        "name_type": "stdlib"
    },
    "urllib.robotparser.Entry": {
        "API_name": "urllib.robotparser.Entry",
        "loc_name": "urllib.robotparser.Entry",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib.robotparser",
        "lineno": 233,
        "namespace": "Entry",
        "body": "",
        "name_type": "stdlib"
    },
    "urllib.robotparser.Entry.__init__": {
        "API_name": "urllib.robotparser.Entry.__init__",
        "loc_name": "urllib.robotparser.Entry.__init__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 235,
        "namespace": "Entry",
        "body": "    def __init__(self):\n        self.useragents = []\n        self.rulelines = []\n        self.delay = None\n        self.req_rate = None",
        "name_type": "stdlib"
    },
    "urllib.robotparser.Entry.__str__": {
        "API_name": "urllib.robotparser.Entry.__str__",
        "loc_name": "urllib.robotparser.Entry.__str__",
        "args": "self",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 241,
        "namespace": "Entry",
        "body": "    def __str__(self):\n        ret = []\n        for agent in self.useragents:\n            ret.append(f\"User-agent: {agent}\")\n        if self.delay is not None:\n            ret.append(f\"Crawl-delay: {self.delay}\")\n        if self.req_rate is not None:\n            rate = self.req_rate\n            ret.append(f\"Request-rate: {rate.requests}/{rate.seconds}\")\n        ret.extend(map(str, self.rulelines))\n        return '\\n'.join(ret)",
        "name_type": "stdlib"
    },
    "urllib.robotparser.Entry.applies_to": {
        "API_name": "urllib.robotparser.Entry.applies_to",
        "loc_name": "urllib.robotparser.Entry.applies_to",
        "args": "self;useragent",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 253,
        "namespace": "Entry",
        "body": "    def applies_to(self, useragent):\n        \"\"\"check if this entry applies to the specified agent\"\"\"\n        # split the name token and make it lower case\n        useragent = useragent.split(\"/\")[0].lower()\n        for agent in self.useragents:\n            if agent == '*':\n                # we have the catch-all agent\n                return True\n            agent = agent.lower()\n            if agent in useragent:\n                return True\n        return False",
        "name_type": "stdlib"
    },
    "urllib.robotparser.Entry.allowance": {
        "API_name": "urllib.robotparser.Entry.allowance",
        "loc_name": "urllib.robotparser.Entry.allowance",
        "args": "self;filename",
        "args_default": 0,
        "filepath": "urllib.robotparser",
        "lineno": 266,
        "namespace": "Entry",
        "body": "    def allowance(self, filename):\n        \"\"\"Preconditions:\n        - our agent applies to this entry\n        - filename is URL decoded\"\"\"\n        for line in self.rulelines:\n            if line.applies_to(filename):\n                return line.allowance\n        return True",
        "name_type": "stdlib"
    },
    "urllib": {
        "API_name": "urllib",
        "loc_name": "urllib",
        "args": "*",
        "args_default": "*",
        "filepath": "urllib",
        "lineno": "*",
        "namespace": "*",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection": {
        "API_name": "multiprocessing.dummy.connection",
        "loc_name": "multiprocessing.dummy.connection",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy.connection",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [ 'Client', 'Listener', 'Pipe' ]\nfamilies = [None]",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener": {
        "API_name": "multiprocessing.dummy.connection.Listener",
        "loc_name": "multiprocessing.dummy.connection.Listener",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 18,
        "namespace": "Listener",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener.__init__": {
        "API_name": "multiprocessing.dummy.connection.Listener.__init__",
        "loc_name": "multiprocessing.dummy.connection.Listener.__init__",
        "args": "self;address;family;backlog",
        "args_default": 3,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 20,
        "namespace": "Listener",
        "body": "    def __init__(self, address=None, family=None, backlog=1):\n        self._backlog_queue = Queue(backlog)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener.accept": {
        "API_name": "multiprocessing.dummy.connection.Listener.accept",
        "loc_name": "multiprocessing.dummy.connection.Listener.accept",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 23,
        "namespace": "Listener",
        "body": "    def accept(self):\n        return Connection(*self._backlog_queue.get())",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener.close": {
        "API_name": "multiprocessing.dummy.connection.Listener.close",
        "loc_name": "multiprocessing.dummy.connection.Listener.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 26,
        "namespace": "Listener",
        "body": "    def close(self):\n        self._backlog_queue = None",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener.address": {
        "API_name": "multiprocessing.dummy.connection.Listener.address",
        "loc_name": "multiprocessing.dummy.connection.Listener.address",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 30,
        "namespace": "Listener",
        "body": "    def address(self):\n        return self._backlog_queue",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener.__enter__": {
        "API_name": "multiprocessing.dummy.connection.Listener.__enter__",
        "loc_name": "multiprocessing.dummy.connection.Listener.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 33,
        "namespace": "Listener",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Listener.__exit__": {
        "API_name": "multiprocessing.dummy.connection.Listener.__exit__",
        "loc_name": "multiprocessing.dummy.connection.Listener.__exit__",
        "args": "self;exc_type;exc_value;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 36,
        "namespace": "Listener",
        "body": "    def __exit__(self, exc_type, exc_value, exc_tb):\n        self.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Client": {
        "API_name": "multiprocessing.dummy.connection.Client",
        "loc_name": "multiprocessing.dummy.connection.Client",
        "args": "address",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 40,
        "namespace": "*",
        "body": "def Client(address):\n    _in, _out = Queue(), Queue()\n    address.put((_out, _in))\n    return Connection(_in, _out)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Pipe": {
        "API_name": "multiprocessing.dummy.connection.Pipe",
        "loc_name": "multiprocessing.dummy.connection.Pipe",
        "args": "duplex",
        "args_default": 1,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 46,
        "namespace": "*",
        "body": "def Pipe(duplex=True):\n    a, b = Queue(), Queue()\n    return Connection(a, b), Connection(b, a)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Connection": {
        "API_name": "multiprocessing.dummy.connection.Connection",
        "loc_name": "multiprocessing.dummy.connection.Connection",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 51,
        "namespace": "Connection",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Connection.__init__": {
        "API_name": "multiprocessing.dummy.connection.Connection.__init__",
        "loc_name": "multiprocessing.dummy.connection.Connection.__init__",
        "args": "self;_in;_out",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 53,
        "namespace": "Connection",
        "body": "    def __init__(self, _in, _out):\n        self._out = _out\n        self._in = _in\n        self.send = self.send_bytes = _out.put\n        self.recv = self.recv_bytes = _in.get",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Connection.poll": {
        "API_name": "multiprocessing.dummy.connection.Connection.poll",
        "loc_name": "multiprocessing.dummy.connection.Connection.poll",
        "args": "self;timeout",
        "args_default": 1,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 59,
        "namespace": "Connection",
        "body": "    def poll(self, timeout=0.0):\n        if self._in.qsize() > 0:\n            return True\n        if timeout <= 0.0:\n            return False\n        with self._in.not_empty:\n            self._in.not_empty.wait(timeout)\n        return self._in.qsize() > 0",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Connection.close": {
        "API_name": "multiprocessing.dummy.connection.Connection.close",
        "loc_name": "multiprocessing.dummy.connection.Connection.close",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 68,
        "namespace": "Connection",
        "body": "    def close(self):\n        pass",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Connection.__enter__": {
        "API_name": "multiprocessing.dummy.connection.Connection.__enter__",
        "loc_name": "multiprocessing.dummy.connection.Connection.__enter__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 71,
        "namespace": "Connection",
        "body": "    def __enter__(self):\n        return self",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.connection.Connection.__exit__": {
        "API_name": "multiprocessing.dummy.connection.Connection.__exit__",
        "loc_name": "multiprocessing.dummy.connection.Connection.__exit__",
        "args": "self;exc_type;exc_value;exc_tb",
        "args_default": 0,
        "filepath": "multiprocessing.dummy.connection",
        "lineno": 74,
        "namespace": "Connection",
        "body": "    def __exit__(self, exc_type, exc_value, exc_tb):\n        self.close()",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy": {
        "API_name": "multiprocessing.dummy",
        "loc_name": "multiprocessing.dummy",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy",
        "lineno": "*",
        "namespace": "*",
        "body": "__all__ = [\n    'Process', 'current_process', 'active_children', 'freeze_support',\n    'Lock', 'RLock', 'Semaphore', 'BoundedSemaphore', 'Condition',\n    'Event', 'Barrier', 'Queue', 'Manager', 'Pipe', 'Pool', 'JoinableQueue'\n    ]\nProcess = DummyProcess\ncurrent_process = threading.current_thread\ncurrent_process()._children = weakref.WeakKeyDictionary()\ndict = dict\nlist = list\nJoinableQueue = Queue",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.DummyProcess": {
        "API_name": "multiprocessing.dummy.DummyProcess",
        "loc_name": "multiprocessing.dummy.DummyProcess",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy",
        "lineno": 34,
        "namespace": "DummyProcess",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.DummyProcess.__init__": {
        "API_name": "multiprocessing.dummy.DummyProcess.__init__",
        "loc_name": "multiprocessing.dummy.DummyProcess.__init__",
        "args": "self;group;target;name;args;kwargs",
        "args_default": 5,
        "filepath": "multiprocessing.dummy",
        "lineno": 36,
        "namespace": "DummyProcess",
        "body": "    def __init__(self, group=None, target=None, name=None, args=(), kwargs={}):\n        threading.Thread.__init__(self, group, target, name, args, kwargs)\n        self._pid = None\n        self._children = weakref.WeakKeyDictionary()\n        self._start_called = False\n        self._parent = current_process()",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.DummyProcess.start": {
        "API_name": "multiprocessing.dummy.DummyProcess.start",
        "loc_name": "multiprocessing.dummy.DummyProcess.start",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 43,
        "namespace": "DummyProcess",
        "body": "    def start(self):\n        if self._parent is not current_process():\n            raise RuntimeError(\n                \"Parent is {0!r} but current_process is {1!r}\".format(\n                    self._parent, current_process()))\n        self._start_called = True\n        if hasattr(self._parent, '_children'):\n            self._parent._children[self] = None\n        threading.Thread.start(self)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.DummyProcess.exitcode": {
        "API_name": "multiprocessing.dummy.DummyProcess.exitcode",
        "loc_name": "multiprocessing.dummy.DummyProcess.exitcode",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 54,
        "namespace": "DummyProcess",
        "body": "    def exitcode(self):\n        if self._start_called and not self.is_alive():\n            return 0\n        else:\n            return None",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.active_children": {
        "API_name": "multiprocessing.dummy.active_children",
        "loc_name": "multiprocessing.dummy.active_children",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 68,
        "namespace": "*",
        "body": "def active_children():\n    children = current_process()._children\n    for p in list(children):\n        if not p.is_alive():\n            children.pop(p, None)\n    return list(children)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.freeze_support": {
        "API_name": "multiprocessing.dummy.freeze_support",
        "loc_name": "multiprocessing.dummy.freeze_support",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 75,
        "namespace": "*",
        "body": "def freeze_support():\n    pass",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Namespace": {
        "API_name": "multiprocessing.dummy.Namespace",
        "loc_name": "multiprocessing.dummy.Namespace",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy",
        "lineno": 82,
        "namespace": "Namespace",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Namespace.__init__": {
        "API_name": "multiprocessing.dummy.Namespace.__init__",
        "loc_name": "multiprocessing.dummy.Namespace.__init__",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 83,
        "namespace": "Namespace",
        "body": "    def __init__(self, /, **kwds):\n        self.__dict__.update(kwds)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Namespace.__repr__": {
        "API_name": "multiprocessing.dummy.Namespace.__repr__",
        "loc_name": "multiprocessing.dummy.Namespace.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 85,
        "namespace": "Namespace",
        "body": "    def __repr__(self):\n        items = list(self.__dict__.items())\n        temp = []\n        for name, value in items:\n            if not name.startswith('_'):\n                temp.append('%s=%r' % (name, value))\n        temp.sort()\n        return '%s(%s)' % (self.__class__.__name__, ', '.join(temp))",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Array": {
        "API_name": "multiprocessing.dummy.Array",
        "loc_name": "multiprocessing.dummy.Array",
        "args": "typecode;sequence;lock",
        "args_default": 1,
        "filepath": "multiprocessing.dummy",
        "lineno": 97,
        "namespace": "*",
        "body": "def Array(typecode, sequence, lock=True):\n    return array.array(typecode, sequence)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Value": {
        "API_name": "multiprocessing.dummy.Value",
        "loc_name": "multiprocessing.dummy.Value",
        "args": "*",
        "args_default": "*",
        "filepath": "multiprocessing.dummy",
        "lineno": 100,
        "namespace": "Value",
        "body": "",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Value.__init__": {
        "API_name": "multiprocessing.dummy.Value.__init__",
        "loc_name": "multiprocessing.dummy.Value.__init__",
        "args": "self;typecode;value;lock",
        "args_default": 1,
        "filepath": "multiprocessing.dummy",
        "lineno": 101,
        "namespace": "Value",
        "body": "    def __init__(self, typecode, value, lock=True):\n        self._typecode = typecode\n        self._value = value",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Value.value": {
        "API_name": "multiprocessing.dummy.Value.value",
        "loc_name": "multiprocessing.dummy.Value.value",
        "args": "self;value",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 110,
        "namespace": "Value",
        "body": "    def value(self, value):\n        self._value = value",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Value.__repr__": {
        "API_name": "multiprocessing.dummy.Value.__repr__",
        "loc_name": "multiprocessing.dummy.Value.__repr__",
        "args": "self",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 113,
        "namespace": "Value",
        "body": "    def __repr__(self):\n        return '<%s(%r, %r)>'%(type(self).__name__,self._typecode,self._value)",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Manager": {
        "API_name": "multiprocessing.dummy.Manager",
        "loc_name": "multiprocessing.dummy.Manager",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 116,
        "namespace": "*",
        "body": "def Manager():\n    return sys.modules[__name__]",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.shutdown": {
        "API_name": "multiprocessing.dummy.shutdown",
        "loc_name": "multiprocessing.dummy.shutdown",
        "args": "",
        "args_default": 0,
        "filepath": "multiprocessing.dummy",
        "lineno": 119,
        "namespace": "*",
        "body": "def shutdown():\n    pass",
        "name_type": "stdlib"
    },
    "multiprocessing.dummy.Pool": {
        "API_name": "multiprocessing.dummy.Pool",
        "loc_name": "multiprocessing.dummy.Pool",
        "args": "processes;initializer;initargs",
        "args_default": 3,
        "filepath": "multiprocessing.dummy",
        "lineno": 122,
        "namespace": "*",
        "body": "def Pool(processes=None, initializer=None, initargs=()):\n    from ..pool import ThreadPool\n    return ThreadPool(processes, initializer, initargs)",
        "name_type": "stdlib"
    }
}