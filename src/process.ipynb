{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name_list = [\"asciinema\",\"autojump\",\"fabric\",\"face_classification\",\"Sublist3r\",'bpytop','furl','rich_cli','sqlparse','sshtunnel','textrank4zh']\n",
    "project_name_list_2 = ['bpytop','furl','rich_cli','sqlparse','sshtunnel','textrank4zh']\n",
    "project_list_id=[1,3,4,7,8,11,12,13,14,15,16,22,23,28,29,32,33,35,36,38,45,48,53,56,58]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "合并data.csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 你的 CSV 文件列表\n",
    "csv_files = []\n",
    "fold = 'data_pycg' #pycg方法\n",
    "fold = 'data' #infercg方法\n",
    "for name in project_name_list:\n",
    "    csv_files.append(f\"./{fold}/{name}_data.csv\") #pycg方法\n",
    "# for name in project_list_id:\n",
    "#     csv_files.append(\"./data/project{}_data.csv\".format(name))\n",
    "\n",
    "# 读取所有 CSV 并合并（没有标题行）\n",
    "dfs = [pd.read_csv(f, header=None, encoding='utf-8') for f in csv_files]\n",
    "merged_df = pd.concat(dfs, ignore_index=True)  # 自动重新索引\n",
    "\n",
    "# 重新设置第一列为 0 开始的唯一标识符\n",
    "merged_df.iloc[:, 0] = range(len(merged_df))\n",
    "\n",
    "# 保存合并后的 CSV\n",
    "merged_df.to_csv(f\"./{fold}/merged_data.csv\", index=False, header=False, encoding='utf-8-sig')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "生成的data.csv转化为离线推理格式的jsonl文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "def messages_builder_example(system_prompt, user_prompt):\n",
    "    #messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\":user_prompt}]\n",
    "    messages = [{\"role\": \"user\", \"content\":system_prompt + user_prompt}]\n",
    "    return messages\n",
    "\n",
    "def csv2jsonl(input_file,output_file):\n",
    "    with open(input_file, \"r\", encoding='utf-8') as fin:\n",
    "        with open(output_file, 'w', encoding='utf-8') as fout:\n",
    "            csvreader = csv.reader(fin)\n",
    "            for row in csvreader:\n",
    "                #body = {\"model\": \"qwen-max\",\"temperature\":0 ,\"messages\": messages_builder_example(row[1],row[2])}\n",
    "                body = {\"model\": \"deepseek-r1\",\"messages\": messages_builder_example(row[1],row[2])}\n",
    "                # 选择Embedding文本向量模型进行调用时，url的值需填写\"/v1/embeddings\"\n",
    "                request = {\"custom_id\": row[0], \"method\": \"POST\", \"url\": \"/v1/chat/completions\", \"body\": body}\n",
    "                fout.write(json.dumps(request, separators=(',', ':'), ensure_ascii=False) + \"\\n\", )\n",
    "\n",
    "# for name in project_name_list:\n",
    "#     input_file = \"./data/{}_data.csv\".format(name)\n",
    "#     output_file = \"./data/{}_data.jsonl\".format(name)\n",
    "#     csv2jsonl(input_file,output_file)\n",
    "\n",
    "# input_file = \"./data/micro-benchmark_data.csv\".format(name)\n",
    "# output_file = \"./data/micro-benchmark_data.jsonl\".format(name)\n",
    "#csv2jsonl(input_file,output_file)\n",
    "\n",
    "fold = 'data_pycg' #pycg方法\n",
    "#fold = 'data' #infercg方法\n",
    "input_file = f\"./{fold}/merged_data.csv\"\n",
    "output_file = f\"./{fold}/merged_data.jsonl\"\n",
    "csv2jsonl(input_file,output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将离线推理的得到的答案(jsonl)转化为result.csv储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "\n",
    "def jsonl2res(input_file = \"result.jsonl\",input_file2 = \"data.csv\",output_file = \"result.csv\"):\n",
    "    columns = [\"custom_id\",\n",
    "            \"model\",\n",
    "            \"request_id\",\n",
    "            \"status_code\",\n",
    "            \"error_code\",\n",
    "            \"error_message\",\n",
    "            \"created\",\n",
    "            \"content\",\n",
    "            \"usage\",\n",
    "            \"project_name\"]\n",
    "\n",
    "    def dict_get_string(dict_obj, path):\n",
    "        obj = dict_obj\n",
    "        try:\n",
    "            for element in path:\n",
    "                obj = obj[element]\n",
    "            return obj\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    with open(input_file, \"r\", encoding='utf-8') as fin:\n",
    "        with open(output_file, 'w', encoding='utf-8', newline='') as fout:\n",
    "            with open(input_file2, 'r', encoding='utf-8', newline='') as fin2:\n",
    "                writer = csv.writer(fout)\n",
    "                writer.writerow(columns)  # 写入列标题行\n",
    "                reader2 = list(csv.reader(fin2))\n",
    "                for i,line in enumerate(fin):\n",
    "                    try:\n",
    "                        request_result = json.loads(line)\n",
    "                        row = [\n",
    "                            dict_get_string(request_result, [\"custom_id\"]),\n",
    "                            dict_get_string(request_result, [\"response\", \"body\", \"model\"]),\n",
    "                            dict_get_string(request_result, [\"response\", \"request_id\"]),\n",
    "                            dict_get_string(request_result, [\"response\", \"status_code\"]),\n",
    "                            dict_get_string(request_result, [\"error\", \"error_code\"]),\n",
    "                            dict_get_string(request_result, [\"error\", \"error_message\"]),\n",
    "                            dict_get_string(request_result, [\"response\", \"body\", \"created\"]),\n",
    "                            dict_get_string(request_result, [\"response\", \"body\", \"choices\", 0, \"message\", \"content\"]),\n",
    "                            dict_get_string(request_result, [\"response\", \"body\", \"usage\"]),\n",
    "                            reader2[i][5]\n",
    "                        ]\n",
    "                        # 如果某个字段为空，可以替换成默认值（例如空字符串）\n",
    "                        row = [value if value is not None else \"\" for value in row]\n",
    "\n",
    "                        # 如果 row 中所有值都为空，则跳过该行\n",
    "                        if any(row):\n",
    "                            writer.writerow(row)\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(\"Invalid JSON in line, skipping.\")\n",
    "\n",
    "# for name in project_name_list:\n",
    "#     try:\n",
    "#         input_file = \"./data/{}_result.jsonl\".format(name)\n",
    "#         input_file2 = \"./data/{}_data.csv\".format(name)\n",
    "#         output_file = \"./data/{}_result.csv\".format(name)\n",
    "#         jsonl2res(input_file,input_file2,output_file)\n",
    "#     except:\n",
    "#         print(name)\n",
    "#         pass\n",
    "\n",
    "#fold = \"data\"\n",
    "fold = \"data_pycg\"\n",
    "input_file = f\"./{fold}/merged_result.jsonl\"\n",
    "input_file2 = f\"./{fold}/merged_data.csv\"\n",
    "output_file = f\"./{fold}/merged_result.csv\"\n",
    "jsonl2res(input_file,input_file2,output_file)\n",
    "\n",
    "# input_file = \"./data/micro-benchmark_result.jsonl\".format(name)\n",
    "# input_file2 = \"./data/micro-benchmark_data.csv\".format(name)\n",
    "# output_file = \"./data/micro-benchmark_result.csv\".format(name)\n",
    "# jsonl2res(input_file,input_file2,output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将储存的csv文件，生成调用图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total edges processed: 7342\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "\n",
    "all_edges = 0\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def extract_percentage(text):\n",
    "    matches = re.findall(r'(?<![-\\d])(?:100|[1-9]?\\d(?:\\.\\d)?)%(?!\\d)', text)\n",
    "    percentages = [float(match.rstrip('%')) for match in matches]  # 去掉 '%' 并转换为浮点数\n",
    "    return min(percentages) if percentages else None  # 返回最小值，如果为空则返回 None\n",
    "\n",
    "def solve(name,input_file1=\"data.csv\",input_file2=\"result.csv\") :\n",
    "\n",
    "    project_data = {}\n",
    "    project_json_path = {}\n",
    "    \n",
    "    project_json_path[name] = \"../PyCG_data/{}.json\".format(name)\n",
    "    project_data[name] = load_json(project_json_path[name])\n",
    "    project_data[name] = {}\n",
    "    if name in project_name_list_2:\n",
    "        project_json_path[name] = \"../file2class_data/{}.json\".format(name)\n",
    "        project_data[name] = load_json(project_json_path[name])\n",
    "\n",
    "    caller_candidates = []\n",
    "    with open(input_file1, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            caller = row[3]\n",
    "            callee = row[4]\n",
    "            caller_candidates.append({\"caller\":caller,\"callee\":callee})\n",
    "    global all_edges\n",
    "    all_edges += len(caller_candidates)\n",
    "    result = [0] * len(caller_candidates)\n",
    "    project_name_idx = []\n",
    "    with open(input_file2, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # 跳过标题行\n",
    "        next(reader)\n",
    "        for i,row in enumerate(reader):\n",
    "            custom_id = int(row[0])\n",
    "            content = row[7]\n",
    "            project_name_idx.append(row[9])\n",
    "            precent = extract_percentage(content)\n",
    "            if precent >= 75:\n",
    "                result[i] += 1\n",
    "            \n",
    "\n",
    "    for i, call in enumerate(caller_candidates):\n",
    "\n",
    "        caller, candidate = call[\"caller\"], call[\"callee\"]\n",
    "        yes_total = result[i]\n",
    "        name = project_name_idx[i]\n",
    "        if yes_total:\n",
    "            if caller in project_data[name]:\n",
    "                project_data[name][caller].append(candidate)  # 将 candidate 添加到原列表\n",
    "                # 去重\n",
    "                project_data[name][caller] = list(set(project_data[name][caller]))\n",
    "            else:\n",
    "                project_data[name][caller] = []\n",
    "                project_data[name][caller].append(candidate)  # 如果 caller 不存在，直接插入\n",
    "\n",
    "\n",
    "    filename_with_extension = project_json_path[name].split('/')[-1]\n",
    "    with open(\"../Ae_data/{}\".format(filename_with_extension), \"w\", encoding=\"utf-8\") as file:\n",
    "        json.dump(project_data[name], file, indent=4, ensure_ascii=False)\n",
    "\n",
    "for name in project_name_list:\n",
    "    #try:\n",
    "        input_file1 = \"./data/{}_data.csv\".format(name)\n",
    "        input_file2 = \"./data/{}_result.csv\".format(name)\n",
    "        solve(name,input_file1,input_file2) \n",
    "\n",
    "\n",
    "print(f\"Total edges processed: {all_edges}\")\n",
    "    #except:\n",
    "    #    print(name)\n",
    "    #    pass \n",
    "# input_file1 = \"./data/micro-benchmark_data.csv\"\n",
    "# input_file2 = \"./data/micro-benchmark_result.csv\"\n",
    "# solve('micro-benchmark',input_file1,input_file2) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "merged生成调用图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prune rate:0/3644=0.00%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "\n",
    "def load_json(filepath):\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def extract_percentage(text):\n",
    "    matches = re.findall(r'(?<![-\\d])(?:100|[1-9]?\\d(?:\\.\\d)?)%(?!\\d)', text)\n",
    "    percentages = [float(match.rstrip('%')) for match in matches]  # 去掉 '%' 并转换为浮点数\n",
    "    return min(percentages) if percentages else None  # 返回最小值，如果为空则返回 None\n",
    "\n",
    "def solve(input_file1=\"data.csv\",input_file2=\"result.csv\",op=\"dynamic\") :\n",
    "\n",
    "    project_data = {}\n",
    "    project_json_path = {}\n",
    "    \n",
    "    if op!=\"dynamic\":\n",
    "        for name in project_name_list:\n",
    "            project_json_path[name] = \"../PyCG_data/{}.json\".format(name)\n",
    "            project_data[name] = load_json(project_json_path[name])\n",
    "            project_data[name] = {}\n",
    "            if name in project_name_list_2:\n",
    "                project_json_path[name] = \"../file2class_data/{}.json\".format(name)\n",
    "                project_data[name] = load_json(project_json_path[name])\n",
    "    else :\n",
    "        for id in project_list_id:\n",
    "            name = \"project{}\".format(id)\n",
    "            project_json_path[name] = \"../PyCG_data/{}.json\".format(name)\n",
    "            project_data[name] = load_json(project_json_path[name])\n",
    "            project_data[name] = {}\n",
    "            if name in project_name_list_2:\n",
    "                project_json_path[name] = \"../file2class_data/{}.json\".format(name)\n",
    "                project_data[name] = load_json(project_json_path[name])\n",
    "\n",
    "    caller_candidates = []\n",
    "    project_name_idx = []\n",
    "    with open(input_file1, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        for row in reader:\n",
    "            caller = row[3]\n",
    "            callee = row[4]\n",
    "            caller_candidates.append({\"caller\":caller,\"callee\":callee})\n",
    "            project_name_idx.append(row[5])\n",
    "\n",
    "    result = [0] * len(caller_candidates)\n",
    "    \n",
    "    #print(len(caller_candidates))\n",
    "    all_edges = 0\n",
    "    jian = 0\n",
    "    with open(input_file2, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        # 跳过标题行\n",
    "        next(reader)\n",
    "        for i,row in enumerate(reader):\n",
    "            custom_id = int(row[0])\n",
    "            #print(custom_id)\n",
    "            content = row[7]\n",
    "            #project_name_idx.append(row[9])\n",
    "            #project_name_idx[custom_id] = row[9]\n",
    "            precent = extract_percentage(content)\n",
    "            all_edges += 1\n",
    "            if precent == None or precent >= 75:\n",
    "                result[custom_id] += 1\n",
    "            # else:\n",
    "            #     jian += 1\n",
    "            \"\"\"随机剪枝\"\"\"\n",
    "            # import random\n",
    "            # if random.random()>0.44:\n",
    "            #     result[custom_id] += 1\n",
    "\n",
    "    for i, call in enumerate(caller_candidates):\n",
    "\n",
    "        #try:\n",
    "            caller, candidate = call[\"caller\"], call[\"callee\"]\n",
    "            yes_total = result[i]\n",
    "            name = project_name_idx[i]\n",
    "            if yes_total:\n",
    "                if caller in project_data[name]:\n",
    "                    project_data[name][caller].append(candidate)  # 将 candidate 添加到原列表\n",
    "                    # 去重\n",
    "                    project_data[name][caller] = list(set(project_data[name][caller]))\n",
    "                else:\n",
    "                    project_data[name][caller] = []\n",
    "                    project_data[name][caller].append(candidate)  # 如果 caller 不存在，直接插入\n",
    "        # except :\n",
    "        #     pass\n",
    "    print(f\"prune rate:{jian}/{all_edges}={jian/all_edges:.2%}\")\n",
    "    if op!=\"dynamic\":\n",
    "        for name in project_name_list:\n",
    "            filename_with_extension = project_json_path[name].split('/')[-1]\n",
    "            with open(\"../Ae_data/{}\".format(filename_with_extension), \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(project_data[name], file, indent=4, ensure_ascii=False)\n",
    "    else :\n",
    "        for id in project_list_id:\n",
    "            name = \"project{}\".format(id)\n",
    "            filename_with_extension = project_json_path[name].split('/')[-1]\n",
    "            with open(\"../Ae_data/{}\".format(filename_with_extension), \"w\", encoding=\"utf-8\") as file:\n",
    "                json.dump(project_data[name], file, indent=4, ensure_ascii=False)\n",
    "\n",
    "\n",
    "fold = \"data\"\n",
    "fold = \"data_pycg\"\n",
    "input_file1 = f\"./{fold}/merged_data.csv\"\n",
    "input_file2 = f\"./{fold}/merged_result.csv\"\n",
    "op=\"dynamic\"\n",
    "op=\"marco\"\n",
    "solve(input_file1,input_file2,op) \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
